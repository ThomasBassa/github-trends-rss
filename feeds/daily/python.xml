<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Python, Today</title><link>https://github.com/trending/python?since=daily</link><description>The top repositories on GitHub for python, measured daily</description><pubDate>Wed, 20 Nov 2019 01:08:48 GMT</pubDate><lastBuildDate>Wed, 20 Nov 2019 01:08:48 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>dragen1860/Deep-Learning-with-TensorFlow-book #1 in Python, Today</title><link>https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book</link><description>&lt;p&gt;&lt;i&gt;æ·±åº¦å­¦ä¹ å¼€æºä¹¦ï¼ŒåŸºäºTensorFlow 2.0å®æˆ˜ã€‚Open source Deep Learning book, based on TensorFlow 2.0 framework.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-20æ·±åº¦å­¦ä¹ å¼€æºä¹¦" class="anchor" aria-hidden="true" href="#tensorflow-20æ·±åº¦å­¦ä¹ å¼€æºä¹¦"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 2.0æ·±åº¦å­¦ä¹ å¼€æºä¹¦&lt;/h1&gt;
&lt;p&gt;åŸºäºTensorFlow 2.0æ­£å¼ç‰ˆï¼ï¼ï¼&lt;/p&gt;
&lt;p&gt;åŒ…å«ç”µå­ä¹¦ï¼Œé…å¥—æºä»£ç ç­‰ï¼Œæ—¶é—´ä»“ä¿ƒï¼Œæºä»£ç è¿˜æ²¡æœ‰æ•´ç†å®Œå…¨~~&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æœ¬åº“åœ¨Githubè¶‹åŠ¿æ—¥æ¦œå•å…¨çƒæ’åç¬¬1ï¼&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æœ¬åº“è¢«â€œæœºå™¨ä¹‹å¿ƒâ€ï¼Œâ€œé‡å­ä½â€ç­‰åª’ä½“æŠ¥å¯¼ï¼&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;ä¸»é¡µä¸Šæ–¹æœ‰ä¸ªâ€œClone or Downloadâ€ç»¿è‰²æŒ‰é’®ï¼Œä¸‹è½½æ•´ä¸ªä»“åº“å³å¯ã€‚ä¹‹æ‰€ä»¥æ˜¾ç¤ºåœ¨çº¿æ‰“ä¸å¼€æ˜¯å› ä¸ºGithubåœ¨å›½å¤–ï¼Œè¿æ¥ä¸ç¨³å®šå°±ä¼šæç¤ºæ‰“ä¸å¼€ã€‚&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/1.jpg"&gt;&lt;img src="assets/1.jpg" align="center" width="600" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/2.png"&gt;&lt;img src="assets/2.png" align="center" width="600" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æäº¤é”™è¯¯æˆ–è€…ä¿®æ”¹ç­‰åé¦ˆæ„è§ï¼Œè¯·åœ¨Github Issuesé¡µé¢æäº¤ï¼š&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book/issues"&gt;https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book/issues&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TensorFlow 2.0 å®æˆ˜æ¡ˆä¾‹ï¼š
&lt;a href="https://github.com/dragen1860/TensorFlow-2.x-Tutorials"&gt;https://github.com/dragen1860/TensorFlow-2.x-Tutorials&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;è”ç³»é‚®ç®±(ä¸€èˆ¬é—®é¢˜å»ºè®®Github issuesäº¤æµ)ï¼šliangqu.long AT gmail.com&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ä½¿ç”¨æœ¬ä¹¦æœ¬çš„ä»»ä½•å†…å®¹æ—¶(ä»…é™ä¸ªäººçš„éå•†ä¸šç”¨é€”)ï¼Œè¯·æ³¨æ˜ä½œè€…å’ŒGithubé“¾æ¥&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-ä»‹ç»çŸ­è§†é¢‘" class="anchor" aria-hidden="true" href="#ä»‹ç»çŸ­è§†é¢‘"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä»‹ç»çŸ­è§†é¢‘&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/av75331861?from=search&amp;amp;seid=15021582016949033280" rel="nofollow"&gt;https://www.bilibili.com/video/av75331861?from=search&amp;amp;seid=15021582016949033280&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-ç›®å½•" class="anchor" aria-hidden="true" href="#ç›®å½•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ç›®å½•&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/0.4.ç›®å½•-åŒæ’-1.jpg"&gt;&lt;img src="assets/0.4.ç›®å½•-åŒæ’-1.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/0.4.ç›®å½•-åŒæ’-2.jpg"&gt;&lt;img src="assets/0.4.ç›®å½•-åŒæ’-2.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/0.4.ç›®å½•-åŒæ’-3.jpg"&gt;&lt;img src="assets/0.4.ç›®å½•-åŒæ’-3.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-åˆå­¦è€…äº¤æµqqç¾¤" class="anchor" aria-hidden="true" href="#åˆå­¦è€…äº¤æµqqç¾¤"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;åˆå­¦è€…äº¤æµQQç¾¤&lt;/h1&gt;
&lt;p&gt;äººå·¥æ™ºèƒ½101å­¦é™¢ï¼š295208768&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-é…å¥—è§†é¢‘è¯¾ç¨‹" class="anchor" aria-hidden="true" href="#é…å¥—è§†é¢‘è¯¾ç¨‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é…å¥—è§†é¢‘è¯¾ç¨‹&lt;/h1&gt;
&lt;p&gt;æ”¶è´¹ï¼Œé€‚åˆé›¶åŸºç¡€ã€å¸Œæœ›å¿«é€Ÿå…¥é—¨AIçš„æœ‹å‹ï¼Œæä¾›ç­”ç–‘ç­‰å…¨æ–¹ä½æœåŠ¡ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ·±åº¦å­¦ä¹ ä¸TensorFlowå…¥é—¨å®æˆ˜
&lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=9e74eb6f891d47cfaa6f00b5cb5f617c" rel="nofollow"&gt;https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=9e74eb6f891d47cfaa6f00b5cb5f617c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;æ·±åº¦å­¦ä¹ ä¸PyTorchå…¥é—¨å®æˆ˜
&lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=8d1b10e04bd34d69855bb71da65b0549" rel="nofollow"&gt;https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=8d1b10e04bd34d69855bb71da65b0549&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dragen1860</author><guid isPermaLink="false">https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book</guid><pubDate>Wed, 20 Nov 2019 00:01:00 GMT</pubDate></item><item><title>zhaoolee/ChromeAppHeroes #2 in Python, Today</title><link>https://github.com/zhaoolee/ChromeAppHeroes</link><description>&lt;p&gt;&lt;i&gt;ğŸŒˆè°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œ, ä¸ºä¼˜ç§€çš„Chromeæ’ä»¶å†™ä¸€æœ¬ä¸­æ–‡è¯´æ˜ä¹¦, è®©Chromeæ’ä»¶è‹±é›„ä»¬é€ ç¦äººç±»~  ChromePluginHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/readme-en.html" rel="nofollow"&gt;English&lt;/a&gt; | &lt;a href="https://zhaoolee.gitbooks.io/chrome/content/" rel="nofollow"&gt;ä¸­æ–‡ç®€ä½“&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/996icu/996.ICU/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/41215df7ff78cefe41536bf897fe1c7e55b10bd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d416e74692532303939362d626c75652e737667" alt="LICENSE" data-canonical-src="https://img.shields.io/badge/license-Anti%20996-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://996.icu" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/13ac320a9a774e316fe72ffb1eaacf09b01b59a3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c696e6b2d3939362e6963752d7265642e737667" alt="996.icu" data-canonical-src="https://img.shields.io/badge/link-996.icu-red.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-è°·ç²’-chromeæ’ä»¶è‹±é›„æ¦œ" class="anchor" aria-hidden="true" href="#è°·ç²’-chromeæ’ä»¶è‹±é›„æ¦œ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œ&lt;/h1&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="rainbow" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f308.png"&gt;ğŸŒˆ&lt;/g-emoji&gt;è°·ç²’-Chromeæ’ä»¶è‹±é›„æ¦œ, ä¸ºä¼˜ç§€çš„Chromeæ’ä»¶å†™ä¸€æœ¬ä¸­æ–‡è¯´æ˜ä¹¦, è®©Chromeæ’ä»¶è‹±é›„ä»¬é€ ç¦äººç±»~
ChromeAppHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/5ecd2856f287477c89c20efb7de11a9b.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/5ecd2856f287477c89c20efb7de11a9b.png" alt="è°·ç²’VIè®¾è®¡.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ„Ÿè°¢&lt;a href="https://github.com/LuoJiangYong"&gt;è€ç½—å·´æ‰å˜¿&lt;/a&gt;ä¸ºæœ¬é¡¹ç›®è®¾è®¡çš„æ–°çš„Logo | &lt;a href="https://zhaoolee.gitbooks.io/chrome/content/gu-li-qu-yi.html" rel="nofollow"&gt;è°·ç²’æ–‡åŒ–(è€ç½—å·´æ‰å˜¿è¯­å½•)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ç›¸å…³é¡¹ç›®æ¨å¹¿-ç”¨chromeå­¦ç¼–ç¨‹" class="anchor" aria-hidden="true" href="#ç›¸å…³é¡¹ç›®æ¨å¹¿-ç”¨chromeå­¦ç¼–ç¨‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ç›¸å…³é¡¹ç›®æ¨å¹¿: &lt;a href="https://github.com/zhaoolee/ProgrammingWithChrome"&gt;ç”¨Chromeå­¦ç¼–ç¨‹&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;ã€Šç”¨Chromeå­¦ç¼–ç¨‹(å¦‚ä½•ç”¨Chromeä¼˜é›…è£…B)ã€‹, ç”¨Gifå›¾å±•ç¤ºChromeçš„éªšæ“ä½œ, å……åˆ†æŒ–æ˜Chromeçš„ç¼–ç¨‹æ½œåŠ›! &lt;a href="https://github.com/zhaoolee/ProgrammingWithChrome"&gt;https://github.com/zhaoolee/ProgrammingWithChrome&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://github.com/996icu/996.ICU/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/41215df7ff78cefe41536bf897fe1c7e55b10bd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d416e74692532303939362d626c75652e737667" alt="LICENSE" data-canonical-src="https://img.shields.io/badge/license-Anti%20996-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://996.icu" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/13ac320a9a774e316fe72ffb1eaacf09b01b59a3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c696e6b2d3939362e6963752d7265642e737667" alt="996.icu" data-canonical-src="https://img.shields.io/badge/link-996.icu-red.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ç›®å½•ç‚¹å‡»ä»¥ä¸‹æ ‡é¢˜-å¯ä»¥è¿›å…¥æ–‡ç« é¡µ" class="anchor" aria-hidden="true" href="#ç›®å½•ç‚¹å‡»ä»¥ä¸‹æ ‡é¢˜-å¯ä»¥è¿›å…¥æ–‡ç« é¡µ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ç›®å½•(ç‚¹å‡»ä»¥ä¸‹æ ‡é¢˜, å¯ä»¥è¿›å…¥æ–‡ç« é¡µ~)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/060_tabagotchi.html" rel="nofollow"&gt;060ã€ŠTabagotchiã€‹ä¸ºå‡ç¼“å…¨çƒå˜æš–åšå‡ºè´¡çŒ®&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/059_page_speed_insight_and_check_list.html" rel="nofollow"&gt;059ã€ŠPageSpeed Insight and CheckListã€‹ä¸ºç½‘é¡µä¼˜åŒ–æä¾›å»ºè®®å’Œé‡åŒ–æŒ‡æ ‡&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/058_ip_address.html" rel="nofollow"&gt;058ã€ŠIP-Addressã€‹å¿«é€ŸæŸ¥çœ‹å½“å‰è®¾å¤‡IP&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/057_webp_save_as_png.html" rel="nofollow"&gt;057ã€Šå›¾ç‰‡å¦å­˜ä¸ºJPG/PNG/WebPã€‹è®©WebPå›¾ç‰‡ä¸‹è½½ä¸ºPNGæ ¼å¼&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/056_search.html" rel="nofollow"&gt;056ã€ŠSearchã€‹ä¸ºChromeè®¾ç½®æœç´¢å¼•æ“å…³é”®è¯&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/055_keylines.html" rel="nofollow"&gt;055ã€ŠKeylinesã€‹ä¸ºç½‘é¡µå…ƒç´ æ·»åŠ éšæœºæè¾¹é¢œè‰² &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/054_er_xiang_yi_tu_sou_tu.html" rel="nofollow"&gt;054ã€ŠäºŒç®± ä»¥å›¾æœå›¾ã€‹è®©ä½ åœ¨æœå›¾æ–¹é¢éšå¿ƒæ‰€æ¬²ï¼ˆä¸ºæ‰€æ¬²ä¸ºï¼‰&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/053_shu_biao_dian_ji_te_xiao.html" rel="nofollow"&gt;053ã€Šé¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ (à¹‘â€¢Ì âˆ€ â€¢Ì€à¹‘)ã€‹ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/052_site_palette.html" rel="nofollow"&gt;052ã€ŠSite Paletteã€‹è‡ªåŠ¨æå–ç½‘ç«™é…è‰²&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/051_custom_cursor_for_chrome.html" rel="nofollow"&gt;051ã€ŠCustom Cursor for Chromeâ„¢ã€‹ä¸ºChromeæ¢ä¸Šå¯çˆ±åˆéŸ³å…‰æ ‡&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/050_google_results_previewer.html" rel="nofollow"&gt;050ã€ŠGoogle Results Previewerã€‹æ— ç‚¹å‡»æŸ¥çœ‹è°·æ­Œæœç´¢ç»“æœ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/049_web_server_for_chrome.html" rel="nofollow"&gt;049ã€ŠWeb Server for Chromeã€‹æ­å»ºæœ¬åœ°WebæœåŠ¡å™¨, å®ç°å±€åŸŸç½‘å…±äº«æ–‡ä»¶å¤¹&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/048_words_discoverer.html" rel="nofollow"&gt;048ã€ŠWords Discovererã€‹é«˜äº®æ ‡æ³¨å•è¯,æå‡ä½ çš„è¯æ±‡é‡&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/047_go_to_tab.html" rel="nofollow"&gt;047ã€ŠGo to Tabã€‹å¿«é€Ÿè·³è½¬åˆ°æ‰“å¼€çš„ç½‘é¡µ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/046_whatfont.html" rel="nofollow"&gt;046ã€ŠWhatFontã€‹å­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/045_restlet_client.html" rel="nofollow"&gt;045ã€ŠRestlet Clientã€‹ä¼˜ç§€çš„Apiæµ‹è¯•å·¥å…·&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/044_gu_ge_fang_wen_zhu_shou.html" rel="nofollow"&gt;044ã€Šè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹è®¿é—®Chromeå•†åº— Gmail è°·æ­Œæœç´¢&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/043_dream_afar_new_tab.html" rel="nofollow"&gt;043ã€ŠDream Afar New Tabã€‹æ¢ç´¢ä¸–ç•Œçš„æ–°æ–¹å¼&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/042_edge.html" rel="nofollow"&gt;042 åœ¨Edgeä¸­å®‰è£…Chromeæ‰©å±•ç¨‹åº&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/041_copy_all_urls.html" rel="nofollow"&gt;041ã€ŠCopy All Urlsã€‹ä¼˜é›…åœ°ä¿å­˜-å¼€å¯å¤šä¸ªæ ‡ç­¾é¡µ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/040_gitzip_for_github.html" rel="nofollow"&gt;040ã€ŠGitZip for githubã€‹ä»Githubæ‰¹é‡ä¸‹è½½è¡¨æƒ…åŒ…&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/039_simplify_gmail.html" rel="nofollow"&gt;039ã€ŠSimplify Gmailã€‹è®©ç½‘é¡µç‰ˆGmailæ›´æ¸…çˆ½&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/038_alexa_traffic_rank.html" rel="nofollow"&gt;038ã€ŠAlexa Traffic Rankã€‹ä¸€é”®æŸ¥çœ‹ç½‘ç«™å…¨çƒæ’å&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/037_saladict.html" rel="nofollow"&gt;037ã€ŠSaladictã€‹è°·æ­Œ!æœ‰é“!æˆ‘å…¨éƒ½è¦! èšåˆè¯å…¸, å¹¶è¡Œç¿»è¯‘&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/036_screen_shader.html" rel="nofollow"&gt;036ã€ŠScreen Shaderã€‹æŠŠç½‘é¡µè°ƒæˆæš–è‰²ï¼Œä½ çš„çœ¼ç›ä¼šæ„Ÿè°¢ä½ &lt;g-emoji class="g-emoji" alias="pray" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png"&gt;ğŸ™&lt;/g-emoji&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/035_print_friendly_and_pdf.html" rel="nofollow"&gt;035ã€ŠPrint Friendly &amp;amp; PDFã€‹è®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/034_astro_bot.html" rel="nofollow"&gt;034ã€ŠAstro Botã€‹ç”¨æ–°æ ‡ç­¾é¡µåˆ·ç¼–ç¨‹é¢˜&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/033_yi_ye.html" rel="nofollow"&gt;033ã€Šä¸€å¶ã€‹åœ¨ä»»æ„ç½‘é¡µå¼€å¯å®æ—¶å¼¹å¹• èŠå¤©çª—å£ ç•™è¨€æ¿&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/032_smallpdf.html" rel="nofollow"&gt;032ã€ŠSmallpdfã€‹ç®€å•å¥½ç”¨çš„çº¿ä¸ŠPDFå·¥å…·&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/031_onetab.html" rel="nofollow"&gt;031ã€ŠOneTabã€‹æŠŠå¤šä¸ªTabè½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/030_jue_jin.html" rel="nofollow"&gt;030ã€Šæ˜é‡‘ã€‹ç›¸ä¿¡ä¼˜è´¨æŠ€æœ¯å†…å®¹çš„åŠ›é‡&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/029_simread.html" rel="nofollow"&gt;029 ã€ŠSimpReadã€‹ä¸ºä»»æ„ç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/028_adblock.html" rel="nofollow"&gt;028ã€ŠAdBlockã€‹Adblockè‡ªå®šä¹‰å±è”½ç®€ä¹¦å¹¿å‘Š&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/027_text.html" rel="nofollow"&gt;027ã€ŠTextã€‹æ¥è‡ªChromeå®éªŒå®¤çš„è·¨å¹³å°è®°äº‹æœ¬&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/026_quickey_launcher.html" rel="nofollow"&gt;026ã€ŠQuickey Launcherã€‹æ‰“å¼€ç½‘ç«™åªéœ€ä¸€é”®&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/025_console.html" rel="nofollow"&gt;025ã€ŠConsoleã€‹Chromeè‡ªå¸¦å¥½ç”¨çš„è®¡ç®—å™¨&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/024_dark_reader.html" rel="nofollow"&gt;024ã€ŠDark Readerã€‹ä¸ºä»»æ„ç½‘ç«™å¯ç”¨å¤œé—´æ¨¡å¼&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/023_fireshot.html" rel="nofollow"&gt;023ã€ŠFireShotã€‹ä¸€é”®æ»šåŠ¨æˆªå±æ•´ä¸ªç½‘é¡µ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/022kuo_zhan_guan_li_qi.html" rel="nofollow"&gt;022ã€Šæ‰©å±•ç®¡ç†å™¨ã€‹ç®¡ç†ä½ çš„Chromeæ‰©å±•&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/021_bi_li_bi_li_zhu_shou.html" rel="nofollow"&gt;021ã€Šå“”å“©å“”å“©åŠ©æ‰‹ã€‹åŠ©ä½ å¿«é€Ÿæˆä¸ºBç«™è€å¸æœº&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/020_boxel_rebound.html" rel="nofollow"&gt;020ã€ŠBoxel Reboundã€‹â€œå—¨åˆ°ä¸­æ¯’â€çš„å¼¹è·³å°æ–¹å—(é™„è‡ªåˆ¶èµ›é“åˆ†äº«æ–¹æ³•)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/019_mega.html" rel="nofollow"&gt;019ã€ŠMEGAã€‹ç½‘ç›˜å¯ä»¥è‰¯å¿ƒåˆ°ä»€ä¹ˆç¨‹åº¦? è¯•è¯•MEGAå§!&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/018_enhanced_github.html" rel="nofollow"&gt;018ã€ŠEnhanced Githubã€‹ä»â€œå†°æŸœâ€åˆ°â€œå†°æ£å„¿â€,ä¸‹è½½Githubå•ä¸ªæ–‡ä»¶&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/017_xin_lang_wei_bo_tu_chuang.html" rel="nofollow"&gt;017ã€Šæ–°æµªå¾®åšå›¾åºŠã€‹æœ¬åœ°Markdownç¼–å†™æ›´æµç•…, æ–°æµªå¾®åšå›¾åºŠæ¥å¸®å¿™&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/016_jie_chu_b_zhan_qu_yu_xian_zhi.html" rel="nofollow"&gt;016ã€Šè§£é™¤Bç«™åŒºåŸŸé™åˆ¶ã€‹æŸ¥çœ‹è¿›å‡»çš„å·¨äººç¬¬ä¸‰å­£&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/015_xpath_helper.html" rel="nofollow"&gt;015 ã€ŠXPath Helperã€‹å®ŒæˆBingæ¯æ—¥å£çº¸çš„å°çˆ¬è™«&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/014_chao_ji_ma_li_ao_you_xi.html" rel="nofollow"&gt;014ã€Šè¶…çº§é©¬é‡Œå¥¥æ¸¸æˆã€‹Chromeå˜èº«å°éœ¸ç‹&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/013_quick_qr.html" rel="nofollow"&gt;013ã€ŠQuick QRã€‹ç”¨äºŒç»´ç å®ç°äº‘ç²˜è´´&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/012_ourstickys.html" rel="nofollow"&gt;012ã€ŠOurStickysã€‹Chromeç‰¹è‰²ç½‘é¡µä¾¿ç­¾çº¸&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/011_whatruns.html" rel="nofollow"&gt;011 ã€Šwhatrunsã€‹ä¸€é”®åˆ†æç½‘ç«™æŠ€æœ¯æ ˆ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/010_speedtest.html" rel="nofollow"&gt;010ã€Šspeedtestã€‹ç½‘ç»œæµ‹é€Ÿæ’ä»¶speedtest&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/009_vimium.html" rel="nofollow"&gt;009ã€Švimiumã€‹Chromeä¸vimåŒç¥å™¨èåˆ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/008_chrome_cleaner_pro.html" rel="nofollow"&gt;008ã€ŠChrome Cleaner Proã€‹ä¸ºChromeåŠ é€Ÿ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/007_loom.html" rel="nofollow"&gt;007ã€Šloomã€‹ Chromeç¿»å½•ç½‘é¡µè§†é¢‘ç¥å™¨&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/006_similarsites.html" rel="nofollow"&gt;006ã€ŠSimilarSitesã€‹ ä¸€é”®æŸ¥æ‰¾å§Šå¦¹ç½‘ç«™ SimilarSites&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/005_video_speed_controller.html" rel="nofollow"&gt;005ã€ŠVideo Speed Controllerã€‹ åˆ·è¯¾ï¼ˆåˆ·å‰§ï¼‰ç¥å™¨ï¼ç»™ç½‘é¡µè§†é¢‘åŠ ä¸ªé€Ÿ(æœ€å¿«å¯è¾¾16å€!)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/004_tampermonkey.html" rel="nofollow"&gt;004ã€ŠTampermonkeyã€‹ æ²¹çŒ´å­! ç»™æµè§ˆå™¨å¼€ä¸ªæŒ‚&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/003_secure_shell_app.html" rel="nofollow"&gt;003ã€ŠSecure Shell Appã€‹ Chromeä¸­å¼€å¯sshä¸€ç§ä»€ä¹ˆä½“éªŒ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/002_chrono.html" rel="nofollow"&gt;002ã€Šchronoã€‹ è®©Chromeä¸‹è½½èµ„æºæ›´å®¹æ˜“&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/001_markdown_here.html" rel="nofollow"&gt;001ã€Šmarkdown-hereã€‹ Markdownä¸€é”®è½¬æ¢åˆ°"å¯Œæ–‡æœ¬æ ¼å¼"&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-å¼€æºæ’ä»¶æ¨å¹¿ä½œè€…è‡ªè" class="anchor" aria-hidden="true" href="#å¼€æºæ’ä»¶æ¨å¹¿ä½œè€…è‡ªè"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¼€æºæ’ä»¶æ¨å¹¿(ä½œè€…è‡ªè)&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;åç§°&lt;/th&gt;
&lt;th&gt;ä½œè€…ä¸»é¡µ&lt;/th&gt;
&lt;th&gt;å¼€æºä¿¡æ¯&lt;/th&gt;
&lt;th&gt;ç®€ä»‹&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/the-fucking-github/agajobpbaphiohkbkjigcalebbfmofdo" rel="nofollow"&gt;The Fucking Github&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lvxianchao"&gt;lvxianchao&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lvxianchao/the-fucking-github"&gt;Githubä»“åº“åœ°å€&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;å¾ˆæ–¹ä¾¿åœ°æŸ¥çœ‹ã€æ•´ç†ã€æœç´¢ä½ å·²ç» Star è¿‡çš„é¡¹ç›®å’Œæœç´¢ Github ä¸Šçš„é¡¹ç›®ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/hitup/eiokaohkigpbonodjcbjpecbnccijkjb" rel="nofollow"&gt;HitUP&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/wonderbeyond"&gt;wonderbeyond&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/wonderbeyond/HitUP"&gt;Githubä»“åº“åœ°å€&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;åˆ©ç”¨ New Tab â€œç©ºç™½é¡µâ€ åŠ©æ‚¨ä¿æŒå¯¹æµè¡ŒæŠ€æœ¯è¶‹åŠ¿çš„è·Ÿè¿›ï¼Œé™„å¸¦å…¶å®ƒç¦åˆ©ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/gitako-github-file-tree/giljefjcheohhamkjphiebfjnlphnokk" rel="nofollow"&gt;Gitako - Github file tree&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/EnixCoda"&gt;EnixCoda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/EnixCoda/Gitako"&gt;Githubä»“åº“åœ°å€&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;åŠŸèƒ½ä¸Šç±»ä¼¼äºå¤§åé¼é¼çš„ Octotree ï¼Œä½†æ˜¯ç”¨äº†æ›´ç°ä»£åŒ–çš„å‰ç«¯å·¥å…·ï¼Œæ€§èƒ½å¥½å¾ˆå¤šã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/githuber/janmcneaglgklfljjcpihkkomeghljnf" rel="nofollow"&gt;GITHUBER&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/zhuowenli"&gt;zhuowenli&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/zhuowenli/githuber"&gt;Githubä»“åº“åœ°å€&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;è¿™æ˜¯ä¸€ä¸ªå¸®åŠ© GitHub å¼€å‘è€…æ¯æ—¥å‘ç°ä¼˜è´¨å†…å®¹çš„ Chrome ä¸»é¡µæ‹“å±•ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/60c92f0de3d44bb7a612d08e2e1f3d18.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/60c92f0de3d44bb7a612d08e2e1f3d18.png" alt="é€ ç¦äººç±».png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-å’¦å¾®ä¿¡æ‰“èµ" class="anchor" aria-hidden="true" href="#å’¦å¾®ä¿¡æ‰“èµ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å’¦?(å¾®ä¿¡æ‰“èµ)&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c4fdea49e11241e392d6bcaa33855897.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c4fdea49e11241e392d6bcaa33855897.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;èµèµé‡‘é¢&lt;/th&gt;
&lt;th&gt;èµèµè€…(å¾®ä¿¡å)&lt;/th&gt;
&lt;th&gt;èµèµæ—¶é—´&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;20.00&lt;/td&gt;
&lt;td&gt;(æœªç•™å§“å)&lt;/td&gt;
&lt;td&gt;2019å¹´8æœˆ2æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20.00&lt;/td&gt;
&lt;td&gt;(æœªç•™å§“å)&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ11æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12.34&lt;/td&gt;
&lt;td&gt;å¼ æ˜è¾‰&lt;/td&gt;
&lt;td&gt;2019å¹´8æœˆ20æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;å…­å°ç™»ç™»&lt;/td&gt;
&lt;td&gt;2019å¹´9æœˆ5æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;äº‘æ·¡é£æ™´&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ24æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;é‡‘ä¸‰å¤æœˆ&lt;/td&gt;
&lt;td&gt;2019å¹´6æœˆ2æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;Azuno&lt;/td&gt;
&lt;td&gt;2019å¹´6æœˆ1æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;é‚¦å¦¥&lt;/td&gt;
&lt;td&gt;2019å¹´5æœˆ22æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;enjoy life&lt;/td&gt;
&lt;td&gt;2019å¹´9æœˆ20æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;L__hooåŸ&lt;/td&gt;
&lt;td&gt;2019å¹´9æœˆ20æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;æ¢¦æƒ³æ—…ç¨‹(å…¬ä¼—å·:è‹ç”Ÿä¸æƒ‘)&lt;/td&gt;
&lt;td&gt;2019å¹´9æœˆ14æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;1111&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ27æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;é‚£éƒ½ä¸é‡è¦&lt;/td&gt;
&lt;td&gt;2019å¹´5æœˆ19æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;Lismg&lt;/td&gt;
&lt;td&gt;2019å¹´6æœˆ5æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;smallèƒ–&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ9æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.00&lt;/td&gt;
&lt;td&gt;è‰¯è¾°ç¾&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ20æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.00&lt;/td&gt;
&lt;td&gt;@Coolstar&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ6æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(æœªç•™å§“å)&lt;/td&gt;
&lt;td&gt;2019å¹´9æœˆ26æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;å¤å¤©çš„å°è™«å­&lt;/td&gt;
&lt;td&gt;2019å¹´9æœˆ23æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(æœªç•™å§“å)&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ26æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ12æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(æœªç•™å§“å)&lt;/td&gt;
&lt;td&gt;2019å¹´6æœˆ13æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Walter Wu&lt;/td&gt;
&lt;td&gt;2019å¹´6æœˆ1æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Joseph&lt;/td&gt;
&lt;td&gt;2019å¹´4æœˆ24æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(æœªç•™å§“å)&lt;/td&gt;
&lt;td&gt;2019å¹´4æœˆ12æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;äºäº‘é¹Edward&lt;/td&gt;
&lt;td&gt;2019å¹´4æœˆ12æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;é»„é‡‘æ˜Ÿ&lt;/td&gt;
&lt;td&gt;2019å¹´4æœˆ11æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Cloud 9&lt;/td&gt;
&lt;td&gt;2019å¹´4æœˆ5æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.20&lt;/td&gt;
&lt;td&gt;(æœªç•™å§“å)&lt;/td&gt;
&lt;td&gt;2019å¹´7æœˆ25æ—¥&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;æ„Ÿè°¢ä»¥ä¸Šèµèµè€…å¯¹æœ¬å¼€æºé¡¹ç›®çš„æ”¯æŒ[æ‰‹åŠ¨æ»‘ç¨½]&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-060tabagotchiä¸ºå‡ç¼“å…¨çƒå˜æš–åšå‡ºè´¡çŒ®" class="anchor" aria-hidden="true" href="#060tabagotchiä¸ºå‡ç¼“å…¨çƒå˜æš–åšå‡ºè´¡çŒ®"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/060_tabagotchi.html" rel="nofollow"&gt;060ã€ŠTabagotchiã€‹ä¸ºå‡ç¼“å…¨çƒå˜æš–åšå‡ºè´¡çŒ®&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63478935-7b1f7400-c4be-11e9-8679-5f4a6a56c89c.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63478935-7b1f7400-c4be-11e9-8679-5f4a6a56c89c.gif" alt="tabagotchi" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tabagotchiæ‰©å±•ä»¥ä¸€ç§æœ‰è¶£çš„æ–¹å¼, æé†’æˆ‘ä»¬å‡å°‘æ ‡ç­¾é¡µæ•°é‡, å‡å°‘äº†è®¡ç®—æœºäº§ç”Ÿçš„çƒ­é‡, ä¸ºé˜»æ­¢å…¨çƒå˜æš–åšå‡ºäº†è´¡çŒ®~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-059pagespeed-insight-and-checklistä¸ºç½‘é¡µä¼˜åŒ–æä¾›å»ºè®®å’Œé‡åŒ–æŒ‡æ ‡" class="anchor" aria-hidden="true" href="#059pagespeed-insight-and-checklistä¸ºç½‘é¡µä¼˜åŒ–æä¾›å»ºè®®å’Œé‡åŒ–æŒ‡æ ‡"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/059_page_speed_insight_and_check_list.html" rel="nofollow"&gt;059ã€ŠPageSpeed Insight and CheckListã€‹ä¸ºç½‘é¡µä¼˜åŒ–æä¾›å»ºè®®å’Œé‡åŒ–æŒ‡æ ‡&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63309328-f818e500-c328-11e9-8f1a-68fed13a4015.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63309328-f818e500-c328-11e9-8f1a-68fed13a4015.gif" alt="pag_speed" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63309327-f7804e80-c328-11e9-8eab-9055db8a5d2c.png"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63309327-f7804e80-c328-11e9-8eab-9055db8a5d2c.png" alt="001" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PageSpeed Insight and CheckList å’Œ Google Page Speed ç»“åˆä½¿ç”¨, èƒ½å¤Ÿä¸ºç½‘é¡µè´¨é‡è¯„åˆ†,é‡åŒ–ç½‘é¡µä¼˜åŒ–çš„æ•ˆæœ,ä¹Ÿä¸ºä¼˜åŒ–ç½‘é¡µæŒ‡æ˜äº†æ–¹å‘,å¯¹å‰ç«¯å·¥ç¨‹å¸ˆè€Œè¨€,æ˜¯éå¸¸é‡è¦çš„å·¥å…·&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-058ip-addresså¿«é€ŸæŸ¥çœ‹å½“å‰è®¾å¤‡ip" class="anchor" aria-hidden="true" href="#058ip-addresså¿«é€ŸæŸ¥çœ‹å½“å‰è®¾å¤‡ip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/058_ip_address.html" rel="nofollow"&gt;058ã€ŠIP-Addressã€‹å¿«é€ŸæŸ¥çœ‹å½“å‰è®¾å¤‡IP&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63222725-ee369b00-c1dd-11e9-986e-cbc002168db8.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63222725-ee369b00-c1dd-11e9-986e-cbc002168db8.gif" alt="ip_address" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;è·å–å½“å‰è®¾å¤‡çš„IPåœ°å€,å¯¹äºå¼€å‘è€…è€Œè¨€,æ˜¯ä¸€ä¸ªç»å¸¸é‡åˆ°çš„é—®é¢˜,è€Œã€ŠIP-Addressã€‹è¿™æ¬¾ç®€æ´å°å·§çš„è½¯ä»¶, èƒ½æ»¡è¶³æˆ‘ä»¬çš„éœ€æ±‚&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-057å›¾ç‰‡å¦å­˜ä¸ºjpgpngwebpè®©webpå›¾ç‰‡ä¸‹è½½ä¸ºpngæ ¼å¼md" class="anchor" aria-hidden="true" href="#057å›¾ç‰‡å¦å­˜ä¸ºjpgpngwebpè®©webpå›¾ç‰‡ä¸‹è½½ä¸ºpngæ ¼å¼md"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/057_webp_save_as_png.html" rel="nofollow"&gt;057ã€Šå›¾ç‰‡å¦å­˜ä¸ºJPG/PNG/WebPã€‹è®©WebPå›¾ç‰‡ä¸‹è½½ä¸ºPNGæ ¼å¼.md&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63221240-ce48ac80-c1c8-11e9-9860-376fedc0845e.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63221240-ce48ac80-c1c8-11e9-9860-376fedc0845e.gif" alt="save_as_png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;WebPæ˜¯éå¸¸å…ˆè¿›çš„æ ¼å¼, ä½†ç”±äºPhotoshopè¿™ç±»å…ƒè€çº§å›¾åƒç¼–è¾‘è½¯ä»¶ä¸æ”¯æŒ, æˆ‘ä»¬åªèƒ½å°†å›¾ç‰‡ä¸ºpngæ ¼å¼,å†è¿›è¡Œç¼–è¾‘, å…ˆè¿›æŠ€æœ¯æ”¹å˜ä¸–ç•Œ, éœ€è¦ä¸€ä¸ªè¿‡ç¨‹, è€Œåœ¨è¿‡ç¨‹ä¸­æä¾›ä¸€ä¸ªæŠ˜ä¸­çš„æ–¹æ¡ˆ(æŠŠWebPè£…æ¢ä¸ºpng, å†å°†pngå›¾ç‰‡è£…æ¢ä¸ºWebP), ä¹Ÿæ˜¯ä¸€ä»¶æœ‰ä»·å€¼çš„äº‹~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-056searchä¸ºchromeè®¾ç½®æœç´¢å¼•æ“å…³é”®è¯" class="anchor" aria-hidden="true" href="#056searchä¸ºchromeè®¾ç½®æœç´¢å¼•æ“å…³é”®è¯"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/056_search.html" rel="nofollow"&gt;056ã€ŠSearchã€‹ä¸ºChromeè®¾ç½®æœç´¢å¼•æ“å…³é”®è¯&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/62503773-3c37c000-b828-11e9-9605-4ecce76830ec.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/62503773-3c37c000-b828-11e9-9605-4ecce76830ec.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;åœ¨æ—©æœŸçš„ç½‘å€å¯¼èˆªä¸»é¡µä¸Š, å¯ä»¥é€šè¿‡ç‚¹å‡»é€‰æ‹©ä¸åŒçš„æœç´¢å¼•æ“è¿›è¡Œæœç´¢(æ•°é‡æœ‰é™, è€Œä¸”ä¸æ”¯æŒè‡ªå®šä¹‰), è€ŒChromeæœç´¢æ›´æå®¢ä¸€äº›, é€šè¿‡&lt;strong&gt;è‡ªå®šä¹‰å…³é”®è¯åŠ ç©ºæ ¼&lt;/strong&gt;çš„æ–¹æ³•, åœ¨æœç´¢å¼•æ“ä¹‹é—´è‡ªç”±åˆ‡æ¢, æ˜¯ä¸€ç§å…¼å…·æ‰©å±•æ€§ä¸æ˜“ç”¨æ€§çš„åšæ³•&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-055keylinesä¸ºç½‘é¡µå…ƒç´ æ·»åŠ éšæœºæè¾¹é¢œè‰²-" class="anchor" aria-hidden="true" href="#055keylinesä¸ºç½‘é¡µå…ƒç´ æ·»åŠ éšæœºæè¾¹é¢œè‰²-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/055_keylines.html" rel="nofollow"&gt;055ã€ŠKeylinesã€‹ä¸ºç½‘é¡µå…ƒç´ æ·»åŠ éšæœºæè¾¹é¢œè‰² &lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61917657-dbcf9580-af80-11e9-87d3-528609ab85b0.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61917657-dbcf9580-af80-11e9-87d3-528609ab85b0.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keylinesçš„å®ç°åŸç†éå¸¸ç®€å•(ä¸ºç½‘é¡µdomå…ƒç´ æ·»åŠ äº†outlineå±æ€§), ä½†å±•ç¤ºçš„æ•ˆæœå´éå¸¸æƒŠè‰³, è¿™åº”è¯¥å½’åŠŸäºKeylinesä½œè€…ä¼˜ç§€çš„æƒ³æ³•, å¾ˆå¤šæ—¶å€™, ä¼˜ç§€çš„è½¯ä»¶å¹¶ä¸ä¸€å®šä½¿ç”¨äº†å¾ˆéš¾æŒæ¡çš„æŠ€æœ¯, è€Œæ˜¯åŒ…å«äº†ä½œè€…ä¼˜ç§€çš„æƒ³æ³•~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-054äºŒç®±ä»¥å›¾æœå›¾è®©ä½ åœ¨æœå›¾æ–¹é¢éšå¿ƒæ‰€æ¬²ä¸ºæ‰€æ¬²ä¸º" class="anchor" aria-hidden="true" href="#054äºŒç®±ä»¥å›¾æœå›¾è®©ä½ åœ¨æœå›¾æ–¹é¢éšå¿ƒæ‰€æ¬²ä¸ºæ‰€æ¬²ä¸º"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/054_er_xiang_yi_tu_sou_tu.html" rel="nofollow"&gt;054ã€ŠäºŒç®±+ä»¥å›¾æœå›¾ã€‹è®©ä½ åœ¨æœå›¾æ–¹é¢éšå¿ƒæ‰€æ¬²ï¼ˆä¸ºæ‰€æ¬²ä¸ºï¼‰&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61757068-93ce3880-adf1-11e9-8903-ebf313fb6098.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61757068-93ce3880-adf1-11e9-8903-ebf313fb6098.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ã€ŠäºŒç®± ä»¥å›¾æœå›¾ã€‹æ˜¯ä¸€æ¬¾ç®€å•å®ç”¨çš„æœå›¾å°å·¥å…·ï¼Œå¦‚æœä½ æ˜¯ä¸€åè®¾è®¡å¸ˆ, å¯ä»¥å¸®ä½ å¿«é€ŸæŸ¥æ‰¾ä»–äººè®¾è®¡ä½œå“ä¸­æ‰€ç”¨çš„ç´ ææ¥æº, æå‡ä½ çš„å·¥ä½œæ•ˆç‡~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-053é¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ-à¹‘Ì--Ì€à¹‘ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆ" class="anchor" aria-hidden="true" href="#053é¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ-à¹‘Ì--Ì€à¹‘ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/053_shu_biao_dian_ji_te_xiao.htmll" rel="nofollow"&gt;053ã€Šé¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ (à¹‘â€¢Ì âˆ€ â€¢Ì€à¹‘)ã€‹ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆ&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61600040-04921b00-ac61-11e9-8446-533752d71de1.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61600040-04921b00-ac61-11e9-8446-533752d71de1.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ã€Šé¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ (à¹‘â€¢Ì âˆ€ â€¢Ì€à¹‘)ã€‹æ˜¯ä¸€æ¬¾ä¸ºé¼ æ ‡ç‚¹å‡»æ·»åŠ æœ‰è¶£çš„ç‰¹æ•ˆçš„æ‰©å±•ç¨‹åº,è™½ç„¶æ²¡å•¥å®é™…ç”¨é€”,ä½†å¾ˆå¥½ç©, å½•åˆ¶ä¸€äº›æœ‰è¶£çš„ç½‘é¡µå°ç¨‹åºæ—¶, ä¼šéå¸¸å‡ºå½©~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-052site-paletteè‡ªåŠ¨æå–ç½‘ç«™é…è‰²" class="anchor" aria-hidden="true" href="#052site-paletteè‡ªåŠ¨æå–ç½‘ç«™é…è‰²"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/052_site_palette.html" rel="nofollow"&gt;052ã€ŠSite Paletteã€‹è‡ªåŠ¨æå–ç½‘ç«™é…è‰²&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61169390-2f101400-a58f-11e9-8769-4d62b7b64f37.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61169390-2f101400-a58f-11e9-8769-4d62b7b64f37.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Site Paletteä½¿ç”¨ç®€å•, åŠŸèƒ½å®ç”¨, æ²¡æœ‰å¹¿å‘Š, æ˜¯å…¸å‹çš„å°è€Œç¾çš„æ‰©å±•ç¨‹åº, è¿™ç±»æ‰©å±•ç¨‹åºè¶Šå¤š, Chromeçš„ç”¨æˆ·ä½“éªŒä¹Ÿå°±è¶Šå¥½~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-051custom-cursor-for-chromeä¸ºchromeæ¢ä¸Šå¯çˆ±åˆéŸ³å…‰æ ‡" class="anchor" aria-hidden="true" href="#051custom-cursor-for-chromeä¸ºchromeæ¢ä¸Šå¯çˆ±åˆéŸ³å…‰æ ‡"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/051_custom_cursor_for_chrome.html" rel="nofollow"&gt;051ã€ŠCustom Cursor for Chromeâ„¢ã€‹ä¸ºChromeæ¢ä¸Šå¯çˆ±åˆéŸ³å…‰æ ‡&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61166967-d0846f00-a569-11e9-9141-15cef4983098.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61166967-d0846f00-a569-11e9-9141-15cef4983098.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ—©æœŸçš„QQç©ºé—´å’Œä¸ªäººåšå®¢, æˆ‘ä»¬ä¼šç»™é¡µé¢åŠ å„ç§å„æ ·çš„è£…é¥°, è¿é¼ æ ‡æŒ‡é’ˆä¹Ÿè¦å®šåˆ¶ä¸€ä¸‹, å½“æ—¶æ„Ÿè§‰ä¹è¶£æ— ç©·, åé¢å°±å¤±å»äº†å…´è¶£, å¯¹äºä¸ªäººåšå®¢, æ„Ÿè§‰è¶Šç®€æ´è¶Šå¥½, äºæ˜¯å°±æœ‰äº†Nextè¿™äº›å¤§é‡ç•™ç™½çš„åšå®¢ä¸»é¢˜,ä½†æˆ‘æ„Ÿè§‰åœ¨Nextè¿™ç±»ä¸»é¢˜ä¸­åŠ ä¸€äº›å®šåˆ¶åŒ–çš„å°ç‰©ä»¶ä¹Ÿæ˜¯ä¸é”™çš„, åœ¨ç®€æ´ä¸èŠ±å“¨ä¹‹é—´æ‰¾åˆ°å¹³è¡¡, ä¸æ­£æ˜¯ç”Ÿæ´»çš„ä¹è¶£ä¹‹æºä¹ˆ~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-050google-results-previeweræ— ç‚¹å‡»æŸ¥çœ‹è°·æ­Œæœç´¢ç»“æœ" class="anchor" aria-hidden="true" href="#050google-results-previeweræ— ç‚¹å‡»æŸ¥çœ‹è°·æ­Œæœç´¢ç»“æœ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/050_google_results_previewer.html" rel="nofollow"&gt;050ã€ŠGoogle Results Previewerã€‹æ— ç‚¹å‡»æŸ¥çœ‹è°·æ­Œæœç´¢ç»“æœ&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/9219a092f0f4eb1c6f614c1667b316d1.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/9219a092f0f4eb1c6f614c1667b316d1.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Google Results Previewerçš„åŠŸèƒ½ç®€å•å®ç”¨, ä¹Ÿæ²¡æœ‰å¤šä½™çš„è®¾ç½®, å±äºæ–°æ‰‹å‹å¥½å‹å·¥å…·&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-049web-server-for-chromeæ­å»ºæœ¬åœ°webæœåŠ¡å™¨-å®ç°å±€åŸŸç½‘å…±äº«æ–‡ä»¶å¤¹" class="anchor" aria-hidden="true" href="#049web-server-for-chromeæ­å»ºæœ¬åœ°webæœåŠ¡å™¨-å®ç°å±€åŸŸç½‘å…±äº«æ–‡ä»¶å¤¹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/049_web_server_for_chrome.html" rel="nofollow"&gt;049ã€ŠWeb Server for Chromeã€‹æ­å»ºæœ¬åœ°WebæœåŠ¡å™¨, å®ç°å±€åŸŸç½‘å…±äº«æ–‡ä»¶å¤¹&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/74d3eb882b103e0fb1e5e5dd651c052f.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/74d3eb882b103e0fb1e5e5dd651c052f.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Web Server for Chromeå¯ä»¥å¸®æˆ‘ä»¬åœ¨æœ¬åœ°å¿«é€Ÿå¼€å¯httpæœåŠ¡,è®©å¼€å‘å’Œæµ‹è¯•å˜å¾—æ›´åŠ ç®€å•, å¦‚æœä½ æƒ³å’ŒåŒå¤„æŸä¸ªå±€åŸŸç½‘çš„å°ä¼™ä¼´, å»ºç«‹ä¸€ä¸ªå…±äº«æ–‡ä»¶å¤¹, Web Server for Chromeæˆ–è®¸æ˜¯ä½ æœ€ç®€å•çš„å®ç°æ–¹æ³•~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-048words-discovererèƒŒå•è¯æ–°å§¿åŠ¿æå‡ä½ çš„è¯æ±‡é‡" class="anchor" aria-hidden="true" href="#048words-discovererèƒŒå•è¯æ–°å§¿åŠ¿æå‡ä½ çš„è¯æ±‡é‡"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/048_words_discoverer.html" rel="nofollow"&gt;048ã€ŠWords Discovererã€‹èƒŒå•è¯æ–°å§¿åŠ¿,æå‡ä½ çš„è¯æ±‡é‡&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/305439fdd84017da654e00f16aaee752.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/305439fdd84017da654e00f16aaee752.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Words Discoverer(ä¸­æ–‡è¯‘å: å•è¯å‘ç°è€…),&lt;strong&gt;å¯ä»¥çªå‡ºæ˜¾ç¤ºç½‘é¡µä¸Šç½•è§çš„è‹±è¯­å­—å…¸è¯æ±‡å’Œæƒ¯ç”¨è¯­ã€‚ä¿ƒè¿›è‹±è¯­è¯­è¨€å­¦ä¹ å¹¶æ‰©å¤§è¯æ±‡é‡&lt;/strong&gt;,é€šè¿‡è‡ªåŠ¨é«˜äº®ç½‘é¡µå•è¯, è¾…åŠ©å•è¯è®°å¿†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è·¯å­, å»ºè®®è¿‡ä¸€æ®µæ—¶é—´,å°±ç¨å¾®è°ƒé«˜&lt;strong&gt;ä¸çªå‡ºæ˜¾ç¤º æœ€å¸¸ç”¨çš„è‹±è¯­å•è¯&lt;/strong&gt;çš„æ•°é‡, æ¯”å¦‚ä»é»˜è®¤çš„15%è°ƒæ•´åˆ°16%,  å•è¯å‘ç°è€…ä¸æ²™æ‹‰æŸ¥è¯ç»“åˆä½¿ç”¨, çœŸçš„æ˜¯ä½“éªŒæä½³~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-047go-to-tabå¿«é€Ÿè·³è½¬åˆ°æ‰“å¼€çš„ç½‘é¡µ" class="anchor" aria-hidden="true" href="#047go-to-tabå¿«é€Ÿè·³è½¬åˆ°æ‰“å¼€çš„ç½‘é¡µ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/047_go_to_tab.html" rel="nofollow"&gt;047ã€ŠGo to Tabã€‹å¿«é€Ÿè·³è½¬åˆ°æ‰“å¼€çš„ç½‘é¡µ&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/59550928-2a623b00-8fa4-11e9-8525-8e830907463b.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/59550928-2a623b00-8fa4-11e9-8525-8e830907463b.gif" alt="2019-06-15-18 54 23" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Go to Tabå¯¹äºå·¥ä½œæœŸé—´å¤§é‡æ‰“å¼€é¡µé¢, åˆé•¿æ—¶é—´ä¸å…³æœºçš„ç¨‹åºå‘˜ä»¬, æ˜¯éå¸¸æœ‰å¸®åŠ©çš„&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-046whatfontå­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“" class="anchor" aria-hidden="true" href="#046whatfontå­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/046_whatfont.html" rel="nofollow"&gt;046ã€ŠWhatFontã€‹å­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/59549312-4529b500-8f8e-11e9-8107-004486a02258.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/59549312-4529b500-8f8e-11e9-8107-004486a02258.gif" alt="font 2019-06-15 16_04_10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;WhatFontå±äºåŠŸèƒ½éå¸¸å•ä¸€çš„å°å·¥å…·, è®©å­—ä½“çˆ±å¥½è€…ä¼˜é›…æŸ¥çœ‹ç½‘é¡µå­—ä½“å±æ€§, å¦‚æœä½ å¯¹æ¼‚äº®å­—ä½“æœ‰ä¸€ä»½æ‰§å¿µ, æ¨èåˆ°&lt;a href="https://fonts.google.com/" rel="nofollow"&gt;https://fonts.google.com/&lt;/a&gt;, &lt;a href="https://www.myfonts.com/" rel="nofollow"&gt;https://www.myfonts.com/&lt;/a&gt;
ç­‰å­—ä½“ç½‘ç«™,æ‰¾å¯»æ›´å¤šå¯çˆ±çš„å­—ä½“~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-045restlet-clientä¼˜ç§€çš„apiæµ‹è¯•å·¥å…·" class="anchor" aria-hidden="true" href="#045restlet-clientä¼˜ç§€çš„apiæµ‹è¯•å·¥å…·"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/045_restlet_client.html" rel="nofollow"&gt;045ã€ŠRestlet Clientã€‹ä¼˜ç§€çš„Apiæµ‹è¯•å·¥å…·&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/89ea1e51dab48d5a84f089adf33eb274.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/89ea1e51dab48d5a84f089adf33eb274.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Restlet Clientæ˜¯ä¸€æ¬¾å¼€å‘å®ç”¨å·¥å…·, æ”¯æŒä¸€é”®å¯¼å…¥Postmanç­‰apiæµ‹è¯•å·¥å…·çš„æµ‹è¯•ç”¨ä¾‹&lt;/li&gt;
&lt;li&gt;è¿‘æ¥, Postmanå¼€å§‹ä¸»æ¨è‡ªå·±çš„70Må·¦å³çš„å®¢æˆ·ç«¯å®‰è£…åŒ…, åŠŸèƒ½æ²¡ä»€ä¹ˆæ”¹è¿›, ä½“ç§¯å´å˜å¾—è¶…å¤§,è€Œä¸”Postmançš„Chromeæ‰©å±•ç¨‹åº, å¯¹macOSçš„æ”¯æŒä¸å¤ªå¥½(æ¯æ¬¡æ‰“å¼€, éƒ½ä¼šå¼¹çª—æŠ¥ä¸€ä¸ªé”™)&lt;/li&gt;
&lt;li&gt;Restlet Clientä¾ç„¶åªæ˜¯ä¸€ä¸ªå¼€ç®±å³ç”¨çš„Chromeæ‰©å±•ç¨‹åº, éå¸¸é€‚åˆç¡¬ç›˜ç©ºé—´æœ‰é™çš„å°ä¼™ä¼´ä½¿ç”¨(è½¯ä»¶åŠŸèƒ½å¤Ÿç”¨å°±å¯ä»¥äº†~)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-044è°·æ­Œè®¿é—®åŠ©æ‰‹è®¿é—®chromeå•†åº—-gmail-è°·æ­Œæœç´¢" class="anchor" aria-hidden="true" href="#044è°·æ­Œè®¿é—®åŠ©æ‰‹è®¿é—®chromeå•†åº—-gmail-è°·æ­Œæœç´¢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/044_gu_ge_fang_wen_zhu_shou.html" rel="nofollow"&gt;044ã€Šè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹è®¿é—®Chromeå•†åº— Gmail è°·æ­Œæœç´¢&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/deff71a536ba4027a01fe3c7a558c277.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/deff71a536ba4027a01fe3c7a558c277.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ã€Šè°·æ­Œè®¿é—®åŠ©æ‰‹ã€‹å¯ä»¥è®©æˆ‘ä»¬è®¿é—®Chromeå•†åº—, ä»¥åŠè°·æ­Œæœç´¢, è°·æ­ŒGmailç­‰æœåŠ¡
&lt;code&gt;ä»…ä¸ºé¦™æ¸¯åœ°åŒºç”¨æˆ·æï¼Œä¾›æ–¹ä¾¿ç§‘ç ”,å¤–è´¸æä¾›å¸®åŠ©,ä¸è‰¯ç”¨æˆ·,å°†å°é”è®¿é—®IP,åæœè‡ªè´Ÿ&lt;/code&gt;, è°·æ­Œè®¿é—®åŠ©æ‰‹éœ€è¦ä½ è®¾ç½®ä¸»é¡µä¸º&lt;code&gt;https://2018.hao245.com/&lt;/code&gt;æ‰èƒ½ä½¿ç”¨, æœ‰ç™¾åº¦å…¨å®¶æ¡¶, 360å…¨å®¶æ¡¶çš„æµæ°“å†…æ¶µ~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-043dream-afar-new-tabæ¢ç´¢ä¸–ç•Œçš„æ–°æ–¹å¼" class="anchor" aria-hidden="true" href="#043dream-afar-new-tabæ¢ç´¢ä¸–ç•Œçš„æ–°æ–¹å¼"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/043_dream_afar_new_tab.html" rel="nofollow"&gt;043ã€ŠDream Afar New Tabã€‹æ¢ç´¢ä¸–ç•Œçš„æ–°æ–¹å¼&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e40b7bec41ce4ac892578bc88a03d25c.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e40b7bec41ce4ac892578bc88a03d25c.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ã€ŠDream Afar New Tabã€‹çš„è®¾è®¡éå¸¸æ¼‚äº®, åŠŸèƒ½è°ƒèŠ‚ä¹Ÿéå¸¸ç®€å•, åªæœ‰ä¸¤çº§èœå•, å£çº¸ä¹Ÿéå¸¸ç²¾ç¾, å¯¹æµè§ˆå™¨é¢œå€¼æœ‰è¦æ±‚çš„å°ä¼™ä¼´, å¯ä»¥è¯•ä¸€è¯•~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-042-åœ¨edgeä¸­å®‰è£…chromeæ‰©å±•ç¨‹åº" class="anchor" aria-hidden="true" href="#042-åœ¨edgeä¸­å®‰è£…chromeæ‰©å±•ç¨‹åº"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/042_edge.html" rel="nofollow"&gt;042 åœ¨Edgeä¸­å®‰è£…Chromeæ‰©å±•ç¨‹åº&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a131b9833d20424ab93cb258ab8542e8.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a131b9833d20424ab93cb258ab8542e8.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Edgeå¯ä»¥å®‰è£…ç»å¤§å¤šæ•°Chromeå•†åº—ä¸­çš„æ‰©å±•, ä½†Chromeä¸­çš„è°·æ­Œå¼€å‘Appç¨‹åº, ç±»ä¼¼&lt;a href="https://chrome.google.com/webstore/detail/secure-shell-app/pnhechapfaindjhompbnflcldabbghjo" rel="nofollow"&gt;Secure Shell App&lt;/a&gt;, ç›®å‰æ˜¯æ— æ³•å®‰è£…çš„, æ–°ç‰ˆEdgeä½¿ç”¨äº†Chromeçš„Chromiumå†…æ ¸, å¯ä»¥å…¼å®¹å®‰è£…Chromeç”Ÿæ€ä¸­çš„å„ç§åº”ç”¨ç¨‹åº,ä¸ºEdgeæœªæ¥çš„å‘å±•å¸¦æ¥äº†æ— é™å¯èƒ½~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-041copy-all-urlsä¼˜é›…åœ°ä¿å­˜-å¼€å¯å¤šä¸ªæ ‡ç­¾é¡µ" class="anchor" aria-hidden="true" href="#041copy-all-urlsä¼˜é›…åœ°ä¿å­˜-å¼€å¯å¤šä¸ªæ ‡ç­¾é¡µ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/041_copy_all_urls.html" rel="nofollow"&gt;041ã€ŠCopy All Urlsã€‹ä¼˜é›…åœ°ä¿å­˜-å¼€å¯å¤šä¸ªæ ‡ç­¾é¡µ&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/eac219ff189a4295bbf88974b045ba5b.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/eac219ff189a4295bbf88974b045ba5b.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Copy All Urlså±äºå°è€Œç¾åœ°å·¥å…·ï¼Œå¦‚æœä½ æ¯å¤©éƒ½éœ€è¦æŸ¥çœ‹å‡ ä¸ªå›ºå®šçš„ç½‘é¡µ, Copy All Urlsèƒ½å¸®ä½ çœå¾ˆå¤šæ—¶é—´~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-040gitzip-for-githubä»githubæ‰¹é‡ä¸‹è½½è¡¨æƒ…åŒ…" class="anchor" aria-hidden="true" href="#040gitzip-for-githubä»githubæ‰¹é‡ä¸‹è½½è¡¨æƒ…åŒ…"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/040_gitzip_for_github.html" rel="nofollow"&gt;040ã€ŠGitZip for githubã€‹ä»Githubæ‰¹é‡ä¸‹è½½è¡¨æƒ…åŒ…&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/f5b923dc4a21437484e90859342ed366.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/f5b923dc4a21437484e90859342ed366.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ä»¥å‰ä»‹ç»è¿‡Githubå¿«é€Ÿä¸‹è½½å•ä¸ªæ–‡ä»¶çš„æ‰©å±•å·¥å…·&lt;a href="https://zhaoolee.gitbooks.io/chrome/content/018enhanced-github300b-cong-201c-bing-gui-201d-dao-201c-bing-gun-er-201d2c-xia-zai-github-dan-ge-wen-jian.html" rel="nofollow"&gt;ã€ŠEnhanced Githubã€‹&lt;/a&gt; , ã€ŠEnhanced Githubã€‹ å’Œ ã€ŠGitZip for githubã€‹ ç»“åˆåˆ°ä¸€èµ·, å°±å¯ä»¥è®©æˆ‘ä»¬å¿«é€Ÿä¸‹è½½, githubä»»æ„ä»“åº“ä»»æ„æ–‡ä»¶å¤¹çš„ä¼˜è´¨èµ„æºäº†~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-039simplify-gmailè®©ç½‘é¡µç‰ˆgmailæ›´æ¸…çˆ½" class="anchor" aria-hidden="true" href="#039simplify-gmailè®©ç½‘é¡µç‰ˆgmailæ›´æ¸…çˆ½"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/039_simplify_gmail.html" rel="nofollow"&gt;039ã€ŠSimplify Gmailã€‹è®©ç½‘é¡µç‰ˆGmailæ›´æ¸…çˆ½&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c9b1aa8201c24208b0e0aedfcdbdc992.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c9b1aa8201c24208b0e0aedfcdbdc992.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å¥½çš„æ‰©å±•ç¨‹åºå°±åº”è¯¥è¿™æ ·, è®©äººè§åˆ°åè€³ç›®ä¸€æ–°, ä½¿ç”¨çš„æ–¹æ³•å´éå¸¸ç®€å•ã€‚
å¦‚æœä½ å¹¶æ²¡æœ‰æ³¨å†Œè¿‡Gmailé‚®ç®±, å¯ä»¥å°è¯•æ³¨å†Œä¸€ä¸ª, Gmailæ˜¯éå¸¸å¥½ç”¨çš„, æ‹¥æœ‰è§„èŒƒçš„æ¥å£, ä¸ä¼šéšä¾¿æ‹¦æˆªé‚®ä»¶, ä¹Ÿä¸ä¼šåœ¨é¡µé¢é“ºæ»¡å¹¿å‘Š&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-038alexa-traffic-rankä¸€é”®æŸ¥çœ‹ç½‘ç«™å…¨çƒæ’å" class="anchor" aria-hidden="true" href="#038alexa-traffic-rankä¸€é”®æŸ¥çœ‹ç½‘ç«™å…¨çƒæ’å"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/038_alexa_traffic_rank.html" rel="nofollow"&gt;038ã€ŠAlexa Traffic Rankã€‹ä¸€é”®æŸ¥çœ‹ç½‘ç«™å…¨çƒæ’å&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcefd45a5cc74e4c824f567535f79c5c.webp"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcefd45a5cc74e4c824f567535f79c5c.webp" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Alexaç»™å‡ºçš„ç½‘ç«™æ’å, æ˜¯ç›®å‰å…¬è®¤æœ€å…·å‚è€ƒä»·å€¼çš„æ’å, æ‰“å¼€ä¸€ä¸ªæ–°ç«™ç‚¹, æŸ¥ä¸€ä¸‹æ–°ç«™ç‚¹çš„Alexaæ’å, ä»¥åŠä¸å®ƒç±»ä¼¼çš„ç«™ç‚¹, è®©æˆ‘ä»¬å¾ˆå¿«å¯¹æ–°ç«™ç‚¹çš„å®šä½, æœ‰ä¸€ä¸ªå¤§è‡´çš„è®¤çŸ¥~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-037saladictè°·æ­Œæœ‰é“æˆ‘å…¨éƒ½è¦-èšåˆè¯å…¸-å¹¶è¡Œç¿»è¯‘" class="anchor" aria-hidden="true" href="#037saladictè°·æ­Œæœ‰é“æˆ‘å…¨éƒ½è¦-èšåˆè¯å…¸-å¹¶è¡Œç¿»è¯‘"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/037_saladict.html" rel="nofollow"&gt;037ã€ŠSaladictã€‹è°·æ­Œ!æœ‰é“!æˆ‘å…¨éƒ½è¦! èšåˆè¯å…¸, å¹¶è¡Œç¿»è¯‘&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/07322f3c4b13484a8a048194558cec5c.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/07322f3c4b13484a8a048194558cec5c.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;æ²™æ‹‰æŸ¥è¯(Saladict)æ˜¯ä¸€æ¬¾éå¸¸ä¼˜ç§€çš„æŸ¥è¯æ‰©å±•, ä¸Šæ–‡åªæ˜¯æåŠäº†å®ƒæœ€å¸¸ç”¨çš„ä¸€äº›åŠŸèƒ½, æ²™æ‹‰æŸ¥è¯çš„åå°ç®¡ç†é€‰é¡¹éå¸¸ä¸°å¯Œ, æ„Ÿå…´è¶£çš„å°ä¼™ä¼´å¯ä»¥æ…¢æ…¢æ¢ç´¢&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-036screen-shaderæŠŠå±å¹•è°ƒæˆæš–è‰²ä½ çš„çœ¼ç›ä¼šæ„Ÿè°¢ä½ " class="anchor" aria-hidden="true" href="#036screen-shaderæŠŠå±å¹•è°ƒæˆæš–è‰²ä½ çš„çœ¼ç›ä¼šæ„Ÿè°¢ä½ "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/036_screen_shader.html" rel="nofollow"&gt;036ã€ŠScreen Shaderã€‹æŠŠå±å¹•è°ƒæˆæš–è‰²ï¼Œä½ çš„çœ¼ç›ä¼šæ„Ÿè°¢ä½ &lt;g-emoji class="g-emoji" alias="pray" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png"&gt;ğŸ™&lt;/g-emoji&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/3a94a283267047c39114694706de7293.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/3a94a283267047c39114694706de7293.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å¯¹äºé•¿æ—¶é—´çœ‹ç”µè„‘çš„åŠå…¬äººå‘˜, å¯ä»¥å°è¯•å§å±å¹•è°ƒæˆæš–è‰², å¼€å§‹å¯èƒ½ä¼šä¸ä¹ æƒ¯, ä½†åé¢ä¼šæ„Ÿè§‰çœ¼ç›ä¼šèˆ’æœå¾ˆå¤š, ä½ çš„çœ¼ç›ä¹Ÿä¼šæ„Ÿè°¢ä½ çš„~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-035print-friendly--pdfè®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ" class="anchor" aria-hidden="true" href="#035print-friendly--pdfè®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/035_print_friendly_and_pdf.html" rel="nofollow"&gt;035ã€ŠPrint Friendly &amp;amp; PDFã€‹è®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a71d2b280298482ba2408482c1537bf9.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a71d2b280298482ba2408482c1537bf9.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ã€ŠPrint Friendly &amp;amp; PDFã€‹æ˜¯ä¸€æ¬¾æ–‡ä»¶æ‰“å°chromeæ’ä»¶ï¼Œä¼šåœ¨æ‰“å°ä¹‹å‰åˆ é™¤åƒåœ¾å¹¿å‘Šï¼Œå¯¼èˆªå’Œæ— ç”¨æµ®çª—ä»è€Œå®ç°é¡µé¢ä¼˜åŒ–ï¼Œè®©ä½ æ‹¥æœ‰æœ€ä½³çš„æ‰“å°é˜…è¯»ä½“éªŒ, å¦‚æœä½ ç»å¸¸éœ€è¦æ‰“å°ç½‘é¡µ, å¯ä»¥é€šè¿‡ã€ŠPrint Friendly &amp;amp; PDFã€‹è®©ä½ çš„æ‰“å°å·¥ä½œå˜å¾—çœæ—¶çœåŠ›~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-034astro-botç”¨æ–°æ ‡ç­¾é¡µåˆ·ç¼–ç¨‹é¢˜" class="anchor" aria-hidden="true" href="#034astro-botç”¨æ–°æ ‡ç­¾é¡µåˆ·ç¼–ç¨‹é¢˜"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/034_astro_bot.html" rel="nofollow"&gt;034ã€ŠAstro Botã€‹ç”¨æ–°æ ‡ç­¾é¡µåˆ·ç¼–ç¨‹é¢˜&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/671d39ca714f437fa1d287bfb988724e.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/671d39ca714f437fa1d287bfb988724e.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Astro Botå¯ä»¥åœ¨æ–°æ ‡ç­¾é¡µ,å±•ç¤ºä¸€é“ä¸ç¨‹åºç›¸å…³çš„é—®é¢˜æˆ–ç›¸å…³æ–°é—»&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-033ä¸€å¶åœ¨ä»»æ„ç½‘é¡µå¼€å¯å®æ—¶å¼¹å¹•-èŠå¤©çª—å£-ç•™è¨€æ¿" class="anchor" aria-hidden="true" href="#033ä¸€å¶åœ¨ä»»æ„ç½‘é¡µå¼€å¯å®æ—¶å¼¹å¹•-èŠå¤©çª—å£-ç•™è¨€æ¿"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/033_yi_ye.html" rel="nofollow"&gt;033ã€Šä¸€å¶ã€‹åœ¨ä»»æ„ç½‘é¡µå¼€å¯å®æ—¶å¼¹å¹• èŠå¤©çª—å£ ç•™è¨€æ¿&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6a328e8eb9984f5abea5816c681b8e4e.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6a328e8eb9984f5abea5816c681b8e4e.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ä¸€å¶æ˜¯ä¸€æ¬¾å¾ˆæœ‰æƒ³æ³•çš„äº§å“,ä½†ç›®å‰ç”¨æˆ·é‡è¿˜æ˜¯å¾ˆå°‘, å¯¹æ­¤,æˆ‘ä¸ªäººä¹Ÿæœ‰ä¸€äº›æƒ³æ³•,å¦‚æœå®˜æ–¹å¯ä»¥æ•ˆä»¿pokemongoè¿™ç±»å¯»å®æ¸¸æˆ,åœ¨å„å¤§ç½‘ç«™çš„ä¸»é¡µå¯¹åº”çš„ç•™è¨€æ¿å†…,åŸ‹ä¸‹ä¸€äº›æœ‰æ„æ€çš„å½©è›‹,è®©ç”¨æˆ·å»å¯»å®,æˆ–è®¸ä¼šæœ‰åˆ©äºäº§å“çš„æ¨å¹¿~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-032smallpdfç®€å•å¥½ç”¨çš„çº¿ä¸Špdfå·¥å…·" class="anchor" aria-hidden="true" href="#032smallpdfç®€å•å¥½ç”¨çš„çº¿ä¸Špdfå·¥å…·"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/032_smallpdf.html" rel="nofollow"&gt;032ã€ŠSmallpdfã€‹ç®€å•å¥½ç”¨çš„çº¿ä¸ŠPDFå·¥å…·&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/2c00d25291db4750963c60e78344d4cc.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/2c00d25291db4750963c60e78344d4cc.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Smallpdfæ˜¯ä¸€ä¸ªéå¸¸å¥½ç”¨çš„PDFå·¥å…·,å¯ä»¥æ”¶è—èµ·æ¥,ä½œä¸ºæ—¥å¸¸åŠå…¬çš„å·¥å…·, Smallpdfå¯ä»¥è¿›è¡Œå¤šä»½pdfåœ¨çº¿åˆå¹¶, pdfåœ¨çº¿ç¼–è¾‘, å¦‚æœä½ æ˜¯ä¸€ä¸ªç»å¸¸å’ŒPDFæ‰“äº¤é“çš„äºº, å¯ä¸è¦é”™è¿‡å®ƒ~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-031onetabæŠŠå¤šä¸ªtabè½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨" class="anchor" aria-hidden="true" href="#031onetabæŠŠå¤šä¸ªtabè½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/031_onetab.htmll" rel="nofollow"&gt;031ã€ŠOneTabã€‹æŠŠå¤šä¸ªTabè½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/93781d48870742e08dc68fa17e79169e.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/93781d48870742e08dc68fa17e79169e.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å½“ä½ å‘ç°è‡ªå·±æœ‰å¤ªå¤šçš„æ ‡ç­¾é¡µæ—¶,å•å‡»OneTabå›¾æ ‡,æ‰€æœ‰æ ‡ç­¾é¡µä¼šè½¬æ¢æˆä¸€ä¸ªåˆ—è¡¨,å½“ä½ éœ€è¦å†æ¬¡è®¿é—®è¿™äº›æ ‡ç­¾é¡µæ—¶,ç‚¹å‡»OneTabå›¾æ ‡å”¤å‡ºåˆ—è¡¨,ç‚¹å‡»åˆ—è¡¨æ¢å¤æ ‡ç­¾é¡µ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-030æ˜é‡‘ç›¸ä¿¡ä¼˜è´¨æŠ€æœ¯å†…å®¹çš„åŠ›é‡" class="anchor" aria-hidden="true" href="#030æ˜é‡‘ç›¸ä¿¡ä¼˜è´¨æŠ€æœ¯å†…å®¹çš„åŠ›é‡"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/030_jue_jin.html" rel="nofollow"&gt;030ã€Šæ˜é‡‘ã€‹ç›¸ä¿¡ä¼˜è´¨æŠ€æœ¯å†…å®¹çš„åŠ›é‡&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcca47d65f2542808281c17ec379d7d9.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcca47d65f2542808281c17ec379d7d9.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å¦‚æœä½ æƒ³å¯¹ ç¨‹åºå‘˜, äº§å“ç»ç†, è®¾è®¡å¸ˆçš„è¡Œä¸šçŸ¥è¯†æœ‰æ‰€äº†è§£, å¯ä»¥æ²¡äº‹å„¿æ‰“å¼€æ˜é‡‘æ’ä»¶çœ‹ä¸€çœ‹, å¦‚æœä½ æ„Ÿè§‰å¾ˆå–œæ¬¢é‡Œé¢çš„å†…å®¹, å¯ä»¥åˆ°æ˜é‡‘å®˜ç½‘ &lt;a href="https://juejin.im/" rel="nofollow"&gt;https://juejin.im/&lt;/a&gt; é€›ä¸€é€›&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-029-simpreadä¸ºä»»æ„ç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼" class="anchor" aria-hidden="true" href="#029-simpreadä¸ºä»»æ„ç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/029_simread.html" rel="nofollow"&gt;029 ã€ŠSimpReadã€‹ä¸ºä»»æ„ç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0f9aa9ca332c4325806f92784af9f9ac.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0f9aa9ca332c4325806f92784af9f9ac.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
ä¸ºç½‘é¡µå¼€å¯é˜…è¯»æ¨¡å¼, èƒ½è®©æˆ‘ä»¬æ›´ä¸“æ³¨äºå†…å®¹, ä¸ä¼šè¢«èŠ±èŠ±ç»¿ç»¿çš„å¹¿å‘Šæ¨å¹¿åˆ†æ•£ç²¾åŠ›, è€ŒSimpReadå°±æ˜¯ä¸€æ­€ä¸ºç½‘é¡µå¼€å¯&lt;strong&gt;é˜…è¯»æ¨¡å¼&lt;/strong&gt;çš„æ’ä»¶&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-028adblockadblockå±è”½ç®€ä¹¦å¹¿å‘Š" class="anchor" aria-hidden="true" href="#028adblockadblockå±è”½ç®€ä¹¦å¹¿å‘Š"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/028_adblock.html" rel="nofollow"&gt;028ã€ŠAdBlockã€‹Adblockå±è”½ç®€ä¹¦å¹¿å‘Š&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e149c42ac1f343b88f50e522cba9ad64.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e149c42ac1f343b88f50e522cba9ad64.gif" alt="å±è”½ç®€ä¹¦å¹¿å‘Š" style="max-width:100%;"&gt;&lt;/a&gt;
Adblockçš„åŠŸèƒ½éå¸¸ä¸°å¯Œ, ä½†å¾ˆå¤šåŠŸèƒ½åŸºæœ¬ç”¨ä¸åˆ°, æ™®é€šç”¨æˆ·åªéœ€è¦å¼€å¯Adblock, èƒ½ä½¿ç”¨å³é”®å·¥å…·å±è”½ä¸å–œæ¬¢çš„å¹¿å‘Š, ä¹Ÿå°±å¤Ÿç”¨äº†~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-027textæ¥è‡ªchromeå®éªŒå®¤çš„è·¨å¹³å°è®°äº‹æœ¬" class="anchor" aria-hidden="true" href="#027textæ¥è‡ªchromeå®éªŒå®¤çš„è·¨å¹³å°è®°äº‹æœ¬"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/027_text.html" rel="nofollow"&gt;027ã€ŠTextã€‹æ¥è‡ªChromeå®éªŒå®¤çš„è·¨å¹³å°è®°äº‹æœ¬&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6e287798ca1d4b939705447d4b8b2b3b.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6e287798ca1d4b939705447d4b8b2b3b.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Textç”±è°·æ­ŒChromeå®éªŒå®¤ç ”å‘å¹¶å¼€æº, å¼€æºåœ°å€&lt;a href="https://github.com/GoogleChromeLabs/text-app"&gt;https://github.com/GoogleChromeLabs/text-app&lt;/a&gt; , Textå±äºå°è€Œç¾çš„äº§å“, åŠŸèƒ½ä¸ç®—å¼ºå¤§, ä½†æ˜¯å¤Ÿç”¨, è€Œä¸”å€ŸåŠ©Chromeå®Œæˆäº†è·¨å¹³å°(åœ¨Linuxä¹Ÿå¯ä»¥ä½¿ç”¨å“¦~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-026quickey-launcheræ‰“å¼€ç½‘ç«™åªéœ€ä¸€é”®" class="anchor" aria-hidden="true" href="#026quickey-launcheræ‰“å¼€ç½‘ç«™åªéœ€ä¸€é”®"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/026_quickey_launcher.html" rel="nofollow"&gt;026ã€ŠQuickey Launcherã€‹æ‰“å¼€ç½‘ç«™åªéœ€ä¸€é”®&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/322a82d214b34ff2ba70d9c1cd71d276.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/322a82d214b34ff2ba70d9c1cd71d276.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
Quickey Launcherä»¥ä¼˜é›…çš„æ–¹å¼, ä¸ºä»»æ„ç½‘é¡µç»‘å®šä¸€ä¸ªå¿«æ·é”®, ç»‘å®šå®Œæˆå, å³å¯é€šè¿‡å¿«æ·é”®,æ‰“å¼€ç½‘é¡µ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-025consolechromeè‡ªå¸¦å¥½ç”¨çš„è®¡ç®—å™¨" class="anchor" aria-hidden="true" href="#025consolechromeè‡ªå¸¦å¥½ç”¨çš„è®¡ç®—å™¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/025_console.html" rel="nofollow"&gt;025ã€ŠConsoleã€‹Chromeè‡ªå¸¦å¥½ç”¨çš„è®¡ç®—å™¨&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c7bc7cabd06a453dbed2bae0a2bf08d5.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c7bc7cabd06a453dbed2bae0a2bf08d5.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Chromeè®¡ç®—æœºçš„å¥½ç”¨ä¹‹å¤„: æ—¢å¯ä»¥çœ‹åˆ°åŠ æ•°å­—çš„è®°å½•,ä¹Ÿå¯ä»¥å®æ—¶é¢„è§ˆè¿ç®—çš„ç»“æœ, è¾“å…¥å®Œæˆåè¿˜å¯ä»¥å¾ˆæ–¹ä¾¿çš„æ ¸æŸ¥ä¸€é, è¿˜æœ‰ä¸€ç‚¹: Chromeè®¡ç®—å™¨è§‚èµæ€§å¼º(é€¼æ ¼å¾ˆé«˜)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-024dark-readerä¸ºä»»æ„ç½‘ç«™å¯ç”¨å¤œé—´æ¨¡å¼" class="anchor" aria-hidden="true" href="#024dark-readerä¸ºä»»æ„ç½‘ç«™å¯ç”¨å¤œé—´æ¨¡å¼"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/024_dark_reader.html" rel="nofollow"&gt;024ã€ŠDark Readerã€‹ä¸ºä»»æ„ç½‘ç«™å¯ç”¨å¤œé—´æ¨¡å¼&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/35e84f58945d4775a31154ea4dc51cac.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/35e84f58945d4775a31154ea4dc51cac.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å–œæ¬¢å¤œé—´æ¨¡å¼çš„å°ä¼™ä¼´, Dark Readeråº”è¯¥å¯ä»¥æ»¡è¶³ä½ äº†~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5&gt;&lt;a id="user-content-023fireshotä¸€é”®æ»šåŠ¨æˆªå±æ•´ä¸ªç½‘é¡µ" class="anchor" aria-hidden="true" href="#023fireshotä¸€é”®æ»šåŠ¨æˆªå±æ•´ä¸ªç½‘é¡µ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/023_fireshot.html" rel="nofollow"&gt;023ã€ŠFireShotã€‹ä¸€é”®æ»šåŠ¨æˆªå±æ•´ä¸ªç½‘é¡µ&lt;/a&gt;&lt;/h5&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/81ac43fe1d6e454b93dc7f3ae57d96cd.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/81ac43fe1d6e454b93dc7f3ae57d96cd.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
æ€»ä½“æ¥è®², FireShotæ˜¯ä¸€æ¬¾ä¸é”™çš„è½¯ä»¶, å…è´¹ä¸”åŠŸèƒ½å¤Ÿç”¨, æ»šåŠ¨æˆªå›¾çš„åŠŸèƒ½æ¯”åŒç±»è½¯ä»¶åšçš„éƒ½è¦å¥½&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-022æ‰©å±•ç®¡ç†å™¨ç®¡ç†ä½ çš„chromeæ‰©å±•" class="anchor" aria-hidden="true" href="#022æ‰©å±•ç®¡ç†å™¨ç®¡ç†ä½ çš„chromeæ‰©å±•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/022kuo_zhan_guan_li_qi.html" rel="nofollow"&gt;022ã€Šæ‰©å±•ç®¡ç†å™¨ã€‹ç®¡ç†ä½ çš„Chromeæ‰©å±•&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0480fffebb10437c8d5555f085de9006.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0480fffebb10437c8d5555f085de9006.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
å¦‚æœChromeå®‰è£…çš„æ’ä»¶å¾ˆå¤š, æˆ‘ä»¬å¯ä»¥å¯¹æ’ä»¶è¿›è¡Œåˆ†ç»„, æŒ‰ç…§åœºæ™¯,å¯ç”¨ä¸åŒç»„çš„æ’ä»¶&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-021å“”å“©å“”å“©åŠ©æ‰‹åŠ©ä½ å¿«é€Ÿæˆä¸ºbç«™è€å¸æœº" class="anchor" aria-hidden="true" href="#021å“”å“©å“”å“©åŠ©æ‰‹åŠ©ä½ å¿«é€Ÿæˆä¸ºbç«™è€å¸æœº"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/021_bi_li_bi_li_zhu_shou.html" rel="nofollow"&gt;021ã€Šå“”å“©å“”å“©åŠ©æ‰‹ã€‹åŠ©ä½ å¿«é€Ÿæˆä¸ºBç«™è€å¸æœº&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6ccb9837b60d4d79814a8add20723d97.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6ccb9837b60d4d79814a8add20723d97.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å“”å“©å“”å“©åŠ©æ‰‹, åŠŸèƒ½å®ç”¨,å¼€å‘è€…ä¹Ÿä¸€ç›´ä¿æŒç€è¾ƒé«˜é¢‘ç‡çš„æ›´æ–°,å¯ä»¥æ”¾å¿ƒé£Ÿç”¨~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-020boxel-reboundå—¨åˆ°ä¸­æ¯’çš„å¼¹è·³å°æ–¹å—é™„è‡ªåˆ¶èµ›é“åˆ†äº«æ–¹æ³•" class="anchor" aria-hidden="true" href="#020boxel-reboundå—¨åˆ°ä¸­æ¯’çš„å¼¹è·³å°æ–¹å—é™„è‡ªåˆ¶èµ›é“åˆ†äº«æ–¹æ³•"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/020_boxel_rebound.html" rel="nofollow"&gt;020ã€ŠBoxel Reboundã€‹â€œå—¨åˆ°ä¸­æ¯’â€çš„å¼¹è·³å°æ–¹å—(é™„è‡ªåˆ¶èµ›é“åˆ†äº«æ–¹æ³•)&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dbc83cc53c26492db8843ff3e35fc75d.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dbc83cc53c26492db8843ff3e35fc75d.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
Boxel Reboundæ˜¯ä¸€ä¸ªåæå®¢çš„å°æ¸¸æˆ, ç©æ³•ç®€å•, å¯ä»¥è‡ªç”±åˆ›å»ºèµ›é“, åˆ†äº«èµ›é“, è·å–åˆ«äººçš„èµ›é“è¿›è¡ŒäºŒæ¬¡å¼€å‘; æ— è®ºä½ æ˜¯Macç”¨æˆ·,Windowsç”¨æˆ·,Linuxç”¨æˆ·, åªè¦å®‰è£…äº†Chromeæµè§ˆå™¨, å°±å¯ä»¥ç©è€Boxel Rebound&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-019megaç½‘ç›˜å¯ä»¥è‰¯å¿ƒåˆ°ä»€ä¹ˆç¨‹åº¦-è¯•è¯•megaå§" class="anchor" aria-hidden="true" href="#019megaç½‘ç›˜å¯ä»¥è‰¯å¿ƒåˆ°ä»€ä¹ˆç¨‹åº¦-è¯•è¯•megaå§"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/019_mega.html" rel="nofollow"&gt;019ã€ŠMEGAã€‹ç½‘ç›˜å¯ä»¥è‰¯å¿ƒåˆ°ä»€ä¹ˆç¨‹åº¦? è¯•è¯•MEGAå§!&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b5aea0b5e3c54f0a9a050a754a67093d.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b5aea0b5e3c54f0a9a050a754a67093d.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;æ²¡æœ‰é™é€Ÿçš„æ¦‚å¿µ(çœŸçš„è¢«ç™¾åº¦ç›˜çš„é™é€Ÿç­–ç•¥æ¶å¿ƒåˆ°äº†)&lt;/li&gt;
&lt;li&gt;åœ¨å›½å†…å¯ç”¨(googleè™½å¥½, ä½†å›½å†…ç”¨ä¸äº†, MEGAsyncäº²æµ‹å›½å†…å¯ç”¨)&lt;/li&gt;
&lt;li&gt;äº‘ç«¯åŠ å¯†, èµ„æºä¸ä¼šè¢«å°æ€&lt;/li&gt;
&lt;li&gt;å®˜æ–¹æä¾›äº†Linuxå®¢æˆ·ç«¯&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-018enhanced-githubä»å†°æŸœåˆ°å†°æ£å„¿ä¸‹è½½githubå•ä¸ªæ–‡ä»¶" class="anchor" aria-hidden="true" href="#018enhanced-githubä»å†°æŸœåˆ°å†°æ£å„¿ä¸‹è½½githubå•ä¸ªæ–‡ä»¶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/018_enhanced_github.html" rel="nofollow"&gt;018ã€ŠEnhanced Githubã€‹ä»â€œå†°æŸœâ€åˆ°â€œå†°æ£å„¿â€,ä¸‹è½½Githubå•ä¸ªæ–‡ä»¶&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/769a22f995d74226ba4104aba7e8ab59.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/769a22f995d74226ba4104aba7e8ab59.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/00541b7bd6954f8ea2a6a1beaebbb79b.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/00541b7bd6954f8ea2a6a1beaebbb79b.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
æˆ‘éœ€è¦Githubç»™æˆ‘ä¸€æ ¹å†°æ£è§£æš‘,Githubå´åšæŒæŠŠè£…æœ‰å†°æ£çš„å†°æŸœä¹Ÿé€ç»™æˆ‘ï¼ˆå“¥ä»¬å„¿çœŸå¤Ÿæ„æ€ï¼‰... æœ‰äº†Enhanced Githubè¿™æ¬¾æ’ä»¶, æˆ‘ä»¬å¯ä»¥ä¸‹è½½Githubä¼˜ç§€é¡¹ç›®ä¸­æœ€æ ¸å¿ƒçš„ä»£ç æ–‡ä»¶è¿›è¡Œå­¦ä¹ , è€Œä¸æ˜¯ ä¸‹è½½ æ•´ä¸ªä»“åº“ä½œä¸ºè—å“&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-017æ–°æµªå¾®åšå›¾åºŠæœ¬åœ°markdownç¼–å†™æ›´æµç•…-æ–°æµªå¾®åšå›¾åºŠæ¥å¸®å¿™" class="anchor" aria-hidden="true" href="#017æ–°æµªå¾®åšå›¾åºŠæœ¬åœ°markdownç¼–å†™æ›´æµç•…-æ–°æµªå¾®åšå›¾åºŠæ¥å¸®å¿™"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/017_xin_lang_wei_bo_tu_chuang.html" rel="nofollow"&gt;017ã€Šæ–°æµªå¾®åšå›¾åºŠã€‹æœ¬åœ°Markdownç¼–å†™æ›´æµç•…, æ–°æµªå¾®åšå›¾åºŠæ¥å¸®å¿™&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/48c12b3864f84e988e073209fd7cf8e4.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/48c12b3864f84e988e073209fd7cf8e4.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
ç”¨Markdownå†™æ–‡ç« , å¦‚æœæ–‡ç« ä¸­ä½¿ç”¨äº†æœ¬åœ°é…å›¾, é‚£æœ¬åœ°é…å›¾å°±è¦å’Œæ–‡ç« ä¸€èµ·æ‰“åŒ…,å¦åˆ™åˆ«äººæ˜¯çœ‹ä¸åˆ°å›¾ç‰‡çš„,å¦‚æœæŠŠæœ¬åœ°å›¾ç‰‡æ”¾åˆ°ç½‘ç»œæœåŠ¡å™¨, ç„¶åç›´æ¥æŠŠå›¾ç‰‡çš„urlç²˜è´´åˆ°æ–‡ç« é‡Œé¢, å°±å¯ä»¥å…é™¤å›¾ç‰‡æ‰“åŒ…çš„æ­¥éª¤&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-016è§£é™¤bç«™åŒºåŸŸé™åˆ¶æŸ¥çœ‹è¿›å‡»çš„å·¨äººç¬¬ä¸‰å­£" class="anchor" aria-hidden="true" href="#016è§£é™¤bç«™åŒºåŸŸé™åˆ¶æŸ¥çœ‹è¿›å‡»çš„å·¨äººç¬¬ä¸‰å­£"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/016_jie_chu_b_zhan_qu_yu_xian_zhi.html" rel="nofollow"&gt;016ã€Šè§£é™¤Bç«™åŒºåŸŸé™åˆ¶ã€‹æŸ¥çœ‹è¿›å‡»çš„å·¨äººç¬¬ä¸‰å­£&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/34d50d4d15094ca08e1bbd76c477122a.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/34d50d4d15094ca08e1bbd76c477122a.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/99fd518796894945aa87225a5022c453.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/99fd518796894945aa87225a5022c453.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
è§£é™¤Bç«™åŒºåŸŸé™åˆ¶,Bç«™è€å¸æœºå¿…å¤‡æŠ€èƒ½&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-015xpath-helperå®Œæˆbingæ¯æ—¥å£çº¸çš„å°çˆ¬è™«" class="anchor" aria-hidden="true" href="#015xpath-helperå®Œæˆbingæ¯æ—¥å£çº¸çš„å°çˆ¬è™«"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/015_xpath_helper.html" rel="nofollow"&gt;015ã€ŠXPath Helperã€‹å®ŒæˆBingæ¯æ—¥å£çº¸çš„å°çˆ¬è™«&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/308bec78f4674130b85a5852f0b25a88.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/308bec78f4674130b85a5852f0b25a88.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;XPathæ˜¯ä¸€ä¸ªè¾…åŠ©æˆ‘ä»¬å†™çˆ¬è™«çš„å°æ’ä»¶, æˆ‘ä»¬å¯ä»¥ç”¨XPathè¾…åŠ©æˆ‘ä»¬å®Œæˆä¸€ä¸ªBingå£çº¸çš„å°çˆ¬è™«~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-014è¶…çº§é©¬é‡Œå¥¥æ¸¸æˆchromeå˜èº«å°éœ¸ç‹" class="anchor" aria-hidden="true" href="#014è¶…çº§é©¬é‡Œå¥¥æ¸¸æˆchromeå˜èº«å°éœ¸ç‹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/014_chao_ji_ma_li_ao_you_xi.html" rel="nofollow"&gt;014ã€Šè¶…çº§é©¬é‡Œå¥¥æ¸¸æˆã€‹Chromeå˜èº«å°éœ¸ç‹&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/008f3bd3c8b8483b9d70be5d5ed4f9ee.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/008f3bd3c8b8483b9d70be5d5ed4f9ee.gif" alt="è¶…çº§ç›ä¸½.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;ç”¨Chromeç©è¶…çº§é©¬é‡Œå¥¥æ˜¯ä¸€ç§ä»€ä¹ˆä½“éªŒ? å“ˆå“ˆ, å¥½ç©! ã€Šè¶…çº§é©¬é‡Œå¥¥æ¸¸æˆã€‹è¿™æ¬¾æ’ä»¶,å¯ä»¥è®©ä½ æ‰“å¼€Chrome, éšæ—¶ç©ä¸€å±€è¶…çº§ç›ä¸½, å˜¿å˜¿&lt;g-emoji class="g-emoji" alias="yum" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f60b.png"&gt;ğŸ˜‹&lt;/g-emoji&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-013quick-qrç”¨äºŒç»´ç å®ç°äº‘ç²˜è´´" class="anchor" aria-hidden="true" href="#013quick-qrç”¨äºŒç»´ç å®ç°äº‘ç²˜è´´"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/013_quick_qr.html" rel="nofollow"&gt;013ã€ŠQuick QRã€‹ç”¨äºŒç»´ç å®ç°äº‘ç²˜è´´&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b59f299316624e86aa7cdd379a02aac4.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b59f299316624e86aa7cdd379a02aac4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;é€šè¿‡Quick QR, æˆ‘ä»¬å¯ä»¥ä¸å€ŸåŠ©ä»»ä½•é€šè®¯è½¯ä»¶,é€šè¿‡æ‰‹æœºæ‰«ç ,è·å–PCæµè§ˆå™¨ä¸Šä»»æ„ä¸€æ®µæ–‡å­—ä¿¡æ¯(äº‘ç²˜è´´æ¿å“¦~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-012ourstickyschromeç‰¹è‰²ç½‘é¡µä¾¿ç­¾çº¸" class="anchor" aria-hidden="true" href="#012ourstickyschromeç‰¹è‰²ç½‘é¡µä¾¿ç­¾çº¸"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/012_ourstickys.html" rel="nofollow"&gt;012ã€ŠOurStickysã€‹Chromeç‰¹è‰²ç½‘é¡µä¾¿ç­¾çº¸&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/62597d60ffd6443396725c9677951221.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/62597d60ffd6443396725c9677951221.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å‘ä¼—äººä»‹ç»å–œæ¬¢çš„ç½‘é¡µåŠŸèƒ½æ—¶,å¯ä»¥è¾¹è®²,è¾¹å‘ç½‘é¡µæ‰“ä¾¿ç­¾,è¿™æ ·æ—¢èƒ½è®©äººçœ¼å‰ä¸€äº®,ä¹Ÿè®©å¬ä¼—å®¹æ˜“æŠ“ä½é‡ç‚¹~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-011-whatrunsä¸€é”®åˆ†æç½‘ç«™æŠ€æœ¯æ ˆ" class="anchor" aria-hidden="true" href="#011-whatrunsä¸€é”®åˆ†æç½‘ç«™æŠ€æœ¯æ ˆ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/011_whatruns.html" rel="nofollow"&gt;011 ã€Šwhatrunsã€‹ä¸€é”®åˆ†æç½‘ç«™æŠ€æœ¯æ ˆ&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/28cc002358c647878b54f9bcaaf67a0a.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/28cc002358c647878b54f9bcaaf67a0a.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å¦‚æœä½ å¯¹å½“å‰æµè§ˆçš„ç½‘ç«™éå¸¸æ„Ÿå…´è¶£, å¯ä»¥é€šè¿‡whatrunsäº†è§£è½¯ä»¶çš„æŠ€æœ¯æ ˆ, æ¯”å¦‚çœ‹çœ‹è¿™ä¸ªåä¸ºfacebookç”¨äº†ä»€ä¹ˆæŠ€æœ¯&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-010speedtestç½‘ç»œæµ‹é€Ÿæ’ä»¶speedtest" class="anchor" aria-hidden="true" href="#010speedtestç½‘ç»œæµ‹é€Ÿæ’ä»¶speedtest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/010_speedtest.html" rel="nofollow"&gt;010ã€Šspeedtestã€‹ç½‘ç»œæµ‹é€Ÿæ’ä»¶speedtest&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9aa1e5323a6a4cbcb96304b33a5261c8.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9aa1e5323a6a4cbcb96304b33a5261c8.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å½“ä¸Šç½‘é€Ÿåº¦å¾ˆæ…¢çš„æ—¶å€™, äººä»¬æƒ³åˆ°çš„ç¬¬ä¸€ä»¶äº‹å°±è¿›è¡Œç½‘ç»œæµ‹é€Ÿ,åœ¨windowä¸Š, åªè¦ä½ å®‰è£…äº†360å…¨å®¶æ¡¶, æµ‹é€ŸåŠŸèƒ½å°±æ˜¯é»˜è®¤å®‰è£…çš„, ä½†æµ‹é€Ÿè¿™ç§åŠŸèƒ½æ ¹æœ¬ä¸éœ€è¦å®‰è£…åˆ°æœ¬åœ°, äº¤ç»™æµè§ˆå™¨å°±å¥½äº†&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-009vimiumchromeä¸vimåŒç¥å™¨èåˆ" class="anchor" aria-hidden="true" href="#009vimiumchromeä¸vimåŒç¥å™¨èåˆ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/009_vimium.html" rel="nofollow"&gt;009ã€Švimiumã€‹Chromeä¸vimåŒç¥å™¨èåˆ&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/7d6e9fadef3f48409c81a8c76d24e0cc.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/7d6e9fadef3f48409c81a8c76d24e0cc.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;vimiumå¯ä»¥è®©æˆ‘ä»¬åªä½¿ç”¨é”®ç›˜å°±å¯ä»¥æµè§ˆç½‘é¡µ, å¦‚æœä½ ç¬¬ä¸€æ¬¡çœ‹åˆ°æœ‰äººä½¿ç”¨vimium, å®ƒçš„æ“ä½œæ–¹å¼ç»å¯¹èƒ½è®©ä½ æ„Ÿåˆ°æƒŠè‰³~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-008chrome-cleaner-proä¸ºchromeåŠ é€Ÿ" class="anchor" aria-hidden="true" href="#008chrome-cleaner-proä¸ºchromeåŠ é€Ÿ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/008_chrome_cleaner_pro.html" rel="nofollow"&gt;008ã€ŠChrome Cleaner Proã€‹ä¸ºChromeåŠ é€Ÿ&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/30899ae22f644a9bb62eb8b24d75c884.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/30899ae22f644a9bb62eb8b24d75c884.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Chromeç»è¿‡æœ€è¿‘å‡ å¹´çš„å‘å±•, å¼ºåŠ›çš„æ‰©å±•è¶Šæ¥è¶Šå¤š, ç¦»Chrome OSçš„ç›®æ ‡ä¹Ÿè¶Šæ¥è¶Šè¿‘, è½¯ä»¶åšå¤§äº†å°±ä¼šæœ‰ç±»ä¼¼Windowsçš„é€šç—…, è½¯ä»¶ä¼šå˜æ…¢, è®©Chromeå˜å¿«çš„æœ€ç®€å•æ–¹å¼å°±æ˜¯æ¸…ç†åƒåœ¾, è€ŒChrome Cleaner Proèµ°çš„æ˜¯ä¸€é”®æ¸…ç†çš„è·¯å­~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-007loom-chromeç¿»å½•ç½‘é¡µè§†é¢‘ç¥å™¨" class="anchor" aria-hidden="true" href="#007loom-chromeç¿»å½•ç½‘é¡µè§†é¢‘ç¥å™¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/007_loom.html" rel="nofollow"&gt;007ã€Šloomã€‹ Chromeç¿»å½•ç½‘é¡µè§†é¢‘ç¥å™¨&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/4058cf0008074c5f86b8eb1684e7a1a0.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/4058cf0008074c5f86b8eb1684e7a1a0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Loomå¯ä»¥ä¸€é”®å½•åˆ¶æµè§ˆå™¨çš„å•ä¸ªæ ‡ç­¾é¡µ(ç›—ç‰ˆç¿»å½•è§†é¢‘çš„ç¥å™¨), å½•åˆ¶å®Œæˆåè‡ªåŠ¨ç”Ÿæˆåœ¨çº¿ç½‘é¡µ,è¿›è¡Œè§†é¢‘æ’­æ”¾, å¯ä»¥ä¸‹è½½åˆšåˆšå½•åˆ¶çš„è§†é¢‘, ä¹Ÿå¯ä»¥ä¸ºåˆšåˆšç”Ÿæˆçš„åœ¨çº¿è§†é¢‘è®¾ç½®å¯†ç (ç›—ç‰ˆå½•å±åŠ å‘å¸ƒä¸€æ¡é¾™æœåŠ¡~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-006similarsites-ä¸€é”®æŸ¥æ‰¾å§Šå¦¹ç½‘ç«™-similarsites" class="anchor" aria-hidden="true" href="#006similarsites-ä¸€é”®æŸ¥æ‰¾å§Šå¦¹ç½‘ç«™-similarsites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/006_similarsites.html" rel="nofollow"&gt;006ã€ŠSimilarSitesã€‹ ä¸€é”®æŸ¥æ‰¾å§Šå¦¹ç½‘ç«™ SimilarSites&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/26c6c604be1c41e88ebfe79c733173b0.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/26c6c604be1c41e88ebfe79c733173b0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å½“ä½ æµè§ˆä¸€ä¸ªå¾ˆæ£’çš„ç«™ç‚¹çš„æ—¶å€™, æˆ–è®¸ä½ ä¼šæƒ³åˆ°, å’Œå®ƒ"å·®ä¸å¤š"çš„ç«™ç‚¹æœ‰å“ªäº›, å°¤å…¶æ˜¯é’ˆå¯¹ä¸€äº›èµ„æºç«™ç‚¹, è¿™ä¸ªç«™ç‚¹æ²¡æœ‰, è€Œå®ƒåŒç±»çš„ç«™ç‚¹"å¾€å¾€æœ‰"! SimilarSites, å®ƒçš„ä½œç”¨åªæœ‰ä¸€ä¸ª, å‘ç°åŒç±»ç«™ç‚¹!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-005video-speed-controller-åˆ·è¯¾åˆ·å‰§ç¥å™¨ç»™ç½‘é¡µè§†é¢‘åŠ ä¸ªé€Ÿæœ€å¿«å¯è¾¾16å€" class="anchor" aria-hidden="true" href="#005video-speed-controller-åˆ·è¯¾åˆ·å‰§ç¥å™¨ç»™ç½‘é¡µè§†é¢‘åŠ ä¸ªé€Ÿæœ€å¿«å¯è¾¾16å€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/005_video_speed_controller.html" rel="nofollow"&gt;005ã€ŠVideo Speed Controllerã€‹ åˆ·è¯¾ï¼ˆåˆ·å‰§ï¼‰ç¥å™¨ï¼ç»™ç½‘é¡µè§†é¢‘åŠ ä¸ªé€Ÿ(æœ€å¿«å¯è¾¾16å€!)&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/083c51a1c32a4ad6931646bb005fd5a3.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/083c51a1c32a4ad6931646bb005fd5a3.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;åˆ·ä¸€äº›æ²¡è¥å…»è§†é¢‘çš„æ—¶å€™, æˆ‘ä»¬ä¼šæœ‰å€é€Ÿæ’­æ”¾è§†é¢‘çš„éœ€æ±‚, è€Œç½‘ç«™çš„åœ¨çº¿æ’­æ”¾å™¨ä¸€èˆ¬åªæä¾›ä¸é«˜äº4å€çš„æ’­æ”¾é€Ÿåº¦, è€ŒVideo Speed Controllerå¯ä»¥å°†è§†é¢‘æ’­æ”¾é€Ÿåº¦æé«˜åˆ°16å€é€Ÿ~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-004tampermonkey-æ²¹çŒ´å­-ç»™æµè§ˆå™¨å¼€ä¸ªæŒ‚" class="anchor" aria-hidden="true" href="#004tampermonkey-æ²¹çŒ´å­-ç»™æµè§ˆå™¨å¼€ä¸ªæŒ‚"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/004_tampermonkey.html" rel="nofollow"&gt;004ã€ŠTampermonkeyã€‹ æ²¹çŒ´å­! ç»™æµè§ˆå™¨å¼€ä¸ªæŒ‚&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e87601eb459549b3b8e33994fc3fdfb4.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e87601eb459549b3b8e33994fc3fdfb4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;æ²¹çŒ´å­å¿…å¤‡æˆä¸ºChromeçš„ç¬¬äºŒåº”ç”¨å•†åº—, æœ‰äº†æ²¹çŒ´å­, ä½ å¯ä»¥å…è´¹æŸ¥çœ‹VIPè§†é¢‘, æ¸…é™¤å„ç§ç½‘é¡µå¹¿å‘Š, åœ¨è±†ç“£å½±è¯„é¡µé¢æ˜¾ç¤ºç”µå½±èµ„æºçš„ä¸‹è½½åœ°å€~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-003secure-shell-app-chromeä¸­å¼€å¯sshä¸€ç§ä»€ä¹ˆä½“éªŒ" class="anchor" aria-hidden="true" href="#003secure-shell-app-chromeä¸­å¼€å¯sshä¸€ç§ä»€ä¹ˆä½“éªŒ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/003_secure_shell_app.html" rel="nofollow"&gt;003ã€ŠSecure Shell Appã€‹ Chromeä¸­å¼€å¯sshä¸€ç§ä»€ä¹ˆä½“éªŒ&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/87b66b4cbd12426bbab65a3443f1f1ec.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/87b66b4cbd12426bbab65a3443f1f1ec.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;å¾ˆå¤šå°ç™½æƒ³è¦é€šè¿‡è´­ä¹°æœåŠ¡å™¨æ­å»ºè‡ªå·±çš„VPN, è´­ä¹°æœåŠ¡å™¨å, ç¬¬ä¸€æ­¥å°±æ˜¯è¦é€šè¿‡sshç™»å½•æœåŠ¡å™¨, è€ŒWindowså¹¶æ²¡æœ‰è‡ªå¸¦sshè½¯ä»¶,ç°åœ¨ä½ æ— éœ€ä¸‹è½½puttyæˆ–xshell ,å¯ä»¥é€šè¿‡è¿™æ¬¾Secure Shell Appåœ¨chromeç›´æ¥å®ç°sshç™»å½•æœåŠ¡å™¨äº†&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-002-chrono-è®©chromeä¸‹è½½èµ„æºæ›´å®¹æ˜“" class="anchor" aria-hidden="true" href="#002-chrono-è®©chromeä¸‹è½½èµ„æºæ›´å®¹æ˜“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/002_chrono.html" rel="nofollow"&gt;002 ã€Šchronoã€‹ è®©Chromeä¸‹è½½èµ„æºæ›´å®¹æ˜“&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b574ee1798984ff49396837b620f51ef.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b574ee1798984ff49396837b620f51ef.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;chronoå¯ä»¥éå¸¸æ–¹ä¾¿çš„å—…æ¢è¯†åˆ«ç½‘é¡µä¸­çš„èµ„æº, ç„¶åä¸€é”®ä¸‹è½½æ‰€æœ‰èµ„æº(æ”¶å›¾å–½!)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-001markdown-here-markdownä¸€é”®è½¬æ¢åˆ°å¯Œæ–‡æœ¬æ ¼å¼" class="anchor" aria-hidden="true" href="#001markdown-here-markdownä¸€é”®è½¬æ¢åˆ°å¯Œæ–‡æœ¬æ ¼å¼"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/001_markdown_here.html" rel="nofollow"&gt;001ã€Šmarkdown-hereã€‹ Markdownä¸€é”®è½¬æ¢åˆ°"å¯Œæ–‡æœ¬æ ¼å¼"&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fc5de2eb22184a138c618728cfb40ede.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fc5de2eb22184a138c618728cfb40ede.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;æœ‰äº†markdown-hereè¿™ä¸ªæ’ä»¶, å¯ä»¥åœ¨ç½‘é¡µç‰ˆ QQé‚®ç®±, Gmail, æ–°æµªå¤´æ¡æ–‡ç« , é‡Œé¢ä½¿ç”¨mardownæ ¼å¼è¿›è¡Œä¹¦å†™,ç„¶åä¸€é”®è½¬æ¢ä¸ºå¯Œæ–‡æœ¬&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-ä»–äººçœ¼ä¸­çš„-chromeæ’ä»¶è‹±é›„æ¦œå•†ä¸šäº’å¹æ¨¡å—" class="anchor" aria-hidden="true" href="#ä»–äººçœ¼ä¸­çš„-chromeæ’ä»¶è‹±é›„æ¦œå•†ä¸šäº’å¹æ¨¡å—"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ä»–äººçœ¼ä¸­çš„ Chromeæ’ä»¶è‹±é›„æ¦œ(å•†ä¸šäº’å¹æ¨¡å—)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/88386634" rel="nofollow"&gt;ã€Šè¿™ä»½â€œæ’ä»¶è‹±é›„æ¦œTop20â€æ‰æ˜¯Chromeçš„æ­£ç¡®æ‰“å¼€æ–¹å¼ï¼ã€‹&lt;/a&gt; ä½œè€…: &lt;a href="https://me.csdn.net/dQCFKyQDXYm3F8rB0" rel="nofollow"&gt;AIç§‘æŠ€å¤§æœ¬è¥&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58636515" rel="nofollow"&gt;ã€ŠChrome æ’ä»¶è‹±é›„æ¦œã€‹&lt;/a&gt; ä½œè€…: &lt;a href="https://www.zhihu.com/people/loonggg/activities" rel="nofollow"&gt;éè‘—åç¨‹åºå‘˜&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://openingsource.org/6190/zh-tw/" rel="nofollow"&gt;ã€Šé–‹æºæ—¥å ±ç¬¬363æœŸã€‹&lt;/a&gt; ä½œè€…: &lt;a href="https://openingsource.org/" rel="nofollow"&gt;å¼€æºå·¥å‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/Y-9ht-E7-OdJOEDDb3yyWw" rel="nofollow"&gt;ã€Šä¸€æ ¹ç«æŸ´çš„Nç§æ‰“å¼€æ–¹å¼ã€‹&lt;/a&gt; ä½œè€…: &lt;a href="https://github.com/LuoJiangYong"&gt;è€ç½—å·´æ‰å˜¿&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-åå­—èµ·å•¥å¥½" class="anchor" aria-hidden="true" href="#åå­—èµ·å•¥å¥½"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;åå­—èµ·å•¥å¥½?&lt;/h2&gt;
&lt;p&gt;å°†è¿™ä¸ªä»“åº“å‘½åä¸º&lt;strong&gt;Chromeæ‰©å±•è‹±é›„æ¦œ&lt;/strong&gt;å¯èƒ½æ›´å‡†ç¡®äº›,ä½†&lt;strong&gt;æ’ä»¶&lt;/strong&gt;è¿™ä¸ªåè¯, æ›´é€šä¿—æ˜“æ‡‚, æ‰€ä»¥å°±ä½¿ç”¨äº†&lt;strong&gt;Chromeæ’ä»¶è‹±é›„æ¦œ&lt;/strong&gt;è¿™ä¸ªå‘½å ,æ„Ÿè°¢@&lt;a href="https://github.com/hjthjthjt"&gt;hjthjthjt&lt;/a&gt; ç»™å‡ºçš„&lt;a href="https://github.com/zhaoolee/ChromeAppHeroes/issues/14"&gt;issue&lt;/a&gt;çº æ­£&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-æ¨èå§Šå¦¹ä»“åº“" class="anchor" aria-hidden="true" href="#æ¨èå§Šå¦¹ä»“åº“"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;æ¨èå§Šå¦¹ä»“åº“&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;æœ¬ä»“åº“çš„å§Šå¦¹ç¯‡:**&lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;ã€ŠGithubæ˜Ÿèšå¼ƒç–—æ¦œã€‹&lt;/a&gt;**ä¸ºGithubåˆ›æ„é¡¹ç›®å†™ä¸€æœ¬æ¨èä¹¦ï¼Œè®©Githubä¼˜ç§€é¡¹ç›®é€ ç¦äººç±»~ å·²å¼€æºåˆ°Github: &lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;https://github.com/zhaoolee/StarsAndClown&lt;/a&gt; åŒæ ·æœ‰è¶£æœ‰æ–™å“¦~&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-æ„Ÿè°¢" class="anchor" aria-hidden="true" href="#æ„Ÿè°¢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ„Ÿè°¢&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;æ„Ÿè°¢ æ˜é‡‘æ²¸ç‚¹è¿è¥ &lt;a href="https://juejin.im/user/5b39bd7de51d4558d43ff06d" rel="nofollow"&gt;@æ¸…è’¸ä¸æ˜¯æ°´ç…®&lt;/a&gt; ç»™å‡ºçš„ &lt;strong&gt;æ­£é¢æœ€å¼€å§‹æ”¾ä¸ªç´¢å¼•ç›®å½•æ¯”è¾ƒå¥½&lt;/strong&gt; çš„å°å»ºè®®&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;æ„Ÿè°¢&lt;a href="https://www.jianshu.com/" rel="nofollow"&gt;ç®€ä¹¦&lt;/a&gt;ç¤¾åŒºæä¾›è¶…æ£’çš„Markdownç¼–è¾‘å™¨,&lt;strong&gt;Chromeæ’ä»¶è‹±é›„æ¦œ&lt;/strong&gt;çš„ç¼–è¾‘å·¥ä½œ,å‡ ä¹å…¨éƒ¨ç”±é€šè¿‡ç®€ä¹¦ç¼–è¾‘å™¨å®Œæˆ&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;** emm... &lt;a href="https://zhaoolee.com/ChromeAppHeroes/download_the_chrome_extension_from_the_store.html" rel="nofollow"&gt;ä»å®˜æ–¹å•†åº—ä¸‹è½½Chromeæ’ä»¶çš„æ–¹æ³•&lt;/a&gt;**&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chromeæ’ä»¶è‹±é›„æ¦œ&lt;/strong&gt; Githubåœ°å€: &lt;a href="https://github.com/zhaoolee/ChromeAppHeroes"&gt;https://github.com/zhaoolee/ChromeAppHeroes&lt;/a&gt;
æˆ‘éœ€è¦ä½ çš„æ”¯æŒ, å¸Œæœ›ä½ èƒ½ä¸ºæœ¬é¡¹ç›®å¡«åŠ ä¸€ä¸ª &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;ğŸŒŸ&lt;/g-emoji&gt;æ˜Ÿ.
I need your support, I hope you can add a star &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;ğŸŒŸ&lt;/g-emoji&gt; to this project.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ä¸€æ ¹ç«æŸ´çš„nç§æ‰“å¼€æ–¹å¼è°·ç²’æ–‡åŒ–" class="anchor" aria-hidden="true" href="#ä¸€æ ¹ç«æŸ´çš„nç§æ‰“å¼€æ–¹å¼è°·ç²’æ–‡åŒ–"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/meaning_of_gu_li.html" rel="nofollow"&gt;ä¸€æ ¹ç«æŸ´çš„Nç§æ‰“å¼€æ–¹å¼(è°·ç²’æ–‡åŒ–)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg" alt="smartmockups_juunlhbe.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dc9ab48d958843c98f2a4c9336cff748.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dc9ab48d958843c98f2a4c9336cff748.png" alt="2.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-é¡¹ç›®ç›¸å…³é˜…è¯»" class="anchor" aria-hidden="true" href="#é¡¹ç›®ç›¸å…³é˜…è¯»"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;é¡¹ç›®ç›¸å…³é˜…è¯»&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/chrome_extended_resources_site.html" rel="nofollow"&gt;Chromeæ‰©å±•èµ„æºç«™ç‚¹æ¨è&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zhaoolee</author><guid isPermaLink="false">https://github.com/zhaoolee/ChromeAppHeroes</guid><pubDate>Wed, 20 Nov 2019 00:02:00 GMT</pubDate></item><item><title>Kayzaks/HackingNeuralNetworks #3 in Python, Today</title><link>https://github.com/Kayzaks/HackingNeuralNetworks</link><description>&lt;p&gt;&lt;i&gt;A small course on exploiting and defending neural networks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-hacking-neural-networks-a-short-introduction" class="anchor" aria-hidden="true" href="#hacking-neural-networks-a-short-introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hacking Neural Networks: A Short Introduction&lt;/h1&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Disclaimer: This article and all the associated exercises are for educational purposes only.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is a short introduction on methods that use neural networks in an offensive manner (bug hunting, shellcode obfuscation, etc.) and how to exploit neural networks found in the wild (information extraction, malware injection, backdooring, etc.).&lt;/p&gt;
&lt;p&gt;Most of the methods presented are accompanied by an exercise found in this repo. The full article can be found here in '&lt;a href="Article.pdf"&gt;Article.pdf&lt;/a&gt;' or on arXiv (&lt;a href="https://arxiv.org/pdf/1911.07658.pdf" rel="nofollow"&gt;arXiv:1911.07658&lt;/a&gt;).&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-python-and-pip" class="anchor" aria-hidden="true" href="#python-and-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python and pip&lt;/h3&gt;
&lt;p&gt;Download and install Python3 and its package installer pip using a package manager or directly from the website &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;https://www.python.org/downloads/&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-editor" class="anchor" aria-hidden="true" href="#editor"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Editor&lt;/h3&gt;
&lt;p&gt;An editor is required to work with the code, preferably one that allows code highlighting for Python. Vim/Emacs will do. As a reference, all exercises were prepared using Visual Studio Code &lt;a href="https://code.visualstudio.com/docs/python/python-tutorial" rel="nofollow"&gt;https://code.visualstudio.com/docs/python/python-tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-packages" class="anchor" aria-hidden="true" href="#packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Packages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Keras&lt;/strong&gt;: Installing Keras can be tricky. We refer to the official installation guide at &lt;a href="https://keras.io/#installation" rel="nofollow"&gt;https://keras.io/#installation&lt;/a&gt; and suggest TensorFlow as a backend (using the GPU-enabled version, if one is available on the machine).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NumPy&lt;/strong&gt; and &lt;strong&gt;SciPy&lt;/strong&gt;: NumPy and SciPy are excellent helper packages, which are used throughout all exercises. Following the official SciPy instructions should also install NumPy &lt;a href="https://www.scipy.org/install.html" rel="nofollow"&gt;https://www.scipy.org/install.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyCuda&lt;/strong&gt;: PyCuda is required for the GPU-based attack exercise. If no nVidia GPU is available on the machine, this can be skipped. &lt;a href="https://wiki.tiker.net/PyCuda/Installation" rel="nofollow"&gt;https://wiki.tiker.net/PyCuda/Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NLTK&lt;/strong&gt;: NLTK provides functionalities for natural language processing and is very helpful for some of the exercises. &lt;a href="https://www.nltk.org/install.html" rel="nofollow"&gt;https://www.nltk.org/install.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-the-exercises" class="anchor" aria-hidden="true" href="#the-exercises"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The exercises&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;0 - Last Layer Attack&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;1 - Backdooring&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2 - Extracting Information&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;3 - Brute Forcing&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;4 - Neural Overflow&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;5 - Malware Injection&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;6 - Neural Obfuscation&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;7 - Bug Hunting&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;8 - GPU Attack&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For instructions, please read the 'README.md' file in each of the exercise directories.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-further-reading--watching" class="anchor" aria-hidden="true" href="#further-reading--watching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Further Reading / Watching&lt;/h2&gt;
&lt;p&gt;Check out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Isao Takaesu's course on &lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Security_and_MachineLearning"&gt;Security and Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Will Pearce and Nick Landers' &lt;a href="https://www.youtube.com/watch?v=CsvkYoxtexQ" rel="nofollow"&gt;Talk at Derbycon 2019&lt;/a&gt; on Offensive Machine Learning techniques.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-what-else" class="anchor" aria-hidden="true" href="#what-else"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What else?&lt;/h2&gt;
&lt;p&gt;The neural networks found in the exercises are based on the examples provided by &lt;a href="https://keras.io/" rel="nofollow"&gt;keras&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you find that there are errors or missing references, feel free to make a PR or contact me.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Kayzaks</author><guid isPermaLink="false">https://github.com/Kayzaks/HackingNeuralNetworks</guid><pubDate>Wed, 20 Nov 2019 00:03:00 GMT</pubDate></item><item><title>modin-project/modin #4 in Python, Today</title><link>https://github.com/modin-project/modin</link><description>&lt;p&gt;&lt;i&gt;Modin: Speed up your Pandas workflows by changing a single line of code&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;&lt;a href="https://modin.readthedocs.io" rel="nofollow"&gt;&lt;img width="77%" alt="" src="https://github.com/modin-project/modin/raw/3d6368edf311995ad231ec5342a51cd9e4e3dc20/docs/img/MODIN_ver2_hrz.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-scale-your-pandas-workflows-by-changing-one-line-of-code" class="anchor" aria-hidden="true" href="#scale-your-pandas-workflows-by-changing-one-line-of-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scale your pandas workflows by changing one line of code&lt;/h2&gt;
&lt;p align="center"&gt;
&lt;a href="https://discuss.modin.org" rel="nofollow"&gt;&lt;img alt="" src="https://camo.githubusercontent.com/6cc9f05fe09a8ebcba0aa3f33fdca8309d766b8e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f757273652d666f72756d2d707572706c652e7376673f6c6f676f3d646973636f75727365266c6f676f436f6c6f723d7768697465" align="center" data-canonical-src="https://img.shields.io/badge/discourse-forum-purple.svg?logo=discourse&amp;amp;logoColor=white" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/modin-project/modin" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/88a250fb24777d5d5ed61bb529af58364455c168/68747470733a2f2f636f6465636f762e696f2f67682f6d6f64696e2d70726f6a6563742f6d6f64696e2f6272616e63682f6d61737465722f67726170682f62616467652e737667" align="center" data-canonical-src="https://codecov.io/gh/modin-project/modin/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/modin-project/modin/actions"&gt;&lt;img src="https://github.com/modin-project/modin/workflows/Modin_CI/badge.svg" align="center" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://modin.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img alt="" src="https://camo.githubusercontent.com/0fc8d6d44205d9e22194150d5dd93540476e196a/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6d6f64696e2f62616467652f3f76657273696f6e3d6c6174657374" align="center" data-canonical-src="https://readthedocs.org/projects/modin/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://modin.readthedocs.io/en/latest/pandas_supported.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1b407ae701085ca3e88680f6f5eb24043675c897/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70616e646173253230617069253230636f7665726167652d37312e37372532352d6f72616e67652e737667" align="center" data-canonical-src="https://img.shields.io/badge/pandas%20api%20coverage-71.77%25-orange.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/modin/" rel="nofollow"&gt;&lt;img alt="" src="https://camo.githubusercontent.com/8c41d5714e8c7f91e2b30b58e24991b15e66cc7c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692d302e362e332d626c75652e737667" align="center" data-canonical-src="https://img.shields.io/badge/pypi-0.6.3-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;&lt;b&gt;To use Modin, replace the pandas import:&lt;/b&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; import pandas as pd&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;p&gt;Modin can be installed from PyPI:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install modin&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you don't have &lt;a href="https://github.com/ray-project/ray"&gt;Ray&lt;/a&gt; or
&lt;a href="https://github.com/dask/dask"&gt;Dask&lt;/a&gt; installed, you will need to install Modin with one
of the targets:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install modin[ray] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Install Modin dependencies and Ray to run on Ray&lt;/span&gt;
pip install modin[dask] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Install Modin dependencies and Dask to run on Dask&lt;/span&gt;
pip install modin[all] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Install all of the above&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Modin will automatically detect which engine you have installed and use that for
scheduling computation!&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-choosing-a-compute-engine" class="anchor" aria-hidden="true" href="#choosing-a-compute-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Choosing a Compute Engine&lt;/h5&gt;
&lt;p&gt;If you want to choose a specific compute engine to run on, you can set the environment
variable &lt;code&gt;MODIN_ENGINE&lt;/code&gt; and Modin will do computation with that engine:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; MODIN_ENGINE=ray  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Ray&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; MODIN_ENGINE=dask  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Dask&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This can also be done within a notebook/interpreter before you import Modin:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; os

os.environ[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MODIN_ENGINE&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;ray&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Ray&lt;/span&gt;
os.environ[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MODIN_ENGINE&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dask&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Dask&lt;/span&gt;

&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note: You should not change the engine after you have imported Modin as it will result in undefined behavior&lt;/strong&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-which-engine-should-i-use" class="anchor" aria-hidden="true" href="#which-engine-should-i-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Which engine should I use?&lt;/h5&gt;
&lt;p&gt;If you are on Windows, you must use Dask. Ray does not support Windows. If you are on
Linux or Mac OS, you can install and use either engine.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-full-documentation" class="anchor" aria-hidden="true" href="#full-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Full Documentation&lt;/h3&gt;
&lt;p&gt;Visit the complete documentation on readthedocs: &lt;a href="https://modin.readthedocs.io" rel="nofollow"&gt;https://modin.readthedocs.io&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-scale-your-pandas-workflow-by-changing-a-single-line-of-code" class="anchor" aria-hidden="true" href="#scale-your-pandas-workflow-by-changing-a-single-line-of-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scale your pandas workflow by changing a single line of code.&lt;/h3&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np

frame_data &lt;span class="pl-k"&gt;=&lt;/span&gt; np.random.randint(&lt;span class="pl-c1"&gt;0&lt;/span&gt;, &lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;10&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;8&lt;/span&gt;))
df &lt;span class="pl-k"&gt;=&lt;/span&gt; pd.DataFrame(frame_data)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To use Modin, you do not need to know how many cores your system has and you do not need
to  specify how to distribute the data. In fact, you can continue using your previous
pandas notebooks while experiencing a considerable speedup from Modin, even on a single
machine. Once youâ€™ve changed your import statement, youâ€™re ready to use Modin just like
you would pandas.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-faster-pandas-even-on-your-laptop" class="anchor" aria-hidden="true" href="#faster-pandas-even-on-your-laptop"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Faster pandas, even on your laptop&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/modin-project/modin/blob/master/docs/img/read_csv_benchmark.png?raw=true"&gt;&lt;img align="right" height="350" width="300" src="https://github.com/modin-project/modin/raw/master/docs/img/read_csv_benchmark.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;modin.pandas&lt;/code&gt; DataFrame is an extremely light-weight parallel DataFrame. Modin
transparently distributes the data and computation so that all you need to do is
continue using the pandas API as you were before installing Modin. Unlike other parallel
DataFrame systems, Modin is an extremely light-weight, robust DataFrame. Because it is
so light-weight, Modin provides speed-ups of up to 4x on a laptop with 4 physical cores.&lt;/p&gt;
&lt;p&gt;In pandas, you are only able to use one core at a time when you are doing computation of
any kind. With Modin, you are able to use all of the CPU cores on your machine. Even in
&lt;code&gt;read_csv&lt;/code&gt;, we see large gains by efficiently distributing the work across your entire
machine.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd

df &lt;span class="pl-k"&gt;=&lt;/span&gt; pd.read_csv(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;my_dataset.csv&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-modin-is-a-dataframe-designed-for-datasets-from-1mb-to-1tb" class="anchor" aria-hidden="true" href="#modin-is-a-dataframe-designed-for-datasets-from-1mb-to-1tb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Modin is a DataFrame designed for datasets from 1MB to 1TB+&lt;/h4&gt;
&lt;p&gt;We have focused heavily on bridging the solutions between DataFrames for small data
(e.g. pandas) and large data. Often data scientists require different tools for doing
the same thing on different sizes of data. The DataFrame solutions that exist for 1KB do
not scale to 1TB+, and the overheads of the solutions for 1TB+ are too costly for
datasets in the 1KB range. With Modin, because of its light-weight, robust, and scalable
nature, you get a fast DataFrame at small and large data. With preliminary &lt;a href="https://modin.readthedocs.io/en/latest/using_modin.html#using-modin-on-a-cluster" rel="nofollow"&gt;cluster&lt;/a&gt;
and &lt;a href="https://modin.readthedocs.io/en/latest/out_of_core.html" rel="nofollow"&gt;out of core&lt;/a&gt;
support, Modin is a DataFrame library with great single-node performance and high
scalability in a cluster.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-modin-architecture" class="anchor" aria-hidden="true" href="#modin-architecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Modin Architecture&lt;/h4&gt;
&lt;p&gt;We designed Modin to be modular so we can plug in different components as they develop
and improve:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/img/modin_architecture.png"&gt;&lt;img src="docs/img/modin_architecture.png" alt="Architecture" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Visit the &lt;a href="https://modin.readthedocs.io/en/latest/architecture.html" rel="nofollow"&gt;Documentation&lt;/a&gt; for
more information!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;modin.pandas&lt;/code&gt; is currently under active development. Requests and contributions are welcome!&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-more-information-and-getting-involved" class="anchor" aria-hidden="true" href="#more-information-and-getting-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More information and Getting Involved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://modin.readthedocs.io/en/latest/" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ask questions or participate in discussions on our &lt;a href="https://discuss.modin.org" rel="nofollow"&gt;Discourse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Join our mailing list &lt;a href="https://groups.google.com/forum/#!forum/modin-dev" rel="nofollow"&gt;modin-dev@googlegroups.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Submit bug reports to our &lt;a href="https://github.com/modin-project/modin/issues"&gt;GitHub Issues Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Contributions are welcome! Open a &lt;a href="https://github.com/modin-project/modin/pulls"&gt;pull request&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>modin-project</author><guid isPermaLink="false">https://github.com/modin-project/modin</guid><pubDate>Wed, 20 Nov 2019 00:04:00 GMT</pubDate></item><item><title>ct-Open-Source/tuya-convert #5 in Python, Today</title><link>https://github.com/ct-Open-Source/tuya-convert</link><description>&lt;p&gt;&lt;i&gt;A collection of scripts to flash Tuya IoT devices to alternative firmwares&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tuya-convert" class="anchor" aria-hidden="true" href="#tuya-convert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TUYA-CONVERT&lt;/h1&gt;
&lt;p&gt;A Chinese company named Tuya offers a free-to-brand turnkey smart home solution to anyone. Using their offer is dead-simple, since everything can be done by clicking through the &lt;a href="https://en.tuya.com/" rel="nofollow"&gt;Tuya web page&lt;/a&gt;, from choosing your pre-designed products or pre-programmed wifi-modules (mostly ESP8266) to building your own app. In the end, this has resulted in as they claim over 11 000 devices 'made' by over 10 000 vendors using Tuyas firmware and cloud services.&lt;/p&gt;
&lt;p&gt;Aside from that, they claim their cloud solution has 'military grade security'. Michael Steigerwald, founder of the German IT security startup VTRUST, was able to disprove this claim and presented his results in the "Smart home - Smart hack" talk at 35C3 in Leipzig: &lt;a href="https://media.ccc.de/v/35c3-9723-smart_home_-_smart_hack" rel="nofollow"&gt;https://media.ccc.de/v/35c3-9723-smart_home_-_smart_hack&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the following days, VTRUST and the German tech magazine c't decided to work together. Since reflashing devices using the ESP8266/85 is widespread among DIY smart home enthusiasts, we wanted to provide an easy way for everyone to free their devices from the cloud without the need for a soldering iron.&lt;/p&gt;
&lt;p&gt;Please make sure to visit VTRUST (&lt;a href="https://www.vtrust.de/" rel="nofollow"&gt;https://www.vtrust.de/&lt;/a&gt;), since the hack is their work.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-warning" class="anchor" aria-hidden="true" href="#warning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="rotating_light" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a8.png"&gt;ğŸš¨&lt;/g-emoji&gt;WARNING&lt;g-emoji class="g-emoji" alias="rotating_light" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a8.png"&gt;ğŸš¨&lt;/g-emoji&gt;&lt;/h2&gt;
&lt;p&gt;Please be sure that you understand what you're doing before using this software. Flashing an alternative firmware can lead to unexpected behavior and/or render the device unusable, so that it might be permanently damaged (highly unlikely) or require soldering a serial connection to the processor in order to reflash it (likely).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-ï¸-be-aware-that-you-use-this-software-at-your-own-risk-so-neither-vtrust-nor-ctheise-can-be-held-accountable-for-any-damage-done-or-loss-of-functionality-ï¸" class="anchor" aria-hidden="true" href="#ï¸-be-aware-that-you-use-this-software-at-your-own-risk-so-neither-vtrust-nor-ctheise-can-be-held-accountable-for-any-damage-done-or-loss-of-functionality-ï¸"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png"&gt;âš ï¸&lt;/g-emoji&gt; Be aware that you use this software at your own risk so neither VTRUST nor c't/heise can be held accountable for any damage done or loss of functionality. &lt;g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png"&gt;âš ï¸&lt;/g-emoji&gt;&lt;/h3&gt;
&lt;p&gt;TUYA-CONVERT only provides with the means to backup the original and flash an alternative firmware. Please do not ask for hardware support for your favorite alternative firmware in this repository, rather open an issue in the corresponding repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DOCUMENTATION&lt;/h2&gt;
&lt;p&gt;Since Tuya devices are spread around the world with likely a vast amount of different brand names, please tell the community if you find one! There is a device list in the wiki that you can help extend. Please at least add the device model number, brand name, geographical area where you have bought the device and its flash mode (as seen in the device information). Add the GPIO assignments as well if you have found them to save the developers of alternative firmwares some time. Please note that we do not develop or maintain alternative firmwares and so post installation issues should be directed to the respective project.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://asciinema.org/a/2aDZweVGfliwc9TjB1ncwmKvm" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3136d6f61b012a424773993ef2f9b500958a000c/68747470733a2f2f61736369696e656d612e6f72672f612f3261445a77655647666c69776339546a42316e63776d4b766d2e706e67" alt="asciicast" data-canonical-src="https://asciinema.org/a/2aDZweVGfliwc9TjB1ncwmKvm.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;REQUIREMENTS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linux computer with a wifi adapter&lt;/li&gt;
&lt;li&gt;Secondary wifi device (e.g. smartphone)&lt;/li&gt;
&lt;li&gt;Dependencies will be installed by &lt;code&gt;install_prereq.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These scripts were tested in&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kali-Linux 2018.4 in VMWARE&lt;/li&gt;
&lt;li&gt;a Raspberry Pi 3B / 3B+ with Raspbian Stretch and its internal Wifi chip&lt;/li&gt;
&lt;li&gt;a Raspberry Pi 3B+ + USB-WIFI with this image from &lt;a href="https://www.offensive-security.com/kali-linux-arm-images/" rel="nofollow"&gt;here&lt;/a&gt;
&lt;a href="https://images.offensive-security.com/arm-images/kali-linux-2018.4a-rpi3-nexmon-64.img.xz" rel="nofollow"&gt;https://images.offensive-security.com/arm-images/kali-linux-2018.4a-rpi3-nexmon-64.img.xz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any Linux with a Wifi adapter which can act as an Access Point should also work. Please note that we have tested the Raspberry Pi with clean installations only. If you use your Raspberry Pi for anything else, we recommend using another SD card with a clean installation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-procedure" class="anchor" aria-hidden="true" href="#procedure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PROCEDURE&lt;/h2&gt;
&lt;p&gt;On January 28th, 2019, Tuya started &lt;a href="https://www.heise.de/newsticker/meldung/Smart-Home-Hack-Tuya-veroeffentlicht-Sicherheitsupdate-4292028.html" rel="nofollow"&gt;distributing a patch&lt;/a&gt; that prevented older versions of tuya-convert from completing successfully. We have since developed a work around to enable OTA flashing once again, but there is always the possibility that Tuya will respond with yet another patch. To ensure the best chance of success, &lt;strong&gt;do not connect your device with the official app&lt;/strong&gt; as it may automatically update the device, preventing you from flashing with tuya-convert. It is up to the individual brands to update their firmware, so some devices may be affected sooner than others.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;INSTALLATION&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;# git clone https://github.com/ct-Open-Source/tuya-convert
# cd tuya-convert
# ./install_prereq.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-flash-loader-firmware--backup" class="anchor" aria-hidden="true" href="#flash-loader-firmware--backup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;flash loader firmware + backup&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;# ./start_flash.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Follow the instructions in the start_flash script. It will install our flash loader onto the ESP and connect to the access point created by your wifi adapter.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;WIFI: vtrust-flash
IP: 10.42.42.42
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A backup of the original firmware will be created and stored locally&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-device-information" class="anchor" aria-hidden="true" href="#device-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Device information&lt;/h3&gt;
&lt;p&gt;After the firmware backup procedure, the retrieved device information will be shown.
Please make sure to write down your devices flash mode and size!
You can show this information again by executing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl http://10.42.42.42
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-backup-only-and-undo" class="anchor" aria-hidden="true" href="#backup-only-and-undo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BACKUP only and UNDO&lt;/h3&gt;
&lt;p&gt;You can use the flash loader to create a backup only.
If you want to delete the FLASH loader out of the flash again and go back to the stock software just do following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl http://10.42.42.42/undo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-flash-loader-to-user2" class="anchor" aria-hidden="true" href="#flash-loader-to-user2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FLASH loader to user2&lt;/h3&gt;
&lt;p&gt;The FLASH loader only allows flashing the third party firmware if the loader is running in the userspace user2 starting from 0x81000.
This will flash the FLASH loader in user2 if it is not already there.
It will destroy your ability to undo and go back to the original firmware&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl http://10.42.42.42/flash2
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-flash-third-party-firmware" class="anchor" aria-hidden="true" href="#flash-third-party-firmware"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FLASH third-party firmware&lt;/h3&gt;
&lt;p&gt;BE SURE THE FIRMWARE FITS YOUR DEVICE!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Place or link your binary file to ./files/thirdparty.bin.&lt;/p&gt;
&lt;p&gt;Currently a Tasmota &lt;a href="https://github.com/arendst/Tasmota/releases"&gt;v7.0.0.3&lt;/a&gt; &lt;code&gt;tasmota-wifiman.bin&lt;/code&gt; build is included. You can update to a &lt;a href="http://thehackbox.org/tasmota" rel="nofollow"&gt;current version&lt;/a&gt; via OTA after the Tuya-Convert process completes successfully. Please note that while we include this for your convenience, we are not affiliated with the Tasmota project and cannot provide support for post installation issues. Please refer to &lt;a href="https://github.com/arendst/Tasmota"&gt;the respective project&lt;/a&gt; for configuration and support.&lt;/p&gt;
&lt;p&gt;An ESPurna &lt;a href="https://github.com/xoseperez/espurna/releases/tag/1.13.5"&gt;1.13.5&lt;/a&gt; binary is also included (&lt;code&gt;espurna-base.bin&lt;/code&gt;). Like before, the binary included does not have any specific hardware defined. Once flashed using Tuya-Convert you can update to the device-specific version via any of the means that ESPurna provides (OTA, web interface update, update via telnet or MQTT). Please refer to the &lt;a href="http://espurna.io" rel="nofollow"&gt;ESPurna project page&lt;/a&gt; for more info and support.&lt;/p&gt;
&lt;p&gt;Binary requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;full binary including first-stage bootloader&lt;/li&gt;
&lt;li&gt;maximum filesize 512KB for first flash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start flashing process&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; # curl http://10.42.42.42/flash3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively you can request a certain file to be requested and flashed by the device:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; # curl http://10.42.42.42/flash3?url=http://10.42.42.1/files/certain_file.bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Initial Configuration&lt;/p&gt;
&lt;p&gt;If you flashed the included Tasmota firmware file, it will broadcast a &lt;code&gt;tasmota-xxxx&lt;/code&gt; access point (AP) when the device boots. Connect to this AP and open the browser to 192.168.4.1 to configure the device's Wi-Fi credentials. When entering the Wi-Fi password, click the checkbox to view the password you enter to ensure that it is correct and that your mobile device has not inadvertently capitalized the first letter if it is supposed to be lower case nor autocorrected what you entered. &lt;del&gt;Double&lt;/del&gt; &lt;strong&gt;Triple check the Wi-Fi credentials&lt;/strong&gt; before clicking &lt;strong&gt;Save&lt;/strong&gt; to apply the settings.&lt;/p&gt;
&lt;p&gt;If you flashed the included ESPurna firmware file, the procedure will be very similar. The device will broadcast a &lt;code&gt;ESPURNA-XXXXXX&lt;/code&gt; access point. You will have to connect to it using the default password: &lt;code&gt;fibonacci&lt;/code&gt;. Once connected open the browser to 192.168.4.1 and follow the initial configuration instructions. Then go to the WIFI tab and configure your home WiFi connection (remember to save) or go to the ADMIN tab to upgrade the firmware to the device-specific image.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CONTRIBUTING&lt;/h2&gt;
&lt;p&gt;This project is currently maintained by Colin Kuebler @kueblc&lt;/p&gt;
&lt;p&gt;Significant time and resources are devoted to supporting and maintaining this project. Research, development, and testing requires obtaining and often breaking IoT devices and related hardware. To help offset costs and support the developers who make this project possible, please consider making a one-time or recurring donation. This allows us to spend less time worrying about putting food on the table and more time making great software accessible to everyone.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.patreon.com/kueblc" rel="nofollow"&gt;Become a Patron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.buymeacoffee.com/kueblc" rel="nofollow"&gt;Buy Me A Coffee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://paypal.me/kueblc" rel="nofollow"&gt;PayPal&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also give back by providing or improving documentation, tutorials, issue support, bug reports, feature requests, and pull requests. When planning to contribute major code changes, please post your intention beforehand so we can coordinate, avoid redundant contributions and ensure the changes match project philosophy. Any major PR should be made against the &lt;code&gt;development&lt;/code&gt; branch.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-related-works" class="anchor" aria-hidden="true" href="#related-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RELATED WORKS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/codetheweb/tuyapi"&gt;TuyAPI&lt;/a&gt; NPM library for LAN control of Tuya devices with stock firmware&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SynAckFin/TuyOTA"&gt;TuyOTA&lt;/a&gt; Perl based Tuya flashing script using a similar strategy&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kueblc/mocktuyacloud"&gt;MockTuyaCloud&lt;/a&gt; Framework replicating much of the Tuya cloud functionality&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ct-Open-Source</author><guid isPermaLink="false">https://github.com/ct-Open-Source/tuya-convert</guid><pubDate>Wed, 20 Nov 2019 00:05:00 GMT</pubDate></item><item><title>tensorflow/models #6 in Python, Today</title><link>https://github.com/tensorflow/models</link><description>&lt;p&gt;&lt;i&gt;Models and examples built with TensorFlow&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-models" class="anchor" aria-hidden="true" href="#tensorflow-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow Models&lt;/h1&gt;
&lt;p&gt;This repository contains a number of different models implemented in &lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;The &lt;a href="official"&gt;official models&lt;/a&gt; are a collection of example models that use TensorFlow's high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest stable TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read. We especially recommend newer TensorFlow users to start here.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/tensorflow/models/tree/master/research"&gt;research models&lt;/a&gt; are a large collection of models implemented in TensorFlow by researchers. They are not officially supported or available in release branches; it is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.&lt;/p&gt;
&lt;p&gt;The &lt;a href="samples"&gt;samples folder&lt;/a&gt; contains code snippets and smaller models that demonstrate features of TensorFlow, including code presented in various blog posts.&lt;/p&gt;
&lt;p&gt;The &lt;a href="tutorials"&gt;tutorials folder&lt;/a&gt; is a collection of models described in the &lt;a href="https://www.tensorflow.org/tutorials/" rel="nofollow"&gt;TensorFlow tutorials&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to models, be sure to review the &lt;a href="CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tensorflow</author><guid isPermaLink="false">https://github.com/tensorflow/models</guid><pubDate>Wed, 20 Nov 2019 00:06:00 GMT</pubDate></item><item><title>streamlit/streamlit #7 in Python, Today</title><link>https://github.com/streamlit/streamlit</link><description>&lt;p&gt;&lt;i&gt;Streamlit â€” The fastest way to build custom ML tools&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-welcome-to-streamlit-wave" class="anchor" aria-hidden="true" href="#welcome-to-streamlit-wave"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to Streamlit &lt;g-emoji class="g-emoji" alias="wave" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44b.png"&gt;ğŸ‘‹&lt;/g-emoji&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The fastest way to build custom ML tools.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Streamlit lets you create apps for your machine learning projects with deceptively simple Python scripts. It supports hot-reloading, so your app updates live as you edit and save your file. No need to mess with HTTP requests, HTML, JavaScript, etc. All you need is your favorite editor and a browser. Take a look at Streamlit in action:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5ae1dcfd188be26bbb0648fb62e9d6d593dbb6f5/68747470733a2f2f617773312e646973636f757273652d63646e2e636f6d2f7374616e6461726431302f75706c6f6164732f73747265616d6c69742f6f726967696e616c2f31582f323932653938356637663735656637626566386332376235383939663731663736636435373765302e676966"&gt;&lt;img src="https://camo.githubusercontent.com/5ae1dcfd188be26bbb0648fb62e9d6d593dbb6f5/68747470733a2f2f617773312e646973636f757273652d63646e2e636f6d2f7374616e6461726431302f75706c6f6164732f73747265616d6c69742f6f726967696e616c2f31582f323932653938356637663735656637626566386332376235383939663731663736636435373765302e676966" alt="Example of live coding a dashboard in Streamlit|635x380" data-canonical-src="https://aws1.discourse-cdn.com/standard10/uploads/streamlit/original/1X/292e985f7f75ef7bef8c27b5899f71f76cd577e0.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check out our &lt;a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace" rel="nofollow"&gt;launch blog post&lt;/a&gt;!!&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install streamlit
streamlit hello&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;p&gt;Streamlit lets you build interactive apps ridiculously easily:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; streamlit &lt;span class="pl-k"&gt;as&lt;/span&gt; st

x &lt;span class="pl-k"&gt;=&lt;/span&gt; st.slider(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Select a value&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
st.write(x, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;squared is&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, x &lt;span class="pl-k"&gt;*&lt;/span&gt; x)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1e18efff3f06946e9d1559712cea0cb76364f004/68747470733a2f2f73747265616d6c69742d64656d6f2d646174612e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f737175617265642d696d6167652d666f722d6769746875622d726561646d652d322e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1e18efff3f06946e9d1559712cea0cb76364f004/68747470733a2f2f73747265616d6c69742d64656d6f2d646174612e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f737175617265642d696d6167652d666f722d6769746875622d726561646d652d322e706e67" width="490/" data-canonical-src="https://streamlit-demo-data.s3-us-west-2.amazonaws.com/squared-image-for-github-readme-2.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-a-bigger-example" class="anchor" aria-hidden="true" href="#a-bigger-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Bigger Example&lt;/h2&gt;
&lt;p&gt;Despite its simplicity Streamlit lets you build incredibly rich and powerful tools. &lt;a href="https://github.com/streamlit/demo-self-driving"&gt;This demo project&lt;/a&gt; lets you browse the entire &lt;a href="https://github.com/udacity/self-driving-car"&gt;Udacity self-driving-car dataset&lt;/a&gt; and run inference in real time using the &lt;a href="https://pjreddie.com/darknet/yolo" rel="nofollow"&gt;YOLO object detection net&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/streamlit/demo-self-driving/master/av_final_optimized.gif"&gt;&lt;img src="https://raw.githubusercontent.com/streamlit/demo-self-driving/master/av_final_optimized.gif" alt="Making-of Animation" title="Making-of Animation" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The complete demo is implemented in less than 300 lines of Python. In fact, the app contains &lt;a href="https://github.com/streamlit/demo-self-driving/blob/master/app.py"&gt;only 23 Streamlit calls&lt;/a&gt; which illustrates all the major building blocks of Streamlit. You can try it right now with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install --upgrade streamlit opencv-python
streamlit run https://raw.githubusercontent.com/streamlit/demo-self-driving/master/app.py&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-more-information" class="anchor" aria-hidden="true" href="#more-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Our &lt;a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace" rel="nofollow"&gt;launch post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Our lovely &lt;a href="https://discuss.streamlit.io/" rel="nofollow"&gt;community&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Streamlit &lt;a href="https://streamlit.io/docs" rel="nofollow"&gt;documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More &lt;a href="https://github.com/streamlit/"&gt;demo projects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If you would like to contribute, see &lt;a href="https://github.com/streamlit/streamlit/wiki/Contributing"&gt;instructions here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-streamlit-for-teams" class="anchor" aria-hidden="true" href="#streamlit-for-teams"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Streamlit for Teams&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://streamlit.io/forteams/" rel="nofollow"&gt;Streamlit for Teams&lt;/a&gt; is our enterprise edition, with single-click deploy, authentication, web editing, versioning, and more. Please contact us if you would like to learn more.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Streamlit is completely free and open source and licensed under the &lt;a href="https://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;Apache 2.0&lt;/a&gt; license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>streamlit</author><guid isPermaLink="false">https://github.com/streamlit/streamlit</guid><pubDate>Wed, 20 Nov 2019 00:07:00 GMT</pubDate></item><item><title>eastlakeside/interpy-zh #8 in Python, Today</title><link>https://github.com/eastlakeside/interpy-zh</link><description>&lt;p&gt;&lt;i&gt;ğŸ“˜ã€ŠPythonè¿›é˜¶ã€‹ï¼ˆIntermediate Python ä¸­æ–‡ç‰ˆï¼‰&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pythonè¿›é˜¶" class="anchor" aria-hidden="true" href="#pythonè¿›é˜¶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pythonè¿›é˜¶&lt;/h1&gt;
&lt;p&gt;ã€ŠPythonè¿›é˜¶ã€‹æ˜¯ã€ŠIntermediate Pythonã€‹çš„ä¸­æ–‡è¯‘æœ¬, è°¨ä»¥æ­¤çŒ®ç»™è¿›å‡»çš„ Python å’Œ Python ç¨‹åºå‘˜ä»¬!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-å¿«é€Ÿé˜…è¯»ä¼ é€é—¨" class="anchor" aria-hidden="true" href="#å¿«é€Ÿé˜…è¯»ä¼ é€é—¨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¿«é€Ÿé˜…è¯»ä¼ é€é—¨&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Githubå¿«é€Ÿé˜…è¯»ä»»ä¸€ç« èŠ‚ï¼š&lt;a href="https://github.com/eastlakeside/interpy-zh/blob/master/SUMMARY.md"&gt;è¿›å…¥ç›®å½•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gitbookå®Œæ•´é¡ºåºåœ°é˜…è¯»ï¼š&lt;a href="https://eastlakeside.gitbooks.io/interpy-zh/content/" rel="nofollow"&gt;è¿›å…¥Gitbook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;æœ¬åœ°æˆ–kindleä¸Šé˜…è¯»ï¼š&lt;a href="https://github.com/eastlakeside/interpy-zh/releases"&gt;ä¸‹è½½pdf/epub/mobi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;å›½å†…æ¨èé•œåƒï¼ˆå®æ—¶åŒæ­¥ï¼‰ï¼š&lt;a href="http://wiki.jikexueyuan.com/project/interpy-zh/" rel="nofollow"&gt;æå®¢å­¦é™¢æ”¶å½•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;å…¶ä»–é•œåƒï¼ˆä¸å®šæœŸåŒæ­¥ï¼‰ï¼š&lt;a href="http://docs.pythontab.com/interpy/" rel="nofollow"&gt;Pythontabæ”¶å½•&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;çº¯ä»£ç é˜…è¯»å’Œæ¼”ç¤ºï¼š&lt;a href="https://github.com/eastlakeside/interpy-zh/tree/master/code/"&gt;è¿›å…¥codeç›®å½•&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-å‰è¨€" class="anchor" aria-hidden="true" href="#å‰è¨€"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å‰è¨€&lt;/h1&gt;
&lt;p&gt;Pythonï¼Œä½œä¸ºä¸€ä¸ª"è€ç»ƒ"ã€"å°æ¸…æ–°"çš„å¼€å‘è¯­è¨€ï¼Œå·²å—åˆ°å¹¿å¤§æ‰ç”·ä¿Šå¥³çš„å–œçˆ±ã€‚æˆ‘ä»¬ä¹Ÿä»æœ€åŸºç¡€çš„Pythonç²‰ï¼Œç»è¿‡æ—¶é—´çš„æ‘§æ®‹æ…¢æ…¢çš„å˜æˆäº†Pythonè€é¬¼ã€‚&lt;/p&gt;
&lt;p&gt;IntermediatePythonè¿™æœ¬ä¹¦å…·æœ‰å¦‚ä¸‹å‡ ä¸ªä¼˜ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ç®€å•&lt;/li&gt;
&lt;li&gt;æ˜“è¯»&lt;/li&gt;
&lt;li&gt;æ˜“è¯‘&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;è¿™äº›éƒ½ä¸æ˜¯é‡ç‚¹ï¼Œé‡ç‚¹æ˜¯ï¼š&lt;strong&gt;å®ƒæ˜¯ä¸€æœ¬å¼€è„‘æ´çš„ä¹¦&lt;/strong&gt;ã€‚æ— è®ºä½ æ˜¯Pythonåˆå­¦è€…ï¼Œè¿˜æ˜¯Pythoné«˜æ‰‹ï¼Œå®ƒæ˜¾ç°ç»™ä½ çš„æ°¸è¿œæ˜¯Pythoné‡Œæœ€ç¾å¥½çš„äº‹ç‰©ã€‚&lt;/p&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;ä¸–ä¸Šè¯­è¨€åƒä¸‡ç§
ç¾å¥½äº‹ç‰©è—å…¶ä¸­&lt;/p&gt;
&lt;p&gt;è¯‘è€…åœ¨ç¿»è¯‘è¿‡ç¨‹ä¸­ï¼Œæ…¢æ…¢å‘ç°ï¼Œæœ¬ä¹¦ä½œè€…çš„è¡Œæ–‡æ–¹å¼æœ‰ç€ç§‘æ™®ä½œå®¶çš„é£èŒƒï¼Œ--é‚£å°±æ˜¯èƒ½å°†æ™¦æ¶©éš¾æ‡‚çš„æŠ€æœ¯ç”¨æ¯”è¾ƒæ¸…æ™°ç®€æ´çš„æ–¹å¼è¿›è¡Œå‘ˆç°ï¼Œæ·±å…¥æµ…å‡ºçš„é£æ ¼åœ¨æ¯ä¸ªç« èŠ‚çš„è®¨è®ºä¸­éƒ½å¾—åˆ°äº†ä½“ç°ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ¯ä¸ªç« èŠ‚éƒ½éå¸¸ç²¾ç®€ï¼Œ5åˆ†é’Ÿå°±èƒ½çœ‹å®Œï¼Œç”¨æœ€ç®€æ´çš„ä¾‹å­ç²¾è¾Ÿåœ°å±•ç°äº†åŸç†&lt;/li&gt;
&lt;li&gt;æ¯ä¸ªç« èŠ‚éƒ½ä¼šé€šè¿‡ç–‘é—®ï¼Œæ¥å¼•å¯¼è¯»è€…ä¸»åŠ¨æ€è€ƒç­”æ¡ˆ&lt;/li&gt;
&lt;li&gt;æ¯ä¸ªç« èŠ‚éƒ½å¼•å¯¼è¯»è€…åšå»¶ä¼¸é˜…è¯»ï¼Œè®©æœ‰å…´è¶£çš„è¯»è€…èƒ½è¿›ä¸€æ­¥ä¸¾ä¸€åä¸‰&lt;/li&gt;
&lt;li&gt;æ¯ä¸ªç« èŠ‚éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œä½ å¯ä»¥æŒ‘é€‰ä»»æ„çš„ç« èŠ‚å¼€å§‹é˜…è¯»ï¼Œè€Œä¸å—å½±å“&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ€»ä¹‹ï¼Œè¿™æœ¬ä¹¦éå¸¸æ–¹ä¾¿éšæ—¶é€‰å–ä¸€ä¸ªç« èŠ‚è¿›è¡Œé˜…è¯»ï¼Œè€Œä¸”æ¯æ¬¡é˜…è¯»ä¸€ä¸ªç« èŠ‚ï¼Œä½ éƒ½å¯èƒ½ä¼šæœ‰ä¸€äº›æ–°çš„å‘ç°ã€‚&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-åŸä¹¦ä½œè€…" class="anchor" aria-hidden="true" href="#åŸä¹¦ä½œè€…"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;åŸä¹¦ä½œè€…&lt;/h2&gt;
&lt;p&gt;æ„Ÿè°¢è‹±æ–‡åŸè‘—ä½œè€… @yasoobã€Š&lt;a href="https://github.com/yasoob/intermediatePython"&gt;Intermediate Python&lt;/a&gt;ã€‹ï¼Œæœ‰äº†ä»–æ‰æœ‰äº†è¿™é‡Œçš„ä¸€åˆ‡&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-è¯‘è€…" class="anchor" aria-hidden="true" href="#è¯‘è€…"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è¯‘è€…&lt;/h2&gt;
&lt;p&gt;æ€»é¡¾é—®+å®¡æ ¡: åˆ˜å®‡ @liuyu&lt;br&gt;
ä¸»è¯‘: PyConè€é«˜ @spawnris&lt;br&gt;
ä¸»è¯‘: å¤§ç‰™matt @suqi&lt;br&gt;
å‚è¯‘: æ˜æº @muxueqz&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-æ¬¢è¿å»ºè®®æŒ‡æ­£æˆ–ç›´æ¥è´¡çŒ®ä»£ç " class="anchor" aria-hidden="true" href="#æ¬¢è¿å»ºè®®æŒ‡æ­£æˆ–ç›´æ¥è´¡çŒ®ä»£ç "&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;æ¬¢è¿å»ºè®®æŒ‡æ­£æˆ–ç›´æ¥è´¡çŒ®ä»£ç &lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/eastlakeside/interpy-zh/issues"&gt;https://github.com/eastlakeside/interpy-zh/issues&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-å¾®ä¿¡äº¤æµç¾¤" class="anchor" aria-hidden="true" href="#å¾®ä¿¡äº¤æµç¾¤"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¾®ä¿¡äº¤æµç¾¤&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/096898f5a8cad462c01aee9847014e43413a86a7/687474703a2f2f77656978696e2e71712e636f6d2f6367692d62696e2f7172636f64653f747970653d75736572266172673d6a6876364e344d494b3949444734457361576d6e786d4e65785675423233253246685036305662765573524538253344"&gt;&lt;img src="https://camo.githubusercontent.com/096898f5a8cad462c01aee9847014e43413a86a7/687474703a2f2f77656978696e2e71712e636f6d2f6367692d62696e2f7172636f64653f747970653d75736572266172673d6a6876364e344d494b3949444734457361576d6e786d4e65785675423233253246685036305662765573524538253344" alt="å¾®ä¿¡ç¾¤" data-canonical-src="http://weixin.qq.com/cgi-bin/qrcode?type=user&amp;amp;arg=jhv6N4MIK9IDG4EsaWmnxmNexVuB23%2FhP60VbvUsRE8%3D" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-å¾®ä¿¡æ‰“èµæ”¯æŒ" class="anchor" aria-hidden="true" href="#å¾®ä¿¡æ‰“èµæ”¯æŒ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;å¾®ä¿¡æ‰“èµæ”¯æŒï¼š&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="__img/donate.png"&gt;&lt;img src="__img/donate.png" alt="wechat_donate" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>eastlakeside</author><guid isPermaLink="false">https://github.com/eastlakeside/interpy-zh</guid><pubDate>Wed, 20 Nov 2019 00:08:00 GMT</pubDate></item><item><title>donnemartin/system-design-primer #9 in Python, Today</title><link>https://github.com/donnemartin/system-design-primer</link><description>&lt;p&gt;&lt;i&gt;Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;em&gt;&lt;a href="README.md"&gt;English&lt;/a&gt; âˆ™ &lt;a href="README-ja.md"&gt;æ—¥æœ¬èª&lt;/a&gt; âˆ™ &lt;a href="README-zh-Hans.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; âˆ™ &lt;a href="README-zh-TW.md"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/170"&gt;Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/220"&gt;à¦¬à¦¾à¦‚à¦²à¦¾&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/40"&gt;PortuguÃªs do Brasil&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/186"&gt;Deutsch&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/130"&gt;ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/272"&gt;×¢×‘×¨×™×ª&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/104"&gt;Italiano&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/102"&gt;éŸ“åœ‹èª&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/110"&gt;ÙØ§Ø±Ø³ÛŒ&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/68"&gt;Polski&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/87"&gt;Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/136"&gt;EspaÃ±ol&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/187"&gt;à¸ à¸²à¸©à¸²à¹„à¸—à¸¢&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/39"&gt;TÃ¼rkÃ§e&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/127"&gt;tiáº¿ng Viá»‡t&lt;/a&gt; âˆ™ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/250"&gt;FranÃ§ais&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-the-system-design-primer" class="anchor" aria-hidden="true" href="#the-system-design-primer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The System Design Primer&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67" data-canonical-src="http://i.imgur.com/jj3A5N8.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt;
&lt;p&gt;Prep for the system design interview.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-learn-how-to-design-large-scale-systems" class="anchor" aria-hidden="true" href="#learn-how-to-design-large-scale-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn how to design large-scale systems&lt;/h3&gt;
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt;
&lt;p&gt;System design is a broad topic.  There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt;
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learn-from-the-open-source-community" class="anchor" aria-hidden="true" href="#learn-from-the-open-source-community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn from the open source community&lt;/h3&gt;
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt;
&lt;p&gt;&lt;a href="#contributing"&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-prep-for-the-system-design-interview" class="anchor" aria-hidden="true" href="#prep-for-the-system-design-interview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prep for the system design interview&lt;/h3&gt;
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#study-guide"&gt;Study guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-anki-flashcards" class="anchor" aria-hidden="true" href="#anki-flashcards"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Anki flashcards&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/75b5cf737556050871218226ea211256f19f3a40/687474703a2f2f692e696d6775722e636f6d2f7a6443416b42332e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/75b5cf737556050871218226ea211256f19f3a40/687474703a2f2f692e696d6775722e636f6d2f7a6443416b42332e706e67" data-canonical-src="http://i.imgur.com/zdCAkB3.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;The provided &lt;a href="https://apps.ankiweb.net/" rel="nofollow"&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg"&gt;System design deck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg"&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg"&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-coding-resource-interactive-coding-challenges" class="anchor" aria-hidden="true" href="#coding-resource-interactive-coding-challenges"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt;
&lt;p&gt;Looking for resources to help you prep for the &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/473700c20356af5875155f24d3a26b57ae940bdc/687474703a2f2f692e696d6775722e636f6d2f6234597441454e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/473700c20356af5875155f24d3a26b57ae940bdc/687474703a2f2f692e696d6775722e636f6d2f6234597441454e2e706e67" data-canonical-src="http://i.imgur.com/b4YtAEN.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;Check out the sister repo &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg"&gt;Coding deck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn from the community.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fix errors&lt;/li&gt;
&lt;li&gt;Improve sections&lt;/li&gt;
&lt;li&gt;Add new sections&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Translate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Content that needs some polishing is placed &lt;a href="#under-development"&gt;under development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Review the &lt;a href="CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-index-of-system-design-topics" class="anchor" aria-hidden="true" href="#index-of-system-design-topics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index of system design topics&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Summaries of various system design topics, including pros and cons.  &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67" data-canonical-src="http://i.imgur.com/jrUBAF7.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#system-design-topics-start-here"&gt;System design topics: start here&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#step-1-review-the-scalability-video-lecture"&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#step-2-review-the-scalability-article"&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#next-steps"&gt;Next steps&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#performance-vs-scalability"&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-vs-throughput"&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-vs-consistency"&gt;Availability vs consistency&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cap-theorem"&gt;CAP theorem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cp---consistency-and-partition-tolerance"&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ap---availability-and-partition-tolerance"&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#consistency-patterns"&gt;Consistency patterns&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#weak-consistency"&gt;Weak consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eventual-consistency"&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#strong-consistency"&gt;Strong consistency&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-patterns"&gt;Availability patterns&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#fail-over"&gt;Fail-over&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#replication"&gt;Replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-in-numbers"&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#domain-name-system"&gt;Domain name system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#content-delivery-network"&gt;Content delivery network&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#push-cdns"&gt;Push CDNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pull-cdns"&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#load-balancer"&gt;Load balancer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#active-passive"&gt;Active-passive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#active-active"&gt;Active-active&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-4-load-balancing"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-7-load-balancing"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#horizontal-scaling"&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#reverse-proxy-web-server"&gt;Reverse proxy (web server)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#load-balancer-vs-reverse-proxy"&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#application-layer"&gt;Application layer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#microservices"&gt;Microservices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#service-discovery"&gt;Service discovery&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#database"&gt;Database&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#relational-database-management-system-rdbms"&gt;Relational database management system (RDBMS)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sharding"&gt;Sharding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sql-tuning"&gt;SQL tuning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#nosql"&gt;NoSQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#key-value-store"&gt;Key-value store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#document-store"&gt;Document store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wide-column-store"&gt;Wide column store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#graph-database"&gt;Graph Database&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#cache"&gt;Cache&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#client-caching"&gt;Client caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cdn-caching"&gt;CDN caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-server-caching"&gt;Web server caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database-caching"&gt;Database caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#application-caching"&gt;Application caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching-at-the-database-query-level"&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching-at-the-object-level"&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#when-to-update-the-cache"&gt;When to update the cache&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cache-aside"&gt;Cache-aside&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#write-through"&gt;Write-through&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#write-behind-write-back"&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#refresh-ahead"&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#asynchronism"&gt;Asynchronism&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#message-queues"&gt;Message queues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#task-queues"&gt;Task queues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#back-pressure"&gt;Back pressure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#communication"&gt;Communication&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#transmission-control-protocol-tcp"&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#user-datagram-protocol-udp"&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#remote-procedure-call-rpc"&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#representational-state-transfer-rest"&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#security"&gt;Security&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#appendix"&gt;Appendix&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#company-architectures"&gt;Company architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#under-development"&gt;Under development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#credits"&gt;Credits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact-info"&gt;Contact info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-study-guide" class="anchor" aria-hidden="true" href="#study-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Study guide&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eb92600aa3bb1314b33edd0204da8428d4d3a493/687474703a2f2f692e696d6775722e636f6d2f4f66566c6c65782e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/eb92600aa3bb1314b33edd0204da8428d4d3a493/687474703a2f2f692e696d6775722e636f6d2f4f66566c6c65782e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/OfVllex.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A: No, you don't need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How much experience you have&lt;/li&gt;
&lt;li&gt;What your technical background is&lt;/li&gt;
&lt;li&gt;What positions you are interviewing for&lt;/li&gt;
&lt;li&gt;Which companies you are interviewing with&lt;/li&gt;
&lt;li&gt;Luck&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More experienced candidates are generally expected to know more about system design.  Architects or team leads might be expected to know more than individual contributors.  Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt;
&lt;p&gt;Start broad and go deeper in a few areas.  It helps to know a little about various key system design topics.  Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Short&lt;/th&gt;
&lt;th&gt;Medium&lt;/th&gt;
&lt;th&gt;Long&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Read through the &lt;a href="#index-of-system-design-topics"&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read through a few articles in the &lt;a href="#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read through a few &lt;a href="#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Review &lt;a href="#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;ğŸ‘&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Work through &lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Work through &lt;a href="#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Review &lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-approach-a-system-design-interview-question" class="anchor" aria-hidden="true" href="#how-to-approach-a-system-design-interview-question"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to approach a system design interview question&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;How to tackle a system design interview question.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;.  You are expected to lead it.&lt;/p&gt;
&lt;p&gt;You can use the following steps to guide the discussion.  To help solidify this process, work through the &lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-outline-use-cases-constraints-and-assumptions" class="anchor" aria-hidden="true" href="#step-1-outline-use-cases-constraints-and-assumptions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt;
&lt;p&gt;Gather requirements and scope the problem.  Ask questions to clarify use cases and constraints.  Discuss assumptions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who is going to use it?&lt;/li&gt;
&lt;li&gt;How are they going to use it?&lt;/li&gt;
&lt;li&gt;How many users are there?&lt;/li&gt;
&lt;li&gt;What does the system do?&lt;/li&gt;
&lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt;
&lt;li&gt;How much data do we expect to handle?&lt;/li&gt;
&lt;li&gt;How many requests per second do we expect?&lt;/li&gt;
&lt;li&gt;What is the expected read to write ratio?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-create-a-high-level-design" class="anchor" aria-hidden="true" href="#step-2-create-a-high-level-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2: Create a high level design&lt;/h3&gt;
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sketch the main components and connections&lt;/li&gt;
&lt;li&gt;Justify your ideas&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-3-design-core-components" class="anchor" aria-hidden="true" href="#step-3-design-core-components"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3: Design core components&lt;/h3&gt;
&lt;p&gt;Dive into details for each core component.  For example, if you were asked to &lt;a href="solutions/system_design/pastebin/README.md"&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generating and storing a hash of the full url
&lt;ul&gt;
&lt;li&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;MD5&lt;/a&gt; and &lt;a href="solutions/system_design/pastebin/README.md"&gt;Base62&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hash collisions&lt;/li&gt;
&lt;li&gt;SQL or NoSQL&lt;/li&gt;
&lt;li&gt;Database schema&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Translating a hashed url to the full url
&lt;ul&gt;
&lt;li&gt;Database lookup&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API and object-oriented design&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-4-scale-the-design" class="anchor" aria-hidden="true" href="#step-4-scale-the-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 4: Scale the design&lt;/h3&gt;
&lt;p&gt;Identify and address bottlenecks, given the constraints.  For example, do you need the following to address scalability issues?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Load balancer&lt;/li&gt;
&lt;li&gt;Horizontal scaling&lt;/li&gt;
&lt;li&gt;Caching&lt;/li&gt;
&lt;li&gt;Database sharding&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Discuss potential solutions and trade-offs.  Everything is a trade-off.  Address bottlenecks using &lt;a href="#index-of-system-design-topics"&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-back-of-the-envelope-calculations" class="anchor" aria-hidden="true" href="#back-of-the-envelope-calculations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Back-of-the-envelope calculations&lt;/h3&gt;
&lt;p&gt;You might be asked to do some estimates by hand.  Refer to the &lt;a href="#appendix"&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html" rel="nofollow"&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading" class="anchor" aria-hidden="true" href="#sources-and-further-reading"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/" rel="nofollow"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design" rel="nofollow"&gt;The system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZgdS0EUmn70" rel="nofollow"&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-system-design-interview-questions-with-solutions" class="anchor" aria-hidden="true" href="#system-design-interview-questions-with-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System design interview questions with solutions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/twitter/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a web crawler&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/web_crawler/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Mint.com&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/mint/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the data structures for a social network&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/social_graph/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a key-value store for a search engine&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/query_cache/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Amazon's sales ranking by category feature&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/sales_rank/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/scaling_aws/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add a system design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-design-pastebincom-or-bitly" class="anchor" aria-hidden="true" href="#design-pastebincom-or-bitly"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4aee2d26ebedc20e7fa07a2c30780e332fa29f2c/687474703a2f2f692e696d6775722e636f6d2f346564584730542e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/4aee2d26ebedc20e7fa07a2c30780e332fa29f2c/687474703a2f2f692e696d6775722e636f6d2f346564584730542e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/4edXG0T.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-the-twitter-timeline-and-search-or-facebook-feed-and-search" class="anchor" aria-hidden="true" href="#design-the-twitter-timeline-and-search-or-facebook-feed-and-search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/twitter/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/jrUBAF7.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-web-crawler" class="anchor" aria-hidden="true" href="#design-a-web-crawler"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a web crawler&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/web_crawler/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba21a95852d1cf7bb64c8c4622a79d1d5a20d344/687474703a2f2f692e696d6775722e636f6d2f625778507451412e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba21a95852d1cf7bb64c8c4622a79d1d5a20d344/687474703a2f2f692e696d6775722e636f6d2f625778507451412e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/bWxPtQA.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-mintcom" class="anchor" aria-hidden="true" href="#design-mintcom"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Mint.com&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/mint/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/12fea5f9324f74189a9cd983b02239c68615b67e/687474703a2f2f692e696d6775722e636f6d2f563571353776552e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/12fea5f9324f74189a9cd983b02239c68615b67e/687474703a2f2f692e696d6775722e636f6d2f563571353776552e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/V5q57vU.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-the-data-structures-for-a-social-network" class="anchor" aria-hidden="true" href="#design-the-data-structures-for-a-social-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design the data structures for a social network&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/social_graph/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/16d78e51c2e2949e23122f4c26afe5886f82a96f/687474703a2f2f692e696d6775722e636f6d2f636443763567372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/16d78e51c2e2949e23122f4c26afe5886f82a96f/687474703a2f2f692e696d6775722e636f6d2f636443763567372e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/cdCv5g7.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-key-value-store-for-a-search-engine" class="anchor" aria-hidden="true" href="#design-a-key-value-store-for-a-search-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a key-value store for a search engine&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/query_cache/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b6439861687b9a0fc62d0149a364082643ebaf86/687474703a2f2f692e696d6775722e636f6d2f346a39396d68652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b6439861687b9a0fc62d0149a364082643ebaf86/687474703a2f2f692e696d6775722e636f6d2f346a39396d68652e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/4j99mhe.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-amazons-sales-ranking-by-category-feature" class="anchor" aria-hidden="true" href="#design-amazons-sales-ranking-by-category-feature"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Amazon's sales ranking by category feature&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/sales_rank/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a56f5600f7ae29dc0c2e436b8e4e4b55c44d6894/687474703a2f2f692e696d6775722e636f6d2f4d7a45785030362e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a56f5600f7ae29dc0c2e436b8e4e4b55c44d6894/687474703a2f2f692e696d6775722e636f6d2f4d7a45785030362e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/MzExP06.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-system-that-scales-to-millions-of-users-on-aws" class="anchor" aria-hidden="true" href="#design-a-system-that-scales-to-millions-of-users-on-aws"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/scaling_aws/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/jj3A5N8.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-object-oriented-design-interview-questions-with-solutions" class="anchor" aria-hidden="true" href="#object-oriented-design-interview-questions-with-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Object-oriented design interview questions with solutions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design a hash map&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/hash_table/hash_map.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a least recently used cache&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/lru_cache/lru_cache.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a call center&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/call_center/call_center.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a deck of cards&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a parking lot&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/parking_lot/parking_lot.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a chat server&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/online_chat/online_chat.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a circular array&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add an object-oriented design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-system-design-topics-start-here" class="anchor" aria-hidden="true" href="#system-design-topics-start-here"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System design topics: start here&lt;/h2&gt;
&lt;p&gt;New to system design?&lt;/p&gt;
&lt;p&gt;First, you'll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-review-the-scalability-video-lecture" class="anchor" aria-hidden="true" href="#step-1-review-the-scalability-video-lecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Review the scalability video lecture&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4" rel="nofollow"&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topics covered:
&lt;ul&gt;
&lt;li&gt;Vertical scaling&lt;/li&gt;
&lt;li&gt;Horizontal scaling&lt;/li&gt;
&lt;li&gt;Caching&lt;/li&gt;
&lt;li&gt;Load balancing&lt;/li&gt;
&lt;li&gt;Database replication&lt;/li&gt;
&lt;li&gt;Database partitioning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-review-the-scalability-article" class="anchor" aria-hidden="true" href="#step-2-review-the-scalability-article"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2: Review the scalability article&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.lecloud.net/tagged/scalability/chrono" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topics covered:
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones" rel="nofollow"&gt;Clones&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database" rel="nofollow"&gt;Databases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache" rel="nofollow"&gt;Caches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism" rel="nofollow"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-next-steps" class="anchor" aria-hidden="true" href="#next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next steps&lt;/h3&gt;
&lt;p&gt;Next, we'll look at high-level trade-offs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Then we'll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-performance-vs-scalability" class="anchor" aria-hidden="true" href="#performance-vs-scalability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance vs scalability&lt;/h2&gt;
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html" rel="nofollow"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt;
&lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-1" class="anchor" aria-hidden="true" href="#sources-and-further-reading-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html" rel="nofollow"&gt;A word on scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-latency-vs-throughput" class="anchor" aria-hidden="true" href="#latency-vs-throughput"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency vs throughput&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt;
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-2" class="anchor" aria-hidden="true" href="#sources-and-further-reading-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://community.cadence.com/cadence_blogs_8/b/sd/archive/2010/09/13/understanding-latency-vs-throughput" rel="nofollow"&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-availability-vs-consistency" class="anchor" aria-hidden="true" href="#availability-vs-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability vs consistency&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-cap-theorem" class="anchor" aria-hidden="true" href="#cap-theorem"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CAP theorem&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/13719354da7dcd34cd79ff5f8b6306a67bc18261/687474703a2f2f692e696d6775722e636f6d2f62674c4d4932752e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/13719354da7dcd34cd79ff5f8b6306a67bc18261/687474703a2f2f692e696d6775722e636f6d2f62674c4d4932752e706e67" data-canonical-src="http://i.imgur.com/bgLMI2u.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited" rel="nofollow"&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Networks aren't reliable, so you'll need to support partition tolerance.  You'll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-cp---consistency-and-partition-tolerance" class="anchor" aria-hidden="true" href="#cp---consistency-and-partition-tolerance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CP - consistency and partition tolerance&lt;/h4&gt;
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error.  CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-ap---availability-and-partition-tolerance" class="anchor" aria-hidden="true" href="#ap---availability-and-partition-tolerance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AP - availability and partition tolerance&lt;/h4&gt;
&lt;p&gt;Responses return the most recent version of the data available on a node, which might not be the latest.  Writes might take some time to propagate when the partition is resolved.&lt;/p&gt;
&lt;p&gt;AP is a good choice if the business needs allow for &lt;a href="#eventual-consistency"&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-3" class="anchor" aria-hidden="true" href="#sources-and-further-reading-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/" rel="nofollow"&gt;CAP theorem revisited&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem/" rel="nofollow"&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/henryr/cap-faq"&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-consistency-patterns" class="anchor" aria-hidden="true" href="#consistency-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Consistency patterns&lt;/h2&gt;
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data.  Recall the definition of consistency from the &lt;a href="#cap-theorem"&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-weak-consistency" class="anchor" aria-hidden="true" href="#weak-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Weak consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads may or may not see it.  A best effort approach is taken.&lt;/p&gt;
&lt;p&gt;This approach is seen in systems such as memcached.  Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games.  For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-eventual-consistency" class="anchor" aria-hidden="true" href="#eventual-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eventual consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds).  Data is replicated asynchronously.&lt;/p&gt;
&lt;p&gt;This approach is seen in systems such as DNS and email.  Eventual consistency works well in highly available systems.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-strong-consistency" class="anchor" aria-hidden="true" href="#strong-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Strong consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads will see it.  Data is replicated synchronously.&lt;/p&gt;
&lt;p&gt;This approach is seen in file systems and RDBMSes.  Strong consistency works well in systems that need transactions.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-4" class="anchor" aria-hidden="true" href="#sources-and-further-reading-4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://snarfed.org/transactions_across_datacenters_io.html" rel="nofollow"&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-availability-patterns" class="anchor" aria-hidden="true" href="#availability-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability patterns&lt;/h2&gt;
&lt;p&gt;There are two main patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-fail-over" class="anchor" aria-hidden="true" href="#fail-over"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fail-over&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-active-passive" class="anchor" aria-hidden="true" href="#active-passive"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Active-passive&lt;/h4&gt;
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby.  If the heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.&lt;/p&gt;
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in 'hot' standby or whether it needs to start up from 'cold' standby.  Only the active server handles traffic.&lt;/p&gt;
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-active-active" class="anchor" aria-hidden="true" href="#active-active"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Active-active&lt;/h4&gt;
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt;
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers.  If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt;
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-failover" class="anchor" aria-hidden="true" href="#disadvantages-failover"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): failover&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt;
&lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-replication" class="anchor" aria-hidden="true" href="#replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Replication&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-master-slave-and-master-master" class="anchor" aria-hidden="true" href="#master-slave-and-master-master"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-slave and master-master&lt;/h4&gt;
&lt;p&gt;This topic is further discussed in the &lt;a href="#database"&gt;Database&lt;/a&gt; section:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-availability-in-numbers" class="anchor" aria-hidden="true" href="#availability-in-numbers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability in numbers&lt;/h3&gt;
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available.  Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-999-availability---three-9s" class="anchor" aria-hidden="true" href="#999-availability---three-9s"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;99.9% availability - three 9s&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Acceptable downtime&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per year&lt;/td&gt;
&lt;td&gt;8h 45min 57s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per month&lt;/td&gt;
&lt;td&gt;43m 49.7s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per week&lt;/td&gt;
&lt;td&gt;10m 4.8s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per day&lt;/td&gt;
&lt;td&gt;1m 26.4s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-9999-availability---four-9s" class="anchor" aria-hidden="true" href="#9999-availability---four-9s"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;99.99% availability - four 9s&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Acceptable downtime&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per year&lt;/td&gt;
&lt;td&gt;52min 35.7s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per month&lt;/td&gt;
&lt;td&gt;4m 23s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per week&lt;/td&gt;
&lt;td&gt;1m 5s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per day&lt;/td&gt;
&lt;td&gt;8.6s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-availability-in-parallel-vs-in-sequence" class="anchor" aria-hidden="true" href="#availability-in-parallel-vs-in-sequence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability in parallel vs in sequence&lt;/h4&gt;
&lt;p&gt;If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt;
&lt;h6&gt;&lt;a id="user-content-in-sequence" class="anchor" aria-hidden="true" href="#in-sequence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In sequence&lt;/h6&gt;
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt;
&lt;h6&gt;&lt;a id="user-content-in-parallel" class="anchor" aria-hidden="true" href="#in-parallel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In parallel&lt;/h6&gt;
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-domain-name-system" class="anchor" aria-hidden="true" href="#domain-name-system"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Domain name system&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fae27d1291ed38dd120595d692eacd2505cd3a9c/687474703a2f2f692e696d6775722e636f6d2f494f794c6a34692e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/fae27d1291ed38dd120595d692eacd2505cd3a9c/687474703a2f2f692e696d6775722e636f6d2f494f794c6a34692e6a7067" data-canonical-src="http://i.imgur.com/IOyLj4i.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/srikrupa5/dns-security-presentation-issa" rel="nofollow"&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href="http://www.example.com" rel="nofollow"&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt;
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level.  Your router or ISP provides information about which DNS server(s) to contact when doing a lookup.  Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays.  DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href="https://en.wikipedia.org/wiki/Time_to_live" rel="nofollow"&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href="http://www.example.com" rel="nofollow"&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Services such as &lt;a href="https://www.cloudflare.com/dns/" rel="nofollow"&gt;CloudFlare&lt;/a&gt; and &lt;a href="https://aws.amazon.com/route53/" rel="nofollow"&gt;Route 53&lt;/a&gt; provide managed DNS services.  Some DNS services can route traffic through various methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://g33kinfo.com/info/archives/2657" rel="nofollow"&gt;Weighted round robin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt;
&lt;li&gt;Balance between varying cluster sizes&lt;/li&gt;
&lt;li&gt;A/B testing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Latency-based&lt;/li&gt;
&lt;li&gt;Geolocation-based&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-dns" class="anchor" aria-hidden="true" href="#disadvantages-dns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): DNS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt;
&lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href="http://superuser.com/questions/472695/who-controls-the-dns-servers/472729" rel="nofollow"&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;DNS services have recently come under &lt;a href="http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/" rel="nofollow"&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter's IP address(es).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-5" class="anchor" aria-hidden="true" href="#sources-and-further-reading-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx" rel="nofollow"&gt;DNS architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Domain_Name_System" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://support.dnsimple.com/categories/dns/" rel="nofollow"&gt;DNS articles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-content-delivery-network" class="anchor" aria-hidden="true" href="#content-delivery-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content delivery network&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/853a8603651149c686bf3c504769fc594ff08849/687474703a2f2f692e696d6775722e636f6d2f683954417547492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/853a8603651149c686bf3c504769fc594ff08849/687474703a2f2f692e696d6775722e636f6d2f683954417547492e6a7067" data-canonical-src="http://i.imgur.com/h9TAuGI.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/" rel="nofollow"&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user.  Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content.  The site's DNS resolution will tell clients which server to contact.&lt;/p&gt;
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users receive content at data centers close to them&lt;/li&gt;
&lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-push-cdns" class="anchor" aria-hidden="true" href="#push-cdns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Push CDNs&lt;/h3&gt;
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server.  You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN.  You can configure when content expires and when it is updated.  Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt;
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs.  Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pull-cdns" class="anchor" aria-hidden="true" href="#pull-cdns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pull CDNs&lt;/h3&gt;
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content.  You leave the content on your server and rewrite URLs to point to the CDN.  This results in a slower request until the content is cached on the CDN.&lt;/p&gt;
&lt;p&gt;A &lt;a href="https://en.wikipedia.org/wiki/Time_to_live" rel="nofollow"&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached.  Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt;
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-cdn" class="anchor" aria-hidden="true" href="#disadvantages-cdn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): CDN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt;
&lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt;
&lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-6" class="anchor" aria-hidden="true" href="#sources-and-further-reading-6"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972" rel="nofollow"&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/" rel="nofollow"&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-load-balancer" class="anchor" aria-hidden="true" href="#load-balancer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load balancer&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/21caea3d7f67f451630012f657ae59a56709365c/687474703a2f2f692e696d6775722e636f6d2f6838316e39694b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/21caea3d7f67f451630012f657ae59a56709365c/687474703a2f2f692e696d6775722e636f6d2f6838316e39694b2e706e67" data-canonical-src="http://i.imgur.com/h81n9iK.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases.  In each case, the load balancer returns the response from the computing resource to the appropriate client.  Load balancers are effective at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt;
&lt;li&gt;Preventing overloading resources&lt;/li&gt;
&lt;li&gt;Helping eliminate single points of failure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt;
&lt;p&gt;Additional benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
&lt;ul&gt;
&lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509" rel="nofollow"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To protect against failures, it's common to set up multiple load balancers, either in &lt;a href="#active-passive"&gt;active-passive&lt;/a&gt; or &lt;a href="#active-active"&gt;active-active&lt;/a&gt; mode.&lt;/p&gt;
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Random&lt;/li&gt;
&lt;li&gt;Least loaded&lt;/li&gt;
&lt;li&gt;Session/cookies&lt;/li&gt;
&lt;li&gt;&lt;a href="http://g33kinfo.com/info/archives/2657" rel="nofollow"&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-4-load-balancing"&gt;Layer 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-7-load-balancing"&gt;Layer 7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-layer-4-load-balancing" class="anchor" aria-hidden="true" href="#layer-4-load-balancing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Layer 4 load balancing&lt;/h3&gt;
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href="#communication"&gt;transport layer&lt;/a&gt; to decide how to distribute requests.  Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet.  Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/" rel="nofollow"&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-layer-7-load-balancing" class="anchor" aria-hidden="true" href="#layer-7-load-balancing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Layer 7 load balancing&lt;/h3&gt;
&lt;p&gt;Layer 7 load balancers look at the &lt;a href="#communication"&gt;application layer&lt;/a&gt; to decide how to distribute requests.  This can involve contents of the header, message, and cookies.  Layer 7 load balancers terminates network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server.  For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt;
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-horizontal-scaling" class="anchor" aria-hidden="true" href="#horizontal-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Horizontal scaling&lt;/h3&gt;
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability.  Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;.  It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-horizontal-scaling" class="anchor" aria-hidden="true" href="#disadvantages-horizontal-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers
&lt;ul&gt;
&lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt;
&lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href="#database"&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href="#cache"&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-load-balancer" class="anchor" aria-hidden="true" href="#disadvantages-load-balancer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): load balancer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt;
&lt;li&gt;Introducing a load balancer to help eliminate single points of failure results in increased complexity.&lt;/li&gt;
&lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-7" class="anchor" aria-hidden="true" href="#sources-and-further-reading-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" rel="nofollow"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt" rel="nofollow"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Load_balancing_(computing)" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/" rel="nofollow"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/" rel="nofollow"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html" rel="nofollow"&gt;ELB listener config&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reverse-proxy-web-server" class="anchor" aria-hidden="true" href="#reverse-proxy-web-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reverse proxy (web server)&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e88216d0999853426f72b28e41223f43977d22b7/687474703a2f2f692e696d6775722e636f6d2f6e3431417a66662e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e88216d0999853426f72b28e41223f43977d22b7/687474703a2f2f692e696d6775722e636f6d2f6e3431417a66662e706e67" data-canonical-src="http://i.imgur.com/n41Azff.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg" rel="nofollow"&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public.  Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.&lt;/p&gt;
&lt;p&gt;Additional benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy's IP, allowing you to scale servers or change their configuration&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
&lt;ul&gt;
&lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509" rel="nofollow"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly
&lt;ul&gt;
&lt;li&gt;HTML/CSS/JS&lt;/li&gt;
&lt;li&gt;Photos&lt;/li&gt;
&lt;li&gt;Videos&lt;/li&gt;
&lt;li&gt;Etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-load-balancer-vs-reverse-proxy" class="anchor" aria-hidden="true" href="#load-balancer-vs-reverse-proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load balancer vs reverse proxy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deploying a load balancer is useful when you have multiple servers.  Often, load balancers  route traffic to a set of servers serving the same function.&lt;/li&gt;
&lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt;
&lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-reverse-proxy" class="anchor" aria-hidden="true" href="#disadvantages-reverse-proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): reverse proxy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt;
&lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href="https://en.wikipedia.org/wiki/Failover" rel="nofollow"&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-8" class="anchor" aria-hidden="true" href="#sources-and-further-reading-8"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/" rel="nofollow"&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" rel="nofollow"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt" rel="nofollow"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Reverse_proxy" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-application-layer" class="anchor" aria-hidden="true" href="#application-layer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Application layer&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/feeb549c5b6e94f65c613635f7166dc26e0c7de7/687474703a2f2f692e696d6775722e636f6d2f7942355359776d2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/feeb549c5b6e94f65c613635f7166dc26e0c7de7/687474703a2f2f692e696d6775722e636f6d2f7942355359776d2e706e67" data-canonical-src="http://i.imgur.com/yB5SYwm.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer" rel="nofollow"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently.  Adding a new API results in adding application servers without necessarily adding additional web servers.  The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together.  Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt;
&lt;p&gt;Workers in the application layer also help enable &lt;a href="#asynchronism"&gt;asynchronism&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-microservices" class="anchor" aria-hidden="true" href="#microservices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Microservices&lt;/h3&gt;
&lt;p&gt;Related to this discussion are &lt;a href="https://en.wikipedia.org/wiki/Microservices" rel="nofollow"&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services.  Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href="https://smartbear.com/learn/api-design/what-are-microservices" rel="nofollow"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-service-discovery" class="anchor" aria-hidden="true" href="#service-discovery"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Service Discovery&lt;/h3&gt;
&lt;p&gt;Systems such as &lt;a href="https://www.consul.io/docs/index.html" rel="nofollow"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/docs/latest" rel="nofollow"&gt;Etcd&lt;/a&gt;, and &lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports.  &lt;a href="https://www.consul.io/intro/getting-started/checks.html" rel="nofollow"&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href="#hypertext-transfer-protocol-http"&gt;HTTP&lt;/a&gt; endpoint.  Both Consul and Etcd have a built in &lt;a href="#key-value-store"&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-application-layer" class="anchor" aria-hidden="true" href="#disadvantages-application-layer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): application layer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt;
&lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-9" class="anchor" aria-hidden="true" href="#sources-and-further-reading-9"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale" rel="nofollow"&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Service-oriented_architecture" rel="nofollow"&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/" rel="nofollow"&gt;Here's what you need to know about building microservices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-database" class="anchor" aria-hidden="true" href="#database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/15a7553727e6da98d0de5e9ca3792f6d2b5e92d4/687474703a2f2f692e696d6775722e636f6d2f586b6d3543587a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/15a7553727e6da98d0de5e9ca3792f6d2b5e92d4/687474703a2f2f692e696d6775722e636f6d2f586b6d3543587a2e706e67" data-canonical-src="http://i.imgur.com/Xkm5CXz.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-relational-database-management-system-rdbms" class="anchor" aria-hidden="true" href="#relational-database-management-system-rdbms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Relational database management system (RDBMS)&lt;/h3&gt;
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href="https://en.wikipedia.org/wiki/Database_transaction" rel="nofollow"&gt;transactions&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-master-slave-replication" class="anchor" aria-hidden="true" href="#master-slave-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-slave replication&lt;/h4&gt;
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads.  Slaves can also replicate to additional slaves in a tree-like fashion.  If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6a097809b9690236258747d969b1d3e0d93bb8ca/687474703a2f2f692e696d6775722e636f6d2f4339696f47746e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6a097809b9690236258747d969b1d3e0d93bb8ca/687474703a2f2f692e696d6775722e636f6d2f4339696f47746e2e706e67" data-canonical-src="http://i.imgur.com/C9ioGtn.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-master-slave-replication" class="anchor" aria-hidden="true" href="#disadvantages-master-slave-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): master-slave replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt;
&lt;li&gt;See &lt;a href="#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-master-master-replication" class="anchor" aria-hidden="true" href="#master-master-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-master replication&lt;/h4&gt;
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes.  If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5862604b102ee97d85f86f89edda44bde85a5b7f/687474703a2f2f692e696d6775722e636f6d2f6b7241484c47672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/5862604b102ee97d85f86f89edda44bde85a5b7f/687474703a2f2f692e696d6775722e636f6d2f6b7241484c47672e706e67" data-canonical-src="http://i.imgur.com/krAHLGg.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-master-master-replication" class="anchor" aria-hidden="true" href="#disadvantages-master-master-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): master-master replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;You'll need a load balancer or you'll need to make changes to your application logic to determine where to write.&lt;/li&gt;
&lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt;
&lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt;
&lt;li&gt;See &lt;a href="#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-replication" class="anchor" aria-hidden="true" href="#disadvantages-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt;
&lt;li&gt;Writes are replayed to the read replicas.  If there are a lot of writes, the read replicas can get bogged down with replaying writes and can't do as many reads.&lt;/li&gt;
&lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt;
&lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt;
&lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-replication" class="anchor" aria-hidden="true" href="#sources-and-further-reading-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication" rel="nofollow"&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-federation" class="anchor" aria-hidden="true" href="#federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Federation&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6eb6570a8b6b4e1d52e3d7cc07e7959ea5dac75f/687474703a2f2f692e696d6775722e636f6d2f553371563333652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6eb6570a8b6b4e1d52e3d7cc07e7959ea5dac75f/687474703a2f2f692e696d6775722e636f6d2f553371563333652e706e67" data-canonical-src="http://i.imgur.com/U3qV33e.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Federation (or functional partitioning) splits up databases by function.  For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag.  Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality.  With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-federation" class="anchor" aria-hidden="true" href="#disadvantages-federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): federation&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt;
&lt;li&gt;You'll need to update your application logic to determine which database to read and write.&lt;/li&gt;
&lt;li&gt;Joining data from two databases is more complex with a &lt;a href="http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers" rel="nofollow"&gt;server link&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-federation" class="anchor" aria-hidden="true" href="#sources-and-further-reading-federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: federation&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sharding" class="anchor" aria-hidden="true" href="#sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sharding&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1df78be67b749171569a0e11a51aa76b3b678d4f/687474703a2f2f692e696d6775722e636f6d2f775538783549642e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1df78be67b749171569a0e11a51aa76b3b678d4f/687474703a2f2f692e696d6775722e636f6d2f775538783549642e706e67" data-canonical-src="http://i.imgur.com/wU8x5Id.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data.  Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt;
&lt;p&gt;Similar to the advantages of &lt;a href="#federation"&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits.  Index size is also reduced, which generally improves performance with faster queries.  If one shard goes down, the other shards are still operational, although you'll want to add some form of replication to avoid data loss.  Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt;
&lt;p&gt;Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-sharding" class="anchor" aria-hidden="true" href="#disadvantages-sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): sharding&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;You'll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt;
&lt;li&gt;Data distribution can become lopsided in a shard.  For example, a set of power users on a shard could result in increased load to that shard compared to others.
&lt;ul&gt;
&lt;li&gt;Rebalancing adds additional complexity.  A sharding function based on &lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" rel="nofollow"&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt;
&lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sharding" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: sharding&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html" rel="nofollow"&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)" rel="nofollow"&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" rel="nofollow"&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-denormalization" class="anchor" aria-hidden="true" href="#denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Denormalization&lt;/h4&gt;
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance.  Redundant copies of the data are written in multiple tables to avoid expensive joins.  Some RDBMS such as &lt;a href="https://en.wikipedia.org/wiki/PostgreSQL" rel="nofollow"&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href="https://en.wikipedia.org/wiki/Materialized_view" rel="nofollow"&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt;
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href="#federation"&gt;federation&lt;/a&gt; and &lt;a href="#sharding"&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity.  Denormalization might circumvent the need for such complex joins.&lt;/p&gt;
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1.  A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-denormalization" class="anchor" aria-hidden="true" href="#disadvantages-denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): denormalization&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Data is duplicated.&lt;/li&gt;
&lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt;
&lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6&gt;&lt;a id="user-content-sources-and-further-reading-denormalization" class="anchor" aria-hidden="true" href="#sources-and-further-reading-denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: denormalization&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Denormalization" rel="nofollow"&gt;Denormalization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sql-tuning" class="anchor" aria-hidden="true" href="#sql-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQL tuning&lt;/h4&gt;
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href="https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning" rel="nofollow"&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt;
&lt;p&gt;It's important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href="http://httpd.apache.org/docs/2.2/programs/ab.html" rel="nofollow"&gt;ab&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html" rel="nofollow"&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-tighten-up-the-schema" class="anchor" aria-hidden="true" href="#tighten-up-the-schema"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tighten up the schema&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts.  &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches.  Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt;
&lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search" rel="nofollow"&gt;improve search performance&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-use-good-indices" class="anchor" aria-hidden="true" href="#use-good-indices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use good indices&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt;
&lt;li&gt;Indices are usually represented as self-balancing &lt;a href="https://en.wikipedia.org/wiki/B-tree" rel="nofollow"&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt;
&lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt;
&lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt;
&lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-avoid-expensive-joins" class="anchor" aria-hidden="true" href="#avoid-expensive-joins"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Avoid expensive joins&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#denormalization"&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-partition-tables" class="anchor" aria-hidden="true" href="#partition-tables"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Partition tables&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-tune-the-query-cache" class="anchor" aria-hidden="true" href="#tune-the-query-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tune the query cache&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;In some cases, the &lt;a href="https://dev.mysql.com/doc/refman/5.7/en/query-cache.html" rel="nofollow"&gt;query cache&lt;/a&gt; could lead to &lt;a href="https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/" rel="nofollow"&gt;performance issues&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sql-tuning" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sql-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/" rel="nofollow"&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l" rel="nofollow"&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search" rel="nofollow"&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html" rel="nofollow"&gt;Slow query log&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-nosql" class="anchor" aria-hidden="true" href="#nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NoSQL&lt;/h3&gt;
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;.  Data is denormalized, and joins are generally done in the application code.  Most NoSQL stores lack true ACID transactions and favor &lt;a href="#eventual-consistency"&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases.  In comparison with the &lt;a href="#cap-theorem"&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn't receive input during that period.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to choosing between &lt;a href="#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s).  We'll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-key-value-store" class="anchor" aria-hidden="true" href="#key-value-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Key-value store&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: hash table&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD.  Data stores can maintain keys in &lt;a href="https://en.wikipedia.org/wiki/Lexicographical_order" rel="nofollow"&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges.  Key-value stores can allow for storing of metadata with a value.&lt;/p&gt;
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer.  Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt;
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-key-value-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-key-value-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: key-value store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Key-value_database" rel="nofollow"&gt;Key-value database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or" rel="nofollow"&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qnimate.com/overview-of-redis-architecture/" rel="nofollow"&gt;Redis architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.adayinthelifeof.nl/2011/02/06/memcache-internals/" rel="nofollow"&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-document-store" class="anchor" aria-hidden="true" href="#document-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Document store&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object.  Document stores provide APIs or a query language to query based on the internal structure of the document itself.  &lt;em&gt;Note, many key-value stores include features for working with a value's metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories.  Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt;
&lt;p&gt;Some document stores like &lt;a href="https://www.mongodb.com/mongodb-architecture" rel="nofollow"&gt;MongoDB&lt;/a&gt; and &lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/" rel="nofollow"&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries.  &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf" rel="nofollow"&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt;
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-document-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-document-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: document store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Document-oriented_database" rel="nofollow"&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mongodb.com/mongodb-architecture" rel="nofollow"&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/" rel="nofollow"&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up" rel="nofollow"&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-wide-column-store" class="anchor" aria-hidden="true" href="#wide-column-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Wide column store&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/823668b07b4bff50574e934273c9244e4e5017d6/687474703a2f2f692e696d6775722e636f6d2f6e3136694f476b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/823668b07b4bff50574e934273c9244e4e5017d6/687474703a2f2f692e696d6775722e636f6d2f6e3136694f476b2e706e67" data-canonical-src="http://i.imgur.com/n16iOGk.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html" rel="nofollow"&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A wide column store's basic unit of data is a column (name/value pair).  A column can be grouped in column families (analogous to a SQL table).  Super column families further group column families.  You can access each column independently with a row key, and columns with the same row key form a row.  Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt;
&lt;p&gt;Google introduced &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" rel="nofollow"&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html" rel="nofollow"&gt;Cassandra&lt;/a&gt; from Facebook.  Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt;
&lt;p&gt;Wide column stores offer high availability and high scalability.  They are often used for very large data sets.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-wide-column-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-wide-column-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: wide column store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html" rel="nofollow"&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" rel="nofollow"&gt;HBase architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html" rel="nofollow"&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-graph-database" class="anchor" aria-hidden="true" href="#graph-database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Graph database&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bf6508b65e98a7210d9861515833afa0d9434436/687474703a2f2f692e696d6775722e636f6d2f664e636c3635672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/bf6508b65e98a7210d9861515833afa0d9434436/687474703a2f2f692e696d6775722e636f6d2f664e636c3635672e706e67" data-canonical-src="http://i.imgur.com/fNcl65g.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png" rel="nofollow"&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: graph&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes.  Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt;
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network.  They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources.  Many graphs can only be accessed with &lt;a href="#representational-state-transfer-rest"&gt;REST APIs&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-graph" class="anchor" aria-hidden="true" href="#sources-and-further-reading-graph"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: graph&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database" rel="nofollow"&gt;Graph database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://neo4j.com/" rel="nofollow"&gt;Neo4j&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.twitter.com/2010/introducing-flockdb" rel="nofollow"&gt;FlockDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-nosql" class="anchor" aria-hidden="true" href="#sources-and-further-reading-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: NoSQL&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/3342497/explanation-of-base-terminology" rel="nofollow"&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq" rel="nofollow"&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qI_g07C_Q5I" rel="nofollow"&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html" rel="nofollow"&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sql-or-nosql" class="anchor" aria-hidden="true" href="#sql-or-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQL or NoSQL&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a6e2e844765c9d5382d9c9b64ef7693977981646/687474703a2f2f692e696d6775722e636f6d2f775847714735662e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a6e2e844765c9d5382d9c9b64ef7693977981646/687474703a2f2f692e696d6775722e636f6d2f775847714735662e706e67" data-canonical-src="http://i.imgur.com/wXGqG5f.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.infoq.com/articles/Transition-RDBMS-NoSQL/" rel="nofollow"&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Structured data&lt;/li&gt;
&lt;li&gt;Strict schema&lt;/li&gt;
&lt;li&gt;Relational data&lt;/li&gt;
&lt;li&gt;Need for complex joins&lt;/li&gt;
&lt;li&gt;Transactions&lt;/li&gt;
&lt;li&gt;Clear patterns for scaling&lt;/li&gt;
&lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt;
&lt;li&gt;Lookups by index are very fast&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semi-structured data&lt;/li&gt;
&lt;li&gt;Dynamic or flexible schema&lt;/li&gt;
&lt;li&gt;Non-relational data&lt;/li&gt;
&lt;li&gt;No need for complex joins&lt;/li&gt;
&lt;li&gt;Store many TB (or PB) of data&lt;/li&gt;
&lt;li&gt;Very data intensive workload&lt;/li&gt;
&lt;li&gt;Very high throughput for IOPS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt;
&lt;li&gt;Leaderboard or scoring data&lt;/li&gt;
&lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt;
&lt;li&gt;Frequently accessed ('hot') tables&lt;/li&gt;
&lt;li&gt;Metadata/lookup tables&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sql-or-nosql" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sql-or-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sitepoint.com/sql-vs-nosql-differences/" rel="nofollow"&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-cache" class="anchor" aria-hidden="true" href="#cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cache&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7acedde6aa7853baf2eb4a53f88e2595ebe43756/687474703a2f2f692e696d6775722e636f6d2f51367a32344c612e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/7acedde6aa7853baf2eb4a53f88e2595ebe43756/687474703a2f2f692e696d6775722e636f6d2f51367a32344c612e706e67" data-canonical-src="http://i.imgur.com/Q6z24La.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases.  In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt;
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions.  Popular items can skew the distribution, causing bottlenecks.  Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-client-caching" class="anchor" aria-hidden="true" href="#client-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Client caching&lt;/h3&gt;
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href="#reverse-proxy-web-server"&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-cdn-caching" class="anchor" aria-hidden="true" href="#cdn-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CDN caching&lt;/h3&gt;
&lt;p&gt;&lt;a href="#content-delivery-network"&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-web-server-caching" class="anchor" aria-hidden="true" href="#web-server-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web server caching&lt;/h3&gt;
&lt;p&gt;&lt;a href="#reverse-proxy-web-server"&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href="https://www.varnish-cache.org/" rel="nofollow"&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly.  Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-database-caching" class="anchor" aria-hidden="true" href="#database-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database caching&lt;/h3&gt;
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case.  Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-application-caching" class="anchor" aria-hidden="true" href="#application-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Application caching&lt;/h3&gt;
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage.  Since the data is held in RAM, it is much faster than typical databases where data is stored on disk.  RAM is more limited than disk, so &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms" rel="nofollow"&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used" rel="nofollow"&gt;least recently used (LRU)&lt;/a&gt; can help invalidate 'cold' entries and keep 'hot' data in RAM.&lt;/p&gt;
&lt;p&gt;Redis has the following additional features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Persistence option&lt;/li&gt;
&lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Row level&lt;/li&gt;
&lt;li&gt;Query-level&lt;/li&gt;
&lt;li&gt;Fully-formed serializable objects&lt;/li&gt;
&lt;li&gt;Fully-rendered HTML&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-caching-at-the-database-query-level" class="anchor" aria-hidden="true" href="#caching-at-the-database-query-level"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching at the database query level&lt;/h3&gt;
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache.  This approach suffers from expiration issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt;
&lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-caching-at-the-object-level" class="anchor" aria-hidden="true" href="#caching-at-the-object-level"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching at the object level&lt;/h3&gt;
&lt;p&gt;See your data as an object, similar to what you do with your application code.  Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt;
&lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User sessions&lt;/li&gt;
&lt;li&gt;Fully rendered web pages&lt;/li&gt;
&lt;li&gt;Activity streams&lt;/li&gt;
&lt;li&gt;User graph data&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-when-to-update-the-cache" class="anchor" aria-hidden="true" href="#when-to-update-the-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;When to update the cache&lt;/h3&gt;
&lt;p&gt;Since you can only store a limited amount of data in cache, you'll need to determine which cache update strategy works best for your use case.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-cache-aside" class="anchor" aria-hidden="true" href="#cache-aside"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cache-aside&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7f5934e49a678b67f65e5ed53134bc258b007ebb/687474703a2f2f692e696d6775722e636f6d2f4f4e6a4f52716b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/7f5934e49a678b67f65e5ed53134bc258b007ebb/687474703a2f2f692e696d6775722e636f6d2f4f4e6a4f52716b2e706e67" data-canonical-src="http://i.imgur.com/ONjORqk.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;The application is responsible for reading and writing from storage.  The cache does not interact with storage directly.  The application does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt;
&lt;li&gt;Load entry from the database&lt;/li&gt;
&lt;li&gt;Add entry to cache&lt;/li&gt;
&lt;li&gt;Return entry&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;get_user&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;user_id&lt;/span&gt;):
    user &lt;span class="pl-k"&gt;=&lt;/span&gt; cache.get(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;user.&lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id)
    &lt;span class="pl-k"&gt;if&lt;/span&gt; user &lt;span class="pl-k"&gt;is&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;:
        user &lt;span class="pl-k"&gt;=&lt;/span&gt; db.query(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;SELECT * FROM users WHERE user_id = &lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id)
        &lt;span class="pl-k"&gt;if&lt;/span&gt; user &lt;span class="pl-k"&gt;is&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;:
            key &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;user.&lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;.format(user_id)
            cache.set(key, json.dumps(user))
    &lt;span class="pl-k"&gt;return&lt;/span&gt; user&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://memcached.org/" rel="nofollow"&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt;
&lt;p&gt;Subsequent reads of data added to cache are fast.  Cache-aside is also referred to as lazy loading.  Only requested data is cached, which avoids filling up the cache with data that isn't requested.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-cache-aside" class="anchor" aria-hidden="true" href="#disadvantages-cache-aside"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): cache-aside&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt;
&lt;li&gt;Data can become stale if it is updated in the database.  This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt;
&lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-write-through" class="anchor" aria-hidden="true" href="#write-through"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Write-through&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/56b870f4d199335ccdbc98b989ef6511ed14f0e2/687474703a2f2f692e696d6775722e636f6d2f3076426330684e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/56b870f4d199335ccdbc98b989ef6511ed14f0e2/687474703a2f2f692e696d6775722e636f6d2f3076426330684e2e706e67" data-canonical-src="http://i.imgur.com/0vBc0hN.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application adds/updates entry in cache&lt;/li&gt;
&lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt;
&lt;li&gt;Return&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Application code:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;set_user(&lt;span class="pl-c1"&gt;12345&lt;/span&gt;, {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;foo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;:&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;bar&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;})&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Cache code:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;set_user&lt;/span&gt;(&lt;span class="pl-smi"&gt;user_id&lt;/span&gt;, &lt;span class="pl-smi"&gt;values&lt;/span&gt;):
    user &lt;span class="pl-k"&gt;=&lt;/span&gt; db.query(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;UPDATE Users WHERE id = &lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id, values)
    cache.set(user_id, user)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast.  Users are generally more tolerant of latency when updating data than reading data.  Data in the cache is not stale.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-write-through" class="anchor" aria-hidden="true" href="#disadvantages-write-through"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): write through&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database.  Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt;
&lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-write-behind-write-back" class="anchor" aria-hidden="true" href="#write-behind-write-back"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Write-behind (write-back)&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8aa9f1a2f050c1422898bb5e82f1f01773334e22/687474703a2f2f692e696d6775722e636f6d2f72675372766a472e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/8aa9f1a2f050c1422898bb5e82f1f01773334e22/687474703a2f2f692e696d6775722e636f6d2f72675372766a472e706e67" data-canonical-src="http://i.imgur.com/rgSrvjG.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add/update entry in cache&lt;/li&gt;
&lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-write-behind" class="anchor" aria-hidden="true" href="#disadvantages-write-behind"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): write-behind&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt;
&lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-refresh-ahead" class="anchor" aria-hidden="true" href="#refresh-ahead"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Refresh-ahead&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/49dcb54307763b4f56d61a4a1369826e2e7d52e4/687474703a2f2f692e696d6775722e636f6d2f6b78746a7167452e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/49dcb54307763b4f56d61a4a1369826e2e7d52e4/687474703a2f2f692e696d6775722e636f6d2f6b78746a7167452e706e67" data-canonical-src="http://i.imgur.com/kxtjqgE.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt;
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-refresh-ahead" class="anchor" aria-hidden="true" href="#disadvantages-refresh-ahead"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-cache" class="anchor" aria-hidden="true" href="#disadvantages-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): cache&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms" rel="nofollow"&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt;
&lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-10" class="anchor" aria-hidden="true" href="#sources-and-further-reading-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/" rel="nofollow"&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html" rel="nofollow"&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cache_(computing)" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-asynchronism" class="anchor" aria-hidden="true" href="#asynchronism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Asynchronism&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c01ec137453216bbc188e3a8f16da39ec9131234/687474703a2f2f692e696d6775722e636f6d2f353447597353782e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c01ec137453216bbc188e3a8f16da39ec9131234/687474703a2f2f692e696d6775722e636f6d2f353447597353782e706e67" data-canonical-src="http://i.imgur.com/54GYsSx.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer" rel="nofollow"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line.  They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-message-queues" class="anchor" aria-hidden="true" href="#message-queues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Message queues&lt;/h3&gt;
&lt;p&gt;Message queues receive, hold, and deliver messages.  If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt;
&lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The user is not blocked and the job is processed in the background.  During this time, the client might optionally do a small amount of processing to make it seem like the task has completed.  For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://redis.io/" rel="nofollow"&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.rabbitmq.com/" rel="nofollow"&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the 'AMQP' protocol and manage your own nodes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/sqs/" rel="nofollow"&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-task-queues" class="anchor" aria-hidden="true" href="#task-queues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Task queues&lt;/h3&gt;
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results.  They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Celery&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-back-pressure" class="anchor" aria-hidden="true" href="#back-pressure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Back pressure&lt;/h3&gt;
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance.  &lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html" rel="nofollow"&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue.  Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later.  Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff" rel="nofollow"&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-asynchronism" class="anchor" aria-hidden="true" href="#disadvantages-asynchronism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): asynchronism&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-11" class="anchor" aria-hidden="true" href="#sources-and-further-reading-11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1KRYH75wgy4" rel="nofollow"&gt;It's all a numbers game&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html" rel="nofollow"&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Little%27s_law" rel="nofollow"&gt;Little's law&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function" rel="nofollow"&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-communication" class="anchor" aria-hidden="true" href="#communication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Communication&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1d761d5688d28ce1fb12a0f1c8191bca96eece4c/687474703a2f2f692e696d6775722e636f6d2f354b656f6351732e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/1d761d5688d28ce1fb12a0f1c8191bca96eece4c/687474703a2f2f692e696d6775722e636f6d2f354b656f6351732e6a7067" data-canonical-src="http://i.imgur.com/5KeocQs.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.escotal.com/osilayer.html" rel="nofollow"&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-hypertext-transfer-protocol-http" class="anchor" aria-hidden="true" href="#hypertext-transfer-protocol-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt;
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server.  It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request.  HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt;
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint).  Below are common HTTP verbs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Verb&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Idempotent*&lt;/th&gt;
&lt;th&gt;Safe&lt;/th&gt;
&lt;th&gt;Cacheable&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GET&lt;/td&gt;
&lt;td&gt;Reads a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;POST&lt;/td&gt;
&lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Yes if response contains freshness info&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUT&lt;/td&gt;
&lt;td&gt;Creates or replace a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PATCH&lt;/td&gt;
&lt;td&gt;Partially updates a resource&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Yes if response contains freshness info&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DELETE&lt;/td&gt;
&lt;td&gt;Deletes a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt;
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-http" class="anchor" aria-hidden="true" href="#sources-and-further-reading-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: HTTP&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/http/" rel="nofollow"&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol" rel="nofollow"&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1" rel="nofollow"&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-transmission-control-protocol-tcp" class="anchor" aria-hidden="true" href="#transmission-control-protocol-tcp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transmission control protocol (TCP)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/821620cf6aa83566f4def561e754e5991480ca8d/687474703a2f2f692e696d6775722e636f6d2f4a6441736476472e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/821620cf6aa83566f4def561e754e5991480ca8d/687474703a2f2f692e696d6775722e636f6d2f4a6441736476472e6a7067" data-canonical-src="http://i.imgur.com/JdAsdvG.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/" rel="nofollow"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href="https://en.wikipedia.org/wiki/Internet_Protocol" rel="nofollow"&gt;IP network&lt;/a&gt;.  Connection is established and terminated using a &lt;a href="https://en.wikipedia.org/wiki/Handshaking" rel="nofollow"&gt;handshake&lt;/a&gt;.  All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequence numbers and &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation" rel="nofollow"&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)" rel="nofollow"&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets.  If there are multiple timeouts, the connection is dropped.  TCP also implements &lt;a href="https://en.wikipedia.org/wiki/Flow_control_(data)" rel="nofollow"&gt;flow control&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Network_congestion#Congestion_control" rel="nofollow"&gt;congestion control&lt;/a&gt;.  These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt;
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage.  It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href="https://memcached.org/" rel="nofollow"&gt;memcached&lt;/a&gt; server.  &lt;a href="https://en.wikipedia.org/wiki/Connection_pool" rel="nofollow"&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt;
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical.  Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt;
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need all of the data to arrive intact&lt;/li&gt;
&lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-user-datagram-protocol-udp" class="anchor" aria-hidden="true" href="#user-datagram-protocol-udp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;User datagram protocol (UDP)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/47eb14c0a2dff2166f8781a6ce8c7f33d4c33da8/687474703a2f2f692e696d6775722e636f6d2f797a44724a74412e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/47eb14c0a2dff2166f8781a6ce8c7f33d4c33da8/687474703a2f2f692e696d6775722e636f6d2f797a44724a74412e6a7067" data-canonical-src="http://i.imgur.com/yzDrJtA.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/" rel="nofollow"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;UDP is connectionless.  Datagrams (analogous to packets) are guaranteed only at the datagram level.  Datagrams might reach their destination out of order or not at all.  UDP does not support congestion control.  Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt;
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet.  This is useful with &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol" rel="nofollow"&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt;
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt;
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need the lowest latency&lt;/li&gt;
&lt;li&gt;Late data is worse than loss of data&lt;/li&gt;
&lt;li&gt;You want to implement your own error correction&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-tcp-and-udp" class="anchor" aria-hidden="true" href="#sources-and-further-reading-tcp-and-udp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/" rel="nofollow"&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/" rel="nofollow"&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp" rel="nofollow"&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol" rel="nofollow"&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol" rel="nofollow"&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf" rel="nofollow"&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-remote-procedure-call-rpc" class="anchor" aria-hidden="true" href="#remote-procedure-call-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Remote procedure call (RPC)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a3d7771c0b0a7816d0533fffeb6eeeb442d9945/687474703a2f2f692e696d6775722e636f6d2f6946344d6b62352e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1a3d7771c0b0a7816d0533fffeb6eeeb442d9945/687474703a2f2f692e696d6775722e636f6d2f6946344d6b62352e706e67" data-canonical-src="http://i.imgur.com/iF4Mkb5.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server.  The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program.  Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls.  Popular RPC frameworks include &lt;a href="https://developers.google.com/protocol-buffers/" rel="nofollow"&gt;Protobuf&lt;/a&gt;, &lt;a href="https://thrift.apache.org/" rel="nofollow"&gt;Thrift&lt;/a&gt;, and &lt;a href="https://avro.apache.org/docs/current/" rel="nofollow"&gt;Avro&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure.  The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; -  Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt;
&lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample RPC calls:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  "data":"anId";
  "anotherdata": "another value"
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RPC is focused on exposing behaviors.  RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt;
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You know your target platform.&lt;/li&gt;
&lt;li&gt;You want to control how your "logic" is accessed.&lt;/li&gt;
&lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt;
&lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-rpc" class="anchor" aria-hidden="true" href="#disadvantages-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): RPC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt;
&lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt;
&lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt;
&lt;li&gt;You might not be able to leverage existing technologies out of the box.  For example, it might require additional effort to ensure &lt;a href="http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/" rel="nofollow"&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href="http://www.squid-cache.org/" rel="nofollow"&gt;Squid&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-representational-state-transfer-rest" class="anchor" aria-hidden="true" href="#representational-state-transfer-rest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Representational state transfer (REST)&lt;/h3&gt;
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server.  The server provides a representation of resources and actions that can either manipulate or get a new representation of resources.  All communication must be stateless and cacheable.&lt;/p&gt;
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don't reinvent the wheel.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="http://restcookbook.com/Basics/hateoas/" rel="nofollow"&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample REST calls:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{"anotherdata": "another value"}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;REST is focused on exposing data.  It minimizes the coupling between client/server and is often used for public HTTP APIs.  REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href="https://github.com/for-GET/know-your-http-well/blob/master/headers.md"&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH.  Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-rest" class="anchor" aria-hidden="true" href="#disadvantages-rest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): REST&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy.  For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path.  With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt;
&lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn't fit your use case.  For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt;
&lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt;
&lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rpc-and-rest-calls-comparison" class="anchor" aria-hidden="true" href="#rpc-and-rest-calls-comparison"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RPC and REST calls comparison&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operation&lt;/th&gt;
&lt;th&gt;RPC&lt;/th&gt;
&lt;th&gt;REST&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Signup&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resign&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br&gt;{&lt;br&gt;"personid": "1234"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read a person&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read a personâ€™s items list&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add an item to a personâ€™s items&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br&gt;{&lt;br&gt;"personid": "1234";&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Update an item&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br&gt;{&lt;br&gt;"itemid": "456";&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br&gt;{&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Delete an item&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align="center"&gt;
  &lt;i&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/" rel="nofollow"&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-rest-and-rpc" class="anchor" aria-hidden="true" href="#sources-and-further-reading-rest-and-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/" rel="nofollow"&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://programmers.stackexchange.com/a/181186" rel="nofollow"&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15056878/rest-vs-json-rpc" rel="nofollow"&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/" rel="nofollow"&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs" rel="nofollow"&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.facebook.com/posts/1468950976659943/" rel="nofollow"&gt;Thrift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arstechnica.com/civis/viewtopic.php?t=1190508" rel="nofollow"&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-security" class="anchor" aria-hidden="true" href="#security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Security&lt;/h2&gt;
&lt;p&gt;This section could use some updates.  Consider &lt;a href="#contributing"&gt;contributing&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Security is a broad topic.  Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won't need to know more than the basics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt;
&lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting" rel="nofollow"&gt;XSS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/SQL_injection" rel="nofollow"&gt;SQL injection&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt;
&lt;li&gt;Use the principle of &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege" rel="nofollow"&gt;least privilege&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-12" class="anchor" aria-hidden="true" href="#sources-and-further-reading-12"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/shieldfy/API-Security-Checklist"&gt;API security checklist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/FallibleInc/security-guide-for-developers"&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet" rel="nofollow"&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-appendix" class="anchor" aria-hidden="true" href="#appendix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Appendix&lt;/h2&gt;
&lt;p&gt;You'll sometimes be asked to do 'back-of-the-envelope' estimates.  For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take.  The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-powers-of-two-table" class="anchor" aria-hidden="true" href="#powers-of-two-table"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Powers of two table&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-13" class="anchor" aria-hidden="true" href="#sources-and-further-reading-13"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Power_of_two" rel="nofollow"&gt;Powers of two&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-latency-numbers-every-programmer-should-know" class="anchor" aria-hidden="true" href="#latency-numbers-every-programmer-should-know"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency numbers every programmer should know&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read sequentially from disk at 30 MB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt;
&lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt;
&lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-latency-numbers-visualized" class="anchor" aria-hidden="true" href="#latency-numbers-visualized"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency numbers visualized&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-14" class="anchor" aria-hidden="true" href="#sources-and-further-reading-14"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf" rel="nofollow"&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf" rel="nofollow"&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-additional-system-design-interview-questions" class="anchor" aria-hidden="true" href="#additional-system-design-interview-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional system design interview questions&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc" rel="nofollow"&gt;youtube.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a search engine like Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://queue.acm.org/detail.cfm?id=988407" rel="nofollow"&gt;queue.acm.org&lt;/a&gt;&lt;br&gt;&lt;a href="http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search" rel="nofollow"&gt;stackexchange.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.ardendertat.com/2012/01/11/implementing-search-engines/" rel="nofollow"&gt;ardendertat.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://infolab.stanford.edu/~backrub/google.html" rel="nofollow"&gt;stanford.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Google docs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://code.google.com/p/google-mobwrite/" rel="nofollow"&gt;code.google.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://neil.fraser.name/writing/sync/" rel="nofollow"&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a key-value store like Redis&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a cache system like Memcached&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a recommendation system like Amazon's&lt;/td&gt;
&lt;td&gt;&lt;a href="https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html" rel="nofollow"&gt;hulu.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf" rel="nofollow"&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt;
&lt;td&gt;&lt;a href="http://n00tc0d3r.blogspot.com/" rel="nofollow"&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook news feed function&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook timeline function&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.facebook.com/note.php?note_id=10150468255628920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook chat function&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf" rel="nofollow"&gt;erlang-factory.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a graph search function like Facebook's&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt;
&lt;td&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972" rel="nofollow"&gt;figshare.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a trending topic system like Twitter's&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/" rel="nofollow"&gt;michael-noll.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/" rel="nofollow"&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a random ID generation system&lt;/td&gt;
&lt;td&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake" rel="nofollow"&gt;blog.twitter.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/twitter/snowflake/"&gt;github.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Return the top k requests during a time interval&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cs.ucsb.edu/sites/cs.ucsb.edu/files/docs/reports/2005-23.pdf" rel="nofollow"&gt;cs.ucsb.edu&lt;/a&gt;&lt;br&gt;&lt;a href="http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf" rel="nofollow"&gt;wpi.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design an online multiplayer card game&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html" rel="nofollow"&gt;indieflashblog.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://buildnewgames.com/real-time-multiplayer/" rel="nofollow"&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a garbage collection system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/" rel="nofollow"&gt;stuffwithstuff.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf" rel="nofollow"&gt;washington.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design an API rate limiter&lt;/td&gt;
&lt;td&gt;&lt;a href="https://stripe.com/blog/rate-limiters" rel="nofollow"&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add a system design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-real-world-architectures" class="anchor" aria-hidden="true" href="#real-world-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Real world architectures&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b7c71be73fb466344c2d773178ae74e3fbb1dcc6/687474703a2f2f692e696d6775722e636f6d2f5463556f3266772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b7c71be73fb466344c2d773178ae74e3fbb1dcc6/687474703a2f2f692e696d6775722e636f6d2f5463556f3266772e706e67" data-canonical-src="http://i.imgur.com/TcUo2fw.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability" rel="nofollow"&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don't focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt;
&lt;li&gt;Study what problems are solved by each component, where it works, where it doesn't&lt;/li&gt;
&lt;li&gt;Review the lessons learned&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/AGrishchenko/apache-spark-architecture" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/previa/storm-16094009" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/alexbaranau/intro-to-hbase" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf" rel="nofollow"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/mdirolf/introduction-to-mongodb" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://research.google.com/archive/spanner-osdi2012.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File system&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File system&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt;
&lt;td&gt;&lt;a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" rel="nofollow"&gt;apache.org&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/mumrah/kafka-talk-tri-hug" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Add an architecture&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-company-architectures" class="anchor" aria-hidden="true" href="#company-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Company architectures&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Company&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Amazon&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/amazon-architecture" rel="nofollow"&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cinchcast&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html" rel="nofollow"&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DataSift&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html" rel="nofollow"&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DropBox&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc" rel="nofollow"&gt;How we've scaled Dropbox&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ESPN&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html" rel="nofollow"&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/google-architecture" rel="nofollow"&gt;Google architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Instagram&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html" rel="nofollow"&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br&gt;&lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances" rel="nofollow"&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Justin.tv&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html" rel="nofollow"&gt;Justin.Tv's live video broadcasting architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Facebook&lt;/td&gt;
&lt;td&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf" rel="nofollow"&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf" rel="nofollow"&gt;TAO: Facebookâ€™s distributed data store for the social graph&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf" rel="nofollow"&gt;Facebookâ€™s photo storage&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html" rel="nofollow"&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Flickr&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture" rel="nofollow"&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mailbox&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html" rel="nofollow"&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Netflix&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html" rel="nofollow"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html" rel="nofollow"&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pinterest&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html" rel="nofollow"&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html" rel="nofollow"&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Playfish&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html" rel="nofollow"&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PlentyOfFish&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/plentyoffish-architecture" rel="nofollow"&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Salesforce&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html" rel="nofollow"&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stack Overflow&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html" rel="nofollow"&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TripAdvisor&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html" rel="nofollow"&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tumblr&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html" rel="nofollow"&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster" rel="nofollow"&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html" rel="nofollow"&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html" rel="nofollow"&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability" rel="nofollow"&gt;Timelines at scale&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI" rel="nofollow"&gt;Big and small data at Twitter&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=z8LU0Cj6BOU" rel="nofollow"&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html" rel="nofollow"&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Uber&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html" rel="nofollow"&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html" rel="nofollow"&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WhatsApp&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html" rel="nofollow"&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;YouTube&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=w5WVu624fY8" rel="nofollow"&gt;YouTube scalability&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/youtube-architecture" rel="nofollow"&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-company-engineering-blogs" class="anchor" aria-hidden="true" href="#company-engineering-blogs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Company engineering blogs&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt;
&lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://nerds.airbnb.com/" rel="nofollow"&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.atlassian.com/blog/" rel="nofollow"&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/aws/" rel="nofollow"&gt;AWS Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://word.bitly.com/" rel="nofollow"&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.box.com/blog/category/engineering" rel="nofollow"&gt;Box Blogs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.cloudera.com/" rel="nofollow"&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tech.dropbox.com/" rel="nofollow"&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.quora.com/" rel="nofollow"&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ebaytechblog.com/" rel="nofollow"&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.evernote.com/tech/" rel="nofollow"&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://codeascraft.com/" rel="nofollow"&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.facebook.com/Engineering" rel="nofollow"&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://code.flickr.net/" rel="nofollow"&gt;Flickr Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.foursquare.com/" rel="nofollow"&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://githubengineering.com/" rel="nofollow"&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://googleresearch.blogspot.com/" rel="nofollow"&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.groupon.com/" rel="nofollow"&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.heroku.com/" rel="nofollow"&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://product.hubspot.com/blog/topic/engineering" rel="nofollow"&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/" rel="nofollow"&gt;High Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://instagram-engineering.tumblr.com/" rel="nofollow"&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://software.intel.com/en-us/blogs/" rel="nofollow"&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.janestreet.com/category/ocaml/" rel="nofollow"&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.linkedin.com/blog" rel="nofollow"&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.microsoft.com/" rel="nofollow"&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.msdn.microsoft.com/pythonengineering/" rel="nofollow"&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://techblog.netflix.com/" rel="nofollow"&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://devblog.paypal.com/category/engineering/" rel="nofollow"&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@Pinterest_Engineering" rel="nofollow"&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.quora.com/" rel="nofollow"&gt;Quora Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.redditblog.com/" rel="nofollow"&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.salesforce.com/blogs/engineering/" rel="nofollow"&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://slack.engineering/" rel="nofollow"&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.spotify.com/" rel="nofollow"&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.twilio.com/engineering" rel="nofollow"&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.twitter.com/engineering/" rel="nofollow"&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eng.uber.com/" rel="nofollow"&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yahooeng.tumblr.com/" rel="nofollow"&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineeringblog.yelp.com/" rel="nofollow"&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zynga.com/blogs/engineering" rel="nofollow"&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-15" class="anchor" aria-hidden="true" href="#sources-and-further-reading-15"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;p&gt;Looking to add a blog?  To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kilimchoi/engineering-blogs"&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-under-development" class="anchor" aria-hidden="true" href="#under-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Under development&lt;/h2&gt;
&lt;p&gt;Interested in adding a section or helping complete one in-progress?  &lt;a href="#contributing"&gt;Contribute&lt;/a&gt;!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distributed computing with MapReduce&lt;/li&gt;
&lt;li&gt;Consistent hashing&lt;/li&gt;
&lt;li&gt;Scatter gather&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt;
&lt;p&gt;Special thanks to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/" rel="nofollow"&gt;Hired in tech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/dp/0984782850/" rel="nofollow"&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/" rel="nofollow"&gt;High scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shashank88/system_design"&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mmcgrana/services-engineering"&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f"&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dancres.github.io/Pages/" rel="nofollow"&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact-info" class="anchor" aria-hidden="true" href="#contact-info"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact info&lt;/h2&gt;
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt;
&lt;p&gt;My contact info can be found on my &lt;a href="https://github.com/donnemartin"&gt;GitHub page&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>donnemartin</author><guid isPermaLink="false">https://github.com/donnemartin/system-design-primer</guid><pubDate>Wed, 20 Nov 2019 00:09:00 GMT</pubDate></item><item><title>huggingface/transformers #10 in Python, Today</title><link>https://github.com/huggingface/transformers</link><description>&lt;p&gt;&lt;i&gt;ğŸ¤— Transformers: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;br&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png"&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;br&gt;
&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;&lt;p align="center"&gt;
    &lt;a href="https://circleci.com/gh/huggingface/transformers" rel="nofollow"&gt;
        &lt;img alt="Build" src="https://camo.githubusercontent.com/045b8639882280ff5cd38c403499977386c25134/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f6275696c642f6769746875622f68756767696e67666163652f7472616e73666f726d6572732f6d6173746572" data-canonical-src="https://img.shields.io/circleci/build/github/huggingface/transformers/master" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://github.com/huggingface/transformers/blob/master/LICENSE"&gt;
        &lt;img alt="GitHub" src="https://camo.githubusercontent.com/440e73b137335cc0088bb06e6c90cc7b503b14a2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f68756767696e67666163652f7472616e73666f726d6572732e7376673f636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://huggingface.co/transformers/index.html" rel="nofollow"&gt;
        &lt;img alt="Documentation" src="https://camo.githubusercontent.com/b104c21f478c4d4a37f63292ab2898047f19ee24/68747470733a2f2f696d672e736869656c64732e696f2f776562736974652f687474702f68756767696e67666163652e636f2f7472616e73666f726d6572732f696e6465782e68746d6c2e7376673f646f776e5f636f6c6f723d72656426646f776e5f6d6573736167653d6f66666c696e652675705f6d6573736167653d6f6e6c696e65" data-canonical-src="https://img.shields.io/website/http/huggingface.co/transformers/index.html.svg?down_color=red&amp;amp;down_message=offline&amp;amp;up_message=online" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://github.com/huggingface/transformers/releases"&gt;
        &lt;img alt="GitHub release" src="https://camo.githubusercontent.com/8409fd8716dd1a11afa7ab38e1218b34918164eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f68756767696e67666163652f7472616e73666f726d6572732e737667" data-canonical-src="https://img.shields.io/github/release/huggingface/transformers.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;h3 align="center"&gt;&lt;a id="user-content-state-of-the-art-natural-language-processing-for-tensorflow-20-and-pytorch" class="anchor" aria-hidden="true" href="#state-of-the-art-natural-language-processing-for-tensorflow-20-and-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;p&gt;State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch
&lt;/p&gt;&lt;/h3&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ğŸ¤—&lt;/g-emoji&gt; Transformers (formerly known as &lt;code&gt;pytorch-transformers&lt;/code&gt; and &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt;) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;As easy to use as pytorch-transformers&lt;/li&gt;
&lt;li&gt;As powerful and concise as Keras&lt;/li&gt;
&lt;li&gt;High performance on NLU and NLG tasks&lt;/li&gt;
&lt;li&gt;Low barrier to entry for educators and practitioners&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;State-of-the-art NLP for everyone&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deep learning researchers&lt;/li&gt;
&lt;li&gt;Hands-on practitioners&lt;/li&gt;
&lt;li&gt;AI/ML/NLP teachers and educators&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lower compute costs, smaller carbon footprint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Researchers can share trained models instead of always retraining&lt;/li&gt;
&lt;li&gt;Practitioners can reduce compute time and production costs&lt;/li&gt;
&lt;li&gt;10 architectures with over 30 pretrained models, some in more than 100 languages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Choose the right framework for every part of a model's lifetime&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Train state-of-the-art models in 3 lines of code&lt;/li&gt;
&lt;li&gt;Deep interoperability between TensorFlow 2.0 and PyTorch models&lt;/li&gt;
&lt;li&gt;Move a single model between TF2.0/PyTorch frameworks at will&lt;/li&gt;
&lt;li&gt;Seamlessly pick the right framework for training, evaluation, production&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Section&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;How to install the package&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#model-architectures"&gt;Model architectures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Architectures (with pretrained weights)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#online-demo"&gt;Online demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Experimenting with this repoâ€™s text generation capabilities&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#quick-tour"&gt;Quick tour: Usage&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Tokenizers &amp;amp; models usage: Bert and GPT-2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Quick-tour-TF-20-training-and-PyTorch-interoperability"&gt;Quick tour: TF 2.0 and PyTorch &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Train a TF 2.0 model in 10 lines of code, load it in PyTorch&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#quick-tour-of-the-fine-tuningusage-scripts"&gt;Quick tour: Fine-tuning/usage scripts&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Using provided scripts: GLUE, SQuAD and Text generation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Migrating-from-pytorch-transformers-to-transformers"&gt;Migrating from pytorch-transformers to transformers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Migrating your code from pytorch-transformers to transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Migrating-from-pytorch-pretrained-bert-to-transformers"&gt;Migrating from pytorch-pretrained-bert to pytorch-transformers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Migrating your code from pytorch-pretrained-bert to transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;Documentation&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v2.1.1" rel="nofollow"&gt;(v2.1.1)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v2.0.0" rel="nofollow"&gt;(v2.0.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.2.0" rel="nofollow"&gt;(v1.2.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.1.0" rel="nofollow"&gt;(v1.1.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.0.0" rel="nofollow"&gt;(v1.0.0)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Full API documentation and more&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;This repo is tested on Python 2.7 and 3.5+ (examples are tested only on python 3.5+), PyTorch 1.0.0+ and TensorFlow 2.0.0-rc1&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-with-pip" class="anchor" aria-hidden="true" href="#with-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;With pip&lt;/h3&gt;
&lt;p&gt;First you need to install one of, or both, TensorFlow 2.0 and PyTorch.
Please refer to &lt;a href="https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available" rel="nofollow"&gt;TensorFlow installation page&lt;/a&gt; and/or &lt;a href="https://pytorch.org/get-started/locally/#start-locally" rel="nofollow"&gt;PyTorch installation page&lt;/a&gt; regarding the specific install command for your platform.&lt;/p&gt;
&lt;p&gt;When TensorFlow 2.0 and/or PyTorch has been installed, &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ğŸ¤—&lt;/g-emoji&gt; Transformers can be installed using pip as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install transformers&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-from-source" class="anchor" aria-hidden="true" href="#from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;From source&lt;/h3&gt;
&lt;p&gt;Here also, you first need to install one of, or both, TensorFlow 2.0 and PyTorch.
Please refer to &lt;a href="https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available" rel="nofollow"&gt;TensorFlow installation page&lt;/a&gt; and/or &lt;a href="https://pytorch.org/get-started/locally/#start-locally" rel="nofollow"&gt;PyTorch installation page&lt;/a&gt; regarding the specific install command for your platform.&lt;/p&gt;
&lt;p&gt;When TensorFlow 2.0 and/or PyTorch has been installed, you can install from source by cloning the repository and running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install [--editable] &lt;span class="pl-c1"&gt;.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h3&gt;
&lt;p&gt;A series of tests are included for the library and the example scripts. Library tests can be found in the &lt;a href="https://github.com/huggingface/transformers/tree/master/transformers/tests"&gt;tests folder&lt;/a&gt; and examples tests in the &lt;a href="https://github.com/huggingface/transformers/tree/master/examples"&gt;examples folder&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These tests can be run using &lt;code&gt;pytest&lt;/code&gt; (install pytest if needed with &lt;code&gt;pip install pytest&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Depending on which framework is installed (TensorFlow 2.0 and/or PyTorch), the irrelevant tests will be skipped. Ensure that both frameworks are installed if you want to execute all tests.&lt;/p&gt;
&lt;p&gt;You can run the tests from the root of the cloned repository with the commands:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m pytest -sv ./transformers/tests/
python -m pytest -sv ./examples/&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-do-you-want-to-run-a-transformer-model-on-a-mobile-device" class="anchor" aria-hidden="true" href="#do-you-want-to-run-a-transformer-model-on-a-mobile-device"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Do you want to run a Transformer model on a mobile device?&lt;/h3&gt;
&lt;p&gt;You should check out our &lt;a href="https://github.com/huggingface/swift-coreml-transformers"&gt;&lt;code&gt;swift-coreml-transformers&lt;/code&gt;&lt;/a&gt; repo.&lt;/p&gt;
&lt;p&gt;It contains a set of tools to convert PyTorch or TensorFlow 2.0 trained Transformer models (currently contains &lt;code&gt;GPT-2&lt;/code&gt;, &lt;code&gt;DistilGPT-2&lt;/code&gt;, &lt;code&gt;BERT&lt;/code&gt;, and &lt;code&gt;DistilBERT&lt;/code&gt;) to CoreML models that run on iOS devices.&lt;/p&gt;
&lt;p&gt;At some point in the future, you'll be able to seamlessly move from pre-training or fine-tuning models to productizing them in CoreML, or prototype a model or an app in CoreML then research its hyperparameters or architecture from TensorFlow 2.0 and/or PyTorch. Super exciting!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-architectures" class="anchor" aria-hidden="true" href="#model-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model architectures&lt;/h2&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ğŸ¤—&lt;/g-emoji&gt; Transformers currently provides 10 NLU/NLG architectures:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/google-research/bert"&gt;BERT&lt;/a&gt;&lt;/strong&gt; (from Google) released with the paper &lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt; by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/openai/finetune-transformer-lm"&gt;GPT&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href="https://blog.openai.com/language-unsupervised/" rel="nofollow"&gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt; by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://blog.openai.com/better-language-models/" rel="nofollow"&gt;GPT-2&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href="https://blog.openai.com/better-language-models/" rel="nofollow"&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt; by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/kimiyoung/transformer-xl"&gt;Transformer-XL&lt;/a&gt;&lt;/strong&gt; (from Google/CMU) released with the paper &lt;a href="https://arxiv.org/abs/1901.02860" rel="nofollow"&gt;Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context&lt;/a&gt; by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/zihangdai/xlnet/"&gt;XLNet&lt;/a&gt;&lt;/strong&gt; (from Google/CMU) released with the paper &lt;a href="https://arxiv.org/abs/1906.08237" rel="nofollow"&gt;â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding&lt;/a&gt; by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/facebookresearch/XLM/"&gt;XLM&lt;/a&gt;&lt;/strong&gt; (from Facebook) released together with the paper &lt;a href="https://arxiv.org/abs/1901.07291" rel="nofollow"&gt;Cross-lingual Language Model Pretraining&lt;/a&gt; by Guillaume Lample and Alexis Conneau.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/pytorch/fairseq/tree/master/examples/roberta"&gt;RoBERTa&lt;/a&gt;&lt;/strong&gt; (from Facebook), released together with the paper a &lt;a href="https://arxiv.org/abs/1907.11692" rel="nofollow"&gt;Robustly Optimized BERT Pretraining Approach&lt;/a&gt; by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/huggingface/transformers/tree/master/examples/distillation"&gt;DistilBERT&lt;/a&gt;&lt;/strong&gt; (from HuggingFace), released together with the paper &lt;a href="https://arxiv.org/abs/1910.01108" rel="nofollow"&gt;DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter&lt;/a&gt; by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into &lt;a href="https://github.com/huggingface/transformers/tree/master/examples/distillation"&gt;DistilGPT2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/salesforce/ctrl/"&gt;CTRL&lt;/a&gt;&lt;/strong&gt; (from Salesforce) released with the paper &lt;a href="https://arxiv.org/abs/1909.05858" rel="nofollow"&gt;CTRL: A Conditional Transformer Language Model for Controllable Generation&lt;/a&gt; by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://camembert-model.fr" rel="nofollow"&gt;CamemBERT&lt;/a&gt;&lt;/strong&gt; (from Inria/Facebook/Sorbonne) released with the paper &lt;a href="https://arxiv.org/abs/1911.03894" rel="nofollow"&gt;CamemBERT: a Tasty French Language Model&lt;/a&gt; by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.&lt;/li&gt;
&lt;li&gt;Want to contribute a new model? We have added a &lt;strong&gt;detailed guide and templates&lt;/strong&gt; to guide you in the process of adding a new model. You can find them in the &lt;a href="./templates"&gt;&lt;code&gt;templates&lt;/code&gt;&lt;/a&gt; folder of the repository. Be sure to check the &lt;a href="./CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; and contact the maintainers or open an issue to collect feedbacks before starting your PR.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These implementations have been tested on several datasets (see the example scripts) and should match the performances of the original implementations (e.g. ~93 F1 on SQuAD for BERT Whole-Word-Masking, ~88 F1 on RocStories for OpenAI GPT, ~18.3 perplexity on WikiText 103 for Transformer-XL, ~0.916 Peason R coefficient on STS-B for XLNet). You can find more details on the performances in the Examples section of the &lt;a href="https://huggingface.co/transformers/examples.html" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-online-demo" class="anchor" aria-hidden="true" href="#online-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online demo&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://transformer.huggingface.co" rel="nofollow"&gt;Write With Transformer&lt;/a&gt;&lt;/strong&gt;, built by the Hugging Face team at transformer.huggingface.co, is the official demo of this repoâ€™s text generation capabilities.
You can use it to experiment with completions generated by &lt;code&gt;GPT2Model&lt;/code&gt;, &lt;code&gt;TransfoXLModel&lt;/code&gt;, and &lt;code&gt;XLNetModel&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;â€œ&lt;g-emoji class="g-emoji" alias="unicorn" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f984.png"&gt;ğŸ¦„&lt;/g-emoji&gt; Write with transformer is to writing what calculators are to calculus.â€&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba91bf4a35939363eca4ca83f3ad3f83248bbc60/68747470733a2f2f7472616e73666f726d65722e68756767696e67666163652e636f2f66726f6e742f6173736574732f7468756d626e61696c2d6c617267652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba91bf4a35939363eca4ca83f3ad3f83248bbc60/68747470733a2f2f7472616e73666f726d65722e68756767696e67666163652e636f2f66726f6e742f6173736574732f7468756d626e61696c2d6c617267652e706e67" alt="write_with_transformer" data-canonical-src="https://transformer.huggingface.co/front/assets/thumbnail-large.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour" class="anchor" aria-hidden="true" href="#quick-tour"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour&lt;/h2&gt;
&lt;p&gt;Let's do a very quick overview of the model architectures in &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ğŸ¤—&lt;/g-emoji&gt; Transformers. Detailed examples for each model architecture (Bert, GPT, GPT-2, Transformer-XL, XLNet and XLM) can be found in the &lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;full documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; torch
&lt;span class="pl-k"&gt;from&lt;/span&gt; transformers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Transformers has a unified API&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; for 8 transformer architectures and 30 pretrained weights.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;          Model          | Tokenizer          | Pretrained weights shortcut&lt;/span&gt;
&lt;span class="pl-c1"&gt;MODELS&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [(BertModel,       BertTokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (OpenAIGPTModel,  OpenAIGPTTokenizer,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;openai-gpt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (GPT2Model,       GPT2Tokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gpt2&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (CTRLModel,       CTRLTokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctrl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (TransfoXLModel,  TransfoXLTokenizer,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;transfo-xl-wt103&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (XLNetModel,      XLNetTokenizer,      &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;xlnet-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (XLMModel,        XLMTokenizer,        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;xlm-mlm-enfr-1024&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (DistilBertModel, DistilBertTokenizer, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;distilbert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (RobertaModel,    RobertaTokenizer,    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;roberta-base&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Let's encode some text in a sequence of hidden-states using each model:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; model_class, tokenizer_class, pretrained_weights &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;MODELS&lt;/span&gt;:
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load pretrained model/tokenizer&lt;/span&gt;
    tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer_class.from_pretrained(pretrained_weights)
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Encode text&lt;/span&gt;
    input_ids &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.tensor([tokenizer.encode(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Here is some text to encode&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)])  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Add special tokens takes care of adding [CLS], [SEP], &amp;lt;s&amp;gt;... tokens in the right way for each model.&lt;/span&gt;
    &lt;span class="pl-k"&gt;with&lt;/span&gt; torch.no_grad():
        last_hidden_states &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models outputs are now tuples&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.&lt;/span&gt;
&lt;span class="pl-c1"&gt;BERT_MODEL_CLASSES&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,
                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; All the classes for an architecture can be initiated from pretrained weights for this architecture&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Note that additional weights added for fine-tuning are only initialized&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; and need to be trained on the down-stream task&lt;/span&gt;
pretrained_weights &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(pretrained_weights)
&lt;span class="pl-k"&gt;for&lt;/span&gt; model_class &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;BERT_MODEL_CLASSES&lt;/span&gt;:
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load pretrained model/tokenizer&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models can return full list of hidden-states &amp;amp; attentions weights at each layer&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights,
                                        &lt;span class="pl-v"&gt;output_hidden_states&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                                        &lt;span class="pl-v"&gt;output_attentions&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
    input_ids &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.tensor([tokenizer.encode(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Let's see all hidden-states and attentions on this text&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)])
    all_hidden_states, all_attentions &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids)[&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;:]

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models are compatible with Torchscript&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights, &lt;span class="pl-v"&gt;torchscript&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
    traced_model &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.jit.trace(model, (input_ids,))

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Simple serialization for models and tokenizers&lt;/span&gt;
    model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; save&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; re-load&lt;/span&gt;
    tokenizer.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; save&lt;/span&gt;
    tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; re-load&lt;/span&gt;

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; SOTA examples for GLUE, SQUAD, text generation...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour-tf-20-training-and-pytorch-interoperability" class="anchor" aria-hidden="true" href="#quick-tour-tf-20-training-and-pytorch-interoperability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour TF 2.0 training and PyTorch interoperability&lt;/h2&gt;
&lt;p&gt;Let's do a quick example of how a TensorFlow 2.0 model can be trained in 12 lines of code with &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ğŸ¤—&lt;/g-emoji&gt; Transformers and then loaded in PyTorch for fast inspection/tests.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow &lt;span class="pl-k"&gt;as&lt;/span&gt; tf
&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow_datasets
&lt;span class="pl-k"&gt;from&lt;/span&gt; transformers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load dataset, tokenizer, model from pretrained model/vocabulary&lt;/span&gt;
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
model &lt;span class="pl-k"&gt;=&lt;/span&gt; TFBertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data &lt;span class="pl-k"&gt;=&lt;/span&gt; tensorflow_datasets.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;glue/mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Prepare dataset for GLUE as a tf.data.Dataset instance&lt;/span&gt;
train_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; glue_convert_examples_to_features(data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;train&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], tokenizer, &lt;span class="pl-v"&gt;max_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;task&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
valid_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; glue_convert_examples_to_features(data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;validation&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], tokenizer, &lt;span class="pl-v"&gt;max_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;task&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
train_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; train_dataset.shuffle(&lt;span class="pl-c1"&gt;100&lt;/span&gt;).batch(&lt;span class="pl-c1"&gt;32&lt;/span&gt;).repeat(&lt;span class="pl-c1"&gt;2&lt;/span&gt;)
valid_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; valid_dataset.batch(&lt;span class="pl-c1"&gt;64&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule &lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.optimizers.Adam(&lt;span class="pl-v"&gt;learning_rate&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3e-5&lt;/span&gt;, &lt;span class="pl-v"&gt;epsilon&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1e-08&lt;/span&gt;, &lt;span class="pl-v"&gt;clipnorm&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1.0&lt;/span&gt;)
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.losses.SparseCategoricalCrossentropy(&lt;span class="pl-v"&gt;from_logits&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
metric &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.metrics.SparseCategoricalAccuracy(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
model.compile(&lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;optimizer, &lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;loss, &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[metric])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train and evaluate using tf.keras.Model.fit()&lt;/span&gt;
history &lt;span class="pl-k"&gt;=&lt;/span&gt; model.fit(train_dataset, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-v"&gt;steps_per_epoch&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;115&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_dataset, &lt;span class="pl-v"&gt;validation_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;7&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load the TensorFlow model in PyTorch for inspection&lt;/span&gt;
model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
pytorch_model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;from_tf&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Quickly test a few predictions - MRPC is a paraphrasing task, let's see if our model learned the task&lt;/span&gt;
sentence_0 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;This research was consistent with his findings.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
sentence_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;His findings were compatible with this research.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
sentence_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;His findings were not compatible with this research.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
inputs_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer.encode_plus(sentence_0, sentence_1, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-v"&gt;return_tensors&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
inputs_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer.encode_plus(sentence_0, sentence_2, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-v"&gt;return_tensors&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

pred_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; pytorch_model(inputs_1[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], &lt;span class="pl-v"&gt;token_type_ids&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;inputs_1[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;token_type_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].argmax().item()
pred_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; pytorch_model(inputs_2[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], &lt;span class="pl-v"&gt;token_type_ids&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;inputs_2[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;token_type_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].argmax().item()

&lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sentence_1 is&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; pred_1 &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;not a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;of sentence_0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sentence_2 is&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; pred_2 &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;not a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;of sentence_0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour-of-the-fine-tuningusage-scripts" class="anchor" aria-hidden="true" href="#quick-tour-of-the-fine-tuningusage-scripts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour of the fine-tuning/usage scripts&lt;/h2&gt;
&lt;p&gt;The library comprises several example scripts with SOTA performances for NLU and NLG tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;run_glue.py&lt;/code&gt;: an example fine-tuning Bert, XLNet and XLM on nine different GLUE tasks (&lt;em&gt;sequence-level classification&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_squad.py&lt;/code&gt;: an example fine-tuning Bert, XLNet and XLM on the question answering dataset SQuAD 2.0 (&lt;em&gt;token-level classification&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_generation.py&lt;/code&gt;: an example using GPT, GPT-2, CTRL, Transformer-XL and XLNet for conditional language generation&lt;/li&gt;
&lt;li&gt;other model-specific examples (see the documentation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are three quick usage examples for these scripts:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run_gluepy-fine-tuning-on-glue-tasks-for-sequence-classification" class="anchor" aria-hidden="true" href="#run_gluepy-fine-tuning-on-glue-tasks-for-sequence-classification"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_glue.py&lt;/code&gt;: Fine-tuning on GLUE tasks for sequence classification&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://gluebenchmark.com/" rel="nofollow"&gt;General Language Understanding Evaluation (GLUE) benchmark&lt;/a&gt; is a collection of nine sentence- or sentence-pair language understanding tasks for evaluating and analyzing natural language understanding systems.&lt;/p&gt;
&lt;p&gt;Before running anyone of these GLUE tasks you should download the
&lt;a href="https://gluebenchmark.com/tasks" rel="nofollow"&gt;GLUE data&lt;/a&gt; by running
&lt;a href="https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e"&gt;this script&lt;/a&gt;
and unpack it to some directory &lt;code&gt;$GLUE_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You should also install the additional packages required by the examples:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -r ./examples/requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue
&lt;span class="pl-k"&gt;export&lt;/span&gt; TASK_NAME=MRPC

python ./examples/run_glue.py \
    --model_type bert \
    --model_name_or_path bert-base-uncased \
    --task_name &lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt; \
    --do_train \
    --do_eval \
    --do_lower_case \
    --data_dir &lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/&lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt; \
    --max_seq_length 128 \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --learning_rate 2e-5 \
    --num_train_epochs 3.0 \
    --output_dir /tmp/&lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt;/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where task name can be one of CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, RTE, WNLI.&lt;/p&gt;
&lt;p&gt;The dev set results will be present within the text file 'eval_results.txt' in the specified output_dir. In case of MNLI, since there are two separate dev sets, matched and mismatched, there will be a separate output folder called '/tmp/MNLI-MM/' in addition to '/tmp/MNLI/'.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-fine-tuning-xlnet-model-on-the-sts-b-regression-task" class="anchor" aria-hidden="true" href="#fine-tuning-xlnet-model-on-the-sts-b-regression-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning XLNet model on the STS-B regression task&lt;/h4&gt;
&lt;p&gt;This example code fine-tunes XLNet on the STS-B corpus using parallel training on a server with 4 V100 GPUs.
Parallel training is a simple way to use several GPUs (but is slower and less flexible than distributed training, see below).&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue

python ./examples/run_glue.py \
    --model_type xlnet \
    --model_name_or_path xlnet-large-cased \
    --do_train  \
    --do_eval   \
    --task_name=sts-b     \
    --data_dir=&lt;span class="pl-smi"&gt;${GLUE_DIR}&lt;/span&gt;/STS-B  \
    --output_dir=./proc_data/sts-b-110   \
    --max_seq_length=128   \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --gradient_accumulation_steps=1 \
    --max_steps=1200  \
    --model_name=xlnet-large-cased   \
    --overwrite_output_dir   \
    --overwrite_cache \
    --warmup_steps=120&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On this machine we thus have a batch size of 32, please increase &lt;code&gt;gradient_accumulation_steps&lt;/code&gt; to reach the same batch size if you have a smaller machine. These hyper-parameters should result in a Pearson correlation coefficient of &lt;code&gt;+0.917&lt;/code&gt; on the development set.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-fine-tuning-bert-model-on-the-mrpc-classification-task" class="anchor" aria-hidden="true" href="#fine-tuning-bert-model-on-the-mrpc-classification-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning Bert model on the MRPC classification task&lt;/h4&gt;
&lt;p&gt;This example code fine-tunes the Bert Whole Word Masking model on the Microsoft Research Paraphrase Corpus (MRPC) corpus using distributed training on 8 V100 GPUs to reach a F1 &amp;gt; 92.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m torch.distributed.launch --nproc_per_node 8 ./examples/run_glue.py   \
    --model_type bert \
    --model_name_or_path bert-large-uncased-whole-word-masking \
    --task_name MRPC \
    --do_train   \
    --do_eval   \
    --do_lower_case   \
    --data_dir &lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC/   \
    --max_seq_length 128   \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --learning_rate 2e-5   \
    --num_train_epochs 3.0  \
    --output_dir /tmp/mrpc_output/ \
    --overwrite_output_dir   \
    --overwrite_cache \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Training with these hyper-parameters gave us the following results:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;  acc = 0.8823529411764706
  acc_and_f1 = 0.901702786377709
  eval_loss = 0.3418912578906332
  f1 = 0.9210526315789473
  global_step = 174
  loss = 0.07231863956341798&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-run_squadpy-fine-tuning-on-squad-for-question-answering" class="anchor" aria-hidden="true" href="#run_squadpy-fine-tuning-on-squad-for-question-answering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_squad.py&lt;/code&gt;: Fine-tuning on SQuAD for question-answering&lt;/h3&gt;
&lt;p&gt;This example code fine-tunes BERT on the SQuAD dataset using distributed training on 8 V100 GPUs and Bert Whole Word Masking uncased model to reach a F1 &amp;gt; 93 on SQuAD:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m torch.distributed.launch --nproc_per_node=8 ./examples/run_squad.py \
    --model_type bert \
    --model_name_or_path bert-large-uncased-whole-word-masking \
    --do_train \
    --do_eval \
    --do_lower_case \
    --train_file &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
    --predict_file &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
    --learning_rate 3e-5 \
    --num_train_epochs 2 \
    --max_seq_length 384 \
    --doc_stride 128 \
    --output_dir ../models/wwm_uncased_finetuned_squad/ \
    --per_gpu_eval_batch_size=3   \
    --per_gpu_train_batch_size=3   \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Training with these hyper-parameters gave us the following results:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/evaluate-v1.1.py &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json ../models/wwm_uncased_finetuned_squad/predictions.json
{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 86.91579943235573, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 93.1532499015869}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the model provided as &lt;code&gt;bert-large-uncased-whole-word-masking-finetuned-squad&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run_generationpy-text-generation-with-gpt-gpt-2-ctrl-transformer-xl-and-xlnet" class="anchor" aria-hidden="true" href="#run_generationpy-text-generation-with-gpt-gpt-2-ctrl-transformer-xl-and-xlnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_generation.py&lt;/code&gt;: Text generation with GPT, GPT-2, CTRL, Transformer-XL and XLNet&lt;/h3&gt;
&lt;p&gt;A conditional generation script is also included to generate text from a prompt.
The generation script includes the &lt;a href="https://github.com/rusiaaman/XLNet-gen#methodology"&gt;tricks&lt;/a&gt; proposed by Aman Rusia to get high-quality generation with memory models like Transformer-XL and XLNet (include a predefined text to make short inputs longer).&lt;/p&gt;
&lt;p&gt;Here is how to run the script with the small version of OpenAI GPT-2 model:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./examples/run_generation.py \
    --model_type=gpt2 \
    --length=20 \
    --model_name_or_path=gpt2 \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and from the Salesforce CTRL model:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./examples/run_generation.py \
    --model_type=ctrl \
    --length=20 \
    --model_name_or_path=ctrl \
    --temperature=0 \
    --repetition_penalty=1.2 \&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-migrating-from-pytorch-transformers-to-transformers" class="anchor" aria-hidden="true" href="#migrating-from-pytorch-transformers-to-transformers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Migrating from pytorch-transformers to transformers&lt;/h2&gt;
&lt;p&gt;Here is a quick summary of what you should take care of when migrating from &lt;code&gt;pytorch-transformers&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-positional-order-of-some-models-keywords-inputs-attention_mask-token_type_ids-changed" class="anchor" aria-hidden="true" href="#positional-order-of-some-models-keywords-inputs-attention_mask-token_type_ids-changed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Positional order of some models' keywords inputs (&lt;code&gt;attention_mask&lt;/code&gt;, &lt;code&gt;token_type_ids&lt;/code&gt;...) changed&lt;/h3&gt;
&lt;p&gt;To be able to use Torchscript (see #1010, #1204 and #1195) the specific order of some models &lt;strong&gt;keywords inputs&lt;/strong&gt; (&lt;code&gt;attention_mask&lt;/code&gt;, &lt;code&gt;token_type_ids&lt;/code&gt;...) has been changed.&lt;/p&gt;
&lt;p&gt;If you used to call the models with keyword names for keyword arguments, e.g. &lt;code&gt;model(inputs_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)&lt;/code&gt;, this should not cause any change.&lt;/p&gt;
&lt;p&gt;If you used to call the models with positional inputs for keyword arguments, e.g. &lt;code&gt;model(inputs_ids, attention_mask, token_type_ids)&lt;/code&gt;, you may have to double check the exact order of input arguments.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-migrating-from-pytorch-pretrained-bert-to-transformers" class="anchor" aria-hidden="true" href="#migrating-from-pytorch-pretrained-bert-to-transformers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Migrating from pytorch-pretrained-bert to transformers&lt;/h2&gt;
&lt;p&gt;Here is a quick summary of what you should take care of when migrating from &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-models-always-output-tuples" class="anchor" aria-hidden="true" href="#models-always-output-tuples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models always output &lt;code&gt;tuples&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The main breaking change when migrating from &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt; is that every model's forward method always outputs a &lt;code&gt;tuple&lt;/code&gt; with various elements depending on the model and the configuration parameters.&lt;/p&gt;
&lt;p&gt;The exact content of the tuples for each model is detailed in the models' docstrings and the &lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In pretty much every case, you will be fine by taking the first element of the output as the output you previously used in &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is a &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt; conversion example for a &lt;code&gt;BertForSequenceClassification&lt;/code&gt; classification model:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Let's load our model&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; If you used to have this line in pytorch-pretrained-bert:&lt;/span&gt;
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Now just use this line in transformers to extract the loss from the output tuple:&lt;/span&gt;
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; In transformers you can also have access to the logits:&lt;/span&gt;
loss, logits &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs[:&lt;span class="pl-c1"&gt;2&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; And even the attention weights if you configure the model to output them (and other outputs too, see the docstrings and documentation)&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_attentions&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)
loss, logits, attentions &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-using-hidden-states" class="anchor" aria-hidden="true" href="#using-hidden-states"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using hidden states&lt;/h3&gt;
&lt;p&gt;By enabling the configuration option &lt;code&gt;output_hidden_states&lt;/code&gt;, it was possible to retrieve the last hidden states of the encoder. In &lt;code&gt;pytorch-transformers&lt;/code&gt; as well as &lt;code&gt;transformers&lt;/code&gt; the return value has changed slightly: &lt;code&gt;all_hidden_states&lt;/code&gt; now also includes the hidden state of the embeddings in addition to those of the encoding layers. This allows users to easily access the embeddings final state.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-serialization" class="anchor" aria-hidden="true" href="#serialization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serialization&lt;/h3&gt;
&lt;p&gt;Breaking change in the &lt;code&gt;from_pretrained()&lt;/code&gt; method:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Models are now set in evaluation mode by default when instantiated with the &lt;code&gt;from_pretrained()&lt;/code&gt; method. To train them, don't forget to set them back in training mode (&lt;code&gt;model.train()&lt;/code&gt;) to activate the dropout modules.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The additional &lt;code&gt;*input&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; arguments supplied to the &lt;code&gt;from_pretrained()&lt;/code&gt; method used to be directly passed to the underlying model's class &lt;code&gt;__init__()&lt;/code&gt; method. They are now used to update the model configuration attribute instead, which can break derived model classes built based on the previous &lt;code&gt;BertForSequenceClassification&lt;/code&gt; examples. We are working on a way to mitigate this breaking change in &lt;a href="https://github.com/huggingface/transformers/pull/866"&gt;#866&lt;/a&gt; by forwarding the the model's &lt;code&gt;__init__()&lt;/code&gt; method (i) the provided positional arguments and (ii) the keyword arguments which do not match any configuration class attributes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Also, while not a breaking change, the serialization methods have been standardized and you probably should switch to the new method &lt;code&gt;save_pretrained(save_directory)&lt;/code&gt; if you were using any other serialization method before.&lt;/p&gt;
&lt;p&gt;Here is an example:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Let's load a model and tokenizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Do some stuff to our model and tokenizer&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Ex: add new tokens to the vocabulary and embeddings of our model&lt;/span&gt;
tokenizer.add_tokens([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;[SPECIAL_TOKEN_1]&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;[SPECIAL_TOKEN_2]&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
model.resize_token_embeddings(&lt;span class="pl-c1"&gt;len&lt;/span&gt;(tokenizer))
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train our model&lt;/span&gt;
train(model)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Now let's save our model and tokenizer to a directory&lt;/span&gt;
model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Reload the model and the tokenizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-optimizers-bertadam--openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules" class="anchor" aria-hidden="true" href="#optimizers-bertadam--openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimizers: BertAdam &amp;amp; OpenAIAdam are now AdamW, schedules are standard PyTorch schedules&lt;/h3&gt;
&lt;p&gt;The two optimizers previously included, &lt;code&gt;BertAdam&lt;/code&gt; and &lt;code&gt;OpenAIAdam&lt;/code&gt;, have been replaced by a single &lt;code&gt;AdamW&lt;/code&gt; optimizer which has a few differences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it only implements weights decay correction,&lt;/li&gt;
&lt;li&gt;schedules are now externals (see below),&lt;/li&gt;
&lt;li&gt;gradient clipping is now also external (see below).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The new optimizer &lt;code&gt;AdamW&lt;/code&gt; matches PyTorch &lt;code&gt;Adam&lt;/code&gt; optimizer API and let you use standard PyTorch or apex methods for the schedule and clipping.&lt;/p&gt;
&lt;p&gt;The schedules are now standard &lt;a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" rel="nofollow"&gt;PyTorch learning rate schedulers&lt;/a&gt; and not part of the optimizer anymore.&lt;/p&gt;
&lt;p&gt;Here is a conversion examples from &lt;code&gt;BertAdam&lt;/code&gt; with a linear warmup and decay schedule to &lt;code&gt;AdamW&lt;/code&gt; and the same schedule:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Parameters:&lt;/span&gt;
lr &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1e-3&lt;/span&gt;
max_grad_norm &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1.0&lt;/span&gt;
num_training_steps &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1000&lt;/span&gt;
num_warmup_steps &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt;
warmup_proportion &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;float&lt;/span&gt;(num_warmup_steps) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;float&lt;/span&gt;(num_training_steps)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 0.1&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Previously BertAdam optimizer was instantiated like this:&lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertAdam(model.parameters(), &lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;lr, &lt;span class="pl-v"&gt;schedule&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;warmup_linear&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;warmup&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;warmup_proportion, &lt;span class="pl-v"&gt;t_total&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_training_steps)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## and used like this:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; batch &lt;span class="pl-k"&gt;in&lt;/span&gt; train_data:
    loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(batch)
    loss.backward()
    optimizer.step()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## In Transformers, optimizer and schedules are splitted and instantiated like this:&lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; AdamW(model.parameters(), &lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;lr, &lt;span class="pl-v"&gt;correct_bias&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;False&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; To reproduce BertAdam specific behavior set correct_bias=False&lt;/span&gt;
scheduler &lt;span class="pl-k"&gt;=&lt;/span&gt; get_linear_schedule_with_warmup(optimizer, &lt;span class="pl-v"&gt;num_warmup_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_warmup_steps, &lt;span class="pl-v"&gt;num_training_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_training_steps)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; PyTorch scheduler&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## and used like this:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; batch &lt;span class="pl-k"&gt;in&lt;/span&gt; train_data:
    model.train()
    loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(batch)
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Gradient clipping is not in AdamW anymore (so you can use amp without issue)&lt;/span&gt;
    optimizer.step()
    scheduler.step()
    optimizer.zero_grad()&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;We now have a paper you can cite for the &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ğŸ¤—&lt;/g-emoji&gt; Transformers library:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>huggingface</author><guid isPermaLink="false">https://github.com/huggingface/transformers</guid><pubDate>Wed, 20 Nov 2019 00:10:00 GMT</pubDate></item><item><title>mzfr/rsh #11 in Python, Today</title><link>https://github.com/mzfr/rsh</link><description>&lt;p&gt;&lt;i&gt;generate reverse shell from CLI for linux and Windows.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="Readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://www.gnu.org/licenses/gpl-3.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ec385922fa349d9c349f34b7f3bf311843e35ba8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d626c75652e737667" alt="License: GPL v3" data-canonical-src="https://img.shields.io/badge/License-GPLv3-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://GitHub.com/mzfr/liffy/graphs/commit-activity"&gt;&lt;img src="https://camo.githubusercontent.com/0e6a3f975d68b438efec82fef1f9491600606df8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61696e7461696e65642533462d7965732d677265656e2e737667" alt="Maintenance" data-canonical-src="https://img.shields.io/badge/Maintained%3F-yes-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a id="user-content-rsh" class="anchor" aria-hidden="true" href="#rsh"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;rsh&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/rsh.png"&gt;&lt;img src="images/rsh.png" alt="rsh in action" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="#features"&gt;Introduction&lt;/a&gt; â€¢
  &lt;a href="#usage"&gt;Usage&lt;/a&gt; â€¢
  &lt;a href="#installation"&gt;Installation&lt;/a&gt; â€¢
  &lt;a href="#gallery"&gt;Gallery&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;rsh is a tool purely written in python to easily generate reverse shell command for linux as well as windows.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h3&gt;
&lt;p&gt;This tools makes it easy for you to generate reverse shell command supported in both linux and windows, in the following languages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bash
&lt;ul&gt;
&lt;li&gt;netcat&lt;/li&gt;
&lt;li&gt;netcat OpenBSD&lt;/li&gt;
&lt;li&gt;nc.traditional&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;IPv4&lt;/li&gt;
&lt;li&gt;IPv6&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ruby&lt;/li&gt;
&lt;li&gt;Perl&lt;/li&gt;
&lt;li&gt;PHP&lt;/li&gt;
&lt;li&gt;PowerShell&lt;/li&gt;
&lt;li&gt;Node.JS&lt;/li&gt;
&lt;li&gt;TCLSH&lt;/li&gt;
&lt;li&gt;AWK&lt;/li&gt;
&lt;li&gt;JAVA&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;usage: revsh.py [-h] [-sh SH] lhost lport

positional arguments:
  lhost       Specify local host ip
  lport       Specify a local port

optional arguments:
  -h, --help  show this help message and exit
  -sh SH      Specify the language to generate the reverse shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using rsh is very simple. All you need to do is provide IP and Port and the type of shell that is to be generated.
EX:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;./rsh 192.168.56.1 4444 -sh bash&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./rsh 192.168.56.1 4444 -sh php&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./rsh 192.168.56.1 4444 -sh powershell&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;p&gt;You need python 3.5 or greater. Along with that rsh uses [pyfiglet] which you can install by running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install pyfiglet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nothing else is required to run rsh.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-gallery" class="anchor" aria-hidden="true" href="#gallery"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gallery&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Getting bash command&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/rsh.png"&gt;&lt;img src="images/rsh.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Options&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/options.png"&gt;&lt;img src="images/options.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Wrong IP&lt;/strong&gt; &lt;g-emoji class="g-emoji" alias="smile" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png"&gt;ğŸ˜„&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/ip-err.png"&gt;&lt;img src="images/ip-err.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Wrong PORT&lt;/strong&gt; &lt;g-emoji class="g-emoji" alias="smile" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png"&gt;ğŸ˜„&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/port-err.png"&gt;&lt;img src="images/port-err.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contribution" class="anchor" aria-hidden="true" href="#contribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Report a bug&lt;/li&gt;
&lt;li&gt;Fix something and open a pull request&lt;/li&gt;
&lt;li&gt;Add more reverse shell&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In any case feel free to open an issue&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;All the shell command are taken from &lt;a href="http://pentestmonkey.net/" rel="nofollow"&gt;pentestmonkey&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the GPLv3 License - see the &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file for details&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mzfr</author><guid isPermaLink="false">https://github.com/mzfr/rsh</guid><pubDate>Wed, 20 Nov 2019 00:11:00 GMT</pubDate></item><item><title>google-research/text-to-text-transfer-transformer #12 in Python, Today</title><link>https://github.com/google-research/text-to-text-transfer-transformer</link><description>&lt;p&gt;&lt;i&gt;Code for the paper "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-t5-text-to-text-transfer-transformer" class="anchor" aria-hidden="true" href="#t5-text-to-text-transfer-transformer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;T5: Text-To-Text Transfer Transformer&lt;/h1&gt;
&lt;p&gt;T5 serves primarily as code for reproducing the experiments in &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;&lt;em&gt;Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer&lt;/em&gt;&lt;/a&gt;.
The bulk of the code in this repository is used for loading, preprocessing, mixing, and evaluating datasets.
It also provides a way to fine-tune the &lt;a href="#released-model-checkpoints"&gt;pre-trained models&lt;/a&gt; released alongside the publication.&lt;/p&gt;
&lt;p&gt;T5 can be used as a library for future model development by providing useful modules for training and fine-tuning (potentially &lt;em&gt;huge&lt;/em&gt;) models on mixtures of text-to-text tasks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-organization" class="anchor" aria-hidden="true" href="#organization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Organization&lt;/h2&gt;
&lt;p&gt;T5 is organized into 3 core packages plus configurations for reproducing experiments from the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt;:&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-t5data" class="anchor" aria-hidden="true" href="#t5data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;t5.data&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;t5.data&lt;/code&gt; is a library for defining &lt;code&gt;Task&lt;/code&gt; objects that provide &lt;code&gt;tf.data.Dataset&lt;/code&gt;s. Each &lt;code&gt;Task&lt;/code&gt; references a dataset from &lt;a href="https://www.tensorflow.org/datasets" rel="nofollow"&gt;TensorFlow Datasets&lt;/a&gt; along with a preprocesssing function for converting the dataset into the appropriate format for a text-to-text model with fields for &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;targets&lt;/code&gt;.  For example, the &lt;code&gt;translate&lt;/code&gt; preprocessor converts inputs in the form&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;de&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Das ist gut.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;en&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;That is good.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to the form&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;inputs&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;translate German to English: Das ist gut.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;targets&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;That is good.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;Task&lt;/code&gt; objects also handle tokenization of strings, optional preprocessing of the token representation (e.g., corruptions for unsupservised training), and specification of associated metrics for evaluation.&lt;/p&gt;
&lt;p&gt;Finally, &lt;code&gt;t5.data&lt;/code&gt; contains a &lt;code&gt;Mixture&lt;/code&gt; class that can be instantiated to combine multiple &lt;code&gt;Task&lt;/code&gt; datasets for multi-task training using various functions for specifying the mixture rates.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-t5evaluation" class="anchor" aria-hidden="true" href="#t5evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;t5.evaluation&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;t5.evaluation&lt;/code&gt; contains two core components: a module for specifying metrics to be used during evaluation and utilities for applying these metrics at evaluation time.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-t5models" class="anchor" aria-hidden="true" href="#t5models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;t5.models&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;t5.models&lt;/code&gt; contains shims for connecting T5 &lt;code&gt;Tasks&lt;/code&gt; and &lt;code&gt;Mixtures&lt;/code&gt; to a model implementation for training, evaluation, and inference. Currently the only available shim is to the &lt;a href="https://github.com/tensorflow/mesh/tree/master/mesh_tensorflow/transformer"&gt;Mesh TensorFlow Transformer&lt;/a&gt;, which enables both data and model parallelism for training massive Transformer models. It also includes a binary for launching the model along with &lt;a href="https://github.com/google/gin-config"&gt;gin config&lt;/a&gt; files for setting various hyperparameters.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;Here we provide example usage for how to pre-train, fine-tune, evaluate, and decode from a model with our codebase. You can use these instructions to reproduce our results, fine-tune one of our released checkpoints with your own data and/or hyperparameters, or pre-train a model from scratch.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h3&gt;
&lt;p&gt;We use &lt;a href="https://www.tensorflow.org/datasets" rel="nofollow"&gt;TensorFlow Datasets (TFDS)&lt;/a&gt; as our dataset repository. When you select a dataset and run our training binary (see instructions below), the dataset will automatically be downloaded and prepared on its first use. After preparation is complete, the dataset is cached to your local storage to avoid this overhead in future runs.  If working in the cloud, we recommend you set the &lt;code&gt;--t5_tfds_data_dir&lt;/code&gt; flag to point to a persistent storage location, such as a &lt;a href="https://www.tensorflow.org/datasets/gcs" rel="nofollow"&gt;GCS bucket&lt;/a&gt;. This is a requirement when training on TPU.&lt;/p&gt;
&lt;p&gt;Note that the &lt;a href="https://www.tensorflow.org/datasets/catalog/c4" rel="nofollow"&gt;C4&lt;/a&gt; dataset we created for unsupervised pre-training requires a significant amount of bandwith for downloading the raw &lt;a href="https://commoncrawl.org" rel="nofollow"&gt;Common Crawl&lt;/a&gt; scrapes and compute for its preparation. We suggest you take advantage of the &lt;a href="https://beam.apache.org" rel="nofollow"&gt;Apache Beam&lt;/a&gt; support in TFDS, which enables distributed preprocessing of the dataset and can be run on &lt;a href="https://cloud.google.com/dataflow/" rel="nofollow"&gt;Google Cloud Dataflow&lt;/a&gt;. Otherwise, it is unlikely that you will be able to complete preprocessing in a human lifetime. Read more in the &lt;a href="https://www.tensorflow.org/datasets/beam_datasets" rel="nofollow"&gt;TFDS Beam instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;p&gt;To install the T5 package, simply run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install t5[gcp]&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-setting-up-tpus-on-gcp-for-training-and-evaluation" class="anchor" aria-hidden="true" href="#setting-up-tpus-on-gcp-for-training-and-evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setting up TPUs on GCP for training and evaluation&lt;/h3&gt;
&lt;p&gt;You will first need to launch a Virtual Machine (VM) on Google Cloud. Details about launching the VM can be found at the &lt;a href="http://cloud/compute/docs/instances/create-start-instance" rel="nofollow"&gt;Google Cloud Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order to run training or eval on Cloud TPUs, you must set up the following variables based on your project, zone and GCS bucket appropriately. Please refer to the &lt;a href="https://cloud.google.com/tpu/docs/quickstart" rel="nofollow"&gt;Cloud TPU Quickstart&lt;/a&gt; guide for more details.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; PROJECT=your_project_name
&lt;span class="pl-k"&gt;export&lt;/span&gt; ZONE=your_project_zone
&lt;span class="pl-k"&gt;export&lt;/span&gt; BUCKET=gs://yourbucket/
&lt;span class="pl-k"&gt;export&lt;/span&gt; TPU_NAME=t5-tpu
&lt;span class="pl-k"&gt;export&lt;/span&gt; DATA_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/your_data_dir&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; MODEL_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/your_model_dir&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Please use the following command to create a TPU device in the Cloud VM.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;ctpu up --name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; --project=&lt;span class="pl-smi"&gt;$PROJECT&lt;/span&gt; --zone=&lt;span class="pl-smi"&gt;$ZONE&lt;/span&gt; --tpu-size=v3-8  \
        --tpu-only   --tf-version=1.15 --noconf&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h3&gt;
&lt;p&gt;In the command below, we train a model on the &lt;a href="https://gluebenchmark.com/" rel="nofollow"&gt;GLUE Benchmark&lt;/a&gt; MRPC task from scratch. You can change the &lt;code&gt;MIXTURE_NAME&lt;/code&gt; gin parameter to use any of the tasks or mixtures provided in our package.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --t5_tfds_data_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dataset.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;models/bi_v1.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MIXTURE_NAME = 'glue_mrpc_v002'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The full list of tasks and mixtures can be obtained by running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;import t5; print(t5.data.MixtureRegistry.names())&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-fine-tuning" class="anchor" aria-hidden="true" href="#fine-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning&lt;/h3&gt;
&lt;p&gt;In order to fine-tune one of our &lt;a href="#released-model-checkpoints"&gt;pre-trained models&lt;/a&gt;, you need to pass the operative config of the pre-trained model to the training script. The operative config should be passed in as a &lt;code&gt;gin_file&lt;/code&gt; flag. It specifies the model architecture and other hyperparameters. In addition, you need to specify the mixture to fine-tune on. For example, to fine-tune the T5-small model on the &lt;code&gt;glue_mrpc_v002&lt;/code&gt; mixture, please run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --t5_tfds_data_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dataset.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MIXTURE_NAME = 'glue_mrpc_v002'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;gs://t5-data/pretrained_models/small/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The correct pre-trained checkpoint path is included in the operative config.&lt;/p&gt;
&lt;p&gt;Alternatively, you could fine-tune with a TSV file where each line is formatted as &lt;code&gt;&amp;lt;input&amp;gt;\t&amp;lt;target&amp;gt;&lt;/code&gt;. For example, you could try one of the paired translation datasets from WMT '19 &lt;a href="http://data.statmt.org/news-commentary/v14/training/" rel="nofollow"&gt;News Commentary 14&lt;/a&gt; training set
(e.g., &lt;a href="http://data.statmt.org/news-commentary/v14/training/" rel="nofollow"&gt;English-French&lt;/a&gt;). When using a TSV file, you would replace the &lt;code&gt;MIXTURE_NAME&lt;/code&gt; flag with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;--gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.run.train_dataset_fn = @t5.models.mesh_transformer.tsv_dataset_fn&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
--gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;tsv_dataset_fn.filename = 'gs:/path/to/tsv'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To fine-tune with the same hyperparameters we used in the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt; (using a constant learning rate of 0.001), you can pass in this gin file which is included in the T5 package:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_file="learning_rate_schedules/constant_0_001.gin"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The operative config for the pre-trained models are set so that there is effectively no limit on the number of train steps. If you'd like to train for a specific number of steps, you'll need to pass that in. Since the pre-trained model has already been trained for 1,000,000 steps, you should specify the total number of steps after pre-training and fine-tuning. For example, if you want to fine-tune for an additional 10,000 steps, you should pass&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param="run.train_steps = 1010000"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use a different batch size for fine-tuning. We set the batch size according to the total number of tokens in a batch. By default, a batch uses a sequence length of 512. To set the number of tokens in a batch, you should set&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param = "tokens_per_batch=1048576"
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-eval" class="anchor" aria-hidden="true" href="#eval"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eval&lt;/h3&gt;
&lt;p&gt;In order to evaluate a model in the T5 framework, you need to use the &lt;code&gt;eval.gin&lt;/code&gt; file, specify the model directory, decoding method, and which checkpoint step(s) to evaluate. So, to evaluate on the GLUE MRPC task using beam search on &lt;em&gt;all&lt;/em&gt; checkpoints, use the following command:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --t5_tfds_data_dir=&lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;eval.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;beam_search.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MIXTURE_NAME = 'glue_mrpc_v002'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;eval_checkpoint_step = 'all'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To evaluate a specific checkpoint, simply set the &lt;code&gt;eval_checkpoint_step&lt;/code&gt; parameter to appropriate checkpoint.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param="eval_checkpoint_step = 100000"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use &lt;code&gt;greedy_decode.gin&lt;/code&gt; or &lt;code&gt;sample_decode.gin&lt;/code&gt; instead of &lt;code&gt;beam_search.gin&lt;/code&gt; in the command above.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-decode" class="anchor" aria-hidden="true" href="#decode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Decode&lt;/h4&gt;
&lt;p&gt;In order to produce predictions from a model in the T5 framework, you need to specify the model directory, decoding method, and which checkpoint step(s) to use for decoding. Assuming you have a text file of input sequences stored at &lt;code&gt;/path/to/intputs.txt&lt;/code&gt;, an example command would be:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;infer.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sample_decode.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;input_filename = '/path/to/inputs.txt'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;\
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;output_filename = '/tmp/outputs.txt'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;\
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;\
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;infer_checkpoint_step = 'all'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To predict with a specific checkpoint, simply set the &lt;code&gt;infer_checkpoint_step&lt;/code&gt; parameter to appropriate checkpoint.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param="infer_checkpoint_step = 100000"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use &lt;code&gt;beam_search.gin&lt;/code&gt; or &lt;code&gt;greedy_decode.gin&lt;/code&gt; instead of &lt;code&gt;sample_decode.gin&lt;/code&gt; in the command above.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-reproducing-our-experiments" class="anchor" aria-hidden="true" href="#reproducing-our-experiments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reproducing our experiments&lt;/h3&gt;
&lt;p&gt;We provide operative configs for all of the experiments in the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt; in &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments" rel="nofollow"&gt;gs://t5-data/experiments&lt;/a&gt;.
The &lt;code&gt;experiments&lt;/code&gt; folder has different subdirectories corresponding to the different sections in our paper.
For example, &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives" rel="nofollow"&gt;gs://t5-data/experiments/objectives&lt;/a&gt; contains the experiments from Section 3.3 ("Unsupervised objectives").
Each subdirectory of the &lt;code&gt;objectives&lt;/code&gt; folder contains operative configs for some particular experiment (where loosely speaking an "experiment" is one of the rows in one of the tables in our paper).&lt;/p&gt;
&lt;p&gt;Let's say you want to reproduce the results for the "Prefix language modeling" objective (the first row in Table 4).
The operative configs for that experiment live in &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives/obj-prefix_lm" rel="nofollow"&gt;gs://t5-data/experiments/objectives/obj-prefix_lm&lt;/a&gt;.
In the base directory, there is an operative config for pre-training the model (&lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives/obj-prefix_lm/operative_config.gin" rel="nofollow"&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/operative_config.gin&lt;/a&gt;).
Then, there are subdirectories for each of the downstream fine-tuning mixtures we consider, each of which has its own operative config (for example, &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives/obj-prefix_lm/cnn_dailymail_v002/operative_config.gin" rel="nofollow"&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/cnn_dailymail_v002/operative_config.gin&lt;/a&gt;).
To run this experiment, first pre-train a model with the pre-training operative config:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; PRETRAIN_MODEL_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/obj-prefix_lm&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PRETRAIN_MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, you can fine-tune the pre-trained model on CNN/Daily Mail like so:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; FINETUNE_MODEL_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/obj-prefix_lm/cnn_dailymail_v002&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${FINETUNE_MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/cnn_dailymail_v002/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;init_checkpoint = '&lt;span class="pl-smi"&gt;${PRETRAIN_MODEL_DIR}&lt;/span&gt;/model.ckpt-524288'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-released-model-checkpoints" class="anchor" aria-hidden="true" href="#released-model-checkpoints"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Released Model Checkpoints&lt;/h2&gt;
&lt;p&gt;We have released the following checkpoints for pre-trained models described in our &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;T5-Small&lt;/strong&gt; (60 million parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/small/" rel="nofollow"&gt;gs://t5-data/pretrained_models/small&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-Base&lt;/strong&gt; (220 million parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/base/" rel="nofollow"&gt;gs://t5-data/pretrained_models/base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-Large&lt;/strong&gt; (770 million parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/large/" rel="nofollow"&gt;gs://t5-data/pretrained_models/large&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-3B&lt;/strong&gt; (3 billion parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/3B/" rel="nofollow"&gt;gs://t5-data/pretrained_models/3B&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-11B&lt;/strong&gt; (11 billion parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/11B/" rel="nofollow"&gt;gs://t5-data/pretrained_models/11B&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-cite" class="anchor" aria-hidden="true" href="#how-to-cite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to cite&lt;/h1&gt;
&lt;p&gt;If you extend or use this work, please cite the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt; where it was introduced:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{2019t5,
  author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {arXiv e-prints},
  year = {2019},
  archivePrefix = {arXiv},
  eprint = {1910.10683},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/text-to-text-transfer-transformer</guid><pubDate>Wed, 20 Nov 2019 00:12:00 GMT</pubDate></item><item><title>CVxTz/image_search_engine #13 in Python, Today</title><link>https://github.com/CVxTz/image_search_engine</link><description>&lt;p&gt;&lt;i&gt;Image search engine&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h3&gt;&lt;a id="user-content-building-a-deep-image-search-engine-using-tfkeras" class="anchor" aria-hidden="true" href="#building-a-deep-image-search-engine-using-tfkeras"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building a Deep Image Search Engine using tf.Keras&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-motivation-" class="anchor" aria-hidden="true" href="#motivation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation :&lt;/h3&gt;
&lt;p&gt;Imagine having a data collection of hundreds of thousands to millions of images
without any metadata describing the content of each image. How can we build a
system that is able to find a sub-set of those images that best answer a userâ€™s
search query ?&lt;br&gt; What we will basically need is a search engine that is able
to rank image results given how well they correspond to the search query, which
can be either expressed in a natural language or by another query image.&lt;br&gt; The
way we will solve the problem in this post is by training a deep neural model
that learns a fixed length representation (or embedding) of any input image and
text and makes it so those representations are close in the euclidean space if
the pairs text-image or image-image are â€œsimilarâ€.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-data-set-" class="anchor" aria-hidden="true" href="#data-set-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data set :&lt;/h3&gt;
&lt;p&gt;I could not find a data-set of search result ranking that is big enough but I
was able to get this data-set :
&lt;a href="http://jmcauley.ucsd.edu/data/amazon/" rel="nofollow"&gt;http://jmcauley.ucsd.edu/data/amazon/&lt;/a&gt;
which links E-commerce item images to their title and description. We will use
this metadata as the supervision source to learn meaningful joined text-image
representations. The experiments were limited to fashion (Clothing, Shoes and
Jewelry) items and to 500,000 images in order to manage the computations and
storage costs.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-problem-setting-" class="anchor" aria-hidden="true" href="#problem-setting-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Problem setting :&lt;/h3&gt;
&lt;p&gt;The data-set we have links each image with a description written in natural
language. So we define a task in which we want to learn a joined, fixed length
representation for images and text so that each image representation is close to
the representation of its description.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5354060542215fdfb70956c6cf02c202f16a2ee1/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a5f7350345734366165763974787a59344f337a394f412e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/5354060542215fdfb70956c6cf02c202f16a2ee1/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a5f7350345734366165763974787a59344f337a394f412e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*_sP4W46aev9txzY4O3z9OA.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-model-" class="anchor" aria-hidden="true" href="#model-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model :&lt;/h3&gt;
&lt;p&gt;The model takes 3 inputs : The image (which is the anchor), the image
title+description ( the positive example) and the third input is some randomly
sampled text (the negative example).&lt;br&gt; Then we define two sub-models :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Image encoder : Resnet50 pre-trained on ImageNet+GlobalMaxpooling2D&lt;/li&gt;
&lt;li&gt;Text encoder : GRU+GlobalMaxpooling1D&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The image sub-model produces the embedding for the Anchor **E_a **and the text
sub-model outputs the embedding for the positive title+description &lt;strong&gt;E_p&lt;/strong&gt; and
the embedding for the negative text &lt;strong&gt;E_n&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We then train by optimizing the following triplet loss:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;L = max( d(E_a, E_p)-d(E_a, E_n)+alpha, 0)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Where d is the euclidean distance and alpha is a hyper parameter equal to 0.4 in
this experiment.&lt;/p&gt;
&lt;p&gt;Basically what this loss allows to do is to make **d(E_a, E_p) &lt;strong&gt;small and
make&lt;/strong&gt; d(E_a, E_n) **large, so that each image embedding is close to the
embedding of its description and far from the embedding of random text.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-visualization-results-" class="anchor" aria-hidden="true" href="#visualization-results-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Visualization Results :&lt;/h3&gt;
&lt;p&gt;Once we learned the image embedding model and text embedding model we can
visualize them by projecting them into two dimensions using tsne
(&lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="nofollow"&gt;https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html&lt;/a&gt;
).&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/69209789c63df2bc182555c793ab1d25498b8585/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313230302f312a3842552d4b3675436e4c4341674775386674363448772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/69209789c63df2bc182555c793ab1d25498b8585/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313230302f312a3842552d4b3675436e4c4341674775386674363448772e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/1200/1*8BU-K6uCnLCAgGu8ft64Hw.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;span&gt;Test Images and their corresponding text description are linked by green lines&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can see from the plot that generally, in the embedding space, images and
their corresponding descriptions are close. Which is what we would expect given
the training loss that was used.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-text-image-search-" class="anchor" aria-hidden="true" href="#text-image-search-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text-image Search :&lt;/h3&gt;
&lt;p&gt;Here we use few examples of text queries to search for the best matches in a set
of 70,000 images. We compute the text embedding for the query and then the
embedding for each image in the collection. We finally select the top 9 images
which are the closest to the query in the embedding space.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8152616b1b859ba9c94dde8acbb3edf484e3682e/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a384c6a75664c344733656b687455666e6739777735772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/8152616b1b859ba9c94dde8acbb3edf484e3682e/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a384c6a75664c344733656b687455666e6739777735772e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*8LjufL4G3ekhtUfng9ww5w.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e6fa2301805eae0246dd40a8ae8f75a20d53a6cc/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a46647a5365654877366578506b794f4e4a46637a59672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e6fa2301805eae0246dd40a8ae8f75a20d53a6cc/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a46647a5365654877366578506b794f4e4a46637a59672e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*FdzSeeHw6exPkyONJFczYg.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;These examples show that the embedding models are able to learn useful
representations of images and embeddings of simple composition of words.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-image-image-search-" class="anchor" aria-hidden="true" href="#image-image-search-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image-Image Search :&lt;/h3&gt;
&lt;p&gt;Here we will use an image as a query and then search in the database of 70,000
images for the examples that are most similar to it. The ranking is determined
by how close each pair of images are in the embedding space using the euclidean
distance.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba61620cbe46b468e7370dd52dbe8b7784dda596/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a75495864437a30346339676738366b6b6a3731467a512e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba61620cbe46b468e7370dd52dbe8b7784dda596/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a75495864437a30346339676738366b6b6a3731467a512e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*uIXdCz04c9gg86kkj71FzQ.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/9a5501c1899a79c7766cc41f20acebb53c8f1497/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a665635554955373955694a7233784d645f6e484a42672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/9a5501c1899a79c7766cc41f20acebb53c8f1497/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a665635554955373955694a7233784d645f6e484a42672e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*fV5UIU79UiJr3xMd_nHJBg.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The results illustrate that the embeddings generated are high level
representations of images that capture the most important characteristics of the
objects represented without being excessively influenced by the orientation,
lighting or minor local details, without being trained explicitly to do so.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-conclusion-" class="anchor" aria-hidden="true" href="#conclusion-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conclusion :&lt;/h3&gt;
&lt;p&gt;In this project we worked on the Machine learning blocks that allow us to build
a keyword and image based search engine applied to a collection of images. The
basic idea is to learn a meaningful and joined embedding function for text and
image and then use the distance between items in the embedding space to rank
search results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References :&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.jmlr.org/papers/volume11/chechik10a/chechik10a.pdf" rel="nofollow"&gt;Large Scale Online Learning of Image Similarity Through
Ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cseweb.ucsd.edu/~jmcauley/pdfs/www16a.pdf" rel="nofollow"&gt;Ups and downs: Modeling the visual evolution of fashion trends with one-class
collaborative filtering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/KinWaiCheuk/Triplet-net-keras/blob/master/Triplet%20NN%20Test%20on%20MNIST.ipynb"&gt;https://github.com/KinWaiCheuk/Triplet-net-keras/blob/master/Triplet%20NN%20Test%20on%20MNIST.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CVxTz</author><guid isPermaLink="false">https://github.com/CVxTz/image_search_engine</guid><pubDate>Wed, 20 Nov 2019 00:13:00 GMT</pubDate></item><item><title>13o-bbr-bbq/machine_learning_security #14 in Python, Today</title><link>https://github.com/13o-bbr-bbq/machine_learning_security</link><description>&lt;p&gt;&lt;i&gt;Source code about machine learning and security.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-and-security" class="anchor" aria-hidden="true" href="#machine-learning-and-security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning and Security&lt;/h1&gt;
&lt;p&gt;Source codes about machine learning and security.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-line-up" class="anchor" aria-hidden="true" href="#line-up"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Line up.&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Security_and_MachineLearning"&gt;Cyber security and Machine Learning course&lt;/a&gt;&lt;br&gt;
The elementary training course of Machine learning for security engineer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Vulnerabilities_of_ML/"&gt;Vulnerabilties of Machine Learning&lt;/a&gt;&lt;br&gt;
Summary of Machine Learning vulnerability.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Analytics"&gt;Analytics&lt;/a&gt;&lt;br&gt;
Analyzing packet capture data using k-means.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/CNN_test"&gt;CNN_test&lt;/a&gt;&lt;br&gt;
Generate adversarial example against CNN.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/DeepExploit"&gt;Deep Exploit&lt;/a&gt;&lt;br&gt;
Fully automatic penetration test tool using Machine Learning.&lt;br&gt;
Deep Exploit was presented at &lt;strong&gt;&lt;a href="https://www.blackhat.com/us-18/arsenal/schedule/index.html#deep-exploit-11908" rel="nofollow"&gt;Black Hat USA 2018 Arsenal&lt;/a&gt;&lt;/strong&gt; , &lt;strong&gt;&lt;a href="https://www.blackhat.com/eu-18/arsenal/schedule/index.html#deep-exploit-fully-automatic-penetration-test-tool-using-machine-learning-13320" rel="nofollow"&gt;Black Hat EURO 2018 Arsenal&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://aivillage.org/posts/accepted-talks/" rel="nofollow"&gt;DEF CON 26! AI Village&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gyoisamurai/GyoiThon"&gt;GyoiThon&lt;/a&gt;&lt;br&gt;
Next generation penetration test tool.&lt;br&gt;
GyoiThon was presented at &lt;strong&gt;&lt;a href="https://www.blackhat.com/asia-18/arsenal/schedule/index.html#gyoithon-9651" rel="nofollow"&gt;Black Hat ASIA 2018 Arsenal&lt;/a&gt;&lt;/strong&gt; , &lt;strong&gt;&lt;a href="https://www.blackhat.com/asia-19/arsenal/schedule/index.html#gyoithon-penetration-testing-using-machine-learning-14359" rel="nofollow"&gt;Black Hat ASIA 2019 Arsenal&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://www.defcon.org/html/defcon-26/dc-26-demolabs.html" rel="nofollow"&gt;DEF CON 26! Demo Labs&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Generator"&gt;DeepGenerator&lt;/a&gt;&lt;br&gt;
Fully automatically generate numerous injection codes for web application assessment using Genetic Algorithm and Generative Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Recommender"&gt;Recommender&lt;/a&gt;&lt;br&gt;
Recommend optimal injection code for detecting web app vulnerabilities.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Saivs"&gt;SAIVS (Spider Artificial Intelligence Vulnerability Scanner)&lt;/a&gt;&lt;br&gt;
SAIVS is an artificial intelligence to find vulnerabilities in Web applications.&lt;br&gt;
SAIVS was presented at &lt;strong&gt;&lt;a href="http://www.blackhat.com/asia-16/arsenal.html#saivs-spider-artificial-intelligence-vulnerability-scanner" rel="nofollow"&gt;Black Hat ASIA 2016 Arsenal&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact-us" class="anchor" aria-hidden="true" href="#contact-us"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact us&lt;/h2&gt;
&lt;p&gt;Isao Takaesu&lt;br&gt;
&lt;a href="mailto:takaesu235@gmail.com"&gt;takaesu235@gmail.com&lt;/a&gt;&lt;br&gt;
&lt;a href="https://twitter.com/bbr_bbq" rel="nofollow"&gt;https://twitter.com/bbr_bbq&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>13o-bbr-bbq</author><guid isPermaLink="false">https://github.com/13o-bbr-bbq/machine_learning_security</guid><pubDate>Wed, 20 Nov 2019 00:14:00 GMT</pubDate></item><item><title>plotly/dash #15 in Python, Today</title><link>https://github.com/plotly/dash</link><description>&lt;p&gt;&lt;i&gt;Analytical Web Apps for Python &amp; R. No JavaScript Required.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dash" class="anchor" aria-hidden="true" href="#dash"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dash&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/plotly/dash" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2488249996549b3d8197eb061e51975ede759cb6/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f70726f6a6563742f6769746875622f706c6f746c792f646173682f6d61737465722e737667" alt="CircleCI" data-canonical-src="https://img.shields.io/circleci/project/github/plotly/dash/master.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/plotly/dash/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/3cd42a5b87f7de7a0fe06c16c0de8403cce5ec1e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f706c6f746c792f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="GitHub" data-canonical-src="https://img.shields.io/github/license/plotly/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/dash/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/591a9710a9507f246482d0d57d33e473aef1bba7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/dash/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/09415013d09c9e287dcb0f00c5287fc57825efcd/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/plotly/dash/graphs/contributors"&gt;&lt;img src="https://camo.githubusercontent.com/2c0f084bce301be8501650815385bda2802e580e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f792f706c6f746c792f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="GitHub commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/y/plotly/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/plotly/dash/alerts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1c0f2f026b76562ac6828803af41b652a1c1c113/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f706c6f746c792f646173682e737667" alt="LGTM Alerts" data-canonical-src="https://img.shields.io/lgtm/alerts/g/plotly/dash.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/plotly/dash/context:python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ab2cb9245f5eed317879ce495d4e708c93cab8b7/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f706c6f746c792f646173682e737667" alt="LGTM Grade" data-canonical-src="https://img.shields.io/lgtm/grade/python/g/plotly/dash.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-dash-is-a-python-framework-for-building-analytical-web-applications-no-javascript-required" class="anchor" aria-hidden="true" href="#dash-is-a-python-framework-for-building-analytical-web-applications-no-javascript-required"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Dash is a Python framework for building analytical web applications. No JavaScript required&lt;/em&gt;.&lt;/h4&gt;
&lt;p&gt;Built on top of Plotly.js, React and Flask, Dash ties modern UI elements like dropdowns, sliders, and graphs directly to your analytical Python code. Read our tutorial proudly crafted &lt;g-emoji class="g-emoji" alias="heart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2764.png"&gt;â¤ï¸&lt;/g-emoji&gt; by Dash itself.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dash.plot.ly/getting-started" rel="nofollow"&gt;User Guide&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/plotly/dash-docs/blob/master/pdf-docs/Dash_User_Guide_and_Documentation.pdf"&gt;Offline (PDF) Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://dash-docs.herokuapp.com/" rel="nofollow"&gt;Dash Docs on Heroku&lt;/a&gt; (for corporate network that cannot access plot.ly)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-app-samples" class="anchor" aria-hidden="true" href="#app-samples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;App Samples&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;App&lt;/th&gt;
&lt;th align="center"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif" alt="Sample Dash App" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Hereâ€™s a simple example of a Dash App that ties a Dropdown to a D3.js Plotly Graph. As the user selects a value in the Dropdown, the application code dynamically exports data from Google Finance into a Pandas DataFrame. This app was written in just &lt;strong&gt;43&lt;/strong&gt; lines of code (&lt;a href="https://gist.github.com/chriddyp/3d2454905d8f01886d651f207e2419f0"&gt;view the source&lt;/a&gt;).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif" alt="Crossfiltering Dash App" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash app code is declarative and reactive, which makes it easy to build complex apps that contain many interactive elements. Hereâ€™s an example with 5 inputs, 3 outputs, and cross filtering. This app was composed in just 160 lines of code, all of which were Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif" alt="Dash App with Mapbox map showing walmart store openings" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash uses &lt;a href="https://github.com/plotly/plotly.js"&gt;Plotly.js&lt;/a&gt; for charting. Over 35 chart types are supported, including maps.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/plotly/dash-docs/blob/516f80c417051406210b94ea23a6d3b6cd84d146/assets/images/gallery/dash-financial-report.gif"&gt;&lt;img src="https://github.com/plotly/dash-docs/raw/516f80c417051406210b94ea23a6d3b6cd84d146/assets/images/gallery/dash-financial-report.gif" alt="Financial report" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash isn't just for dashboards. You have full control over the look and feel of your applications. Here's a Dash App that's styled to look like a PDF report.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To learn more about Dash, read the &lt;a href="https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503" rel="nofollow"&gt;extensive announcement letter&lt;/a&gt; or &lt;a href="https://plot.ly/dash" rel="nofollow"&gt;jump in with the user guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contact-and-support" class="anchor" aria-hidden="true" href="#contact-and-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact and Support&lt;/h3&gt;
&lt;p&gt;For companies with software budgets, Plotly offers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Dash Deployment Server&lt;/strong&gt;&lt;/a&gt; speeds your time-to-delivery while providing the right resources, security, and scalability you need to deliver production-quality apps&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Dash Design Kit&lt;/strong&gt;&lt;/a&gt; makes your internal dashboard awesome without expertise in JavaScript &amp;amp; CSS.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Snapshot Engine&lt;/strong&gt;&lt;/a&gt; seamlessly links your analytics and reporting workflows together, giving you a fast way to generate interactive reports of just the data you need&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href="https://plot.ly/dash/support" rel="nofollow"&gt;https://plot.ly/dash/support&lt;/a&gt; for ways to get in touch.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30084008-9fbc68fc-925e-11e7-891c-18a9b8f6ac6b.png"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30084008-9fbc68fc-925e-11e7-891c-18a9b8f6ac6b.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>plotly</author><guid isPermaLink="false">https://github.com/plotly/dash</guid><pubDate>Wed, 20 Nov 2019 00:15:00 GMT</pubDate></item><item><title>dragen1860/Deep-Learning-with-PyTorch-Tutorials #16 in Python, Today</title><link>https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials</link><description>&lt;p&gt;&lt;i&gt;æ·±åº¦å­¦ä¹ ä¸PyTorchå…¥é—¨å®æˆ˜è§†é¢‘æ•™ç¨‹ é…å¥—æºä»£ç å’ŒPPT&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pytorchå®‰è£…æŒ‡ä»¤" class="anchor" aria-hidden="true" href="#pytorchå®‰è£…æŒ‡ä»¤"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyTorchå®‰è£…æŒ‡ä»¤&lt;/h1&gt;
&lt;p&gt;è¯·å…ˆå®‰è£…Anacondaå’ŒCUDA 10.0ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é…ç½®å›½å†…æº&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; é…ç½®å›½å†…æºï¼Œæ–¹ä¾¿å®‰è£…Numpy,Matplotlibç­‰&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;add channels https:&lt;span class="pl-k"&gt;//&lt;/span&gt;mirrors.tuna.tsinghua.edu.cn&lt;span class="pl-k"&gt;/&lt;/span&gt;anaconda&lt;span class="pl-k"&gt;/&lt;/span&gt;pkgs&lt;span class="pl-k"&gt;/&lt;/span&gt;free&lt;span class="pl-k"&gt;/&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;add channels https:&lt;span class="pl-k"&gt;//&lt;/span&gt;mirrors.tuna.tsinghua.edu.cn&lt;span class="pl-k"&gt;/&lt;/span&gt;anaconda&lt;span class="pl-k"&gt;/&lt;/span&gt;pkgs&lt;span class="pl-k"&gt;/&lt;/span&gt;main&lt;span class="pl-k"&gt;/&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; é…ç½®å›½å†…æºï¼Œå®‰è£…PyTorchç”¨&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;add channels https:&lt;span class="pl-k"&gt;//&lt;/span&gt;mirrors.tuna.tsinghua.edu.cn&lt;span class="pl-k"&gt;/&lt;/span&gt;anaconda&lt;span class="pl-k"&gt;/&lt;/span&gt;cloud&lt;span class="pl-k"&gt;/&lt;/span&gt;pytorch&lt;span class="pl-k"&gt;/&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; æ˜¾ç¤ºæºåœ°å€&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;&lt;span class="pl-c1"&gt;set&lt;/span&gt; show_channel_urls yes&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;å®‰è£…PyTorch&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; å®‰è£…PyTorchï¼Œè¦ä½¿ç”¨å›½å†…æºè¯·å»æ‰-c pytorchè¿™ä¸ªå‚æ•°ï¼ï¼&lt;/span&gt;
conda install pytorch torchvision cudatoolkit&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;10.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;å®‰è£…å¸¸ç”¨åº“&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;pip install numpy matplotlib pillow pandas&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-è¯¾ç¨‹é“¾æ¥" class="anchor" aria-hidden="true" href="#è¯¾ç¨‹é“¾æ¥"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;è¯¾ç¨‹é“¾æ¥&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;è¯¾ç¨‹é“¾æ¥:&lt;/strong&gt; &lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=61a9e0a511f7409b92a08d4f4c964330" rel="nofollow"&gt;https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=61a9e0a511f7409b92a08d4f4c964330&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="res/ç‰ˆæƒå£°æ˜.png"&gt;&lt;img width="700" src="res/ç‰ˆæƒå£°æ˜.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è¯¾ç¨‹å¤§çº²:&lt;/strong&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="res/outline.png"&gt;&lt;img src="res/outline.png" alt="è¯¾ç¨‹ä»‹ç»" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dragen1860</author><guid isPermaLink="false">https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials</guid><pubDate>Wed, 20 Nov 2019 00:16:00 GMT</pubDate></item><item><title>TheAlgorithms/Python #17 in Python, Today</title><link>https://github.com/TheAlgorithms/Python</link><description>&lt;p&gt;&lt;i&gt;All Algorithms implemented in Python&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-algorithms---python" class="anchor" aria-hidden="true" href="#the-algorithms---python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Algorithms - Python&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.paypal.me/TheAlgorithms/100" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6e317052a97af57d39fafda024dec0e418ed447a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e7376673f6c6f676f3d70617970616c267374796c653d666c61742d737175617265" alt="Donate" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg?logo=paypal&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;Â 
&lt;a href="https://travis-ci.com/TheAlgorithms/Python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ba096466b22c899fe7f5e02f25b5a4eb9c4981bf/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d5472617669732532304349266c6f676f3d747261766973267374796c653d666c61742d737175617265" alt="Build Status" data-canonical-src="https://img.shields.io/travis/TheAlgorithms/Python.svg?label=Travis%20CI&amp;amp;logo=travis&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;Â 
&lt;a href="https://lgtm.com/projects/g/TheAlgorithms/Python/alerts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5d3181d5ebb9d039f3db9c12cc98e4733966ad45/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f6769746875622f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d4c47544d266c6f676f3d4c47544d267374796c653d666c61742d737175617265" alt="LGTM" data-canonical-src="https://img.shields.io/lgtm/alerts/github/TheAlgorithms/Python.svg?label=LGTM&amp;amp;logo=LGTM&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;Â 
&lt;a href="https://gitter.im/TheAlgorithms" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f697eee68d1130a571859375f6e3cf3b666d3c50/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436861742d4769747465722d6666363962342e7376673f6c6162656c3d43686174266c6f676f3d676974746572267374796c653d666c61742d737175617265" alt="Gitter chat" data-canonical-src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;Â 
&lt;a href="https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md"&gt;&lt;img src="https://camo.githubusercontent.com/71dbcf9e251926ae5ab25476d1d449d107103fe7/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76312e7376673f6c6162656c3d436f6e747269627574696f6e73266d6573736167653d57656c636f6d6526636f6c6f723d303035396233267374796c653d666c61742d737175617265" alt="contributions welcome" data-canonical-src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;Â 
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/310362fb8e8936dc040af9adce51341ad65bf5d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f7265706f2d73697a652f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d5265706f25323073697a65267374796c653d666c61742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/310362fb8e8936dc040af9adce51341ad65bf5d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f7265706f2d73697a652f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d5265706f25323073697a65267374796c653d666c61742d737175617265" alt="" data-canonical-src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;Â &lt;/p&gt;

&lt;h3&gt;&lt;a id="user-content-all-algorithms-implemented-in-python-for-education" class="anchor" aria-hidden="true" href="#all-algorithms-implemented-in-python-for-education"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;All algorithms implemented in Python (for education)&lt;/h3&gt;
&lt;p&gt;These implementations are for learning purposes. They may be less efficient than the implementations in the Python standard library.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution Guidelines&lt;/h2&gt;
&lt;p&gt;Read our &lt;a href="CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community-channel" class="anchor" aria-hidden="true" href="#community-channel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community Channel&lt;/h2&gt;
&lt;p&gt;We're on &lt;a href="https://gitter.im/TheAlgorithms" rel="nofollow"&gt;Gitter&lt;/a&gt;! Please join us.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-list-of-algorithms" class="anchor" aria-hidden="true" href="#list-of-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;List of Algorithms&lt;/h2&gt;
&lt;p&gt;See our &lt;a href="DIRECTORY.md"&gt;directory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6af3650e2f9523e898e3e314ab356b675875483e/68747470733a2f2f676974706f642e696f2f627574746f6e2f6f70656e2d696e2d676974706f642e7376673f7374796c653d666c61742d737175617265" alt="Open in Gitpod" data-canonical-src="https://gitpod.io/button/open-in-gitpod.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>TheAlgorithms</author><guid isPermaLink="false">https://github.com/TheAlgorithms/Python</guid><pubDate>Wed, 20 Nov 2019 00:17:00 GMT</pubDate></item><item><title>alegonz/baikal #18 in Python, Today</title><link>https://github.com/alegonz/baikal</link><description>&lt;p&gt;&lt;i&gt;A graph-based functional API for building complex scikit-learn pipelines.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-baikal" class="anchor" aria-hidden="true" href="#baikal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;baikal&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/alegonz/baikal/tree/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6ea59722c2eb9c5382ff534bf44de76955d667d3/68747470733a2f2f636972636c6563692e636f6d2f67682f616c65676f6e7a2f6261696b616c2f747265652f6d61737465722e7376673f7374796c653d73766726636972636c652d746f6b656e3d66623637656565643230363763333631393839643230393162396434643033653638393930313062" alt="build status" data-canonical-src="https://circleci.com/gh/alegonz/baikal/tree/master.svg?style=svg&amp;amp;circle-token=fb67eeed2067c361989d2091b9d4d03e6899010b" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/alegonz/baikal" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/66b2e25de741354c9cbbf397928468f9d24bc98b/68747470733a2f2f636f6465636f762e696f2f67682f616c65676f6e7a2f6261696b616c2f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d53536f655145544e6836" alt="coverage" data-canonical-src="https://codecov.io/gh/alegonz/baikal/branch/master/graph/badge.svg?token=SSoeQETNh6" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://camo.githubusercontent.com/28a51fe3a2c05048d8ca8ecd039d6b1619037326/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667" alt="code style" data-canonical-src="https://img.shields.io/badge/code%20style-black-000000.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/baikal" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/bba917857991c36014df0108e22a350eed438573/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6261696b616c2e737667" alt="latest release" data-canonical-src="https://img.shields.io/pypi/v/baikal.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/alegonz/baikal/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/1acc6e6dfaf131f05f170de0521461bafd9b62e8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6261696b616c2e737667" alt="license" data-canonical-src="https://img.shields.io/pypi/l/baikal.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A graph-based functional API for building complex scikit-learn pipelines.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;baikal&lt;/strong&gt; is written in pure Python. It supports Python 3.5 and above.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Contents:&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#quick-start-guide"&gt;Quick-start guide&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#user-guide"&gt;User guide&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#next-development-steps"&gt;Next development steps&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-what-is-baikal" class="anchor" aria-hidden="true" href="#what-is-baikal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is baikal?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;baikal is a graph-based, functional API for building complex machine learning pipelines of objects that implement the &lt;a href="https://scikit-learn.org/stable/developers/contributing.html#different-objects" rel="nofollow"&gt;scikit-learn API&lt;/a&gt;&lt;/strong&gt;. It is mostly inspired on the excellent &lt;a href="https://keras.io" rel="nofollow"&gt;Keras&lt;/a&gt; API for Deep Learning, and borrows a few concepts from the &lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;TensorFlow&lt;/a&gt; framework and the (perhaps lesser known) &lt;a href="https://github.com/yahoo/graphkit"&gt;graphkit&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;baikal&lt;/strong&gt; aims to provide an API that allows to build complex, non-linear machine learning pipelines that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="illustrations/multiple_input_nonlinear_pipeline_example_diagram.png"&gt;&lt;img src="illustrations/multiple_input_nonlinear_pipeline_example_diagram.png" alt="multiple_input_nonlinear_pipeline_example_diagram" title="An example of a multiple-input, nonlinear pipeline" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;with code that looks like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;x1 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
x2 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()

y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; ExtraTreesClassifier()(x1, y_t)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; RandomForestClassifier()(x2, y_t)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PowerTransformer()(x2)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PCA()(z)
y3 &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression()(z, y_t)

ensemble_features &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2, y3])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC()(ensemble_features, y_t)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model([x1, x2], y, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-what-can-i-do-with-it" class="anchor" aria-hidden="true" href="#what-can-i-do-with-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What can I do with it?&lt;/h3&gt;
&lt;p&gt;With &lt;strong&gt;baikal&lt;/strong&gt; you can&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;build non-linear pipelines effortlessly&lt;/li&gt;
&lt;li&gt;handle multiple inputs and outputs&lt;/li&gt;
&lt;li&gt;add steps that operate on targets as part of the pipeline&lt;/li&gt;
&lt;li&gt;nest pipelines&lt;/li&gt;
&lt;li&gt;use prediction probabilities (or any other kind of output) as inputs to other steps in the pipeline&lt;/li&gt;
&lt;li&gt;query intermediate outputs, easing debugging&lt;/li&gt;
&lt;li&gt;freeze steps that do not require fitting&lt;/li&gt;
&lt;li&gt;define and add custom steps easily&lt;/li&gt;
&lt;li&gt;plot pipelines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All with boilerplate-free, readable code.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-why-baikal" class="anchor" aria-hidden="true" href="#why-baikal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why baikal?&lt;/h3&gt;
&lt;p&gt;The pipeline above (to the best of the author's knowledge) cannot be easily built using &lt;a href="https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators" rel="nofollow"&gt;scikit-learn's composite estimators API&lt;/a&gt; as you encounter some limitations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is aimed at linear pipelines
&lt;ul&gt;
&lt;li&gt;You could add some step parallelism with the &lt;a href="https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data" rel="nofollow"&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; API, but this is limited to transformer objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Classifiers/Regressors can only be used at the end of the pipeline.
&lt;ul&gt;
&lt;li&gt;This means we cannot use the predicted labels (or their probabilities) as features to other classifiers/regressors.&lt;/li&gt;
&lt;li&gt;You could leverage mlxtend's &lt;a href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/#stackingclassifier" rel="nofollow"&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; and come up with some clever combination of the above composite estimators (&lt;code&gt;Pipeline&lt;/code&gt;s, &lt;code&gt;ColumnTransformer&lt;/code&gt;s, and &lt;code&gt;StackingClassifier&lt;/code&gt;s, etc), but you might end up with code that feels hard-to-follow and verbose.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cannot handle multiple input/multiple output models.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Perhaps you could instead define a big, composite estimator class that integrates each of the pipeline steps through composition. This, however, most likely will require&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;writing big &lt;code&gt;__init__&lt;/code&gt; methods to control each of the internal steps' knobs;&lt;/li&gt;
&lt;li&gt;being careful with &lt;code&gt;get_params&lt;/code&gt; and &lt;code&gt;set_params&lt;/code&gt; if you want to use, say, &lt;code&gt;GridSearchCV&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;and adding some boilerplate code if you want to access the outputs of intermediate steps for debugging.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By using &lt;strong&gt;baikal&lt;/strong&gt; as shown in the example above, code can be more readable, less verbose and closer to our mental representation of the pipeline. &lt;strong&gt;baikal&lt;/strong&gt; also provides an API to fit, predict with, and query the entire pipeline with single commands, as we will see below.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-key-concepts" class="anchor" aria-hidden="true" href="#key-concepts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Key concepts&lt;/h2&gt;
&lt;p&gt;The baikal API introduces three basic elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Step&lt;/strong&gt;: Steps are the building blocks of the API. Conceptually similar to TensorFlow's operations and Keras layers, each Step is a unit of computation (e.g. PCA, Logistic Regression) that take the data from preceding Steps and produce data to be used by other Steps further in the pipeline. Steps are defined by combining the &lt;code&gt;Step&lt;/code&gt; mixin class with a base class that implements the scikit-learn API. This is explained in more detail below.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DataPlaceholder&lt;/strong&gt;: The inputs and outputs of Steps. If Steps are like TensorFlow operations or Keras layers, then DataPlaceHolders are akin to tensors. Don't be misled though, DataPlaceholders are just minimal, low-weight auxiliary objects whose main purpose is to keep track of the input/output connectivity between steps, and serve as the keys to map the actual input data to their appropriate Step. They are not arrays/tensors, nor contain any shape/type information whatsoever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model&lt;/strong&gt;: A Model is a network (more precisely, a directed acyclic graph) of Steps, and it is defined from the input/output specification of the pipeline. Models have fit and predict routines that, together with graph-based engine, allow the automatic (feed-forward) computation of each of the pipeline steps when fed with data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install baikal&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;numpy&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start-guide" class="anchor" aria-hidden="true" href="#quick-start-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick-start guide&lt;/h2&gt;
&lt;p&gt;Without further ado, here's a short example of a simple SVC model built with &lt;strong&gt;baikal&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn.svm
&lt;span class="pl-k"&gt;from&lt;/span&gt; sklearn.datasets &lt;span class="pl-k"&gt;import&lt;/span&gt; load_breast_cancer
&lt;span class="pl-k"&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class="pl-k"&gt;import&lt;/span&gt; train_test_split

&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; make_step, Input, Model


&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 1. Define a step&lt;/span&gt;
&lt;span class="pl-c1"&gt;SVC&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; make_step(sklearn.svm.&lt;span class="pl-c1"&gt;SVC&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 2. Build the model&lt;/span&gt;
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC(&lt;span class="pl-v"&gt;C&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1.0&lt;/span&gt;, &lt;span class="pl-v"&gt;kernel&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;rbf&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;gamma&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.5&lt;/span&gt;)(x, y_t)
model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 3. Train the model&lt;/span&gt;
dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; load_breast_cancer()
X_train, X_test, y_train, y_test &lt;span class="pl-k"&gt;=&lt;/span&gt; train_test_split(
    dataset.data, dataset.target, &lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0&lt;/span&gt;
)

model.fit(X_train, y_train)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 4. Use the model&lt;/span&gt;
y_test_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(X_test)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-user-guide" class="anchor" aria-hidden="true" href="#user-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;User guide&lt;/h2&gt;
&lt;p&gt;As shown in the short example above, the &lt;strong&gt;baikal&lt;/strong&gt; API consists of four basic steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define the steps&lt;/li&gt;
&lt;li&gt;Build the model&lt;/li&gt;
&lt;li&gt;Train the model&lt;/li&gt;
&lt;li&gt;Use the model&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's take a look at each of them in detail. Full examples can be found in the project's &lt;a href="examples"&gt;examples&lt;/a&gt; folder.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-1-define-the-steps" class="anchor" aria-hidden="true" href="#1-define-the-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Define the steps&lt;/h3&gt;
&lt;p&gt;A step is defined very easily, just feed the provided &lt;code&gt;make_step&lt;/code&gt; function with the class you want to make a step from:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn.linear_model
&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; make_step

LogisticRegression &lt;span class="pl-k"&gt;=&lt;/span&gt; make_step(sklearn.linear_model.LogisticRegression)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can make a step from any class you like, so long that class implements the &lt;a href="https://scikit-learn.org/stable/developers/contributing.html#different-objects" rel="nofollow"&gt;scikit-learn API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What this function is doing under the hood, is to combine the given class with the &lt;code&gt;Step&lt;/code&gt; mixin class. The &lt;code&gt;Step&lt;/code&gt; mixin, among other things, endows the given class with a &lt;code&gt;__call__&lt;/code&gt; method, making the class callable on the outputs (&lt;code&gt;DataPlaceholder&lt;/code&gt; objects) of previous steps. If you prefer to do this manually, you only have to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define a class that inherits from both the &lt;code&gt;Step&lt;/code&gt; mixin and the class you wish to make a step of (in that order!).&lt;/li&gt;
&lt;li&gt;In the class &lt;code&gt;__init__&lt;/code&gt;, call &lt;code&gt;super().__init__(...)&lt;/code&gt; and pass the appropriate step parameters.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For example, to make a step for &lt;code&gt;sklearn.linear_model.LogisticRegression&lt;/code&gt; we do:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn.linear_model
&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; Step

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; The order of inheritance is important!&lt;/span&gt;
&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;LogisticRegression&lt;/span&gt;(&lt;span class="pl-e"&gt;Step&lt;/span&gt;, &lt;span class="pl-e"&gt;sklearn&lt;/span&gt;.&lt;span class="pl-e"&gt;linear_model&lt;/span&gt;.&lt;span class="pl-e"&gt;LogisticRegression&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;None&lt;/span&gt;, &lt;span class="pl-smi"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;None&lt;/span&gt;, &lt;span class="pl-smi"&gt;n_outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-smi"&gt;trainable&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-smi"&gt;kwargs&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;super&lt;/span&gt;().&lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(
            &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;name,
            &lt;span class="pl-v"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;function,
            &lt;span class="pl-v"&gt;n_outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;n_outputs,
            &lt;span class="pl-v"&gt;trainable&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;trainable,
            &lt;span class="pl-k"&gt;**&lt;/span&gt;kwargs
        )&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Other steps are defined similarly (omitted here for brevity).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-build-the-model" class="anchor" aria-hidden="true" href="#2-build-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Build the model&lt;/h3&gt;
&lt;p&gt;Once we have defined the steps, we can make a model like shown below. First, you create the initial step, that serves as the entry-point to the model, by calling the &lt;code&gt;Input&lt;/code&gt; helper function. This outputs a DataPlaceholder representing one of the inputs to the model. Then, all you have to do is to instantiate the steps and call them on the outputs (DataPlaceholders from previous steps) as you deem appropriate. Finally, you instantiate the model with the inputs/outputs (also DataPlaceholders) that specify your pipeline.&lt;/p&gt;
&lt;p&gt;This style should feel familiar to users of Keras.&lt;/p&gt;
&lt;p&gt;Note that steps that require target data (like &lt;code&gt;ExtraTreesClassifier&lt;/code&gt;, &lt;code&gt;RandomForestClassifier&lt;/code&gt;, &lt;code&gt;LogisticRegression&lt;/code&gt; and &lt;code&gt;SVC&lt;/code&gt;) are called with two arguments. These arguments correspond to the inputs (e.g. &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;) and targets (e.g. &lt;code&gt;y_t&lt;/code&gt;) of the step. These targets are specified to the Model at instantiation via the third argument. &lt;strong&gt;baikal&lt;/strong&gt; pipelines are made of complex, heterogenous, non-differentiable steps (e.g. a whole RandomForestClassifier, with its own internal learning algorithm), so there's no some magic automatic differentiation that backpropagates the target information from the outputs to the appropriate steps, so we must specify which step needs which targets directly.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; Input, Model
&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal.steps &lt;span class="pl-k"&gt;import&lt;/span&gt; Stack

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Assume the steps below were already defined&lt;/span&gt;
x1 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
x2 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()

y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; ExtraTreesClassifier()(x1, y_t)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; RandomForestClassifier()(x2, y_t)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PowerTransformer()(x2)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PCA()(z)
y3 &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression()(z, y_t)

ensemble_features &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2, y3])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC()(ensemble_features, y_t)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model([x1, x2], y, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(*) Steps are called on and output DataPlaceHolders. DataPlaceholders are produced and consumed exclusively by Steps, so you do not need to instantiate these yourself.&lt;/p&gt;
&lt;p&gt;Note: Currently, calling the same step on different inputs and targets to reuse the step (similar to the concept of shared layers and nodes in Keras) is not supported. Calling a step twice on different inputs will override the connectivity from the first call. Support for shareable steps might be added in future releases.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-3-train-the-model" class="anchor" aria-hidden="true" href="#3-train-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Train the model&lt;/h3&gt;
&lt;p&gt;Now that we have built a model, we are ready to train it. The model also follows the scikit-learn API, as it has a fit method:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.fit(&lt;span class="pl-v"&gt;X&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[X1_train, X2_train], &lt;span class="pl-v"&gt;y&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;y_train)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The model will automatically propagate the data through the pipeline and fit any internal steps that require training.&lt;/p&gt;
&lt;p&gt;The fit function takes three arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;X&lt;/code&gt;: Input data (independent variables).
&lt;ul&gt;
&lt;li&gt;It can be either of the following:
&lt;ul&gt;
&lt;li&gt;A single array-like object (in the case of a single input)&lt;/li&gt;
&lt;li&gt;A list of array-like objects (in the case of multiple inputs)&lt;/li&gt;
&lt;li&gt;A dictionary mapping DataPlaceholders (or their names) to array-like objects. The keys must be among the inputs passed at instantiation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt; (optional): Target data (dependent variables).
&lt;ul&gt;
&lt;li&gt;It can either of the following:
&lt;ul&gt;
&lt;li&gt;None (in the case all steps are either non-trainable and/or unsupervised learning steps)&lt;/li&gt;
&lt;li&gt;A single array-like object (in the case of a single target)&lt;/li&gt;
&lt;li&gt;A list of array-like objects (in the case of multiple targets)&lt;/li&gt;
&lt;li&gt;A dictionary mapping DataPlaceholders (or their names) to array-like objects. The keys must be among the targets passed at instantiation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-4-use-the-model" class="anchor" aria-hidden="true" href="#4-use-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Use the model&lt;/h3&gt;
&lt;p&gt;To predict with model, just pass the input data like you would for the fit method. The model will automatically propagate the inputs through all the steps and produce the outputs specified at instantiation.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;y_test_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict([X1_test, X2_test])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; This also works:&lt;/span&gt;
y_test_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict({x1: X1_test, x2: X2_test})&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Models are query-able&lt;/strong&gt;. That is, you can request other outputs other than those specified at model instantiation. This allows querying intermediate outputs and ease debugging. For example, to get both the output from PCA and the ExtraTreesClassifier:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;outs &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(
    [X1_test, X2_test], &lt;span class="pl-v"&gt;output_names&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;ExtraTreesClassifier_0/0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;PCA_0/0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]
)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You don't need to pass inputs that are not required to compute the queried output. For example, if we just want the output of &lt;code&gt;PowerTransformer&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;outs &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict({x2: X2_data}, &lt;span class="pl-v"&gt;output_names&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;PowerTransformer_0/0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Models are also nestable&lt;/strong&gt;. In fact, Models are steps, too. This allows composing smaller models into bigger ones, like so:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Assume we have two previously built complex&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; classifier models, perhaps loaded from a file.&lt;/span&gt;
submodel1 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;...&lt;/span&gt;
submodel2 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;...&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Now we make an stacked classifier from both submodels&lt;/span&gt;
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; submodel1(x)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; submodel2(x, y_t)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC()(z, y_t)
bigmodel &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-persisting-the-model" class="anchor" aria-hidden="true" href="#persisting-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Persisting the model&lt;/h3&gt;
&lt;p&gt;Like sklearn objects, models can be serialized with pickle or joblib without any extra setup:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; joblib
joblib.dump(model, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;model.pkl&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
model_reloaded &lt;span class="pl-k"&gt;=&lt;/span&gt; joblib.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;model.pkl&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Keep in mind, however, the &lt;a href="https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations" rel="nofollow"&gt;security and maintainability limitations&lt;/a&gt; of these formats.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-utilities" class="anchor" aria-hidden="true" href="#utilities"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Utilities&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-sklearn-wrapper-for-gridsearchcv" class="anchor" aria-hidden="true" href="#sklearn-wrapper-for-gridsearchcv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sklearn wrapper for &lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Currently, &lt;strong&gt;baikal&lt;/strong&gt; also provides a wrapper utility class that allows models to used in scikit-learn's &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn-model-selection-gridsearchcv" rel="nofollow"&gt;&lt;code&gt;GridSearchCV&lt;/code&gt; API&lt;/a&gt;. Below there's a code snippet showing its usage. It follows the style of Keras' own wrapper. &lt;a href="examples/gridsearchcv_sklearn_wrapper.py"&gt;Here&lt;/a&gt; is an example script of this utility.&lt;/p&gt;
&lt;p&gt;A future release of &lt;strong&gt;baikal&lt;/strong&gt; plans to include a custom &lt;code&gt;GridSearchCV&lt;/code&gt; API, based on the original scikit-learn implementation, that can handle baikal models natively, avoiding a couple of gotchas with the current wrapper implementation (mentioned below).&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 1. Define a function that returns your baikal model&lt;/span&gt;
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;build_fn&lt;/span&gt;():
    x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
    y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
    h &lt;span class="pl-k"&gt;=&lt;/span&gt; PCA(&lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;random_state, &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pca&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(x)
    y &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression(&lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;random_state, &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(h, y_t)
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)
    &lt;span class="pl-k"&gt;return&lt;/span&gt; model

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 2. Define a parameter grid&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - keys have the [step-name]__[parameter-name] format, similar to sklearn Pipelines&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - You can also search over the steps themselves using [step-name] keys&lt;/span&gt;
param_grid &lt;span class="pl-k"&gt;=&lt;/span&gt; [
    {
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [LogisticRegression()],
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier__C&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [&lt;span class="pl-c1"&gt;0.01&lt;/span&gt;, &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;],
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pca__n_components&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;4&lt;/span&gt;],
    },
    {
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [RandomForestClassifier()],
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier__n_estimators&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [&lt;span class="pl-c1"&gt;10&lt;/span&gt;, &lt;span class="pl-c1"&gt;50&lt;/span&gt;, &lt;span class="pl-c1"&gt;100&lt;/span&gt;],
    },
]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 3. Instantiate the wrapper&lt;/span&gt;
sk_model &lt;span class="pl-k"&gt;=&lt;/span&gt; SKLearnWrapper(build_fn)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 4. Use GridSearchCV as usual&lt;/span&gt;
gscv_baikal &lt;span class="pl-k"&gt;=&lt;/span&gt; GridSearchCV(sk_model, param_grid)
gscv_baikal.fit(x_data, y_data)
best_model &lt;span class="pl-k"&gt;=&lt;/span&gt; gscv_baikal.best_estimator_.model&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Currently there are a couple of gotchas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;cv&lt;/code&gt; argument of &lt;code&gt;GridSearchCV&lt;/code&gt; will default to KFold if the estimator is a baikal Model, so you have to specify an appropriate splitter directly if you need another splitting scheme.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GridSearchCV&lt;/code&gt; cannot handle models with multiple inputs/outputs. A way to work around this is to split the input data and merge the outputs within the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-plotting-your-model" class="anchor" aria-hidden="true" href="#plotting-your-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Plotting your model&lt;/h4&gt;
&lt;p&gt;The baikal package includes a plot utility:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal.plot &lt;span class="pl-k"&gt;import&lt;/span&gt; plot_model
plot_model(model, &lt;span class="pl-v"&gt;filename&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;model.png&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For the example above, it produces this:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="illustrations/multiple_input_nonlinear_pipeline_example_plot.png"&gt;&lt;img src="illustrations/multiple_input_nonlinear_pipeline_example_plot.png" height="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In order to use the plot utility, you need to install &lt;a href="https://pypi.org/project/pydot" rel="nofollow"&gt;pydot&lt;/a&gt; and &lt;a href="https://graphviz.gitlab.io" rel="nofollow"&gt;graphviz&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-stacked-classifiers" class="anchor" aria-hidden="true" href="#stacked-classifiers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stacked classifiers&lt;/h3&gt;
&lt;p&gt;Similar to the the example in the quick-start above, stacks of classifiers (or regressors) can be built like shown below. Note that you can specify the function the step should use for computation, in this case &lt;code&gt;function='predict_proba'&lt;/code&gt; to use the label probabilities as the features of the meta-classifier.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression(&lt;span class="pl-v"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;predict_proba&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(x, y_t)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; RandomForestClassifier(&lt;span class="pl-v"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;predict_proba&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(x, y_t)
ensemble_features &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; ExtraTreesClassifier()(ensemble_features, y_t)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Click &lt;a href="examples/stacked_classifiers.py"&gt;here&lt;/a&gt; for a full example.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-classifier-chain" class="anchor" aria-hidden="true" href="#classifier-chain"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Classifier chain&lt;/h3&gt;
&lt;p&gt;The API also lends itself for more interesting configurations, such as that of &lt;a href="https://en.wikipedia.org/wiki/Classifier_chains" rel="nofollow"&gt;classifier chains&lt;/a&gt;. By leveraging the API and Python's own control flow, a classifier chain model can be built as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
order &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(&lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_targets))
random.shuffle(order)

ys_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Split(n_targets, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)(y_t)
ys_p &lt;span class="pl-k"&gt;=&lt;/span&gt; []
&lt;span class="pl-k"&gt;for&lt;/span&gt; j, k &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;(order):
    x_stacked &lt;span class="pl-k"&gt;=&lt;/span&gt; ColumnStack()([x, &lt;span class="pl-k"&gt;*&lt;/span&gt;ys_p[:j]])
    ys_t[k] &lt;span class="pl-k"&gt;=&lt;/span&gt; Lambda(np.squeeze, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)(ys_t[k])
    ys_p.append(LogisticRegression()(x_stacked, ys_t[k]))

ys_p &lt;span class="pl-k"&gt;=&lt;/span&gt; [ys_p[order.index(j)] &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_targets)]
y_p &lt;span class="pl-k"&gt;=&lt;/span&gt; ColumnStack()(ys_p)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y_p, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Click &lt;a href="examples/classifier_chain.py"&gt;here&lt;/a&gt; for a full example.&lt;/p&gt;
&lt;p&gt;Sure, scikit-learn already does have &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html#sklearn.multioutput.ClassifierChain" rel="nofollow"&gt;&lt;code&gt;ClassifierChain&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.RegressorChain.html#sklearn.multioutput.RegressorChain" rel="nofollow"&gt;&lt;code&gt;RegressorChain&lt;/code&gt;&lt;/a&gt; classes for this. But with &lt;strong&gt;baikal&lt;/strong&gt; you could, for example, mix classifiers and regressors to predict multilabels that include both categorical and continuous labels.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-next-development-steps" class="anchor" aria-hidden="true" href="#next-development-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next development steps&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Make a step class factory function.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Treat targets as first-class citizens in the Model. Currently, targets are not treated like formal inputs of the graph, and the only way a Model handles them is via the &lt;code&gt;Model.fit&lt;/code&gt; interface, which makes difficult applying steps to them (e.g. log transformation on regression targets).&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; (&lt;strong&gt;in progress&lt;/strong&gt;) Add parallelization to &lt;code&gt;Model.fit&lt;/code&gt; and &lt;code&gt;Model.predict&lt;/code&gt; (using joblib &lt;code&gt;Parallel&lt;/code&gt; API).&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Add caching of intermediate results to &lt;code&gt;Model.fit&lt;/code&gt; and &lt;code&gt;Model.predict&lt;/code&gt; (using joblib &lt;code&gt;Memory&lt;/code&gt; API).&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Make a custom &lt;code&gt;GridSearchCV&lt;/code&gt; API, based on the original scikit-learn implementation, that can handle baikal models with multiple inputs and outputs natively.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Make steps shareable.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Add support for steps that can take extra options in their predict method.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Grow the merge steps module and add support for data structures other than numpy arrays (e.g. pandas dataframes). Some steps that could be added are:
&lt;ul&gt;
&lt;li&gt;Single array aggregation (sum, average, maximum, minimum, etc).&lt;/li&gt;
&lt;li&gt;Element-wise aggregation of multiple arrays.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bug reports and fixes are always welcome!&lt;/li&gt;
&lt;li&gt;Contributions to extend/refactor/improve/document the API are also welcome! &lt;strong&gt;baikal&lt;/strong&gt; is currently a one-man operation, and it could benefit from more minds and hands working on it :)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-setting-up-the-development-environment" class="anchor" aria-hidden="true" href="#setting-up-the-development-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setting up the development environment&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Clone the project.&lt;/li&gt;
&lt;li&gt;From the project root folder run: &lt;code&gt;make setup_dev&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;This will create a virtualenv and install the package in development mode.&lt;/li&gt;
&lt;li&gt;It will also install a pre-commit hook for the black code formatter.&lt;/li&gt;
&lt;li&gt;You need Python 3.5 or above.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To run the tests use: &lt;code&gt;make test&lt;/code&gt;, or &lt;code&gt;make test-cov&lt;/code&gt; to include coverage.
&lt;ul&gt;
&lt;li&gt;The tests include a test for the plot utility, so you need to install graphviz.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>alegonz</author><guid isPermaLink="false">https://github.com/alegonz/baikal</guid><pubDate>Wed, 20 Nov 2019 00:18:00 GMT</pubDate></item><item><title>dagster-io/dagster #19 in Python, Today</title><link>https://github.com/dagster-io/dagster</link><description>&lt;p&gt;&lt;i&gt;A Python library for building data applications: ETL, ML, Data Pipelines, and more.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987382-7e294500-7a35-11e9-9c6a-f73e0f1d3a1c.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987382-7e294500-7a35-11e9-9c6a-f73e0f1d3a1c.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;br&gt;&lt;br&gt;
&lt;a href="https://badge.fury.io/py/dagster" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1e6441ac0fa4d3b9e968e8fef89d18a684fa183b/68747470733a2f2f62616467652e667572792e696f2f70792f646167737465722e737667" data-canonical-src="https://badge.fury.io/py/dagster.svg" style="max-width:100%;"&gt;
&lt;/a&gt;&lt;a href="https://coveralls.io/github/dagster-io/dagster?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0297bd3b6e7c67862d727860f76241f95b6f305a/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f646167737465722d696f2f646167737465722f62616467652e7376673f6272616e63683d6d6173746572" data-canonical-src="https://coveralls.io/repos/github/dagster-io/dagster/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://buildkite.com/dagster/dagster" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ed41dd566dc2f127467ea249a2b539ee42c7e692/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f38383835343562656162383239653431653564373330336462313535323561326263336230663065333361373237353961632e7376673f6272616e63683d6d6173746572" data-canonical-src="https://badge.buildkite.com/888545beab829e41e5d7303db15525a2bc3b0f0e33a72759ac.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://dagster.readthedocs.io/en/master/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e81711b6e8b9cbc5c0509a009136cfa7488aa786/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f646167737465722f62616467652f3f76657273696f6e3d6d6173746572" data-canonical-src="https://readthedocs.org/projects/dagster/badge/?version=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Dagster is a system for building modern data applications.&lt;/p&gt;
&lt;p&gt;Combining an elegant programming model and beautiful tools, Dagster allows infrastructure engineers, data engineers, and data scientists to seamlessly collaborate to process and produce the trusted, reliable data needed in today's world.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h3&gt;
&lt;p&gt;To get started:
&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
&lt;code&gt;pip install dagster dagit&lt;/code&gt;
&lt;/p&gt;
&lt;br&gt;
This installs two modules:
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;dagster&lt;/strong&gt; | The core programming model and abstraction stack; stateless, single-node,
single-process and multi-process execution engines; and a CLI tool for driving those engines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dagit&lt;/strong&gt; | A UI and rich development environment for Dagster, including a DAG browser, a type-aware config editor, and a streaming execution interface.
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-learn" class="anchor" aria-hidden="true" href="#learn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn&lt;/h3&gt;
&lt;p&gt;Next, jump right into our &lt;a href="https://dagster.readthedocs.io/en/stable/sections/learn/tutorial/index.html" rel="nofollow"&gt;tutorial&lt;/a&gt;, or read our &lt;a href="https://dagster.readthedocs.io" rel="nofollow"&gt;complete documentation&lt;/a&gt;. If you're actively using Dagster or have questions on getting started, we'd love to hear from you:&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;
&lt;a href="https://join.slack.com/t/dagster/shared_invite/enQtNjEyNjkzNTA2OTkzLTI0MzdlNjU0ODVhZjQyOTMyMGM1ZDUwZDQ1YjJmYjI3YzExZGViMDI1ZDlkNTY5OThmYWVlOWM1MWVjN2I3NjU" rel="nofollow"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/63558739-f60a7e00-c502-11e9-8434-c8a95b03ce62.png" width="160px;" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h3&gt;
&lt;p&gt;For details on contributing or running the project for development, check out our &lt;a href="https://dagster.readthedocs.io/en/stable/sections/community/contributing.html" rel="nofollow"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-integrations" class="anchor" aria-hidden="true" href="#integrations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Integrations&lt;/h1&gt;
&lt;p&gt;Dagster works with the tools and systems that you're already using with your data, including:&lt;/p&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr align="center"&gt;
			&lt;td colspan="2"&gt;&lt;b&gt;Integration&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;b&gt;Dagster Library&lt;/b&gt;&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987547-a7e36b80-7a37-11e9-95ae-4c4de2618e87.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987547-a7e36b80-7a37-11e9-95ae-4c4de2618e87.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Apache Airflow&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-airflow"&gt;dagster-airflow&lt;/a&gt;&lt;br&gt;Allows Dagster pipelines to be scheduled and executed, either containerized or uncontainerized, as &lt;a href="https://github.com/apache/airflow"&gt;Apache Airflow DAGs&lt;/a&gt;.&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987976-5ccc5700-7a3d-11e9-9fa5-1a51299b1ccb.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987976-5ccc5700-7a3d-11e9-9fa5-1a51299b1ccb.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Apache Spark&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-spark"&gt;dagster-spark&lt;/a&gt; Â·Â &lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-pyspark"&gt;dagster-pyspark&lt;/a&gt;
			&lt;br&gt;Libraries for interacting with Apache Spark and Pyspark.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/58348728-48f66b80-7e16-11e9-9e9f-1a0fea9a49b4.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/58348728-48f66b80-7e16-11e9-9e9f-1a0fea9a49b4.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Dask&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-dask"&gt;dagster-dask&lt;/a&gt;
			&lt;br&gt;Provides a Dagster integration with Dask / Dask.Distributed.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/58349731-f36f8e00-7e18-11e9-8a2e-86e086caab66.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/58349731-f36f8e00-7e18-11e9-8a2e-86e086caab66.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;DataDog&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-datadog"&gt;dagster-datadog&lt;/a&gt;
			&lt;br&gt;Provides a Dagster resource for publishing metrics to DataDog.
			&lt;/td&gt;
		&lt;/tr&gt;
        
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987809-bf245800-7a3b-11e9-8905-494ed99d0852.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987809-bf245800-7a3b-11e9-8905-494ed99d0852.png" style="max-width:100%;"&gt;&lt;/a&gt;
			Â /Â  &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987827-fa268b80-7a3b-11e9-8a18-b675d76c19aa.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987827-fa268b80-7a3b-11e9-8a18-b675d76c19aa.png" style="max-width:100%;"&gt;&lt;/a&gt;
			&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Jupyter / Papermill&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/dagstermill"&gt;dagstermill&lt;/a&gt;&lt;br&gt;Built on the &lt;a href="https://github.com/nteract/papermill"&gt;papermill library&lt;/a&gt;, dagstermill is meant for integrating productionized Jupyter notebooks into dagster pipelines.&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57988016-f431aa00-7a3d-11e9-8cb6-1309d4246b27.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57988016-f431aa00-7a3d-11e9-8cb6-1309d4246b27.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;PagerDuty&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-pagerduty"&gt;dagster-pagerduty&lt;/a&gt;
			&lt;br&gt;A library for creating PagerDuty alerts from Dagster workflows.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/58349397-fcac2b00-7e17-11e9-900c-9ab8cf7cb64a.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/58349397-fcac2b00-7e17-11e9-900c-9ab8cf7cb64a.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Snowflake&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-snowflake"&gt;dagster-snowflake&lt;/a&gt;
			&lt;br&gt;A library for interacting with the Snowflake Data Warehouse.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td colspan="2" align="center"&gt;&lt;b&gt;Cloud Providers&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;b&gt;&lt;/b&gt;&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987557-c2b5e000-7a37-11e9-9310-c274481a4682.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987557-c2b5e000-7a37-11e9-9310-c274481a4682.png" style="max-width:100%;"&gt;&lt;/a&gt; &lt;/td&gt;
			&lt;td&gt;&lt;b&gt;AWS&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-aws"&gt;dagster-aws&lt;/a&gt;
			&lt;br&gt;A library for interacting with Amazon Web Services. Provides integrations with S3, EMR, and (coming soon!) Redshift.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987566-f98bf600-7a37-11e9-81fa-b8ca1ea6cc1e.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987566-f98bf600-7a37-11e9-81fa-b8ca1ea6cc1e.png" style="max-width:100%;"&gt;&lt;/a&gt; &lt;/td&gt;
			&lt;td&gt;&lt;b&gt;GCP&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-gcp"&gt;dagster-gcp&lt;/a&gt;
			&lt;br&gt;A library for interacting with Google Cloud Platform. Provides integrations with BigQuery and Cloud Dataproc.
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This list is growing as we are actively building more integrations, and we welcome contributions!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-example-projects" class="anchor" aria-hidden="true" href="#example-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Projects&lt;/h1&gt;
&lt;p&gt;Several example projects are provided under the examples folder demonstrating how to use Dagster, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/examples/dagster_examples/airline_demo"&gt;&lt;strong&gt;examples/airline-demo&lt;/strong&gt;&lt;/a&gt;: A substantial demo project illustrating how these tools can be used together to manage a realistic data pipeline.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/examples/dagster_examples/event_pipeline_demo"&gt;&lt;strong&gt;examples/event-pipeline-demo&lt;/strong&gt;&lt;/a&gt;: An example illustrating a typical web event processing pipeline with S3, Scala Spark, and Snowflake.&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dagster-io</author><guid isPermaLink="false">https://github.com/dagster-io/dagster</guid><pubDate>Wed, 20 Nov 2019 00:19:00 GMT</pubDate></item><item><title>MorvanZhou/Reinforcement-learning-with-tensorflow #20 in Python, Today</title><link>https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow</link><description>&lt;p&gt;&lt;i&gt;Simple Reinforcement learning tutorials&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;a href="https://www.youtube.com/watch?v=pieI7rOXELI&amp;amp;list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba" rel="nofollow"&gt;
    &lt;img width="60%" src="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/raw/master/RL_cover.jpg" style="max-width:100%;"&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h1&gt;&lt;a id="user-content-reinforcement-learning-methods-and-tutorials" class="anchor" aria-hidden="true" href="#reinforcement-learning-methods-and-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reinforcement Learning Methods and Tutorials&lt;/h1&gt;
&lt;p&gt;In these tutorials for reinforcement learning, it covers from the basic RL algorithms to advanced algorithms developed recent years.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you speak Chinese, visit &lt;a href="https://morvanzhou.github.io/tutorials/" rel="nofollow"&gt;è«çƒ¦ Python&lt;/a&gt; or my &lt;a href="https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg" rel="nofollow"&gt;Youtube channel&lt;/a&gt; for more.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;As many requests about making these tutorials available in English, please find them in this playlist:&lt;/strong&gt; (&lt;a href="https://www.youtube.com/playlist?list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba" rel="nofollow"&gt;https://www.youtube.com/playlist?list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba&lt;/a&gt;)&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Tutorials
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/1_command_line_reinforcement_learning"&gt;Simple entry example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/2_Q_Learning_maze"&gt;Q-learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/3_Sarsa_maze"&gt;Sarsa&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/4_Sarsa_lambda_maze"&gt;Sarsa(lambda)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network"&gt;Deep Q Network (DQN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/6_OpenAI_gym"&gt;Using OpenAI Gym&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN"&gt;Double DQN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.2_Prioritized_Replay_DQN"&gt;DQN with Prioitized Experience Replay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN"&gt;Dueling DQN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/7_Policy_gradient_softmax"&gt;Policy Gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage"&gt;Actor-Critic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG"&gt;Deep Deterministic Policy Gradient (DDPG)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C"&gt;A3C&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/11_Dyna_Q"&gt;Dyna-Q&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization"&gt;Proximal Policy Optimization (PPO)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/contents/Curiosity_Model"&gt;Curiosity Model&lt;/a&gt;, &lt;a href="/contents/Curiosity_Model/Random_Network_Distillation.py"&gt;Random Network Distillation (RND)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments"&gt;Some of my experiments&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/2D_car"&gt;2D Car&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Robot_arm"&gt;Robot arm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Solve_BipedalWalker"&gt;BipedalWalker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Solve_LunarLander"&gt;LunarLander&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-some-rl-networks" class="anchor" aria-hidden="true" href="#some-rl-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Some RL Networks&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-deep-q-network" class="anchor" aria-hidden="true" href="#deep-q-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network"&gt;Deep Q Network&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network"&gt;
    &lt;img src="https://camo.githubusercontent.com/9d349655665f1b25905c42a7b342827a7df1acc2/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f342d332d322e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/4-3-2.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-double-dqn" class="anchor" aria-hidden="true" href="#double-dqn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN"&gt;Double DQN&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN"&gt;
    &lt;img src="https://camo.githubusercontent.com/49c9d71143f31e8e561de3059c9ae8e08fe8c0a6/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f342d352d332e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/4-5-3.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-dueling-dqn" class="anchor" aria-hidden="true" href="#dueling-dqn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN"&gt;Dueling DQN&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN"&gt;
    &lt;img src="https://camo.githubusercontent.com/bb04e5c0fb7f9c46cfb898362faceaf733abff99/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f342d372d342e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/4-7-4.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-actor-critic" class="anchor" aria-hidden="true" href="#actor-critic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage"&gt;Actor Critic&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage"&gt;
    &lt;img src="https://camo.githubusercontent.com/a6c8f9c2ee63bcd5bee37a93f6488f8071066120/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d312d312e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-1-1.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-deep-deterministic-policy-gradient" class="anchor" aria-hidden="true" href="#deep-deterministic-policy-gradient"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG"&gt;Deep Deterministic Policy Gradient&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG"&gt;
    &lt;img src="https://camo.githubusercontent.com/14ecb4ed0905d3b7d9cda452d77385aa5967a418/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d322d322e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-2-2.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-a3c" class="anchor" aria-hidden="true" href="#a3c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C"&gt;A3C&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C"&gt;
    &lt;img src="https://camo.githubusercontent.com/ae5c679885277b64d5284d17a77ed3f5f305154e/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d332d322e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-3-2.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-proximal-policy-optimization-ppo" class="anchor" aria-hidden="true" href="#proximal-policy-optimization-ppo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization"&gt;Proximal Policy Optimization (PPO)&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization"&gt;
    &lt;img src="https://camo.githubusercontent.com/f0872e487fe5a62274acbe83b2f28ba90db63a38/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d342d332e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-4-3.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-curiosity-model" class="anchor" aria-hidden="true" href="#curiosity-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="/contents/Curiosity_Model"&gt;Curiosity Model&lt;/a&gt;&lt;/h3&gt;
&lt;a href="/contents/Curiosity_Model"&gt;
    &lt;img src="/contents/Curiosity_Model/Curiosity.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h1&gt;&lt;a id="user-content-donation" class="anchor" aria-hidden="true" href="#donation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Donation&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;If this does help you, please consider donating to support me for better tutorials. Any contribution is greatly appreciated!&lt;/em&gt;&lt;/p&gt;
&lt;div&gt;
  &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_donations&amp;amp;business=morvanzhou%40gmail%2ecom&amp;amp;lc=C2&amp;amp;item_name=MorvanPython&amp;amp;currency_code=AUD&amp;amp;bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/f75f395714327046e04cbadbee71103f87fd0aa1/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f7765627374617469632f656e5f55532f692f62746e2f706e672f73696c7665722d70696c6c2d70617970616c2d343470782e706e67" alt="Paypal" height="auto" data-canonical-src="https://www.paypalobjects.com/webstatic/en_US/i/btn/png/silver-pill-paypal-44px.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div&gt;
  &lt;a href="https://www.patreon.com/morvan" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/af8133ce68a27bb72e44120b5ec14062fc42dc75/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f696d672f737570706f72742f70617472656f6e2e6a7067" alt="Patreon" height="120" data-canonical-src="https://morvanzhou.github.io/static/img/support/patreon.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>MorvanZhou</author><guid isPermaLink="false">https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow</guid><pubDate>Wed, 20 Nov 2019 00:20:00 GMT</pubDate></item><item><title>python/cpython #21 in Python, Today</title><link>https://github.com/python/cpython</link><description>&lt;p&gt;&lt;i&gt;The Python programming language&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-this-is-python-version-390-alpha-0" class="anchor" aria-hidden="true" href="#this-is-python-version-390-alpha-0"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;This is Python version 3.9.0 alpha 0&lt;/h1&gt;
&lt;a href="https://travis-ci.org/python/cpython" rel="nofollow"&gt;&lt;img alt="CPython build status on Travis CI" src="https://camo.githubusercontent.com/1cf785564e67b5021bcfb04c9e9ba719e53ce233/68747470733a2f2f7472617669732d63692e6f72672f707974686f6e2f63707974686f6e2e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.org/python/cpython.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://dev.azure.com/python/cpython/_build/latest?definitionId=4&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img alt="CPython build status on Azure DevOps" src="https://camo.githubusercontent.com/f83305497e9e201829a929f97fdcbc85cb749208/68747470733a2f2f6465762e617a7572652e636f6d2f707974686f6e2f63707974686f6e2f5f617069732f6275696c642f7374617475732f417a757265253230506970656c696e657325323043493f6272616e63684e616d653d6d6173746572" data-canonical-src="https://dev.azure.com/python/cpython/_apis/build/status/Azure%20Pipelines%20CI?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/python/cpython" rel="nofollow"&gt;&lt;img alt="CPython code coverage on Codecov" src="https://camo.githubusercontent.com/8d830fe82af43496cf4e3c635576df2dc324f266/68747470733a2f2f636f6465636f762e696f2f67682f707974686f6e2f63707974686f6e2f6272616e63682f6d61737465722f67726170682f62616467652e737667" data-canonical-src="https://codecov.io/gh/python/cpython/branch/master/graph/badge.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://python.zulipchat.com" rel="nofollow"&gt;&lt;img alt="Python Zulip chat" src="https://camo.githubusercontent.com/11c063c06dacad518cf3aa987986e97ef2018727/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;p&gt;Copyright (c) 2001-2019 Python Software Foundation.  All rights reserved.&lt;/p&gt;
&lt;p&gt;See the end of this file for further copyright and license information.&lt;/p&gt;
&lt;div id="user-content-contents"&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#general-information" id="user-content-id1"&gt;General Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing-to-cpython" id="user-content-id2"&gt;Contributing to CPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-python" id="user-content-id3"&gt;Using Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#build-instructions" id="user-content-id4"&gt;Build Instructions&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#profile-guided-optimization" id="user-content-id5"&gt;Profile Guided Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#link-time-optimization" id="user-content-id6"&gt;Link Time Optimization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-s-new" id="user-content-id7"&gt;What's New&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation" id="user-content-id8"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#converting-from-python-2-x-to-3-x" id="user-content-id9"&gt;Converting From Python 2.x to 3.x&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing" id="user-content-id10"&gt;Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installing-multiple-versions" id="user-content-id11"&gt;Installing multiple versions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#issue-tracker-and-mailing-list" id="user-content-id12"&gt;Issue Tracker and Mailing List&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#proposals-for-enhancement" id="user-content-id13"&gt;Proposals for enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#release-schedule" id="user-content-id14"&gt;Release Schedule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#copyright-and-license-information" id="user-content-id15"&gt;Copyright and License Information&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;a name="user-content-general-information"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-general-information" class="anchor" aria-hidden="true" href="#general-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id1"&gt;General Information&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Website: &lt;a href="https://www.python.org" rel="nofollow"&gt;https://www.python.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Source code: &lt;a href="https://github.com/python/cpython"&gt;https://github.com/python/cpython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Issue tracker: &lt;a href="https://bugs.python.org" rel="nofollow"&gt;https://bugs.python.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Documentation: &lt;a href="https://docs.python.org" rel="nofollow"&gt;https://docs.python.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Developer's Guide: &lt;a href="https://devguide.python.org/" rel="nofollow"&gt;https://devguide.python.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-contributing-to-cpython"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing-to-cpython" class="anchor" aria-hidden="true" href="#contributing-to-cpython"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id2"&gt;Contributing to CPython&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For more complete instructions on contributing to CPython development,
see the &lt;a href="https://devguide.python.org/" rel="nofollow"&gt;Developer Guide&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-using-python"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-using-python" class="anchor" aria-hidden="true" href="#using-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id3"&gt;Using Python&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Installable Python kits, and information about using Python, are available at
&lt;a href="https://www.python.org/" rel="nofollow"&gt;python.org&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-build-instructions"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-build-instructions" class="anchor" aria-hidden="true" href="#build-instructions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id4"&gt;Build Instructions&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On Unix, Linux, BSD, macOS, and Cygwin:&lt;/p&gt;
&lt;pre&gt;./configure
make
make test
sudo make install
&lt;/pre&gt;
&lt;p&gt;This will install Python as &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can pass many options to the configure script; run &lt;code&gt;./configure --help&lt;/code&gt;
to find out more.  On macOS case-insensitive file systems and on Cygwin,
the executable is called &lt;code&gt;python.exe&lt;/code&gt;; elsewhere it's just &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Building a complete Python installation requires the use of various
additional third-party libraries, depending on your build platform and
configure options.  Not all standard library modules are buildable or
useable on all platforms.  Refer to the
&lt;a href="https://devguide.python.org/setup/#install-dependencies" rel="nofollow"&gt;Install dependencies&lt;/a&gt;
section of the &lt;a href="https://devguide.python.org/" rel="nofollow"&gt;Developer Guide&lt;/a&gt; for current detailed information on
dependencies for various Linux distributions and macOS.&lt;/p&gt;
&lt;p&gt;On macOS, there are additional configure and build options related
to macOS framework and universal builds.  Refer to &lt;a href="https://github.com/python/cpython/blob/master/Mac/README.rst"&gt;Mac/README.rst&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On Windows, see &lt;a href="https://github.com/python/cpython/blob/master/PCbuild/readme.txt"&gt;PCbuild/readme.txt&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you wish, you can create a subdirectory and invoke configure from there.
For example:&lt;/p&gt;
&lt;pre&gt;mkdir debug
cd debug
../configure --with-pydebug
make
make test
&lt;/pre&gt;
&lt;p&gt;(This will fail if you &lt;em&gt;also&lt;/em&gt; built at the top-level directory.  You should do
a &lt;code&gt;make clean&lt;/code&gt; at the top-level first.)&lt;/p&gt;
&lt;p&gt;To get an optimized build of Python, &lt;code&gt;configure --enable-optimizations&lt;/code&gt;
before you run &lt;code&gt;make&lt;/code&gt;.  This sets the default make targets up to enable
Profile Guided Optimization (PGO) and may be used to auto-enable Link Time
Optimization (LTO) on some platforms.  For more details, see the sections
below.&lt;/p&gt;
&lt;a name="user-content-profile-guided-optimization"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-profile-guided-optimization" class="anchor" aria-hidden="true" href="#profile-guided-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id5"&gt;Profile Guided Optimization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;PGO takes advantage of recent versions of the GCC or Clang compilers.  If used,
either via &lt;code&gt;configure --enable-optimizations&lt;/code&gt; or by manually running
&lt;code&gt;make profile-opt&lt;/code&gt; regardless of configure flags, the optimized build
process will perform the following steps:&lt;/p&gt;
&lt;p&gt;The entire Python directory is cleaned of temporary files that may have
resulted from a previous compilation.&lt;/p&gt;
&lt;p&gt;An instrumented version of the interpreter is built, using suitable compiler
flags for each flavour. Note that this is just an intermediary step.  The
binary resulting from this step is not good for real life workloads as it has
profiling instructions embedded inside.&lt;/p&gt;
&lt;p&gt;After the instrumented interpreter is built, the Makefile will run a training
workload.  This is necessary in order to profile the interpreter execution.
Note also that any output, both stdout and stderr, that may appear at this step
is suppressed.&lt;/p&gt;
&lt;p&gt;The final step is to build the actual interpreter, using the information
collected from the instrumented one.  The end result will be a Python binary
that is optimized; suitable for distribution or production installation.&lt;/p&gt;
&lt;a name="user-content-link-time-optimization"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-link-time-optimization" class="anchor" aria-hidden="true" href="#link-time-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id6"&gt;Link Time Optimization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Enabled via configure's &lt;code&gt;--with-lto&lt;/code&gt; flag.  LTO takes advantage of the
ability of recent compiler toolchains to optimize across the otherwise
arbitrary &lt;code&gt;.o&lt;/code&gt; file boundary when building final executables or shared
libraries for additional performance gains.&lt;/p&gt;
&lt;a name="user-content-what-s-new"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-whats-new" class="anchor" aria-hidden="true" href="#whats-new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id7"&gt;What's New&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We have a comprehensive overview of the changes in the &lt;a href="https://docs.python.org/3.9/whatsnew/3.9.html" rel="nofollow"&gt;What's New in Python
3.9&lt;/a&gt; document.  For a more
detailed change log, read &lt;a href="https://github.com/python/cpython/blob/master/Misc/NEWS.d"&gt;Misc/NEWS&lt;/a&gt;, but a full
accounting of changes can only be gleaned from the &lt;a href="https://github.com/python/cpython/commits/master"&gt;commit history&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want to install multiple versions of Python, see the section below
entitled "Installing multiple versions".&lt;/p&gt;
&lt;a name="user-content-documentation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id8"&gt;Documentation&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3.9/" rel="nofollow"&gt;Documentation for Python 3.9&lt;/a&gt; is online,
updated daily.&lt;/p&gt;
&lt;p&gt;It can also be downloaded in many formats for faster access.  The documentation
is downloadable in HTML, PDF, and reStructuredText formats; the latter version
is primarily for documentation authors, translators, and people with special
formatting requirements.&lt;/p&gt;
&lt;p&gt;For information about building Python's documentation, refer to &lt;a href="https://github.com/python/cpython/blob/master/Doc/README.rst"&gt;Doc/README.rst&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-converting-from-python-2-x-to-3-x"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-converting-from-python-2x-to-3x" class="anchor" aria-hidden="true" href="#converting-from-python-2x-to-3x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id9"&gt;Converting From Python 2.x to 3.x&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Significant backward incompatible changes were made for the release of Python
3.0, which may cause programs written for Python 2 to fail when run with Python
3.  For more information about porting your code from Python 2 to Python 3, see
the &lt;a href="https://docs.python.org/3/howto/pyporting.html" rel="nofollow"&gt;Porting HOWTO&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-testing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id10"&gt;Testing&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To test the interpreter, type &lt;code&gt;make test&lt;/code&gt; in the top-level directory.  The
test set produces some output.  You can generally ignore the messages about
skipped tests due to optional features which can't be imported.  If a message
is printed about a failed test or a traceback or core dump is produced,
something is wrong.&lt;/p&gt;
&lt;p&gt;By default, tests are prevented from overusing resources like disk space and
memory.  To enable these tests, run &lt;code&gt;make testall&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If any tests fail, you can re-run the failing test(s) in verbose mode.  For
example, if &lt;code&gt;test_os&lt;/code&gt; and &lt;code&gt;test_gdb&lt;/code&gt; failed, you can run:&lt;/p&gt;
&lt;pre&gt;make test TESTOPTS="-v test_os test_gdb"
&lt;/pre&gt;
&lt;p&gt;If the failure persists and appears to be a problem with Python rather than
your environment, you can &lt;a href="https://bugs.python.org" rel="nofollow"&gt;file a bug report&lt;/a&gt; and
include relevant output from that command to show the issue.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://devguide.python.org/runtests/" rel="nofollow"&gt;Running &amp;amp; Writing Tests&lt;/a&gt;
for more on running tests.&lt;/p&gt;
&lt;a name="user-content-installing-multiple-versions"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installing-multiple-versions" class="anchor" aria-hidden="true" href="#installing-multiple-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id11"&gt;Installing multiple versions&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On Unix and Mac systems if you intend to install multiple versions of Python
using the same installation prefix (&lt;code&gt;--prefix&lt;/code&gt; argument to the configure
script) you must take care that your primary python executable is not
overwritten by the installation of a different version.  All files and
directories installed using &lt;code&gt;make altinstall&lt;/code&gt; contain the major and minor
version and can thus live side-by-side.  &lt;code&gt;make install&lt;/code&gt; also creates
&lt;code&gt;${prefix}/bin/python3&lt;/code&gt; which refers to &lt;code&gt;${prefix}/bin/pythonX.Y&lt;/code&gt;.  If you
intend to install multiple versions using the same prefix you must decide which
version (if any) is your "primary" version.  Install that version using &lt;code&gt;make
install&lt;/code&gt;.  Install all other versions using &lt;code&gt;make altinstall&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, if you want to install Python 2.7, 3.6, and 3.9 with 3.9 being the
primary version, you would execute &lt;code&gt;make install&lt;/code&gt; in your 3.9 build directory
and &lt;code&gt;make altinstall&lt;/code&gt; in the others.&lt;/p&gt;
&lt;a name="user-content-issue-tracker-and-mailing-list"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-issue-tracker-and-mailing-list" class="anchor" aria-hidden="true" href="#issue-tracker-and-mailing-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id12"&gt;Issue Tracker and Mailing List&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Bug reports are welcome!  You can use the &lt;a href="https://bugs.python.org" rel="nofollow"&gt;issue tracker&lt;/a&gt; to report bugs, and/or submit pull requests &lt;a href="https://github.com/python/cpython"&gt;on
GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can also follow development discussion on the &lt;a href="https://mail.python.org/mailman/listinfo/python-dev/" rel="nofollow"&gt;python-dev mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-proposals-for-enhancement"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-proposals-for-enhancement" class="anchor" aria-hidden="true" href="#proposals-for-enhancement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id13"&gt;Proposals for enhancement&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you have a proposal to change Python, you may want to send an email to the
comp.lang.python or &lt;a href="https://mail.python.org/mailman/listinfo/python-ideas/" rel="nofollow"&gt;python-ideas&lt;/a&gt; mailing lists for initial feedback.  A
Python Enhancement Proposal (PEP) may be submitted if your idea gains ground.
All current PEPs, as well as guidelines for submitting a new PEP, are listed at
&lt;a href="https://www.python.org/dev/peps/" rel="nofollow"&gt;python.org/dev/peps/&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-release-schedule"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-release-schedule" class="anchor" aria-hidden="true" href="#release-schedule"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id14"&gt;Release Schedule&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;See &lt;a href="http://www.python.org/dev/peps/pep-0596" rel="nofollow"&gt;PEP 596&lt;/a&gt; for Python 3.9 release details.&lt;/p&gt;
&lt;a name="user-content-copyright-and-license-information"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-copyright-and-license-information" class="anchor" aria-hidden="true" href="#copyright-and-license-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id15"&gt;Copyright and License Information&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Copyright (c) 2001-2019 Python Software Foundation.  All rights reserved.&lt;/p&gt;
&lt;p&gt;Copyright (c) 2000 BeOpen.com.  All rights reserved.&lt;/p&gt;
&lt;p&gt;Copyright (c) 1995-2001 Corporation for National Research Initiatives.  All
rights reserved.&lt;/p&gt;
&lt;p&gt;Copyright (c) 1991-1995 Stichting Mathematisch Centrum.  All rights reserved.&lt;/p&gt;
&lt;p&gt;See the file "LICENSE" for information on the history of this software, terms &amp;amp;
conditions for usage, and a DISCLAIMER OF ALL WARRANTIES.&lt;/p&gt;
&lt;p&gt;This Python distribution contains &lt;em&gt;no&lt;/em&gt; GNU General Public License (GPL) code,
so it may be used in proprietary projects.  There are interfaces to some GNU
code but these are entirely optional.&lt;/p&gt;
&lt;p&gt;All trademarks referenced herein are property of their respective holders.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>python</author><guid isPermaLink="false">https://github.com/python/cpython</guid><pubDate>Wed, 20 Nov 2019 00:21:00 GMT</pubDate></item><item><title>EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi #22 in Python, Today</title><link>https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi</link><description>&lt;p&gt;&lt;i&gt;A tutorial showing how to train, convert, and run TensorFlow Lite object detection models on Android devices, the Raspberry Pi, and more!&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-lite-object-detection-on-android-and-raspberry-pi" class="anchor" aria-hidden="true" href="#tensorflow-lite-object-detection-on-android-and-raspberry-pi"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi&lt;/h1&gt;
&lt;p&gt;A guide showing how to train TensorFlow Lite object detection models and run them on Android, the Raspberry Pi, and more!&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/BSR_demo.gif"&gt;&lt;img src="doc/BSR_demo.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TensorFlow Lite is an optimized framework for deploying lightweight deep learning models on resource-constrained edge devices. TensorFlow Lite models have faster inference time and require less processing power, so they can be used to obtain faster performance in realtime applications. This guide provides step-by-step instructions for how train a custom TensorFlow Object Detection model, convert it into an optimized format that can be used by TensorFlow Lite, and run it on Android phones or the Raspberry Pi.&lt;/p&gt;
&lt;p&gt;The guide is broken into three major portions. Each portion will have its own dedicated README file in this repository.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to Train, Convert, and Run Custom TensorFlow Lite Object Detection Models on Windows 10  &lt;em&gt;&amp;lt;--- You are here!&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md"&gt;How to Run TensorFlow Lite Object Detection Models on the Raspberry Pi (with optional Coral USB Accelerator)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How to Run TensorFlow Lite Object Detection Models on Android Devices
(Expected completion: 11/30/19)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This repository also contains Python code for running the newly converted TensorFlow Lite model to perform detection on images, videos, or webcam feeds.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-a-note-on-versions" class="anchor" aria-hidden="true" href="#a-note-on-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Note on Versions&lt;/h3&gt;
&lt;p&gt;I used TensorFlow v1.13 while creating this guide, because TF v1.13 is a stable version that has great support from Anaconda. I will periodically update the guide to make sure it works with newer versions of TensorFlow.&lt;/p&gt;
&lt;p&gt;The TensorFlow team is always hard at work releasing updated versions of TensorFlow. I recommend picking one version and sticking with it for all your TensorFlow projects. Every part of this guide should work with newer or older versions, but you may need to use different versions of the tools needed to run or build TensorFlow (CUDA, cuDNN, bazel, etc). Google has provided a list of build configurations for &lt;a href="https://www.tensorflow.org/install/source#linux" rel="nofollow"&gt;Linux&lt;/a&gt;, &lt;a href="https://www.tensorflow.org/install/source#macos" rel="nofollow"&gt;macOS&lt;/a&gt;, and &lt;a href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="nofollow"&gt;Windows&lt;/a&gt; that show which tool versions were used to build and run each version of TensorFlow.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-part-1---how-to-train-convert-and-run-custom-tensorflow-lite-object-detection-models-on-windows-10" class="anchor" aria-hidden="true" href="#part-1---how-to-train-convert-and-run-custom-tensorflow-lite-object-detection-models-on-windows-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Part 1 - How to Train, Convert, and Run Custom TensorFlow Lite Object Detection Models on Windows 10&lt;/h2&gt;
&lt;p&gt;Part 1 of this guide gives instructions for training and deploying your own custom TensorFlow Lite object detection model on a Windows 10 PC. The guide is based off the &lt;a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md"&gt;tutorial in the TensorFlow Object Detection repository&lt;/a&gt;, but it gives more detailed instructions and is written specifically for Windows. (It will work on Linux too with some minor changes, which I leave as an exercise for the Linux user.)&lt;/p&gt;
&lt;p&gt;There are three primary steps to training and deploying a TensorFlow Lite model:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph"&gt;Train a quantized SSD-MobileNet model using TensorFlow, and export frozen graph for TensorFlow Lite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-2-build-tensorflow-from-source"&gt;Build TensorFlow from source on your PC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-3-use-toco-to-create-optimzed-tensorflow-lite-model"&gt;Use TensorFlow Lite Optimizing Converter (TOCO) to create optimzed TensorFlow Lite model&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This portion is a continuation of my previous guide: &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;How To Train an Object Detection Model Using TensorFlow on Windows 10&lt;/a&gt;. I'll assume you have already set up TensorFlow to train a custom object detection model as described in that guide, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setting up an Anaconda virtual environment for training&lt;/li&gt;
&lt;li&gt;Setting up TensorFlow directory structure&lt;/li&gt;
&lt;li&gt;Gathering and labeling training images&lt;/li&gt;
&lt;li&gt;Preparing training data (generating TFRecords and label map)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial uses the same Anaconda virtual environment, files, and directory structure that was set up in the previous one.&lt;/p&gt;
&lt;p&gt;Through the course of the guide, I'll use a bird, squirrel, and raccoon detector model I've been working on as an example. The intent of this detection model is to watch a bird feeder, and record videos of birds while triggering an alarm if a squirrel or raccoon is stealing from it! I'll show the steps needed to train, convert, and run a quantized TensorFlow Lite version of the bird/squirrel/raccoon detector.&lt;/p&gt;
&lt;p&gt;Parts 2 and 3 of this guide will go on to show how to deploy this newly trained TensorFlow Lite model on the Raspberry Pi or an Android device. If you're not feeling up to training and converting your own TensorFlow Lite model, you can skip Part 1 and use my custom-trained TFLite BSR detection model (link to be added later) or use the &lt;a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip" rel="nofollow"&gt;TF Lite starter detection model&lt;/a&gt; (taken from &lt;a href="https://www.tensorflow.org/lite/models/object_detection/overview" rel="nofollow"&gt;https://www.tensorflow.org/lite/models/object_detection/overview&lt;/a&gt;) for Part 2 or Part 3.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph" class="anchor" aria-hidden="true" href="#step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Train Quantized SSD-MobileNet Model and Export Frozen TensorFlow Lite Graph&lt;/h3&gt;
&lt;p&gt;First, weâ€™ll use transfer learning to train a â€œquantizedâ€ SSD-MobileNet model. Quantized models use 8-bit integer values instead of 32-bit floating values within the neural network, allowing them to run much more efficiently on GPUs or specialized TPUs (TensorFlow Processing Units).&lt;/p&gt;
&lt;p&gt;You can also use a standard SSD-MobileNet model (V1 or V2), but it will not run quite as fast as the quantized model. Also, you will not be able to run it on the Google Coral TPU Accelerator. If youâ€™re using an SSD-MobileNet model that has already been trained, you can skip to &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1d-export-frozen-inference-graph-for-tensorflow-lite"&gt;Step 1d&lt;/a&gt; of this guide.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you get any errors during this process, please look at the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ section&lt;/a&gt; at the bottom of this guide! It gives solutions to common errors that occur.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned prevoiusly, this guide assumes you have already followed my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous TensorFlow tutorial&lt;/a&gt; and set up the Anaconda virtual environment and full directory structure needed for using the TensorFlow Object Detection API. If you've done so, you should have a folder at C:\tensorflow1\models\research\object_detection that has everything needed for training. (If you used a different base folder name than "tensorflow1", that's fine - just make sure you continue to use that name throughout this guide.)&lt;/p&gt;
&lt;p&gt;Here's what your \object_detection folder should look like:&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/object_detection_folder.png"&gt;&lt;img src="doc/object_detection_folder.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;If you don't have this folder, please go to my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous tutorial&lt;/a&gt; and work through at least Steps 1 and 2. If you'd like to train your own model to detect custom objects, you'll also need to work through Steps 3, 4, and 5. If you don't want to train your own model but want to practice the process for converting a model to TensorFlow Lite, you can download the quantized MobileNet-SSD model (see next paragraph) and then skip to &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1d-export-frozen-inference-graph-for-tensorflow-lite"&gt;Step 1d&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1a-download-and-extract-quantized-ssd-mobilenet-model" class="anchor" aria-hidden="true" href="#step-1a-download-and-extract-quantized-ssd-mobilenet-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1a. Download and extract quantized SSD-MobileNet model&lt;/h4&gt;
&lt;p&gt;Google provides several quantized object detection models in their &lt;a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"&gt;detection model zoo&lt;/a&gt;. This tutorial will use the SSD-MobileNet-V2-Quantized-COCO model. Download the model &lt;a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz" rel="nofollow"&gt;here&lt;/a&gt;. &lt;strong&gt;Note: TensorFlow Lite does NOT support RCNN models such as Faster-RCNN! It only supports SSD models.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Move the downloaded .tar.gz file to the C:\tensorflow1\models\research\object_detection folder. (Henceforth, this folder will be referred to as the â€œ\object_detectionâ€ folder.)  Unzip the .tar.gz file using a file archiver like WinZip or 7-Zip. After the file has been fully unzipped, you should have a folder called "ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03" within the \object_detection folder.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1b-configure-training" class="anchor" aria-hidden="true" href="#step-1b-configure-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1b. Configure training&lt;/h4&gt;
&lt;p&gt;If you're training your own TensorFlow Lite model, make sure the following items from my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous guide&lt;/a&gt; have been completed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Train and test images and their XML label files are placed in the \object_detection\images\train and \object_detection\images\test folders&lt;/li&gt;
&lt;li&gt;train_labels.csv and test_labels.csv have been generated and are located in the \object_detection\images folder&lt;/li&gt;
&lt;li&gt;train.record and test.record have been generated and are located in the \object_detection folder&lt;/li&gt;
&lt;li&gt;labelmap.pbtxt file has been created and is located in the \object_detection\training folder&lt;/li&gt;
&lt;li&gt;proto files in \object_detection\protos have been generated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you have any questions about these files or donâ€™t know how to generate them, &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;Steps 2, 3, 4, and 5 of my previous tutorial&lt;/a&gt; show how they are all created.&lt;/p&gt;
&lt;p&gt;Copy the ssd_mobilenet_v2_quantized_300x300_coco.config file from the \object_detection\samples\configs folder to the \object_detection\training folder. Then, open the file using a text editor.&lt;/p&gt;
&lt;p&gt;Make the following changes to the ssd_mobilenet_v2_quantized_300x300_coco.config file. Note: The paths must be entered with single forward slashes (NOT backslashes), or TensorFlow will give a file path error when trying to train the model! Also, the paths must be in double quotation marks ( " ), not single quotation marks ( ' ).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Line 9. Change num_classes to the number of different objects you want the classifier to detect. For my bird/squirrel/raccoon detector example, there are three classes, so I set num_classes: 3&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 141. Change batch_size: 24 to batch_size: 6 . The smaller batch size will prevent OOM (Out of Memory) errors during training.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 156. Change fine_tune_checkpoint to: "C:/tensorflow1/models/research/object_detection/ ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 175. Change input_path to: "C:/tensorflow1/models/research/object_detection/train.record"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 177. Change label_map_path to: "C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 181. Change num_examples to the number of images you have in the \images\test directory. For my bird/squirrel/raccoon detector example, there are 582 test images, so I set num_examples: 582.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 189. Change input_path to: "C:/tensorflow1/models/research/object_detection/test.record"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 191. Change label_map_path to: "C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt"&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Save and exit the training file after the changes have been made.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1c-run-training-in-anaconda-virtual-environment" class="anchor" aria-hidden="true" href="#step-1c-run-training-in-anaconda-virtual-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1c. Run training in Anaconda virtual environment&lt;/h4&gt;
&lt;p&gt;All that's left to do is train the model! First, move the â€œtrain.pyâ€ file from the \object_detection\legacy folder into the main \object_detection folder. (See the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ&lt;/a&gt; for why I am using the legacy train.py script rather than model_main.py for training.)&lt;/p&gt;
&lt;p&gt;Then, open a new Anaconda Prompt window by searching for â€œAnaconda Promptâ€ in the Start menu and clicking on it. Activate the â€œtensorflow1â€ virtual environment (which was set up in my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous tutorial&lt;/a&gt;) by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;activate tensorflow1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, set the PYTHONPATH environment variable by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set PYTHONPATH=C:\tensorflow1\models;C:\tensorflow1\models\research;C:\tensorflow1\models\research\slim
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, change directories to the \object_detection folder:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd C:\tensorflow1\models\research\object_detection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, train the model by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python train.py --logtostderr â€“train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_quantized_300x300_coco.config
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything was set up correctly, the model will begin training after a couple minutes of initialization.&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/training_in_progress.png"&gt;&lt;img src="doc/training_in_progress.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Allow the model to train until the loss consistently drops below 2. For my bird/squirrel/raccoon detector model, this took about 9000 steps, or 8 hours of training. (Time will vary depending on how powerful your CPU and GPU are. Please see &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/blob/master/README.md#6-run-the-training"&gt;Step 6 of my previous tutorial&lt;/a&gt; for more information on training and an explanation of how to view the progress of the training job using TensorBoard.)&lt;/p&gt;
&lt;p&gt;Once training is complete (i.e. the loss has consistently dropped below 2), press Ctrl+C to stop training. The latest checkpoint will be saved in the \object_detection\training folder, and we will use that checkpoint to export the frozen TensorFlow Lite graph. Take note of the checkpoint number of the model.ckpt file in the training folder (i.e. model.ckpt-XXXX), as it will be used later.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1d-export-frozen-inference-graph-for-tensorflow-lite" class="anchor" aria-hidden="true" href="#step-1d-export-frozen-inference-graph-for-tensorflow-lite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1d. Export frozen inference graph for TensorFlow Lite&lt;/h4&gt;
&lt;p&gt;Now that training has finished, the model can be exported for conversion to TensorFlow Lite using the export_tflite_ssd_graph.py script. First, create a folder in \object_detection called â€œTFLite_modelâ€ by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, letâ€™s set up some environment variables so the commands are easier to type out. Issue the following commands in Anaconda Prompt. (Note, the XXXX in the second command should be replaced with the highest-numbered model.ckpt file in the \object_detection\training folder.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set CONFIG_FILE=C:\\tensorflow1\models\research\object_detection\training\ssd_mobilenet_v2_quantized_300x300_coco.config
set CHECKPOINT_PATH=C:\\tensorflow1\models\research\object_detection\training\model.ckpt-XXXX
set OUTPUT_DIR=C:\\tensorflow1\models\research\object_detection\TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that those are set up, issue this command to export the model for TensorFlow Lite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python export_tflite_ssd_graph.py --pipeline_config_path=%CONFIG_FILE% --trained_checkpoint_prefix=%CHECKPOINT_PATH% --output_directory=%OUTPUT_DIR% --add_postprocessing_op=true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the command has executed, there should be two new files in the \object_detection\TFLite_model folder: tflite_graph.pb and tflite_graph.pbtxt.&lt;/p&gt;
&lt;p&gt;Thatâ€™s it! The new inference graph has been trained and exported. This inference graph's architecture and network operations are compatible with TensorFlow Lite's framework. However, the graph still needs to be converted to an actual TensorFlow Lite model. We'll do that in Step 3. First, we have to build TensorFlow from source. On to Step 2!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-build-tensorflow-from-source" class="anchor" aria-hidden="true" href="#step-2-build-tensorflow-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2. Build TensorFlow From Source&lt;/h3&gt;
&lt;p&gt;To convert the frozen graph we just exported into a model that can be used by TensorFlow Lite, it has to be run through the TensorFlow Lite Optimizing Converter (TOCO). Unfortunately, to use TOCO, we have to build TensorFlow from source on our computer. To do this, weâ€™ll create a separate Anaconda virtual environment for building TensorFlow.&lt;/p&gt;
&lt;p&gt;This part of the tutorial breaks down step-by-step how to build TensorFlow from source on your Windows PC. It follows the &lt;a href="https://www.tensorflow.org/install/source_windows" rel="nofollow"&gt;Build TensorFlow From Source on Windows&lt;/a&gt; instructions given on the official TensorFlow website, with some slight modifications.&lt;/p&gt;
&lt;p&gt;This guide will show how to build either the CPU-only version of TensorFlow or the GPU-enabled version of TensorFlow v1.13. If you would like to build a version other than TF v1.13, you can still use this guide, but check the &lt;a href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="nofollow"&gt;build configuration list&lt;/a&gt; and make sure you use the correct package versions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you are only building TensorFlow to convert a TensorFlow Lite object detection model, I recommend building the CPU-only version!&lt;/strong&gt; It takes very little computational effort to export the model, so your CPU can do it just fine without help from your GPU. If youâ€™d like to build the GPU-enabled version anyway, then you need to have the appropriate version of CUDA and cuDNN installed. &lt;a href="https://www.tensorflow.org/install/gpu#windows_setup" rel="nofollow"&gt;The TensorFlow installation guide&lt;/a&gt; explains how to install CUDA and cuDNN. Check the &lt;a href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="nofollow"&gt;build configuration list&lt;/a&gt; to see which versions of CUDA and cuDNN are compatible with which versions of TensorFlow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you get any errors during this process, please look at the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ section&lt;/a&gt; at the bottom of this guide! It gives solutions to common errors that occur.&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2a-install-msys2" class="anchor" aria-hidden="true" href="#step-2a-install-msys2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2a. Install MSYS2&lt;/h4&gt;
&lt;p&gt;MSYS2 has some binary tools needed for building TensorFlow. It also automatically converts Windows-style directory paths to Linux-style paths when using Bazel. The Bazel build wonâ€™t work without MSYS2 installed!&lt;/p&gt;
&lt;p&gt;First, install MSYS2 by following the instructions on the &lt;a href="https://www.msys2.org/" rel="nofollow"&gt;MSYS2 website&lt;/a&gt;. Download the msys2-x86_64 executable file and run it. Use the default options for installation. After installing, open MSYS2 and issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pacman -Syu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After it's completed, close the window, re-open it, and then issue the following two commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pacman -Su
pacman -S patch unzip
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/MSYS_window.png"&gt;&lt;img src="doc/MSYS_window.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;This updates MSYS2â€™s package manager and downloads the patch and unzip packages. Now, close the MSYS2 window. We'll add the MSYS2 binary to the PATH environment variable in Step 2c.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2b-install-visual-c-build-tools-2015" class="anchor" aria-hidden="true" href="#step-2b-install-visual-c-build-tools-2015"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2b. Install Visual C++ Build Tools 2015&lt;/h4&gt;
&lt;p&gt;Install Microsoft Build Tools 2015 and Microsoft Visual C++ 2015 Redistributable by visiting the &lt;a href="https://visualstudio.microsoft.com/vs/older-downloads/" rel="nofollow"&gt;Visual Studio older downloads&lt;/a&gt; page. Click the â€œRedistributables and Build Toolsâ€ dropdown at the bottom of the list.  Download and install the following two packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Build Tools 2015 Update 3&lt;/strong&gt; - Use the default installation options in the install wizard. Once you begin installing, it goes through a fairly large download, so it will take a while if you have a slow internet connection. It may give you some warnings saying build tools or redistributables have already been installed. If so, that's fine; just click through them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Visual C++ 2015 Redistributable Update 3&lt;/strong&gt; â€“ This may give you an error saying the redistributable has already been installed. If so, thatâ€™s fine.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Restart your PC after installation has finished.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2c-update-anaconda-and-create-tensorflow-build-environment" class="anchor" aria-hidden="true" href="#step-2c-update-anaconda-and-create-tensorflow-build-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2c. Update Anaconda and create tensorflow-build environment&lt;/h4&gt;
&lt;p&gt;Now that the Visual Studio tools are installed and your PC is freshly restarted, open a new Anaconda Prompt window. First, update Anaconda to make sure its package list is up to date. In the Anaconda Prompt window, issue these two commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda update -n base -c defaults conda
conda update --all
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The update process may take up to an hour, depending on how it's been since you installed or updated Anaconda. Next, create a new Anaconda virtual environment called â€œtensorflow-buildâ€. Weâ€™ll work in this environment for the rest of the build process. Create and activate the environment by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda create -n tensorflow-build pip python=3.6
conda activate tensorflow-build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the environment is activated, you should see (tensorflow-build) before the active path in the command window.&lt;/p&gt;
&lt;p&gt;&amp;lt;Maybe I should add a picture of the Anaconda window here?&amp;gt;&lt;/p&gt;
&lt;p&gt;Update pip by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m pip install --upgrade pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We'll use Anaconda's git package to download the TensorFlow repository, so install git using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c anaconda git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, add the MSYS2 binaries to this environment's PATH variable by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set PATH=%PATH%;C:\msys64\usr\bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(If MSYS2 is installed in a different location than C:\msys64, use that location instead.) Youâ€™ll have to re-issue this PATH command if you ever close and re-open the Anaconda Prompt window.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2d-download-bazel-and-python-package-dependencies" class="anchor" aria-hidden="true" href="#step-2d-download-bazel-and-python-package-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2d. Download Bazel and Python package dependencies&lt;/h4&gt;
&lt;p&gt;Next, weâ€™ll install Bazel and some other Python packages that are used for building TensorFlow. Install the necessary Python packages by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install six numpy wheel
pip install keras_applications==1.0.6 --no-deps
pip install keras_preprocessing==1.0.5 --no-deps
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then install Bazel v0.21.0 by issuing the following command. (If you are building a version of TensorFlow other than v1.13, you may need to use a different version of Bazel.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge bazel=0.21.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-step-2d-download-tensorflow-source-and-configure-build" class="anchor" aria-hidden="true" href="#step-2d-download-tensorflow-source-and-configure-build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2d. Download TensorFlow source and configure build&lt;/h4&gt;
&lt;p&gt;Time to download TensorFlowâ€™s source code from GitHub! Issue the following commands to create a new folder directly in C:\ called â€œtensorflow-buildâ€ and cd into it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir C:\tensorflow-build
cd C:\tensorflow-build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, clone the TensorFlow repository and cd into it by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/tensorflow/tensorflow.git 
cd tensorflow 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, check out the branch for TensorFlow v1.13:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout r1.13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The version you check out should match the TensorFlow version you used to train your model in &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph"&gt;Step 1&lt;/a&gt;. If you used a different version than TF v1.13, then replace "1.13" with the version you used. See the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#how-do-i-check-which-tensorflow-version-i-used-to-train-my-detection-model"&gt;FAQs section&lt;/a&gt; for instructions on how to check the TensorFlow version you used for training.&lt;/p&gt;
&lt;p&gt;Next, weâ€™ll configure the TensorFlow build using the configure.py script. From the C:\tensorflow-build\tensorflow directory, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python ./configure.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will initiate a Bazel session. As I mentioned before, you can build either the CPU-only version of TensorFlow or the GPU-enabled version of TensorFlow. If you're only using this TensorFlow build to convert your TensorFlow Lite model, &lt;strong&gt;I recommend building the CPU-only version&lt;/strong&gt;. If youâ€™d still like to build the GPU-enabled version for some other reason, then you need to have the appropriate version of CUDA and cuDNN installed.&lt;/p&gt;
&lt;p&gt;Hereâ€™s what the configuration session will look like if you are building for CPU only. Basically, press Enter to select the default option for each question. You can see the configuration session for building the GPU-enabled version in the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#bazel-configuration-session-for-building-gpu-enabled-tensorflow"&gt;FAQ section&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;You have bazel 0.21.0- (@non-git) installed. 

Please specify the location of python. [Default is C:\ProgramData\Anaconda3\envs\tensorflow-build\python.exe]: 
  
Found possible Python library paths: 

  C:\ProgramData\Anaconda3\envs\tensorflow-build\lib\site-packages 

Please input the desired Python library path to use.  Default is [C:\ProgramData\Anaconda3\envs\tensorflow-build\lib\site-packages] 

Do you wish to build TensorFlow with XLA JIT support? [y/N]: N 
No XLA JIT support will be enabled for TensorFlow. 

Do you wish to build TensorFlow with ROCm support? [y/N]: N 
No ROCm support will be enabled for TensorFlow. 
  
Do you wish to build TensorFlow with CUDA support? [y/N]: N 
No CUDA support will be enabled for TensorFlow. 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the configuration is finished, TensorFlow is ready to be bulit!&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2e-build-tensorflow-package" class="anchor" aria-hidden="true" href="#step-2e-build-tensorflow-package"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2e. Build TensorFlow package&lt;/h4&gt;
&lt;p&gt;Next, use Bazel to create the package builder for TensorFlow. To create the CPU-only version, issue the following command. The build process took about 70 minutes on my computer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If youâ€™re building the GPU-enabled version of TensorFlow, issue the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that the package builder has been created, letâ€™s use it to build the actual TensorFlow wheel file. Issue the following command (it took about 5 minutes to complete on my computer):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel-bin\tensorflow\tools\pip_package\build_pip_package C:/tmp/tensorflow_pkg 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates the wheel file and places it in C:\tmp\tensorflow_pkg.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2f-install-tensorflow-and-test-it-out" class="anchor" aria-hidden="true" href="#step-2f-install-tensorflow-and-test-it-out"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2f. Install TensorFlow and test it out!&lt;/h4&gt;
&lt;p&gt;TensorFlow is finally ready to be installed! Open File Explorer and browse to the C:\tmp\tensorflow_pkg folder. Copy the full filename of the .whl file, and paste it in the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip3 install C:/tmp/tensorflow_pkg/&amp;lt;Paste full .whl filename here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That's it! TensorFlow is installed! Let's make sure it installed correctly by opening a Python shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the shell is opened, issue these commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import tensorflow as tf
&amp;gt;&amp;gt;&amp;gt; tf.__version__
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything was installed properly, it will respond with the installed version of TensorFlow. Note: You may get some deprecation warnings after the "import tensorflow as tf" command. As long as they are warnings and not actual errors, you can ignore them! Exit the shell by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;exit()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With TensorFlow installed, we can finally convert our trained model into a TensorFlow Lite model. On to the last step: Step 3!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-3-use-toco-to-create-optimzed-tensorflow-lite-model-create-label-map-run-model" class="anchor" aria-hidden="true" href="#step-3-use-toco-to-create-optimzed-tensorflow-lite-model-create-label-map-run-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3. Use TOCO to Create Optimzed TensorFlow Lite Model, Create Label Map, Run Model&lt;/h3&gt;
&lt;p&gt;Although we've already exported a frozen graph of our detection model for TensorFlow Lite, we still need run it through the TensorFlow Lite Optimizing Converter (TOCO) before it will work with the TensorFlow Lite interpreter. TOCO converts models into an optimized FlatBuffer format that allows them to run efficiently on TensorFlow Lite. We also need to create a new label map before running the model.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-3a-create-optimized-tensorflow-lite-model" class="anchor" aria-hidden="true" href="#step-3a-create-optimized-tensorflow-lite-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3a. Create optimized TensorFlow Lite model&lt;/h4&gt;
&lt;p&gt;First, weâ€™ll run the model through TOCO to create an optimzed TensorFLow Lite model. The TOCO tool lives deep in the C:\tensorflow-build directory, and it will be run from the â€œtensorflow-buildâ€ Anaconda virtual environment that we created and used during Step 2. Meanwhile, the model we trained in Step 1 lives inside the C:\tensorflow1\models\research\object_detection\TFLite_model directory. Weâ€™ll create an environment variable called OUTPUT_DIR that points at the correct model directory to make it easier to enter the TOCO command.&lt;/p&gt;
&lt;p&gt;If you don't already have an Anaconda Prompt window open with the "tensorflow-build" environment active and working in C:\tensorflow-build, open a new Anaconda Prompt window and issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;activate tensorflow-build
cd C:\tensorflow-build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create the OUTPUT_DIR environment variable by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set OUTPUT_DIR=C:\\tensorflow1\models\research\object_detection\TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, use Bazel to run the model through the TOCO tool by issuing this command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel run --config=opt tensorflow/lite/toco:toco -- --input_file=%OUTPUT_DIR%/tflite_graph.pb --output_file=%OUTPUT_DIR%/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: If you are using a floating, non-quantized SSD model (e.g. the ssdlite_mobilenet_v2_coco model rather than the ssd_mobilenet_v2_quantized_coco model), the Bazel TOCO command must be modified slightly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel run --config=opt tensorflow/lite/toco:toco -- --input_file=$OUTPUT_DIR/tflite_graph.pb --output_file=$OUTPUT_DIR/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=FLOAT --allow_custom_ops 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you are using Linux, make sure to use the commands given in the &lt;a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md"&gt;official TensorFlow instructions here&lt;/a&gt;. I removed the ' characters from the command, because for some reason they cause errors on Windows!&lt;/p&gt;
&lt;p&gt;After the command finishes running, you should see a file called detect.tflite in the \object_detection\TFLite_model directory. This is the model that can be used with TensorFlow Lite!&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-3b-create-new-label-map" class="anchor" aria-hidden="true" href="#step-3b-create-new-label-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3b. Create new label map&lt;/h4&gt;
&lt;p&gt;For some reason, TensorFlow Lite uses a different label map format than classic TensorFlow. The classic TensorFlow label map format looks like this (you can see an example in the \object_detection\data\mscoco_label_map.pbtxt file):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;item { 
  name: "/m/01g317" 
  id: 1 
  display_name: "person" 
} 
item { 
  name: "/m/0199g" 
  id: 2 
  display_name: "bicycle" 
} 
item { 
  name: "/m/0k4j" 
  id: 3 
  display_name: "car" 
} 
item { 
  name: "/m/04_sv" 
  id: 4 
  display_name: "motorcycle" 
} 
And so on...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the label map provided with the &lt;a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip" rel="nofollow"&gt;example TensorFlow Lite object detection model&lt;/a&gt; looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;person 
bicycle 
car 
motorcycle 
And so on...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Basically, rather than explicitly stating the name and ID number for each class like the classic TensorFlow label map format does, the TensorFlow Lite format just lists each class. To stay consistent with the example provided by Google, Iâ€™m going to stick with the TensorFlow Lite label map format for this guide.&lt;/p&gt;
&lt;p&gt;Thus, we need to create a new label map that matches the TensorFlow Lite style. Open a text editor and list each class in order of their class number. Then, save the file as â€œlabelmap.txtâ€ in the TFLite_model folder. As an example, here's what the labelmap.txt file for my bird/squirrel/raccoon detector looks like:&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/labelmap_example.png"&gt;&lt;img src="doc/labelmap_example.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Now weâ€™re ready to run the model!&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-3c-run-the-tensorflow-lite-model" class="anchor" aria-hidden="true" href="#step-3c-run-the-tensorflow-lite-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3c. Run the TensorFlow Lite model!&lt;/h4&gt;
&lt;p&gt;I wrote three Python scripts to run the TensorFlow Lite object detection model on an image, video, or webcam feed: TFLite_detection_image.py, TFLite_detection_video.py, and &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_webcam.py"&gt;TFLite_detection_wecam.py&lt;/a&gt;. The scripts are based off the label_image.py example given in the &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py"&gt;TensorFlow Lite examples GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Weâ€™ll download the Python scripts directly from this repository. First, install wget for Anaconda by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c menpo wget
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once it's installed, download the scripts by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_image.py --no-check-certificate
wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_video.py --no-check-certificate
wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_webcam.py --no-check-certificate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following instructions show how to run the webcam, video, and image scripts. These instructions assume your .tflite model file and labelmap.txt file are in the â€œTFLite_modelâ€ folder in your \object_detection directory as per the instructions given in this guide.&lt;/p&gt;
&lt;p&gt;If youâ€™d like try using the sample TFLite object detection model provided by Google, simply download it &lt;a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip" rel="nofollow"&gt;here&lt;/a&gt; and unzip it into the \object_detection folder. Then, use &lt;code&gt;--modeldir=coco_ssd_mobilenet_v1_1.0_quant_2018_06_29&lt;/code&gt; rather than &lt;code&gt;--modeldir=TFLite_model&lt;/code&gt; when running the script.&lt;/p&gt;
&lt;p&gt;For more information on options that can be used while running the scripts, use the &lt;code&gt;-h&lt;/code&gt; option when calling the script. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py -h
&lt;/code&gt;&lt;/pre&gt;
&lt;h5&gt;&lt;a id="user-content-webcam" class="anchor" aria-hidden="true" href="#webcam"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Webcam&lt;/h5&gt;
&lt;p&gt;Make sure you have a USB webcam plugged into your computer. If youâ€™re on a laptop with a built-in camera, you donâ€™t need to plug in a USB webcam.&lt;/p&gt;
&lt;p&gt;From the \object_detection directory, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_webcam.py --modeldir=TFLite_model 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a few moments of initializing, a window will appear showing the webcam feed. Detected objects will have bounding boxes and labels displayed on them in real time.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-video" class="anchor" aria-hidden="true" href="#video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video&lt;/h5&gt;
&lt;p&gt;To run the video detection script, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A window will appear showing consecutive frames from the video, with each object in the frame labeled. Press 'q' to close the window and end the script. By default, the video detection script will open a video named 'test.mp4'. To open a specific video file, use the &lt;code&gt;--video&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model --video='birdy.mp4'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: Video detection will run at a slower FPS than realtime webcam detection. This is mainly because loading a frame from a video file requires more processor I/O than receiving a frame from a webcam.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-image" class="anchor" aria-hidden="true" href="#image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image&lt;/h5&gt;
&lt;p&gt;To run the image detection script, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The image will appear with all objects labeled. Press 'q' to close the image and end the script. By default, the image detection script will open an image named 'test1.jpg'. To open a specific image file, use the &lt;code&gt;--image&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model --image=squirrel.jpg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can also open an entire folder full of images and perform detection on each image. There can only be images files in the folder, or errors will occur. To specify which folder has images to perform detection on, use the &lt;code&gt;--imagedir&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model --imagedir=squirrels
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press any key (other than 'q') to advance to the next image. Do not use both the --image option and the --imagedir option when running the script, or it will throw an error.&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/squirrels!!.png"&gt;&lt;img src="doc/squirrels!!.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;If you encounter errors while running these scripts, please check the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ section&lt;/a&gt; of this guide. It has a list of common errors and their solutions. If you can successfully run the script, but your object isnâ€™t detected, it is most likely because your model isnâ€™t accurate enough. The FAQ has further discussion on how to resolve this.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-next-steps" class="anchor" aria-hidden="true" href="#next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next Steps&lt;/h3&gt;
&lt;p&gt;This concludes Part 1 of my TensorFlow Lite guide! You now have a trained TensorFlow Lite model and the scripts needed to run it on a PC.&lt;/p&gt;
&lt;p&gt;But who cares about running it on a PC? The whole reason weâ€™re using TensorFlow Lite is so we can run our models on lightweight devices that are more portable and less power-hungry than a PC!  The next two parts of my guide show how to run this TFLite model on a Raspberry Pi or an Android Device.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Links to be added when these are completed!&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part 2. How to Run TensorFlow Lite Object Detection Models on the Raspberry Pi (with optional Coral USB Accelerator)&lt;/li&gt;
&lt;li&gt;Part 3. How to Run TensorFlow Lite Object Detection Models on Android Devices&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-frequently-asked-questions-and-common-errors" class="anchor" aria-hidden="true" href="#frequently-asked-questions-and-common-errors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Frequently Asked Questions and Common Errors&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-why-does-this-guide-use-trainpy-rather-than-model_mainpy-for-training" class="anchor" aria-hidden="true" href="#why-does-this-guide-use-trainpy-rather-than-model_mainpy-for-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why does this guide use train.py rather than model_main.py for training?&lt;/h4&gt;
&lt;p&gt;This guide uses "train.py" to run training on the TFLite detection model. The train.py script is deprecated, but the model_main.py script that replaced it doesn't log training progress by default, and it requires pycocotools to be installed. Using model_main.py requires a few extra setup steps, and I want to keep this guide as simple as possible. Since there are no major differences between train.py and model_main.py that will affect training (&lt;a href="https://github.com/tensorflow/models/issues/6100"&gt;see TensorFlow Issue #6100&lt;/a&gt;), I use train.py for this guide.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-how-do-i-check-which-tensorflow-version-i-used-to-train-my-detection-model" class="anchor" aria-hidden="true" href="#how-do-i-check-which-tensorflow-version-i-used-to-train-my-detection-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How do I check which TensorFlow version I used to train my detection model?&lt;/h4&gt;
&lt;p&gt;Hereâ€™s how you can check the version of TensorFlow you used for training.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open a new Anaconda Prompt window and issue &lt;code&gt;activate tensorflow1&lt;/code&gt; (or whichever environment name you used)&lt;/li&gt;
&lt;li&gt;Open a python shell by issuing &lt;code&gt;python&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Within the Python shell, import TensorFlow by issuing &lt;code&gt;import tensorflow as tf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check the TensorFlow version by issuing &lt;code&gt;tf.__version__&lt;/code&gt; . It will respond with the version of TensorFlow. This is the version that you used for training.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-bazel-configuration-session-for-building-gpu-enabled-tensorflow" class="anchor" aria-hidden="true" href="#bazel-configuration-session-for-building-gpu-enabled-tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bazel configuration session for building GPU-enabled TensorFlow&lt;/h4&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>EdjeElectronics</author><guid isPermaLink="false">https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi</guid><pubDate>Wed, 20 Nov 2019 00:22:00 GMT</pubDate></item><item><title>ddbourgin/numpy-ml #23 in Python, Today</title><link>https://github.com/ddbourgin/numpy-ml</link><description>&lt;p&gt;&lt;i&gt;Machine learning, in numpy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-numpy-ml" class="anchor" aria-hidden="true" href="#numpy-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;numpy-ml&lt;/h1&gt;
&lt;p&gt;Ever wish you had an inefficient but somewhat legible collection of machine
learning algorithms implemented exclusively in numpy? No?&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;To see all of the available models, take a look at the &lt;a href="https://numpy-ml.readthedocs.io/" rel="nofollow"&gt;project documentation&lt;/a&gt; or see &lt;a href="https://github.com/ddbourgin/numpy-ml/blob/master/numpy_ml/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Am I missing your favorite model? Is there something that could be cleaner /
less confusing? Did I mess something up? Submit a PR! The only requirement is
that your models are written with just the &lt;a href="https://docs.python.org/3/library/" rel="nofollow"&gt;Python standard
library&lt;/a&gt; and &lt;a href="https://www.numpy.org/" rel="nofollow"&gt;NumPy&lt;/a&gt;. The
&lt;a href="https://scipy.github.io/devdocs/" rel="nofollow"&gt;SciPy library&lt;/a&gt; is also permitted under special
circumstances ;)&lt;/p&gt;
&lt;p&gt;See full contributing guidelines &lt;a href="./CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ddbourgin</author><guid isPermaLink="false">https://github.com/ddbourgin/numpy-ml</guid><pubDate>Wed, 20 Nov 2019 00:23:00 GMT</pubDate></item><item><title>NVlabs/stylegan #24 in Python, Today</title><link>https://github.com/NVlabs/stylegan</link><description>&lt;p&gt;&lt;i&gt;StyleGAN - Official TensorFlow Implementation&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-stylegan--official-tensorflow-implementation" class="anchor" aria-hidden="true" href="#stylegan--official-tensorflow-implementation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;StyleGAN â€” Official TensorFlow Implementation&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963" alt="Python 3.6" data-canonical-src="https://img.shields.io/badge/python-3.6-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/11658cad8470d233bb733d0b72dc9f85738b0c60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f74656e736f72666c6f772d312e31302d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/11658cad8470d233bb733d0b72dc9f85738b0c60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f74656e736f72666c6f772d312e31302d677265656e2e7376673f7374796c653d706c6173746963" alt="TensorFlow 1.10" data-canonical-src="https://img.shields.io/badge/tensorflow-1.10-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a5dab5f383e89d8397bd6a26b35ecafbca94277c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6375646e6e2d372e332e312d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/a5dab5f383e89d8397bd6a26b35ecafbca94277c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6375646e6e2d372e332e312d677265656e2e7376673f7374796c653d706c6173746963" alt="cuDNN 7.3.1" data-canonical-src="https://img.shields.io/badge/cudnn-7.3.1-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a94f8355ec38c4cee39dec1e250552a499c37ac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43435f42592d2d4e432d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/1a94f8355ec38c4cee39dec1e250552a499c37ac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43435f42592d2d4e432d677265656e2e7376673f7374796c653d706c6173746963" alt="License CC BY-NC" data-canonical-src="https://img.shields.io/badge/license-CC_BY--NC-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./stylegan-teaser.png"&gt;&lt;img src="./stylegan-teaser.png" alt="Teaser image" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;strong&gt;Picture:&lt;/strong&gt; &lt;em&gt;These people are not real â€“ they were produced by our generator that allows control over different aspects of the image.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the official TensorFlow implementation of the following paper:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A Style-Based Generator Architecture for Generative Adversarial Networks&lt;/strong&gt;&lt;br&gt;
Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)&lt;br&gt;
&lt;a href="http://stylegan.xyz/paper" rel="nofollow"&gt;http://stylegan.xyz/paper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;em&gt;We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For business inquiries, please contact &lt;a href="mailto:researchinquiries@nvidia.com"&gt;researchinquiries@nvidia.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For press and other inquiries, please contact Hector Marinez at &lt;a href="mailto:hmarinez@nvidia.com"&gt;hmarinez@nvidia.com&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h2&gt;
&lt;p&gt;All material related to our paper is available via the following links:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Link&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/paper" rel="nofollow"&gt;http://stylegan.xyz/paper&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Paper PDF.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/video" rel="nofollow"&gt;http://stylegan.xyz/video&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Result video.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/code" rel="nofollow"&gt;http://stylegan.xyz/code&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Source code.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;http://stylegan.xyz/ffhq&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Flickr-Faces-HQ dataset.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/drive" rel="nofollow"&gt;http://stylegan.xyz/drive&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Google Drive folder.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Additional material can be found in Google Drive folder:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Path&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/drive" rel="nofollow"&gt;StyleGAN&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Main folder.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”œÂ  &lt;a href="https://drive.google.com/open?id=1v-HkF3Ehrpon7wVIx4r5DLcko_U_V6Lt" rel="nofollow"&gt;stylegan-paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality version of the paper PDF.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”œÂ  &lt;a href="https://drive.google.com/open?id=1uzwkZHQX_9pYg1i0d1Nbe3D9xPO8-qBf" rel="nofollow"&gt;stylegan-video.mp4&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality version of the result video.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”œÂ  &lt;a href="https://drive.google.com/open?id=1-l46akONUWF6LCpDoeq63H53rD7MeiTd" rel="nofollow"&gt;images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Example images produced using our generator.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”‚Â  â”œÂ  &lt;a href="https://drive.google.com/open?id=1ToY5P4Vvf5_c3TyUizQ8fckFFoFtBvD8" rel="nofollow"&gt;representative-images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality images to be used in articles, blog posts, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”‚Â  â””Â  &lt;a href="https://drive.google.com/open?id=100DJ0QXyG89HZzB4w2Cbyf4xjNK54cQ1" rel="nofollow"&gt;100k-generated-images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;100,000 generated images for different amounts of truncation.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”‚Â  â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/open?id=14lm8VRN1pr4g_KVe6_LvyDX1PObst6d4" rel="nofollow"&gt;ffhq-1024x1024&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using Flickr-Faces-HQ dataset at 1024Ã—1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”‚Â  â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/open?id=1Vxz9fksw4kgjiHrvHkX4Hze4dyThFW6t" rel="nofollow"&gt;bedrooms-256x256&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Bedroom dataset at 256Ã—256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”‚Â  â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/open?id=1MFCvOMdLE2_mpeLPTiDw5dxc2CRuKkzS" rel="nofollow"&gt;cars-512x384&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Car dataset at 512Ã—384.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”‚Â  â€‚â€‚ â””Â  &lt;a href="https://drive.google.com/open?id=1gq-Gj3GRFiyghTPKhp8uDMA9HV_0ZFWQ" rel="nofollow"&gt;cats-256x256&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Cat dataset at 256Ã—256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”œÂ  &lt;a href="https://drive.google.com/open?id=1N8pOd_Bf8v89NGUaROdbD8-ayLPgyRRo" rel="nofollow"&gt;videos&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Example videos produced using our generator.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”‚Â  â””Â  &lt;a href="https://drive.google.com/open?id=1NFO7_vH0t98J13ckJYFd7kuaTkyeRJ86" rel="nofollow"&gt;high-quality-video-clips&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Individual segments of the result video as high-quality MP4.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â”œÂ  &lt;a href="https://drive.google.com/open?id=1u2xu7bSrWxrbUxk-dT-UvEJq8IjdmNTP" rel="nofollow"&gt;ffhq-dataset&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Raw data for the &lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;Flickr-Faces-HQ dataset&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â””Â  &lt;a href="https://drive.google.com/open?id=1MASQyN5m0voPcx7-9K0r5gObhvvPups7" rel="nofollow"&gt;networks&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Pre-trained networks as pickled instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ" rel="nofollow"&gt;stylegan-ffhq-1024x1024.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with Flickr-Faces-HQ dataset at 1024Ã—1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1MGqJl28pN4t7SAtSrPdSRJSQJqahkzUf" rel="nofollow"&gt;stylegan-celebahq-1024x1024.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with CelebA-HQ dataset at 1024Ã—1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1MOSKeGF0FJcivpBI7s63V9YHloUTORiF" rel="nofollow"&gt;stylegan-bedrooms-256x256.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Bedroom dataset at 256Ã—256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1MJ6iCfNtMIRicihwRorsM3b7mmtmK9c3" rel="nofollow"&gt;stylegan-cars-512x384.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Car dataset at 512Ã—384.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1MQywl0FNt6lHu8E_EUqnRbviagS7fbiJ" rel="nofollow"&gt;stylegan-cats-256x256.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Cat dataset at 256Ã—256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â””Â  &lt;a href="https://drive.google.com/open?id=1MvYdWCBuMfnoYGptRH-AgKLbPTsIQLhl" rel="nofollow"&gt;metrics&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Auxiliary networks for the quality and disentanglement metrics.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1MzTY44rLToO5APn8TZmfR7_ENSe5aZUn" rel="nofollow"&gt;inception_v3_features.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Standard &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; classifier that outputs a raw feature vector.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1N2-m9qszOeVC9Tq77WxsLnuWwOedQiD2" rel="nofollow"&gt;vgg16_zhang_perceptual.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Standard &lt;a href="https://arxiv.org/abs/1801.03924" rel="nofollow"&gt;LPIPS&lt;/a&gt; metric to estimate perceptual similarity.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â€‚â€‚ â”œÂ  &lt;a href="https://drive.google.com/uc?id=1Q5-AI6TwWhCVM7Muu4tBM7rp5nG_gmCX" rel="nofollow"&gt;celebahq-classifier-00-male.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Binary classifier trained to detect a single attribute of CelebA-HQ.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;â€‚â€‚ â€‚â€‚ â””Â â‹¯&lt;/td&gt;
&lt;td align="left"&gt;Please see the file listing for remaining networks.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-licenses" class="anchor" aria-hidden="true" href="#licenses"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Licenses&lt;/h2&gt;
&lt;p&gt;All material, excluding the Flickr-Faces-HQ dataset, is made available under &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" rel="nofollow"&gt;Creative Commons BY-NC 4.0&lt;/a&gt; license by NVIDIA Corporation. You can &lt;strong&gt;use, redistribute, and adapt&lt;/strong&gt; the material for &lt;strong&gt;non-commercial purposes&lt;/strong&gt;, as long as you give appropriate credit by &lt;strong&gt;citing our paper&lt;/strong&gt; and &lt;strong&gt;indicating any changes&lt;/strong&gt; that you've made.&lt;/p&gt;
&lt;p&gt;For license information regarding the FFHQ dataset, please refer to the &lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;Flickr-Faces-HQ repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;inception_v3_features.pkl&lt;/code&gt; and &lt;code&gt;inception_v3_softmax.pkl&lt;/code&gt; are derived from the pre-trained &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; network by Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. The network was originally shared under &lt;a href="https://github.com/tensorflow/models/blob/master/LICENSE"&gt;Apache 2.0&lt;/a&gt; license on the &lt;a href="https://github.com/tensorflow/models"&gt;TensorFlow Models&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vgg16.pkl&lt;/code&gt; and &lt;code&gt;vgg16_zhang_perceptual.pkl&lt;/code&gt; are derived from the pre-trained &lt;a href="https://arxiv.org/abs/1409.1556" rel="nofollow"&gt;VGG-16&lt;/a&gt; network by Karen Simonyan and Andrew Zisserman. The network was originally shared under &lt;a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow"&gt;Creative Commons BY 4.0&lt;/a&gt; license on the &lt;a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" rel="nofollow"&gt;Very Deep Convolutional Networks for Large-Scale Visual Recognition&lt;/a&gt; project page.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vgg16_zhang_perceptual.pkl&lt;/code&gt; is further derived from the pre-trained &lt;a href="https://arxiv.org/abs/1801.03924" rel="nofollow"&gt;LPIPS&lt;/a&gt; weights by Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, and Oliver Wang. The weights were originally shared under &lt;a href="https://github.com/richzhang/PerceptualSimilarity/blob/master/LICENSE"&gt;BSD 2-Clause "Simplified" License&lt;/a&gt; on the &lt;a href="https://github.com/richzhang/PerceptualSimilarity"&gt;PerceptualSimilarity&lt;/a&gt; repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-system-requirements" class="anchor" aria-hidden="true" href="#system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Both Linux and Windows are supported, but we strongly recommend Linux for performance and compatibility reasons.&lt;/li&gt;
&lt;li&gt;64-bit Python 3.6 installation. We recommend Anaconda3 with numpy 1.14.3 or newer.&lt;/li&gt;
&lt;li&gt;TensorFlow 1.10.0 or newer with GPU support.&lt;/li&gt;
&lt;li&gt;One or more high-end NVIDIA GPUs with at least 11GB of DRAM. We recommend NVIDIA DGX-1 with 8 Tesla V100 GPUs.&lt;/li&gt;
&lt;li&gt;NVIDIA driver 391.35 or newer, CUDA toolkit 9.0 or newer, cuDNN 7.3.1 or newer.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-using-pre-trained-networks" class="anchor" aria-hidden="true" href="#using-pre-trained-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pre-trained networks&lt;/h2&gt;
&lt;p&gt;A minimal example of using a pre-trained StyleGAN generator is given in &lt;a href="./pretrained_example.py"&gt;pretrained_example.py&lt;/a&gt;. When executed, the script downloads a pre-trained StyleGAN generator from Google Drive and uses it to generate an image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python pretrained_example.py
Downloading https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ .... done

Gs                              Params    OutputShape          WeightShape
---                             ---       ---                  ---
latents_in                      -         (?, 512)             -
...
images_out                      -         (?, 3, 1024, 1024)   -
---                             ---       ---                  ---
Total                           26219627

&amp;gt; ls results
example.png # https://drive.google.com/uc?id=1UDLT_zb-rof9kKH0GwiJW_bS9MoZi8oP
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A more advanced example is given in &lt;a href="./generate_figures.py"&gt;generate_figures.py&lt;/a&gt;. The script reproduces the figures from our paper in order to illustrate style mixing, noise inputs, and truncation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python generate_figures.py
results/figure02-uncurated-ffhq.png     # https://drive.google.com/uc?id=1U3r1xgcD7o-Fd0SBRpq8PXYajm7_30cu
results/figure03-style-mixing.png       # https://drive.google.com/uc?id=1U-nlMDtpnf1RcYkaFQtbh5oxnhA97hy6
results/figure04-noise-detail.png       # https://drive.google.com/uc?id=1UX3m39u_DTU6eLnEW6MqGzbwPFt2R9cG
results/figure05-noise-components.png   # https://drive.google.com/uc?id=1UQKPcvYVeWMRccGMbs2pPD9PVv1QDyp_
results/figure08-truncation-trick.png   # https://drive.google.com/uc?id=1ULea0C12zGlxdDQFNLXOWZCHi3QNfk_v
results/figure10-uncurated-bedrooms.png # https://drive.google.com/uc?id=1UEBnms1XMfj78OHj3_cx80mUf_m9DUJr
results/figure11-uncurated-cars.png     # https://drive.google.com/uc?id=1UO-4JtAs64Kun5vIj10UXqAJ1d5Ir1Ke
results/figure12-uncurated-cats.png     # https://drive.google.com/uc?id=1USnJc14prlu3QAYxstrtlfXC9sDWPA-W
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pre-trained networks are stored as standard pickle files on Google Drive:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Load pre-trained network.
url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl
with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:
    _G, _D, Gs = pickle.load(f)
    # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.
    # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.
    # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code downloads the file and unpickles it to yield 3 instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;. To generate images, you will typically want to use &lt;code&gt;Gs&lt;/code&gt; â€“ the other two networks are provided for completeness. In order for &lt;code&gt;pickle.load()&lt;/code&gt; to work, you will need to have the &lt;code&gt;dnnlib&lt;/code&gt; source directory in your PYTHONPATH and a &lt;code&gt;tf.Session&lt;/code&gt; set as default. The session can initialized by calling &lt;code&gt;dnnlib.tflib.init_tf()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There are three ways to use the pre-trained generator:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;Gs.run()&lt;/code&gt; for immediate-mode operation where the inputs and outputs are numpy arrays:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Pick latent vector.
rnd = np.random.RandomState(5)
latents = rnd.randn(1, Gs.input_shape[1])

# Generate image.
fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)
images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first argument is a batch of latent vectors of shape &lt;code&gt;[num, 512]&lt;/code&gt;. The second argument is reserved for class labels (not used by StyleGAN). The remaining keyword arguments are optional and can be used to further modify the operation (see below). The output is a batch of images, whose format is dictated by the &lt;code&gt;output_transform&lt;/code&gt; argument.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;Gs.get_output_for()&lt;/code&gt; to incorporate the generator as a part of a larger TensorFlow expression:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;latents = tf.random_normal([self.minibatch_per_gpu] + Gs_clone.input_shape[1:])
images = Gs_clone.get_output_for(latents, None, is_validation=True, randomize_noise=True)
images = tflib.convert_images_to_uint8(images)
result_expr.append(inception_clone.get_output_for(images))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code is from &lt;a href="./metrics/frechet_inception_distance.py"&gt;metrics/frechet_inception_distance.py&lt;/a&gt;. It generates a batch of random images and feeds them directly to the &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; network without having to convert the data to numpy arrays in between.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Look up &lt;code&gt;Gs.components.mapping&lt;/code&gt; and &lt;code&gt;Gs.components.synthesis&lt;/code&gt; to access individual sub-networks of the generator. Similar to &lt;code&gt;Gs&lt;/code&gt;, the sub-networks are represented as independent instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)
src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]
src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code is from &lt;a href="./generate_figures.py"&gt;generate_figures.py&lt;/a&gt;. It first transforms a batch of latent vectors into the intermediate &lt;em&gt;W&lt;/em&gt; space using the mapping network and then turns these vectors into a batch of images using the synthesis network. The &lt;code&gt;dlatents&lt;/code&gt; array stores a separate copy of the same &lt;em&gt;w&lt;/em&gt; vector for each layer of the synthesis network to facilitate style mixing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The exact details of the generator are defined in &lt;a href="./training/networks_stylegan.py"&gt;training/networks_stylegan.py&lt;/a&gt; (see &lt;code&gt;G_style&lt;/code&gt;, &lt;code&gt;G_mapping&lt;/code&gt;, and &lt;code&gt;G_synthesis&lt;/code&gt;). The following keyword arguments can be specified to modify the behavior when calling &lt;code&gt;run()&lt;/code&gt; and &lt;code&gt;get_output_for()&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;truncation_psi&lt;/code&gt; and &lt;code&gt;truncation_cutoff&lt;/code&gt; control the truncation trick that that is performed by default when using &lt;code&gt;Gs&lt;/code&gt; (Ïˆ=0.7, cutoff=8). It can be disabled by setting &lt;code&gt;truncation_psi=1&lt;/code&gt; or &lt;code&gt;is_validation=True&lt;/code&gt;, and the image quality can be further improved at the cost of variation by setting e.g. &lt;code&gt;truncation_psi=0.5&lt;/code&gt;. Note that truncation is always disabled when using the sub-networks directly. The average &lt;em&gt;w&lt;/em&gt; needed to manually perform the truncation trick can be looked up using &lt;code&gt;Gs.get_var('dlatent_avg')&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;randomize_noise&lt;/code&gt; determines whether to use re-randomize the noise inputs for each generated image (&lt;code&gt;True&lt;/code&gt;, default) or whether to use specific noise values for the entire minibatch (&lt;code&gt;False&lt;/code&gt;). The specific values can be accessed via the &lt;code&gt;tf.Variable&lt;/code&gt; instances that are found using &lt;code&gt;[var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When using the mapping network directly, you can specify &lt;code&gt;dlatent_broadcast=None&lt;/code&gt; to disable the automatic duplication of &lt;code&gt;dlatents&lt;/code&gt; over the layers of the synthesis network.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Runtime performance can be fine-tuned via &lt;code&gt;structure='fixed'&lt;/code&gt; and &lt;code&gt;dtype='float16'&lt;/code&gt;. The former disables support for progressive growing, which is not needed for a fully-trained generator, and the latter performs all computation using half-precision floating point arithmetic.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-preparing-datasets-for-training" class="anchor" aria-hidden="true" href="#preparing-datasets-for-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preparing datasets for training&lt;/h2&gt;
&lt;p&gt;The training and evaluation scripts operate on datasets stored as multi-resolution TFRecords. Each dataset is represented by a directory containing the same image data in several resolutions to enable efficient streaming. There is a separate *.tfrecords file for each resolution, and if the dataset contains labels, they are stored in a separate file as well. By default, the scripts expect to find the datasets at &lt;code&gt;datasets/&amp;lt;NAME&amp;gt;/&amp;lt;NAME&amp;gt;-&amp;lt;RESOLUTION&amp;gt;.tfrecords&lt;/code&gt;. The directory can be changed by editing &lt;a href="./config.py"&gt;config.py&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;result_dir = 'results'
data_dir = 'datasets'
cache_dir = 'cache'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain the FFHQ dataset (&lt;code&gt;datasets/ffhq&lt;/code&gt;), please refer to the &lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;Flickr-Faces-HQ repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To obtain the CelebA-HQ dataset (&lt;code&gt;datasets/celebahq&lt;/code&gt;), please refer to the &lt;a href="https://github.com/tkarras/progressive_growing_of_gans"&gt;Progressive GAN repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To obtain other datasets, including LSUN, please consult their corresponding project pages. The datasets can be converted to multi-resolution TFRecords using the provided &lt;a href="./dataset_tool.py"&gt;dataset_tool.py&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python dataset_tool.py create_lsun datasets/lsun-bedroom-full ~/lsun/bedroom_lmdb --resolution 256
&amp;gt; python dataset_tool.py create_lsun_wide datasets/lsun-car-512x384 ~/lsun/car_lmdb --width 512 --height 384
&amp;gt; python dataset_tool.py create_lsun datasets/lsun-cat-full ~/lsun/cat_lmdb --resolution 256
&amp;gt; python dataset_tool.py create_cifar10 datasets/cifar10 ~/cifar10
&amp;gt; python dataset_tool.py create_from_images datasets/custom-dataset ~/custom-images
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-training-networks" class="anchor" aria-hidden="true" href="#training-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training networks&lt;/h2&gt;
&lt;p&gt;Once the datasets are set up, you can train your own StyleGAN networks as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Edit &lt;a href="./train.py"&gt;train.py&lt;/a&gt; to specify the dataset and training configuration by uncommenting or editing specific lines.&lt;/li&gt;
&lt;li&gt;Run the training script with &lt;code&gt;python train.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The results are written to a newly created directory &lt;code&gt;results/&amp;lt;ID&amp;gt;-&amp;lt;DESCRIPTION&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The training may take several days (or weeks) to complete, depending on the configuration.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By default, &lt;code&gt;train.py&lt;/code&gt; is configured to train the highest-quality StyleGAN (configuration F in Table 1) for the FFHQ dataset at 1024Ã—1024 resolution using 8 GPUs. Please note that we have used 8 GPUs in all of our experiments. Training with fewer GPUs may not produce identical results â€“ if you wish to compare against our technique, we strongly recommend using the same number of GPUs.&lt;/p&gt;
&lt;p&gt;Expected training times for the default configuration using Tesla V100 GPUs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;GPUs&lt;/th&gt;
&lt;th align="left"&gt;1024Ã—1024&lt;/th&gt;
&lt;th align="left"&gt;512Ã—512&lt;/th&gt;
&lt;th align="left"&gt;256Ã—256&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;41 days 4 hours&lt;/td&gt;
&lt;td align="left"&gt;24 days 21 hours&lt;/td&gt;
&lt;td align="left"&gt;14 days 22 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;21 days 22 hours&lt;/td&gt;
&lt;td align="left"&gt;13 days 7 hours&lt;/td&gt;
&lt;td align="left"&gt;9 days 5 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4&lt;/td&gt;
&lt;td align="left"&gt;11 days 8 hours&lt;/td&gt;
&lt;td align="left"&gt;7 days 0 hours&lt;/td&gt;
&lt;td align="left"&gt;4 days 21 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;8&lt;/td&gt;
&lt;td align="left"&gt;6 days 14 hours&lt;/td&gt;
&lt;td align="left"&gt;4 days 10 hours&lt;/td&gt;
&lt;td align="left"&gt;3 days 8 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-evaluating-quality-and-disentanglement" class="anchor" aria-hidden="true" href="#evaluating-quality-and-disentanglement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluating quality and disentanglement&lt;/h2&gt;
&lt;p&gt;The quality and disentanglement metrics used in our paper can be evaluated using &lt;a href="./run_metrics.py"&gt;run_metrics.py&lt;/a&gt;. By default, the script will evaluate the FrÃ©chet Inception Distance (&lt;code&gt;fid50k&lt;/code&gt;) for the pre-trained FFHQ generator and write the results into a newly created directory under &lt;code&gt;results&lt;/code&gt;. The exact behavior can be changed by uncommenting or editing specific lines in &lt;a href="./run_metrics.py"&gt;run_metrics.py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Expected evaluation time and results for the pre-trained FFHQ generator using one Tesla V100 GPU:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Metric&lt;/th&gt;
&lt;th align="left"&gt;Time&lt;/th&gt;
&lt;th align="left"&gt;Result&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;fid50k&lt;/td&gt;
&lt;td align="left"&gt;16 min&lt;/td&gt;
&lt;td align="left"&gt;4.4159&lt;/td&gt;
&lt;td align="left"&gt;FrÃ©chet Inception Distance using 50,000 images.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_zfull&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;664.8854&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for full paths in &lt;em&gt;Z&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_wfull&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;233.3059&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for full paths in &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_zend&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;666.1057&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for path endpoints in &lt;em&gt;Z&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_wend&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;197.2266&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for path endpoints in &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ls&lt;/td&gt;
&lt;td align="left"&gt;10 hours&lt;/td&gt;
&lt;td align="left"&gt;z: 165.0106&lt;br&gt;w: 3.7447&lt;/td&gt;
&lt;td align="left"&gt;Linear Separability in &lt;em&gt;Z&lt;/em&gt; and &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Please note that the exact results may vary from run to run due to the non-deterministic nature of TensorFlow.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;We thank Jaakko Lehtinen, David Luebke, and Tuomas KynkÃ¤Ã¤nniemi for in-depth discussions and helpful comments; Janne Hellsten, Tero Kuosmanen, and Pekka JÃ¤nis for compute infrastructure and help with the code release.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVlabs</author><guid isPermaLink="false">https://github.com/NVlabs/stylegan</guid><pubDate>Wed, 20 Nov 2019 00:24:00 GMT</pubDate></item><item><title>catalyst-team/catalyst #25 in Python, Today</title><link>https://github.com/catalyst-team/catalyst</link><description>&lt;p&gt;&lt;i&gt;Reproducible and fast DL &amp; RL&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
&lt;p&gt;&lt;a href="https://github.com/catalyst-team/catalyst"&gt;&lt;img src="https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/pics/catalyst_logo.png" alt="Catalyst logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reproducible and fast DL &amp;amp; RL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pypi.org/project/catalyst/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c4f41e1d6a05c335a76f37cc05b25f31217bc809/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f636174616c7973742e737667" alt="Pipi version" data-canonical-src="https://img.shields.io/pypi/v/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://catalyst-team.github.io/catalyst/index.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5a2afef7a5a4afd31a003c058e51451cd67a0007/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e2e7376673f6c6162656c3d646f63732675726c3d6874747073253341253246253246707970692e6f726725324670797069253246636174616c7973742532466a736f6e2671756572793d2532342e696e666f2e76657273696f6e26636f6c6f72423d627269676874677265656e267072656669783d76" alt="Docs" data-canonical-src="https://img.shields.io/badge/dynamic/json.svg?label=docs&amp;amp;url=https%3A%2F%2Fpypi.org%2Fpypi%2Fcatalyst%2Fjson&amp;amp;query=%24.info.version&amp;amp;colorB=brightgreen&amp;amp;prefix=v" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pepy.tech/project/catalyst" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/69489501d90b81553e734386061c46aebc849507/68747470733a2f2f706570792e746563682f62616467652f636174616c797374" alt="PyPI Status" data-canonical-src="https://pepy.tech/badge/catalyst" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/catalyst-team/catalyst/graphs/contributors"&gt;&lt;img src="https://camo.githubusercontent.com/f8425658eab8a24a0033afbad274cc4750edc61f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f636174616c7973742d7465616d2f636174616c7973742e7376673f6c6f676f3d676974687562266c6f676f436f6c6f723d7768697465" alt="Github contributors" data-canonical-src="https://img.shields.io/github/contributors/catalyst-team/catalyst.svg?logo=github&amp;amp;logoColor=white" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/4dd98dd86a5776f8d32031475d75fd9bca4ce5c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f636174616c7973742d7465616d2f636174616c7973742e737667" alt="License" data-canonical-src="https://img.shields.io/github/license/catalyst-team/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.com/catalyst-team/catalyst" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5235785ad73d976a0d7cc80c54a4c09b6b979aa7/68747470733a2f2f7472617669732d63692e636f6d2f636174616c7973742d7465616d2f636174616c7973742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/catalyst-team/catalyst.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://t.me/catalyst_team" rel="nofollow"&gt;&lt;img src="./pics/telegram.svg" alt="Telegram" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/catalyst-team/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1c7fa92782c1c4bbe3ddf337253b405382bc0cd3/68747470733a2f2f6261646765732e6769747465722e696d2f636174616c7973742d7465616d2f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/catalyst-team/community.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opendatascience.slack.com/messages/CGK4KQBHD" rel="nofollow"&gt;&lt;img src="./pics/slack.svg" alt="Slack" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.patreon.com/catalyst_team" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/third_party_pics/patreon.png" alt="Donate" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;High-level utils for PyTorch DL &amp;amp; RL research.
It was developed with a focus on reproducibility,
fast experimentation and code/ideas reusing.
Being able to research/develop something new,
rather than write another regular train loop.&lt;/p&gt;
&lt;p&gt;Break the cycle - use the Catalyst!&lt;/p&gt;
&lt;hr&gt;
&lt;h4&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h4&gt;
&lt;p&gt;Common installation:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -U catalyst&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;More specific with additional requirements:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install catalyst[rl] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; installs DL+RL based catalyst&lt;/span&gt;
pip install catalyst[contrib] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; installs DL+contrib based catalyst&lt;/span&gt;
pip install catalyst[all] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; installs everything. Very convenient to deploy on a new server&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Catalyst is compatible with: Python 3.6+. PyTorch 1.0.0+.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-docs-and-examples" class="anchor" aria-hidden="true" href="#docs-and-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docs and examples&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Detailed &lt;a href="./examples/notebooks/classification-tutorial.ipynb"&gt;classification tutorial&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/catalyst-team/catalyst/blob/master/examples/notebooks/classification-tutorial.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Advanced &lt;a href="./examples/notebooks/segmentation-tutorial.ipynb"&gt;segmentation tutorial&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/catalyst-team/catalyst/blob/master/examples/notebooks/segmentation-tutorial.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Comprehensive &lt;a href="https://github.com/catalyst-team/classification"&gt;classification pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Binary and semantic &lt;a href="https://github.com/catalyst-team/segmentation"&gt;segmentation pipeline&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API documentation and an overview of the library can be found here
&lt;a href="https://catalyst-team.github.io/catalyst/index.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5a2afef7a5a4afd31a003c058e51451cd67a0007/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e2e7376673f6c6162656c3d646f63732675726c3d6874747073253341253246253246707970692e6f726725324670797069253246636174616c7973742532466a736f6e2671756572793d2532342e696e666f2e76657273696f6e26636f6c6f72423d627269676874677265656e267072656669783d76" alt="Docs" data-canonical-src="https://img.shields.io/badge/dynamic/json.svg?label=docs&amp;amp;url=https%3A%2F%2Fpypi.org%2Fpypi%2Fcatalyst%2Fjson&amp;amp;query=%24.info.version&amp;amp;colorB=brightgreen&amp;amp;prefix=v" style="max-width:100%;"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;strong&gt;&lt;a href="examples"&gt;examples folder&lt;/a&gt;&lt;/strong&gt;
of the repository, you can find advanced tutorials and Catalyst best practices.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-blog" class="anchor" aria-hidden="true" href="#blog"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Blog&lt;/h5&gt;
&lt;p&gt;To learn more about Catalyst internals and to be aware of the most important features, you can read &lt;strong&gt;&lt;a href="https://github.com/catalyst-team/catalyst-info"&gt;Catalyst-info&lt;/a&gt;&lt;/strong&gt;, our blog where we regularly write facts about the framework.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-awesome-list-of-catalyst-powered-repositories" class="anchor" aria-hidden="true" href="#awesome-list-of-catalyst-powered-repositories"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome list of Catalyst-powered repositories&lt;/h5&gt;
&lt;p&gt;We supervise the &lt;strong&gt;&lt;a href="https://github.com/catalyst-team/awesome-catalyst-list"&gt;Awesome Catalyst list&lt;/a&gt;&lt;/strong&gt;. You can make a PR with your project to the list.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-releases" class="anchor" aria-hidden="true" href="#releases"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Releases&lt;/h5&gt;
&lt;p&gt;We release a major release once a month with a name like &lt;code&gt;YY.MM&lt;/code&gt;.
And micro-releases with hotfixes and framework improvements in the format &lt;code&gt;YY.MM.#&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can view the changelog on the &lt;strong&gt;&lt;a href="https://github.com/catalyst-team/catalyst/releases"&gt;GitHub Releases&lt;/a&gt;&lt;/strong&gt; page.&lt;/p&gt;
&lt;p&gt;Current version: &lt;a href="https://pypi.org/project/catalyst/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c4f41e1d6a05c335a76f37cc05b25f31217bc809/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f636174616c7973742e737667" alt="Pipi version" data-canonical-src="https://img.shields.io/pypi/v/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h2&gt;
&lt;p&gt;Catalyst helps you write compact
but full-featured DL &amp;amp; RL pipelines in a few lines of code.
You get a training loop with metrics, early-stopping, model checkpointing
and other features without the boilerplate.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Universal train/inference loop.&lt;/li&gt;
&lt;li&gt;Configuration files for model/data hyperparameters.&lt;/li&gt;
&lt;li&gt;Reproducibility â€“ all source code and environment variables will be saved.&lt;/li&gt;
&lt;li&gt;Callbacks â€“ reusable train/inference pipeline parts.&lt;/li&gt;
&lt;li&gt;Training stages support.&lt;/li&gt;
&lt;li&gt;Easy customization.&lt;/li&gt;
&lt;li&gt;PyTorch best practices (SWA, AdamW, Ranger optimizer, OneCycleLRWithWarmup, FP16 and more).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-structure" class="anchor" aria-hidden="true" href="#structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DL&lt;/strong&gt; â€“ runner for training and inference,
all of the classic machine learning and computer vision metrics
and a variety of callbacks for training, validation
and inference of neural networks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RL&lt;/strong&gt; â€“ scalable Reinforcement Learning,
on-policy &amp;amp; off-policy algorithms and their improvements
with distributed training support.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;contrib&lt;/strong&gt; - additional modules contributed by Catalyst users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;data&lt;/strong&gt; - useful tools and scripts for data processing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-30-seconds-with-catalyst" class="anchor" aria-hidden="true" href="#getting-started-30-seconds-with-catalyst"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started: 30 seconds with Catalyst&lt;/h2&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; torch
&lt;span class="pl-k"&gt;from&lt;/span&gt; catalyst.dl &lt;span class="pl-k"&gt;import&lt;/span&gt; SupervisedRunner

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; experiment setup&lt;/span&gt;
logdir &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;./logdir&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
num_epochs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;42&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; data&lt;/span&gt;
loaders &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;train&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;...&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;valid&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;...&lt;/span&gt;}

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; model, criterion, optimizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; Net()
criterion &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.nn.CrossEntropyLoss()
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.optim.Adam(model.parameters())
scheduler &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; model runner&lt;/span&gt;
runner &lt;span class="pl-k"&gt;=&lt;/span&gt; SupervisedRunner()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; model training&lt;/span&gt;
runner.train(
    &lt;span class="pl-v"&gt;model&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;model,
    &lt;span class="pl-v"&gt;criterion&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;criterion,
    &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;optimizer,
    &lt;span class="pl-v"&gt;scheduler&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;scheduler,
    &lt;span class="pl-v"&gt;loaders&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;loaders,
    &lt;span class="pl-v"&gt;logdir&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;logdir,
    &lt;span class="pl-v"&gt;num_epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_epochs,
    &lt;span class="pl-v"&gt;verbose&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For Catalyst.RL introduction, please follow &lt;a href="https://github.com/catalyst-team/catalyst/tree/master/examples/rl_gym"&gt;OpenAI Gym example&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;p&gt;Catalyst has its own &lt;a href="https://hub.docker.com/r/catalystteam/catalyst/tags" rel="nofollow"&gt;DockerHub page&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}&lt;/code&gt; â€“ simple image with Catalyst&lt;/li&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}-fp16&lt;/code&gt; â€“ Catalyst with FP16&lt;/li&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}-dev&lt;/code&gt; â€“ Catalyst for development with all the requirements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}-dev-fp16&lt;/code&gt; â€“ Catalyst for development with FP16&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://hub.docker.com/r/catalystteam/catalyst/tags" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2bd63deb2f7eaab1293d2da52ff8e4a5d026cbee/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f636174616c7973747465616d2f636174616c797374" alt="Docker Pulls" data-canonical-src="https://img.shields.io/docker/pulls/catalystteam/catalyst" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To build a docker from the sources and get more information and examples,
please visit &lt;a href="docker"&gt;docker folder&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guide" class="anchor" aria-hidden="true" href="#contribution-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guide&lt;/h2&gt;
&lt;p&gt;We appreciate all contributions.
If you are planning to contribute back bug-fixes,
please do so without any further discussion.
If you plan to contribute new features, utility functions or extensions,
please first open an issue and discuss the feature with us.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please see the &lt;a href="CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; for more information.&lt;/li&gt;
&lt;li&gt;By participating in this project, you agree to abide by its &lt;a href="CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.patreon.com/catalyst_team" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3d9b27bdf72d7e5407fbad6f9240f6cadc98a7a5/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e2e706e67" alt="Donate" data-canonical-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the Apache License, Version 2.0 see the &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file for details
&lt;a href="LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/4dd98dd86a5776f8d32031475d75fd9bca4ce5c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f636174616c7973742d7465616d2f636174616c7973742e737667" alt="License" data-canonical-src="https://img.shields.io/github/license/catalyst-team/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;Please use this bibtex if you want to cite this repository in your publications:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{catalyst,
    author = {Kolesnikov, Sergey},
    title = {Reproducible and fast DL &amp;amp; RL.},
    year = {2018},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/catalyst-team/catalyst}},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>catalyst-team</author><guid isPermaLink="false">https://github.com/catalyst-team/catalyst</guid><pubDate>Wed, 20 Nov 2019 00:25:00 GMT</pubDate></item></channel></rss>