<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Python, Today</title><link>https://github.com/trending/python?since=daily</link><description>The top repositories on GitHub for python, measured daily</description><pubDate>Wed, 20 Nov 2019 01:08:48 GMT</pubDate><lastBuildDate>Wed, 20 Nov 2019 01:08:48 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>dragen1860/Deep-Learning-with-TensorFlow-book #1 in Python, Today</title><link>https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book</link><description>&lt;p&gt;&lt;i&gt;深度学习开源书，基于TensorFlow 2.0实战。Open source Deep Learning book, based on TensorFlow 2.0 framework.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-20深度学习开源书" class="anchor" aria-hidden="true" href="#tensorflow-20深度学习开源书"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 2.0深度学习开源书&lt;/h1&gt;
&lt;p&gt;基于TensorFlow 2.0正式版！！！&lt;/p&gt;
&lt;p&gt;包含电子书，配套源代码等，时间仓促，源代码还没有整理完全~~&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;本库在Github趋势日榜单全球排名第1！&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;本库被“机器之心”，“量子位”等媒体报导！&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;主页上方有个“Clone or Download”绿色按钮，下载整个仓库即可。之所以显示在线打不开是因为Github在国外，连接不稳定就会提示打不开。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/1.jpg"&gt;&lt;img src="assets/1.jpg" align="center" width="600" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/2.png"&gt;&lt;img src="assets/2.png" align="center" width="600" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提交错误或者修改等反馈意见，请在Github Issues页面提交：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book/issues"&gt;https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book/issues&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TensorFlow 2.0 实战案例：
&lt;a href="https://github.com/dragen1860/TensorFlow-2.x-Tutorials"&gt;https://github.com/dragen1860/TensorFlow-2.x-Tutorials&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;联系邮箱(一般问题建议Github issues交流)：liangqu.long AT gmail.com&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用本书本的任何内容时(仅限个人的非商业用途)，请注明作者和Github链接&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-介绍短视频" class="anchor" aria-hidden="true" href="#介绍短视频"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;介绍短视频&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/av75331861?from=search&amp;amp;seid=15021582016949033280" rel="nofollow"&gt;https://www.bilibili.com/video/av75331861?from=search&amp;amp;seid=15021582016949033280&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-目录" class="anchor" aria-hidden="true" href="#目录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/0.4.目录-双排-1.jpg"&gt;&lt;img src="assets/0.4.目录-双排-1.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/0.4.目录-双排-2.jpg"&gt;&lt;img src="assets/0.4.目录-双排-2.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="assets/0.4.目录-双排-3.jpg"&gt;&lt;img src="assets/0.4.目录-双排-3.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-初学者交流qq群" class="anchor" aria-hidden="true" href="#初学者交流qq群"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;初学者交流QQ群&lt;/h1&gt;
&lt;p&gt;人工智能101学院：295208768&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-配套视频课程" class="anchor" aria-hidden="true" href="#配套视频课程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;配套视频课程&lt;/h1&gt;
&lt;p&gt;收费，适合零基础、希望快速入门AI的朋友，提供答疑等全方位服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;深度学习与TensorFlow入门实战
&lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=9e74eb6f891d47cfaa6f00b5cb5f617c" rel="nofollow"&gt;https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1209092816&amp;amp;_trace_c_p_k2_=9e74eb6f891d47cfaa6f00b5cb5f617c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;深度学习与PyTorch入门实战
&lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=8d1b10e04bd34d69855bb71da65b0549" rel="nofollow"&gt;https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=8d1b10e04bd34d69855bb71da65b0549&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dragen1860</author><guid isPermaLink="false">https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book</guid><pubDate>Wed, 20 Nov 2019 00:01:00 GMT</pubDate></item><item><title>zhaoolee/ChromeAppHeroes #2 in Python, Today</title><link>https://github.com/zhaoolee/ChromeAppHeroes</link><description>&lt;p&gt;&lt;i&gt;🌈谷粒-Chrome插件英雄榜, 为优秀的Chrome插件写一本中文说明书, 让Chrome插件英雄们造福人类~  ChromePluginHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/readme-en.html" rel="nofollow"&gt;English&lt;/a&gt; | &lt;a href="https://zhaoolee.gitbooks.io/chrome/content/" rel="nofollow"&gt;中文简体&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/996icu/996.ICU/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/41215df7ff78cefe41536bf897fe1c7e55b10bd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d416e74692532303939362d626c75652e737667" alt="LICENSE" data-canonical-src="https://img.shields.io/badge/license-Anti%20996-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://996.icu" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/13ac320a9a774e316fe72ffb1eaacf09b01b59a3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c696e6b2d3939362e6963752d7265642e737667" alt="996.icu" data-canonical-src="https://img.shields.io/badge/link-996.icu-red.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-谷粒-chrome插件英雄榜" class="anchor" aria-hidden="true" href="#谷粒-chrome插件英雄榜"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;谷粒-Chrome插件英雄榜&lt;/h1&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="rainbow" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f308.png"&gt;🌈&lt;/g-emoji&gt;谷粒-Chrome插件英雄榜, 为优秀的Chrome插件写一本中文说明书, 让Chrome插件英雄们造福人类~
ChromeAppHeroes, Write a Chinese manual for the excellent Chrome plugin, let the Chrome plugin heroes benefit the human~&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/5ecd2856f287477c89c20efb7de11a9b.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/5ecd2856f287477c89c20efb7de11a9b.png" alt="谷粒VI设计.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;感谢&lt;a href="https://github.com/LuoJiangYong"&gt;老罗巴扎嘿&lt;/a&gt;为本项目设计的新的Logo | &lt;a href="https://zhaoolee.gitbooks.io/chrome/content/gu-li-qu-yi.html" rel="nofollow"&gt;谷粒文化(老罗巴扎嘿语录)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-相关项目推广-用chrome学编程" class="anchor" aria-hidden="true" href="#相关项目推广-用chrome学编程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;相关项目推广: &lt;a href="https://github.com/zhaoolee/ProgrammingWithChrome"&gt;用Chrome学编程&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;《用Chrome学编程(如何用Chrome优雅装B)》, 用Gif图展示Chrome的骚操作, 充分挖掘Chrome的编程潜力! &lt;a href="https://github.com/zhaoolee/ProgrammingWithChrome"&gt;https://github.com/zhaoolee/ProgrammingWithChrome&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="https://github.com/996icu/996.ICU/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/41215df7ff78cefe41536bf897fe1c7e55b10bd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d416e74692532303939362d626c75652e737667" alt="LICENSE" data-canonical-src="https://img.shields.io/badge/license-Anti%20996-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://996.icu" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/13ac320a9a774e316fe72ffb1eaacf09b01b59a3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c696e6b2d3939362e6963752d7265642e737667" alt="996.icu" data-canonical-src="https://img.shields.io/badge/link-996.icu-red.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/1f62c412c50e5397395878c4da31205080db55ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/issues/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/eae70f04ac75459320f0ec7397f12bded49476bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616f6f6c65652f4368726f6d654170704865726f65732e7376673f7374796c653d706f706f75742d737175617265" alt="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" data-canonical-src="https://img.shields.io/github/stars/zhaoolee/ChromeAppHeroes.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-目录点击以下标题-可以进入文章页" class="anchor" aria-hidden="true" href="#目录点击以下标题-可以进入文章页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目录(点击以下标题, 可以进入文章页~)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/060_tabagotchi.html" rel="nofollow"&gt;060《Tabagotchi》为减缓全球变暖做出贡献&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/059_page_speed_insight_and_check_list.html" rel="nofollow"&gt;059《PageSpeed Insight and CheckList》为网页优化提供建议和量化指标&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/058_ip_address.html" rel="nofollow"&gt;058《IP-Address》快速查看当前设备IP&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/057_webp_save_as_png.html" rel="nofollow"&gt;057《图片另存为JPG/PNG/WebP》让WebP图片下载为PNG格式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/056_search.html" rel="nofollow"&gt;056《Search》为Chrome设置搜索引擎关键词&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/055_keylines.html" rel="nofollow"&gt;055《Keylines》为网页元素添加随机描边颜色 &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/054_er_xiang_yi_tu_sou_tu.html" rel="nofollow"&gt;054《二箱 以图搜图》让你在搜图方面随心所欲（为所欲为）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/053_shu_biao_dian_ji_te_xiao.html" rel="nofollow"&gt;053《鼠标点击特效 (๑•́ ∀ •̀๑)》为鼠标点击添加有趣的特效&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/052_site_palette.html" rel="nofollow"&gt;052《Site Palette》自动提取网站配色&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/051_custom_cursor_for_chrome.html" rel="nofollow"&gt;051《Custom Cursor for Chrome™》为Chrome换上可爱初音光标&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/050_google_results_previewer.html" rel="nofollow"&gt;050《Google Results Previewer》无点击查看谷歌搜索结果&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/049_web_server_for_chrome.html" rel="nofollow"&gt;049《Web Server for Chrome》搭建本地Web服务器, 实现局域网共享文件夹&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/048_words_discoverer.html" rel="nofollow"&gt;048《Words Discoverer》高亮标注单词,提升你的词汇量&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/047_go_to_tab.html" rel="nofollow"&gt;047《Go to Tab》快速跳转到打开的网页&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/046_whatfont.html" rel="nofollow"&gt;046《WhatFont》字体爱好者优雅查看网页字体&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/045_restlet_client.html" rel="nofollow"&gt;045《Restlet Client》优秀的Api测试工具&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/044_gu_ge_fang_wen_zhu_shou.html" rel="nofollow"&gt;044《谷歌访问助手》访问Chrome商店 Gmail 谷歌搜索&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/043_dream_afar_new_tab.html" rel="nofollow"&gt;043《Dream Afar New Tab》探索世界的新方式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/042_edge.html" rel="nofollow"&gt;042 在Edge中安装Chrome扩展程序&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/041_copy_all_urls.html" rel="nofollow"&gt;041《Copy All Urls》优雅地保存-开启多个标签页&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/040_gitzip_for_github.html" rel="nofollow"&gt;040《GitZip for github》从Github批量下载表情包&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/039_simplify_gmail.html" rel="nofollow"&gt;039《Simplify Gmail》让网页版Gmail更清爽&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/038_alexa_traffic_rank.html" rel="nofollow"&gt;038《Alexa Traffic Rank》一键查看网站全球排名&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/037_saladict.html" rel="nofollow"&gt;037《Saladict》谷歌!有道!我全都要! 聚合词典, 并行翻译&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/036_screen_shader.html" rel="nofollow"&gt;036《Screen Shader》把网页调成暖色，你的眼睛会感谢你&lt;g-emoji class="g-emoji" alias="pray" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png"&gt;🙏&lt;/g-emoji&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/035_print_friendly_and_pdf.html" rel="nofollow"&gt;035《Print Friendly &amp;amp; PDF》让你拥有最佳的打印阅读体验&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/034_astro_bot.html" rel="nofollow"&gt;034《Astro Bot》用新标签页刷编程题&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/033_yi_ye.html" rel="nofollow"&gt;033《一叶》在任意网页开启实时弹幕 聊天窗口 留言板&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/032_smallpdf.html" rel="nofollow"&gt;032《Smallpdf》简单好用的线上PDF工具&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/031_onetab.html" rel="nofollow"&gt;031《OneTab》把多个Tab转换为一个列表&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/030_jue_jin.html" rel="nofollow"&gt;030《掘金》相信优质技术内容的力量&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/029_simread.html" rel="nofollow"&gt;029 《SimpRead》为任意网页开启阅读模式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/028_adblock.html" rel="nofollow"&gt;028《AdBlock》Adblock自定义屏蔽简书广告&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/027_text.html" rel="nofollow"&gt;027《Text》来自Chrome实验室的跨平台记事本&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/026_quickey_launcher.html" rel="nofollow"&gt;026《Quickey Launcher》打开网站只需一键&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/025_console.html" rel="nofollow"&gt;025《Console》Chrome自带好用的计算器&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/024_dark_reader.html" rel="nofollow"&gt;024《Dark Reader》为任意网站启用夜间模式&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/023_fireshot.html" rel="nofollow"&gt;023《FireShot》一键滚动截屏整个网页&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/022kuo_zhan_guan_li_qi.html" rel="nofollow"&gt;022《扩展管理器》管理你的Chrome扩展&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/021_bi_li_bi_li_zhu_shou.html" rel="nofollow"&gt;021《哔哩哔哩助手》助你快速成为B站老司机&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/020_boxel_rebound.html" rel="nofollow"&gt;020《Boxel Rebound》“嗨到中毒”的弹跳小方块(附自制赛道分享方法)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/019_mega.html" rel="nofollow"&gt;019《MEGA》网盘可以良心到什么程度? 试试MEGA吧!&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/018_enhanced_github.html" rel="nofollow"&gt;018《Enhanced Github》从“冰柜”到“冰棍儿”,下载Github单个文件&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/017_xin_lang_wei_bo_tu_chuang.html" rel="nofollow"&gt;017《新浪微博图床》本地Markdown编写更流畅, 新浪微博图床来帮忙&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/016_jie_chu_b_zhan_qu_yu_xian_zhi.html" rel="nofollow"&gt;016《解除B站区域限制》查看进击的巨人第三季&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/015_xpath_helper.html" rel="nofollow"&gt;015 《XPath Helper》完成Bing每日壁纸的小爬虫&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/014_chao_ji_ma_li_ao_you_xi.html" rel="nofollow"&gt;014《超级马里奥游戏》Chrome变身小霸王&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/013_quick_qr.html" rel="nofollow"&gt;013《Quick QR》用二维码实现云粘贴&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/012_ourstickys.html" rel="nofollow"&gt;012《OurStickys》Chrome特色网页便签纸&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/011_whatruns.html" rel="nofollow"&gt;011 《whatruns》一键分析网站技术栈&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/010_speedtest.html" rel="nofollow"&gt;010《speedtest》网络测速插件speedtest&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/009_vimium.html" rel="nofollow"&gt;009《vimium》Chrome与vim双神器融合&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/008_chrome_cleaner_pro.html" rel="nofollow"&gt;008《Chrome Cleaner Pro》为Chrome加速&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/007_loom.html" rel="nofollow"&gt;007《loom》 Chrome翻录网页视频神器&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/006_similarsites.html" rel="nofollow"&gt;006《SimilarSites》 一键查找姊妹网站 SimilarSites&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/005_video_speed_controller.html" rel="nofollow"&gt;005《Video Speed Controller》 刷课（刷剧）神器！给网页视频加个速(最快可达16倍!)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/004_tampermonkey.html" rel="nofollow"&gt;004《Tampermonkey》 油猴子! 给浏览器开个挂&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/003_secure_shell_app.html" rel="nofollow"&gt;003《Secure Shell App》 Chrome中开启ssh一种什么体验&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/002_chrono.html" rel="nofollow"&gt;002《chrono》 让Chrome下载资源更容易&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/001_markdown_here.html" rel="nofollow"&gt;001《markdown-here》 Markdown一键转换到"富文本格式"&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-开源插件推广作者自荐" class="anchor" aria-hidden="true" href="#开源插件推广作者自荐"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;开源插件推广(作者自荐)&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;作者主页&lt;/th&gt;
&lt;th&gt;开源信息&lt;/th&gt;
&lt;th&gt;简介&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/the-fucking-github/agajobpbaphiohkbkjigcalebbfmofdo" rel="nofollow"&gt;The Fucking Github&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lvxianchao"&gt;lvxianchao&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lvxianchao/the-fucking-github"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;很方便地查看、整理、搜索你已经 Star 过的项目和搜索 Github 上的项目。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/hitup/eiokaohkigpbonodjcbjpecbnccijkjb" rel="nofollow"&gt;HitUP&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/wonderbeyond"&gt;wonderbeyond&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/wonderbeyond/HitUP"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;利用 New Tab “空白页” 助您保持对流行技术趋势的跟进，附带其它福利。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/gitako-github-file-tree/giljefjcheohhamkjphiebfjnlphnokk" rel="nofollow"&gt;Gitako - Github file tree&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/EnixCoda"&gt;EnixCoda&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/EnixCoda/Gitako"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;功能上类似于大名鼎鼎的 Octotree ，但是用了更现代化的前端工具，性能好很多。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://chrome.google.com/webstore/detail/githuber/janmcneaglgklfljjcpihkkomeghljnf" rel="nofollow"&gt;GITHUBER&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/zhuowenli"&gt;zhuowenli&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/zhuowenli/githuber"&gt;Github仓库地址&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;这是一个帮助 GitHub 开发者每日发现优质内容的 Chrome 主页拓展。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/60c92f0de3d44bb7a612d08e2e1f3d18.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/60c92f0de3d44bb7a612d08e2e1f3d18.png" alt="造福人类.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-咦微信打赏" class="anchor" aria-hidden="true" href="#咦微信打赏"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;咦?(微信打赏)&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c4fdea49e11241e392d6bcaa33855897.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c4fdea49e11241e392d6bcaa33855897.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;赞赏金额&lt;/th&gt;
&lt;th&gt;赞赏者(微信名)&lt;/th&gt;
&lt;th&gt;赞赏时间&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;20.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年8月2日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年7月11日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12.34&lt;/td&gt;
&lt;td&gt;张明辉&lt;/td&gt;
&lt;td&gt;2019年8月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;六小登登&lt;/td&gt;
&lt;td&gt;2019年9月5日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;云淡风晴&lt;/td&gt;
&lt;td&gt;2019年7月24日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;金三古月&lt;/td&gt;
&lt;td&gt;2019年6月2日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;Azuno&lt;/td&gt;
&lt;td&gt;2019年6月1日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.00&lt;/td&gt;
&lt;td&gt;邦妥&lt;/td&gt;
&lt;td&gt;2019年5月22日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;enjoy life&lt;/td&gt;
&lt;td&gt;2019年9月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;L__hoo原&lt;/td&gt;
&lt;td&gt;2019年9月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;梦想旅程(公众号:苏生不惑)&lt;/td&gt;
&lt;td&gt;2019年9月14日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;1111&lt;/td&gt;
&lt;td&gt;2019年7月27日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;那都不重要&lt;/td&gt;
&lt;td&gt;2019年5月19日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;Lismg&lt;/td&gt;
&lt;td&gt;2019年6月5日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.00&lt;/td&gt;
&lt;td&gt;small胖&lt;/td&gt;
&lt;td&gt;2019年7月9日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.00&lt;/td&gt;
&lt;td&gt;良辰美&lt;/td&gt;
&lt;td&gt;2019年7月20日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.00&lt;/td&gt;
&lt;td&gt;@Coolstar&lt;/td&gt;
&lt;td&gt;2019年7月6日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年9月26日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;夏天的小虫子&lt;/td&gt;
&lt;td&gt;2019年9月23日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年7月26日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;2019年7月12日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年6月13日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Walter Wu&lt;/td&gt;
&lt;td&gt;2019年6月1日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Joseph&lt;/td&gt;
&lt;td&gt;2019年4月24日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年4月12日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;于云鹏Edward&lt;/td&gt;
&lt;td&gt;2019年4月12日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;黄金星&lt;/td&gt;
&lt;td&gt;2019年4月11日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;Cloud 9&lt;/td&gt;
&lt;td&gt;2019年4月5日&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.20&lt;/td&gt;
&lt;td&gt;(未留姓名)&lt;/td&gt;
&lt;td&gt;2019年7月25日&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;感谢以上赞赏者对本开源项目的支持[手动滑稽]&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-060tabagotchi为减缓全球变暖做出贡献" class="anchor" aria-hidden="true" href="#060tabagotchi为减缓全球变暖做出贡献"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/060_tabagotchi.html" rel="nofollow"&gt;060《Tabagotchi》为减缓全球变暖做出贡献&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63478935-7b1f7400-c4be-11e9-8679-5f4a6a56c89c.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63478935-7b1f7400-c4be-11e9-8679-5f4a6a56c89c.gif" alt="tabagotchi" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tabagotchi扩展以一种有趣的方式, 提醒我们减少标签页数量, 减少了计算机产生的热量, 为阻止全球变暖做出了贡献~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-059pagespeed-insight-and-checklist为网页优化提供建议和量化指标" class="anchor" aria-hidden="true" href="#059pagespeed-insight-and-checklist为网页优化提供建议和量化指标"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/059_page_speed_insight_and_check_list.html" rel="nofollow"&gt;059《PageSpeed Insight and CheckList》为网页优化提供建议和量化指标&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63309328-f818e500-c328-11e9-8f1a-68fed13a4015.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63309328-f818e500-c328-11e9-8f1a-68fed13a4015.gif" alt="pag_speed" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63309327-f7804e80-c328-11e9-8eab-9055db8a5d2c.png"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63309327-f7804e80-c328-11e9-8eab-9055db8a5d2c.png" alt="001" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PageSpeed Insight and CheckList 和 Google Page Speed 结合使用, 能够为网页质量评分,量化网页优化的效果,也为优化网页指明了方向,对前端工程师而言,是非常重要的工具&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-058ip-address快速查看当前设备ip" class="anchor" aria-hidden="true" href="#058ip-address快速查看当前设备ip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/058_ip_address.html" rel="nofollow"&gt;058《IP-Address》快速查看当前设备IP&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63222725-ee369b00-c1dd-11e9-986e-cbc002168db8.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63222725-ee369b00-c1dd-11e9-986e-cbc002168db8.gif" alt="ip_address" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;获取当前设备的IP地址,对于开发者而言,是一个经常遇到的问题,而《IP-Address》这款简洁小巧的软件, 能满足我们的需求&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-057图片另存为jpgpngwebp让webp图片下载为png格式md" class="anchor" aria-hidden="true" href="#057图片另存为jpgpngwebp让webp图片下载为png格式md"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/057_webp_save_as_png.html" rel="nofollow"&gt;057《图片另存为JPG/PNG/WebP》让WebP图片下载为PNG格式.md&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/63221240-ce48ac80-c1c8-11e9-9860-376fedc0845e.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/63221240-ce48ac80-c1c8-11e9-9860-376fedc0845e.gif" alt="save_as_png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;WebP是非常先进的格式, 但由于Photoshop这类元老级图像编辑软件不支持, 我们只能将图片为png格式,再进行编辑, 先进技术改变世界, 需要一个过程, 而在过程中提供一个折中的方案(把WebP装换为png, 再将png图片装换为WebP), 也是一件有价值的事~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-056search为chrome设置搜索引擎关键词" class="anchor" aria-hidden="true" href="#056search为chrome设置搜索引擎关键词"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/056_search.html" rel="nofollow"&gt;056《Search》为Chrome设置搜索引擎关键词&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/62503773-3c37c000-b828-11e9-9605-4ecce76830ec.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/62503773-3c37c000-b828-11e9-9605-4ecce76830ec.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在早期的网址导航主页上, 可以通过点击选择不同的搜索引擎进行搜索(数量有限, 而且不支持自定义), 而Chrome搜索更极客一些, 通过&lt;strong&gt;自定义关键词加空格&lt;/strong&gt;的方法, 在搜索引擎之间自由切换, 是一种兼具扩展性与易用性的做法&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-055keylines为网页元素添加随机描边颜色-" class="anchor" aria-hidden="true" href="#055keylines为网页元素添加随机描边颜色-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/055_keylines.html" rel="nofollow"&gt;055《Keylines》为网页元素添加随机描边颜色 &lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61917657-dbcf9580-af80-11e9-87d3-528609ab85b0.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61917657-dbcf9580-af80-11e9-87d3-528609ab85b0.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keylines的实现原理非常简单(为网页dom元素添加了outline属性), 但展示的效果却非常惊艳, 这应该归功于Keylines作者优秀的想法, 很多时候, 优秀的软件并不一定使用了很难掌握的技术, 而是包含了作者优秀的想法~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-054二箱以图搜图让你在搜图方面随心所欲为所欲为" class="anchor" aria-hidden="true" href="#054二箱以图搜图让你在搜图方面随心所欲为所欲为"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/054_er_xiang_yi_tu_sou_tu.html" rel="nofollow"&gt;054《二箱+以图搜图》让你在搜图方面随心所欲（为所欲为）&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61757068-93ce3880-adf1-11e9-8903-ebf313fb6098.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61757068-93ce3880-adf1-11e9-8903-ebf313fb6098.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;《二箱 以图搜图》是一款简单实用的搜图小工具，如果你是一名设计师, 可以帮你快速查找他人设计作品中所用的素材来源, 提升你的工作效率~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-053鼠标点击特效-๑́--̀๑为鼠标点击添加有趣的特效" class="anchor" aria-hidden="true" href="#053鼠标点击特效-๑́--̀๑为鼠标点击添加有趣的特效"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/053_shu_biao_dian_ji_te_xiao.htmll" rel="nofollow"&gt;053《鼠标点击特效 (๑•́ ∀ •̀๑)》为鼠标点击添加有趣的特效&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61600040-04921b00-ac61-11e9-8446-533752d71de1.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61600040-04921b00-ac61-11e9-8446-533752d71de1.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;《鼠标点击特效 (๑•́ ∀ •̀๑)》是一款为鼠标点击添加有趣的特效的扩展程序,虽然没啥实际用途,但很好玩, 录制一些有趣的网页小程序时, 会非常出彩~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-052site-palette自动提取网站配色" class="anchor" aria-hidden="true" href="#052site-palette自动提取网站配色"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/052_site_palette.html" rel="nofollow"&gt;052《Site Palette》自动提取网站配色&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61169390-2f101400-a58f-11e9-8769-4d62b7b64f37.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61169390-2f101400-a58f-11e9-8769-4d62b7b64f37.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Site Palette使用简单, 功能实用, 没有广告, 是典型的小而美的扩展程序, 这类扩展程序越多, Chrome的用户体验也就越好~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-051custom-cursor-for-chrome为chrome换上可爱初音光标" class="anchor" aria-hidden="true" href="#051custom-cursor-for-chrome为chrome换上可爱初音光标"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/051_custom_cursor_for_chrome.html" rel="nofollow"&gt;051《Custom Cursor for Chrome™》为Chrome换上可爱初音光标&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/61166967-d0846f00-a569-11e9-9141-15cef4983098.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/61166967-d0846f00-a569-11e9-9141-15cef4983098.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;早期的QQ空间和个人博客, 我们会给页面加各种各样的装饰, 连鼠标指针也要定制一下, 当时感觉乐趣无穷, 后面就失去了兴趣, 对于个人博客, 感觉越简洁越好, 于是就有了Next这些大量留白的博客主题,但我感觉在Next这类主题中加一些定制化的小物件也是不错的, 在简洁与花哨之间找到平衡, 不正是生活的乐趣之源么~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-050google-results-previewer无点击查看谷歌搜索结果" class="anchor" aria-hidden="true" href="#050google-results-previewer无点击查看谷歌搜索结果"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/050_google_results_previewer.html" rel="nofollow"&gt;050《Google Results Previewer》无点击查看谷歌搜索结果&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/9219a092f0f4eb1c6f614c1667b316d1.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/9219a092f0f4eb1c6f614c1667b316d1.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Google Results Previewer的功能简单实用, 也没有多余的设置, 属于新手友好型工具&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-049web-server-for-chrome搭建本地web服务器-实现局域网共享文件夹" class="anchor" aria-hidden="true" href="#049web-server-for-chrome搭建本地web服务器-实现局域网共享文件夹"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/049_web_server_for_chrome.html" rel="nofollow"&gt;049《Web Server for Chrome》搭建本地Web服务器, 实现局域网共享文件夹&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/74d3eb882b103e0fb1e5e5dd651c052f.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/74d3eb882b103e0fb1e5e5dd651c052f.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Web Server for Chrome可以帮我们在本地快速开启http服务,让开发和测试变得更加简单, 如果你想和同处某个局域网的小伙伴, 建立一个共享文件夹, Web Server for Chrome或许是你最简单的实现方法~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-048words-discoverer背单词新姿势提升你的词汇量" class="anchor" aria-hidden="true" href="#048words-discoverer背单词新姿势提升你的词汇量"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/048_words_discoverer.html" rel="nofollow"&gt;048《Words Discoverer》背单词新姿势,提升你的词汇量&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/305439fdd84017da654e00f16aaee752.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/305439fdd84017da654e00f16aaee752.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Words Discoverer(中文译名: 单词发现者),&lt;strong&gt;可以突出显示网页上罕见的英语字典词汇和惯用语。促进英语语言学习并扩大词汇量&lt;/strong&gt;,通过自动高亮网页单词, 辅助单词记忆是一个很好的路子, 建议过一段时间,就稍微调高&lt;strong&gt;不突出显示 最常用的英语单词&lt;/strong&gt;的数量, 比如从默认的15%调整到16%,  单词发现者与沙拉查词结合使用, 真的是体验极佳~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-047go-to-tab快速跳转到打开的网页" class="anchor" aria-hidden="true" href="#047go-to-tab快速跳转到打开的网页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/047_go_to_tab.html" rel="nofollow"&gt;047《Go to Tab》快速跳转到打开的网页&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/59550928-2a623b00-8fa4-11e9-8525-8e830907463b.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/59550928-2a623b00-8fa4-11e9-8525-8e830907463b.gif" alt="2019-06-15-18 54 23" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Go to Tab对于工作期间大量打开页面, 又长时间不关机的程序员们, 是非常有帮助的&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-046whatfont字体爱好者优雅查看网页字体" class="anchor" aria-hidden="true" href="#046whatfont字体爱好者优雅查看网页字体"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/046_whatfont.html" rel="nofollow"&gt;046《WhatFont》字体爱好者优雅查看网页字体&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/15868458/59549312-4529b500-8f8e-11e9-8107-004486a02258.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/15868458/59549312-4529b500-8f8e-11e9-8107-004486a02258.gif" alt="font 2019-06-15 16_04_10" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;WhatFont属于功能非常单一的小工具, 让字体爱好者优雅查看网页字体属性, 如果你对漂亮字体有一份执念, 推荐到&lt;a href="https://fonts.google.com/" rel="nofollow"&gt;https://fonts.google.com/&lt;/a&gt;, &lt;a href="https://www.myfonts.com/" rel="nofollow"&gt;https://www.myfonts.com/&lt;/a&gt;
等字体网站,找寻更多可爱的字体~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-045restlet-client优秀的api测试工具" class="anchor" aria-hidden="true" href="#045restlet-client优秀的api测试工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/045_restlet_client.html" rel="nofollow"&gt;045《Restlet Client》优秀的Api测试工具&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/89ea1e51dab48d5a84f089adf33eb274.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/zhaoolee_images000000/89ea1e51dab48d5a84f089adf33eb274.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Restlet Client是一款开发实用工具, 支持一键导入Postman等api测试工具的测试用例&lt;/li&gt;
&lt;li&gt;近来, Postman开始主推自己的70M左右的客户端安装包, 功能没什么改进, 体积却变得超大,而且Postman的Chrome扩展程序, 对macOS的支持不太好(每次打开, 都会弹窗报一个错)&lt;/li&gt;
&lt;li&gt;Restlet Client依然只是一个开箱即用的Chrome扩展程序, 非常适合硬盘空间有限的小伙伴使用(软件功能够用就可以了~)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-044谷歌访问助手访问chrome商店-gmail-谷歌搜索" class="anchor" aria-hidden="true" href="#044谷歌访问助手访问chrome商店-gmail-谷歌搜索"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/044_gu_ge_fang_wen_zhu_shou.html" rel="nofollow"&gt;044《谷歌访问助手》访问Chrome商店 Gmail 谷歌搜索&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/deff71a536ba4027a01fe3c7a558c277.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/deff71a536ba4027a01fe3c7a558c277.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;《谷歌访问助手》可以让我们访问Chrome商店, 以及谷歌搜索, 谷歌Gmail等服务
&lt;code&gt;仅为香港地区用户提，供方便科研,外贸提供帮助,不良用户,将封锁访问IP,后果自负&lt;/code&gt;, 谷歌访问助手需要你设置主页为&lt;code&gt;https://2018.hao245.com/&lt;/code&gt;才能使用, 有百度全家桶, 360全家桶的流氓内涵~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-043dream-afar-new-tab探索世界的新方式" class="anchor" aria-hidden="true" href="#043dream-afar-new-tab探索世界的新方式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/043_dream_afar_new_tab.html" rel="nofollow"&gt;043《Dream Afar New Tab》探索世界的新方式&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e40b7bec41ce4ac892578bc88a03d25c.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e40b7bec41ce4ac892578bc88a03d25c.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;《Dream Afar New Tab》的设计非常漂亮, 功能调节也非常简单, 只有两级菜单, 壁纸也非常精美, 对浏览器颜值有要求的小伙伴, 可以试一试~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-042-在edge中安装chrome扩展程序" class="anchor" aria-hidden="true" href="#042-在edge中安装chrome扩展程序"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/042_edge.html" rel="nofollow"&gt;042 在Edge中安装Chrome扩展程序&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a131b9833d20424ab93cb258ab8542e8.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a131b9833d20424ab93cb258ab8542e8.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Edge可以安装绝大多数Chrome商店中的扩展, 但Chrome中的谷歌开发App程序, 类似&lt;a href="https://chrome.google.com/webstore/detail/secure-shell-app/pnhechapfaindjhompbnflcldabbghjo" rel="nofollow"&gt;Secure Shell App&lt;/a&gt;, 目前是无法安装的, 新版Edge使用了Chrome的Chromium内核, 可以兼容安装Chrome生态中的各种应用程序,为Edge未来的发展带来了无限可能~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-041copy-all-urls优雅地保存-开启多个标签页" class="anchor" aria-hidden="true" href="#041copy-all-urls优雅地保存-开启多个标签页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/041_copy_all_urls.html" rel="nofollow"&gt;041《Copy All Urls》优雅地保存-开启多个标签页&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/eac219ff189a4295bbf88974b045ba5b.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/eac219ff189a4295bbf88974b045ba5b.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Copy All Urls属于小而美地工具，如果你每天都需要查看几个固定的网页, Copy All Urls能帮你省很多时间~&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-040gitzip-for-github从github批量下载表情包" class="anchor" aria-hidden="true" href="#040gitzip-for-github从github批量下载表情包"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/040_gitzip_for_github.html" rel="nofollow"&gt;040《GitZip for github》从Github批量下载表情包&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/f5b923dc4a21437484e90859342ed366.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/f5b923dc4a21437484e90859342ed366.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;以前介绍过Github快速下载单个文件的扩展工具&lt;a href="https://zhaoolee.gitbooks.io/chrome/content/018enhanced-github300b-cong-201c-bing-gui-201d-dao-201c-bing-gun-er-201d2c-xia-zai-github-dan-ge-wen-jian.html" rel="nofollow"&gt;《Enhanced Github》&lt;/a&gt; , 《Enhanced Github》 和 《GitZip for github》 结合到一起, 就可以让我们快速下载, github任意仓库任意文件夹的优质资源了~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-039simplify-gmail让网页版gmail更清爽" class="anchor" aria-hidden="true" href="#039simplify-gmail让网页版gmail更清爽"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/039_simplify_gmail.html" rel="nofollow"&gt;039《Simplify Gmail》让网页版Gmail更清爽&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c9b1aa8201c24208b0e0aedfcdbdc992.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c9b1aa8201c24208b0e0aedfcdbdc992.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;好的扩展程序就应该这样, 让人见到后耳目一新, 使用的方法却非常简单。
如果你并没有注册过Gmail邮箱, 可以尝试注册一个, Gmail是非常好用的, 拥有规范的接口, 不会随便拦截邮件, 也不会在页面铺满广告&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-038alexa-traffic-rank一键查看网站全球排名" class="anchor" aria-hidden="true" href="#038alexa-traffic-rank一键查看网站全球排名"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/038_alexa_traffic_rank.html" rel="nofollow"&gt;038《Alexa Traffic Rank》一键查看网站全球排名&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcefd45a5cc74e4c824f567535f79c5c.webp"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcefd45a5cc74e4c824f567535f79c5c.webp" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Alexa给出的网站排名, 是目前公认最具参考价值的排名, 打开一个新站点, 查一下新站点的Alexa排名, 以及与它类似的站点, 让我们很快对新站点的定位, 有一个大致的认知~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-037saladict谷歌有道我全都要-聚合词典-并行翻译" class="anchor" aria-hidden="true" href="#037saladict谷歌有道我全都要-聚合词典-并行翻译"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/037_saladict.html" rel="nofollow"&gt;037《Saladict》谷歌!有道!我全都要! 聚合词典, 并行翻译&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/07322f3c4b13484a8a048194558cec5c.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/07322f3c4b13484a8a048194558cec5c.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;沙拉查词(Saladict)是一款非常优秀的查词扩展, 上文只是提及了它最常用的一些功能, 沙拉查词的后台管理选项非常丰富, 感兴趣的小伙伴可以慢慢探索&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-036screen-shader把屏幕调成暖色你的眼睛会感谢你" class="anchor" aria-hidden="true" href="#036screen-shader把屏幕调成暖色你的眼睛会感谢你"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/036_screen_shader.html" rel="nofollow"&gt;036《Screen Shader》把屏幕调成暖色，你的眼睛会感谢你&lt;g-emoji class="g-emoji" alias="pray" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f64f.png"&gt;🙏&lt;/g-emoji&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/3a94a283267047c39114694706de7293.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/3a94a283267047c39114694706de7293.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;对于长时间看电脑的办公人员, 可以尝试吧屏幕调成暖色, 开始可能会不习惯, 但后面会感觉眼睛会舒服很多, 你的眼睛也会感谢你的~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-035print-friendly--pdf让你拥有最佳的打印阅读体验" class="anchor" aria-hidden="true" href="#035print-friendly--pdf让你拥有最佳的打印阅读体验"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/035_print_friendly_and_pdf.html" rel="nofollow"&gt;035《Print Friendly &amp;amp; PDF》让你拥有最佳的打印阅读体验&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a71d2b280298482ba2408482c1537bf9.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/a71d2b280298482ba2408482c1537bf9.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;《Print Friendly &amp;amp; PDF》是一款文件打印chrome插件，会在打印之前删除垃圾广告，导航和无用浮窗从而实现页面优化，让你拥有最佳的打印阅读体验, 如果你经常需要打印网页, 可以通过《Print Friendly &amp;amp; PDF》让你的打印工作变得省时省力~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-034astro-bot用新标签页刷编程题" class="anchor" aria-hidden="true" href="#034astro-bot用新标签页刷编程题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/034_astro_bot.html" rel="nofollow"&gt;034《Astro Bot》用新标签页刷编程题&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/671d39ca714f437fa1d287bfb988724e.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/671d39ca714f437fa1d287bfb988724e.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Astro Bot可以在新标签页,展示一道与程序相关的问题或相关新闻&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-033一叶在任意网页开启实时弹幕-聊天窗口-留言板" class="anchor" aria-hidden="true" href="#033一叶在任意网页开启实时弹幕-聊天窗口-留言板"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/033_yi_ye.html" rel="nofollow"&gt;033《一叶》在任意网页开启实时弹幕 聊天窗口 留言板&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6a328e8eb9984f5abea5816c681b8e4e.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6a328e8eb9984f5abea5816c681b8e4e.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;一叶是一款很有想法的产品,但目前用户量还是很少, 对此,我个人也有一些想法,如果官方可以效仿pokemongo这类寻宝游戏,在各大网站的主页对应的留言板内,埋下一些有意思的彩蛋,让用户去寻宝,或许会有利于产品的推广~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-032smallpdf简单好用的线上pdf工具" class="anchor" aria-hidden="true" href="#032smallpdf简单好用的线上pdf工具"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/032_smallpdf.html" rel="nofollow"&gt;032《Smallpdf》简单好用的线上PDF工具&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/2c00d25291db4750963c60e78344d4cc.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/2c00d25291db4750963c60e78344d4cc.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Smallpdf是一个非常好用的PDF工具,可以收藏起来,作为日常办公的工具, Smallpdf可以进行多份pdf在线合并, pdf在线编辑, 如果你是一个经常和PDF打交道的人, 可不要错过它~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-031onetab把多个tab转换为一个列表" class="anchor" aria-hidden="true" href="#031onetab把多个tab转换为一个列表"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/031_onetab.htmll" rel="nofollow"&gt;031《OneTab》把多个Tab转换为一个列表&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/93781d48870742e08dc68fa17e79169e.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/93781d48870742e08dc68fa17e79169e.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;当你发现自己有太多的标签页时,单击OneTab图标,所有标签页会转换成一个列表,当你需要再次访问这些标签页时,点击OneTab图标唤出列表,点击列表恢复标签页&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-030掘金相信优质技术内容的力量" class="anchor" aria-hidden="true" href="#030掘金相信优质技术内容的力量"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/030_jue_jin.html" rel="nofollow"&gt;030《掘金》相信优质技术内容的力量&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcca47d65f2542808281c17ec379d7d9.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fcca47d65f2542808281c17ec379d7d9.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;如果你想对 程序员, 产品经理, 设计师的行业知识有所了解, 可以没事儿打开掘金插件看一看, 如果你感觉很喜欢里面的内容, 可以到掘金官网 &lt;a href="https://juejin.im/" rel="nofollow"&gt;https://juejin.im/&lt;/a&gt; 逛一逛&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-029-simpread为任意网页开启阅读模式" class="anchor" aria-hidden="true" href="#029-simpread为任意网页开启阅读模式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/029_simread.html" rel="nofollow"&gt;029 《SimpRead》为任意网页开启阅读模式&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0f9aa9ca332c4325806f92784af9f9ac.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0f9aa9ca332c4325806f92784af9f9ac.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
为网页开启阅读模式, 能让我们更专注于内容, 不会被花花绿绿的广告推广分散精力, 而SimpRead就是一歀为网页开启&lt;strong&gt;阅读模式&lt;/strong&gt;的插件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-028adblockadblock屏蔽简书广告" class="anchor" aria-hidden="true" href="#028adblockadblock屏蔽简书广告"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/028_adblock.html" rel="nofollow"&gt;028《AdBlock》Adblock屏蔽简书广告&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e149c42ac1f343b88f50e522cba9ad64.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e149c42ac1f343b88f50e522cba9ad64.gif" alt="屏蔽简书广告" style="max-width:100%;"&gt;&lt;/a&gt;
Adblock的功能非常丰富, 但很多功能基本用不到, 普通用户只需要开启Adblock, 能使用右键工具屏蔽不喜欢的广告, 也就够用了~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-027text来自chrome实验室的跨平台记事本" class="anchor" aria-hidden="true" href="#027text来自chrome实验室的跨平台记事本"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/027_text.html" rel="nofollow"&gt;027《Text》来自Chrome实验室的跨平台记事本&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6e287798ca1d4b939705447d4b8b2b3b.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6e287798ca1d4b939705447d4b8b2b3b.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Text由谷歌Chrome实验室研发并开源, 开源地址&lt;a href="https://github.com/GoogleChromeLabs/text-app"&gt;https://github.com/GoogleChromeLabs/text-app&lt;/a&gt; , Text属于小而美的产品, 功能不算强大, 但是够用, 而且借助Chrome完成了跨平台(在Linux也可以使用哦~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-026quickey-launcher打开网站只需一键" class="anchor" aria-hidden="true" href="#026quickey-launcher打开网站只需一键"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/026_quickey_launcher.html" rel="nofollow"&gt;026《Quickey Launcher》打开网站只需一键&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/322a82d214b34ff2ba70d9c1cd71d276.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/322a82d214b34ff2ba70d9c1cd71d276.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
Quickey Launcher以优雅的方式, 为任意网页绑定一个快捷键, 绑定完成后, 即可通过快捷键,打开网页&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-025consolechrome自带好用的计算器" class="anchor" aria-hidden="true" href="#025consolechrome自带好用的计算器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/025_console.html" rel="nofollow"&gt;025《Console》Chrome自带好用的计算器&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c7bc7cabd06a453dbed2bae0a2bf08d5.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/c7bc7cabd06a453dbed2bae0a2bf08d5.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Chrome计算机的好用之处: 既可以看到加数字的记录,也可以实时预览运算的结果, 输入完成后还可以很方便的核查一遍, 还有一点: Chrome计算器观赏性强(逼格很高)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-024dark-reader为任意网站启用夜间模式" class="anchor" aria-hidden="true" href="#024dark-reader为任意网站启用夜间模式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/024_dark_reader.html" rel="nofollow"&gt;024《Dark Reader》为任意网站启用夜间模式&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/35e84f58945d4775a31154ea4dc51cac.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/35e84f58945d4775a31154ea4dc51cac.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;喜欢夜间模式的小伙伴, Dark Reader应该可以满足你了~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5&gt;&lt;a id="user-content-023fireshot一键滚动截屏整个网页" class="anchor" aria-hidden="true" href="#023fireshot一键滚动截屏整个网页"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/023_fireshot.html" rel="nofollow"&gt;023《FireShot》一键滚动截屏整个网页&lt;/a&gt;&lt;/h5&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/81ac43fe1d6e454b93dc7f3ae57d96cd.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/81ac43fe1d6e454b93dc7f3ae57d96cd.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
总体来讲, FireShot是一款不错的软件, 免费且功能够用, 滚动截图的功能比同类软件做的都要好&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-022扩展管理器管理你的chrome扩展" class="anchor" aria-hidden="true" href="#022扩展管理器管理你的chrome扩展"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/022kuo_zhan_guan_li_qi.html" rel="nofollow"&gt;022《扩展管理器》管理你的Chrome扩展&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0480fffebb10437c8d5555f085de9006.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/0480fffebb10437c8d5555f085de9006.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
如果Chrome安装的插件很多, 我们可以对插件进行分组, 按照场景,启用不同组的插件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-021哔哩哔哩助手助你快速成为b站老司机" class="anchor" aria-hidden="true" href="#021哔哩哔哩助手助你快速成为b站老司机"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/021_bi_li_bi_li_zhu_shou.html" rel="nofollow"&gt;021《哔哩哔哩助手》助你快速成为B站老司机&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6ccb9837b60d4d79814a8add20723d97.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/6ccb9837b60d4d79814a8add20723d97.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;哔哩哔哩助手, 功能实用,开发者也一直保持着较高频率的更新,可以放心食用~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-020boxel-rebound嗨到中毒的弹跳小方块附自制赛道分享方法" class="anchor" aria-hidden="true" href="#020boxel-rebound嗨到中毒的弹跳小方块附自制赛道分享方法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/020_boxel_rebound.html" rel="nofollow"&gt;020《Boxel Rebound》“嗨到中毒”的弹跳小方块(附自制赛道分享方法)&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dbc83cc53c26492db8843ff3e35fc75d.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dbc83cc53c26492db8843ff3e35fc75d.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
Boxel Rebound是一个偏极客的小游戏, 玩法简单, 可以自由创建赛道, 分享赛道, 获取别人的赛道进行二次开发; 无论你是Mac用户,Windows用户,Linux用户, 只要安装了Chrome浏览器, 就可以玩耍Boxel Rebound&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-019mega网盘可以良心到什么程度-试试mega吧" class="anchor" aria-hidden="true" href="#019mega网盘可以良心到什么程度-试试mega吧"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/019_mega.html" rel="nofollow"&gt;019《MEGA》网盘可以良心到什么程度? 试试MEGA吧!&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b5aea0b5e3c54f0a9a050a754a67093d.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b5aea0b5e3c54f0a9a050a754a67093d.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;没有限速的概念(真的被百度盘的限速策略恶心到了)&lt;/li&gt;
&lt;li&gt;在国内可用(google虽好, 但国内用不了, MEGAsync亲测国内可用)&lt;/li&gt;
&lt;li&gt;云端加密, 资源不会被封杀&lt;/li&gt;
&lt;li&gt;官方提供了Linux客户端&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-018enhanced-github从冰柜到冰棍儿下载github单个文件" class="anchor" aria-hidden="true" href="#018enhanced-github从冰柜到冰棍儿下载github单个文件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/018_enhanced_github.html" rel="nofollow"&gt;018《Enhanced Github》从“冰柜”到“冰棍儿”,下载Github单个文件&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/769a22f995d74226ba4104aba7e8ab59.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/769a22f995d74226ba4104aba7e8ab59.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/00541b7bd6954f8ea2a6a1beaebbb79b.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/00541b7bd6954f8ea2a6a1beaebbb79b.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
我需要Github给我一根冰棍解暑,Github却坚持把装有冰棍的冰柜也送给我（哥们儿真够意思）... 有了Enhanced Github这款插件, 我们可以下载Github优秀项目中最核心的代码文件进行学习, 而不是 下载 整个仓库作为藏品&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-017新浪微博图床本地markdown编写更流畅-新浪微博图床来帮忙" class="anchor" aria-hidden="true" href="#017新浪微博图床本地markdown编写更流畅-新浪微博图床来帮忙"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/017_xin_lang_wei_bo_tu_chuang.html" rel="nofollow"&gt;017《新浪微博图床》本地Markdown编写更流畅, 新浪微博图床来帮忙&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/48c12b3864f84e988e073209fd7cf8e4.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/48c12b3864f84e988e073209fd7cf8e4.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
用Markdown写文章, 如果文章中使用了本地配图, 那本地配图就要和文章一起打包,否则别人是看不到图片的,如果把本地图片放到网络服务器, 然后直接把图片的url粘贴到文章里面, 就可以免除图片打包的步骤&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-016解除b站区域限制查看进击的巨人第三季" class="anchor" aria-hidden="true" href="#016解除b站区域限制查看进击的巨人第三季"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/016_jie_chu_b_zhan_qu_yu_xian_zhi.html" rel="nofollow"&gt;016《解除B站区域限制》查看进击的巨人第三季&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/34d50d4d15094ca08e1bbd76c477122a.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/34d50d4d15094ca08e1bbd76c477122a.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/99fd518796894945aa87225a5022c453.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/99fd518796894945aa87225a5022c453.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
解除B站区域限制,B站老司机必备技能&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-015xpath-helper完成bing每日壁纸的小爬虫" class="anchor" aria-hidden="true" href="#015xpath-helper完成bing每日壁纸的小爬虫"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/015_xpath_helper.html" rel="nofollow"&gt;015《XPath Helper》完成Bing每日壁纸的小爬虫&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/308bec78f4674130b85a5852f0b25a88.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/308bec78f4674130b85a5852f0b25a88.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;XPath是一个辅助我们写爬虫的小插件, 我们可以用XPath辅助我们完成一个Bing壁纸的小爬虫~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-014超级马里奥游戏chrome变身小霸王" class="anchor" aria-hidden="true" href="#014超级马里奥游戏chrome变身小霸王"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/014_chao_ji_ma_li_ao_you_xi.html" rel="nofollow"&gt;014《超级马里奥游戏》Chrome变身小霸王&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/008f3bd3c8b8483b9d70be5d5ed4f9ee.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/008f3bd3c8b8483b9d70be5d5ed4f9ee.gif" alt="超级玛丽.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;用Chrome玩超级马里奥是一种什么体验? 哈哈, 好玩! 《超级马里奥游戏》这款插件,可以让你打开Chrome, 随时玩一局超级玛丽, 嘿嘿&lt;g-emoji class="g-emoji" alias="yum" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f60b.png"&gt;😋&lt;/g-emoji&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-013quick-qr用二维码实现云粘贴" class="anchor" aria-hidden="true" href="#013quick-qr用二维码实现云粘贴"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/013_quick_qr.html" rel="nofollow"&gt;013《Quick QR》用二维码实现云粘贴&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b59f299316624e86aa7cdd379a02aac4.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b59f299316624e86aa7cdd379a02aac4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;通过Quick QR, 我们可以不借助任何通讯软件,通过手机扫码,获取PC浏览器上任意一段文字信息(云粘贴板哦~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-012ourstickyschrome特色网页便签纸" class="anchor" aria-hidden="true" href="#012ourstickyschrome特色网页便签纸"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/012_ourstickys.html" rel="nofollow"&gt;012《OurStickys》Chrome特色网页便签纸&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/62597d60ffd6443396725c9677951221.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/62597d60ffd6443396725c9677951221.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;向众人介绍喜欢的网页功能时,可以边讲,边向网页打便签,这样既能让人眼前一亮,也让听众容易抓住重点~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-011-whatruns一键分析网站技术栈" class="anchor" aria-hidden="true" href="#011-whatruns一键分析网站技术栈"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/011_whatruns.html" rel="nofollow"&gt;011 《whatruns》一键分析网站技术栈&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/28cc002358c647878b54f9bcaaf67a0a.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/28cc002358c647878b54f9bcaaf67a0a.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;如果你对当前浏览的网站非常感兴趣, 可以通过whatruns了解软件的技术栈, 比如看看这个名为facebook用了什么技术&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-010speedtest网络测速插件speedtest" class="anchor" aria-hidden="true" href="#010speedtest网络测速插件speedtest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/010_speedtest.html" rel="nofollow"&gt;010《speedtest》网络测速插件speedtest&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9aa1e5323a6a4cbcb96304b33a5261c8.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9aa1e5323a6a4cbcb96304b33a5261c8.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;当上网速度很慢的时候, 人们想到的第一件事就进行网络测速,在window上, 只要你安装了360全家桶, 测速功能就是默认安装的, 但测速这种功能根本不需要安装到本地, 交给浏览器就好了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-009vimiumchrome与vim双神器融合" class="anchor" aria-hidden="true" href="#009vimiumchrome与vim双神器融合"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/009_vimium.html" rel="nofollow"&gt;009《vimium》Chrome与vim双神器融合&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/7d6e9fadef3f48409c81a8c76d24e0cc.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/7d6e9fadef3f48409c81a8c76d24e0cc.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;vimium可以让我们只使用键盘就可以浏览网页, 如果你第一次看到有人使用vimium, 它的操作方式绝对能让你感到惊艳~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-008chrome-cleaner-pro为chrome加速" class="anchor" aria-hidden="true" href="#008chrome-cleaner-pro为chrome加速"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/008_chrome_cleaner_pro.html" rel="nofollow"&gt;008《Chrome Cleaner Pro》为Chrome加速&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/30899ae22f644a9bb62eb8b24d75c884.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/30899ae22f644a9bb62eb8b24d75c884.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Chrome经过最近几年的发展, 强力的扩展越来越多, 离Chrome OS的目标也越来越近, 软件做大了就会有类似Windows的通病, 软件会变慢, 让Chrome变快的最简单方式就是清理垃圾, 而Chrome Cleaner Pro走的是一键清理的路子~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-007loom-chrome翻录网页视频神器" class="anchor" aria-hidden="true" href="#007loom-chrome翻录网页视频神器"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/007_loom.html" rel="nofollow"&gt;007《loom》 Chrome翻录网页视频神器&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/4058cf0008074c5f86b8eb1684e7a1a0.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/4058cf0008074c5f86b8eb1684e7a1a0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Loom可以一键录制浏览器的单个标签页(盗版翻录视频的神器), 录制完成后自动生成在线网页,进行视频播放, 可以下载刚刚录制的视频, 也可以为刚刚生成的在线视频设置密码(盗版录屏加发布一条龙服务~)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-006similarsites-一键查找姊妹网站-similarsites" class="anchor" aria-hidden="true" href="#006similarsites-一键查找姊妹网站-similarsites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/006_similarsites.html" rel="nofollow"&gt;006《SimilarSites》 一键查找姊妹网站 SimilarSites&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/26c6c604be1c41e88ebfe79c733173b0.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/26c6c604be1c41e88ebfe79c733173b0.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;当你浏览一个很棒的站点的时候, 或许你会想到, 和它"差不多"的站点有哪些, 尤其是针对一些资源站点, 这个站点没有, 而它同类的站点"往往有"! SimilarSites, 它的作用只有一个, 发现同类站点!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-005video-speed-controller-刷课刷剧神器给网页视频加个速最快可达16倍" class="anchor" aria-hidden="true" href="#005video-speed-controller-刷课刷剧神器给网页视频加个速最快可达16倍"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/005_video_speed_controller.html" rel="nofollow"&gt;005《Video Speed Controller》 刷课（刷剧）神器！给网页视频加个速(最快可达16倍!)&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/083c51a1c32a4ad6931646bb005fd5a3.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/083c51a1c32a4ad6931646bb005fd5a3.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;刷一些没营养视频的时候, 我们会有倍速播放视频的需求, 而网站的在线播放器一般只提供不高于4倍的播放速度, 而Video Speed Controller可以将视频播放速度提高到16倍速~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-004tampermonkey-油猴子-给浏览器开个挂" class="anchor" aria-hidden="true" href="#004tampermonkey-油猴子-给浏览器开个挂"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/004_tampermonkey.html" rel="nofollow"&gt;004《Tampermonkey》 油猴子! 给浏览器开个挂&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e87601eb459549b3b8e33994fc3fdfb4.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/e87601eb459549b3b8e33994fc3fdfb4.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;油猴子必备成为Chrome的第二应用商店, 有了油猴子, 你可以免费查看VIP视频, 清除各种网页广告, 在豆瓣影评页面显示电影资源的下载地址~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-003secure-shell-app-chrome中开启ssh一种什么体验" class="anchor" aria-hidden="true" href="#003secure-shell-app-chrome中开启ssh一种什么体验"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/003_secure_shell_app.html" rel="nofollow"&gt;003《Secure Shell App》 Chrome中开启ssh一种什么体验&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/87b66b4cbd12426bbab65a3443f1f1ec.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/87b66b4cbd12426bbab65a3443f1f1ec.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;很多小白想要通过购买服务器搭建自己的VPN, 购买服务器后, 第一步就是要通过ssh登录服务器, 而Windows并没有自带ssh软件,现在你无需下载putty或xshell ,可以通过这款Secure Shell App在chrome直接实现ssh登录服务器了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-002-chrono-让chrome下载资源更容易" class="anchor" aria-hidden="true" href="#002-chrono-让chrome下载资源更容易"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/002_chrono.html" rel="nofollow"&gt;002 《chrono》 让Chrome下载资源更容易&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b574ee1798984ff49396837b620f51ef.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/b574ee1798984ff49396837b620f51ef.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;chrono可以非常方便的嗅探识别网页中的资源, 然后一键下载所有资源(收图喽!)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-001markdown-here-markdown一键转换到富文本格式" class="anchor" aria-hidden="true" href="#001markdown-here-markdown一键转换到富文本格式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/page/001_markdown_here.html" rel="nofollow"&gt;001《markdown-here》 Markdown一键转换到"富文本格式"&lt;/a&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fc5de2eb22184a138c618728cfb40ede.gif"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/fc5de2eb22184a138c618728cfb40ede.gif" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;有了markdown-here这个插件, 可以在网页版 QQ邮箱, Gmail, 新浪头条文章, 里面使用mardown格式进行书写,然后一键转换为富文本&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-他人眼中的-chrome插件英雄榜商业互吹模块" class="anchor" aria-hidden="true" href="#他人眼中的-chrome插件英雄榜商业互吹模块"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;他人眼中的 Chrome插件英雄榜(商业互吹模块)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/88386634" rel="nofollow"&gt;《这份“插件英雄榜Top20”才是Chrome的正确打开方式！》&lt;/a&gt; 作者: &lt;a href="https://me.csdn.net/dQCFKyQDXYm3F8rB0" rel="nofollow"&gt;AI科技大本营&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/58636515" rel="nofollow"&gt;《Chrome 插件英雄榜》&lt;/a&gt; 作者: &lt;a href="https://www.zhihu.com/people/loonggg/activities" rel="nofollow"&gt;非著名程序员&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://openingsource.org/6190/zh-tw/" rel="nofollow"&gt;《開源日報第363期》&lt;/a&gt; 作者: &lt;a href="https://openingsource.org/" rel="nofollow"&gt;开源工厂&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/Y-9ht-E7-OdJOEDDb3yyWw" rel="nofollow"&gt;《一根火柴的N种打开方式》&lt;/a&gt; 作者: &lt;a href="https://github.com/LuoJiangYong"&gt;老罗巴扎嘿&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-名字起啥好" class="anchor" aria-hidden="true" href="#名字起啥好"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;名字起啥好?&lt;/h2&gt;
&lt;p&gt;将这个仓库命名为&lt;strong&gt;Chrome扩展英雄榜&lt;/strong&gt;可能更准确些,但&lt;strong&gt;插件&lt;/strong&gt;这个名词, 更通俗易懂, 所以就使用了&lt;strong&gt;Chrome插件英雄榜&lt;/strong&gt;这个命名 ,感谢@&lt;a href="https://github.com/hjthjthjt"&gt;hjthjthjt&lt;/a&gt; 给出的&lt;a href="https://github.com/zhaoolee/ChromeAppHeroes/issues/14"&gt;issue&lt;/a&gt;纠正&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-推荐姊妹仓库" class="anchor" aria-hidden="true" href="#推荐姊妹仓库"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;推荐姊妹仓库&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;本仓库的姊妹篇:**&lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;《Github星聚弃疗榜》&lt;/a&gt;**为Github创意项目写一本推荐书，让Github优秀项目造福人类~ 已开源到Github: &lt;a href="https://github.com/zhaoolee/StarsAndClown"&gt;https://github.com/zhaoolee/StarsAndClown&lt;/a&gt; 同样有趣有料哦~&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-感谢" class="anchor" aria-hidden="true" href="#感谢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;感谢&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;感谢 掘金沸点运营 &lt;a href="https://juejin.im/user/5b39bd7de51d4558d43ff06d" rel="nofollow"&gt;@清蒸不是水煮&lt;/a&gt; 给出的 &lt;strong&gt;正面最开始放个索引目录比较好&lt;/strong&gt; 的小建议&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;感谢&lt;a href="https://www.jianshu.com/" rel="nofollow"&gt;简书&lt;/a&gt;社区提供超棒的Markdown编辑器,&lt;strong&gt;Chrome插件英雄榜&lt;/strong&gt;的编辑工作,几乎全部由通过简书编辑器完成&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;** emm... &lt;a href="https://zhaoolee.com/ChromeAppHeroes/download_the_chrome_extension_from_the_store.html" rel="nofollow"&gt;从官方商店下载Chrome插件的方法&lt;/a&gt;**&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chrome插件英雄榜&lt;/strong&gt; Github地址: &lt;a href="https://github.com/zhaoolee/ChromeAppHeroes"&gt;https://github.com/zhaoolee/ChromeAppHeroes&lt;/a&gt;
我需要你的支持, 希望你能为本项目填加一个 &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;🌟&lt;/g-emoji&gt;星.
I need your support, I hope you can add a star &lt;g-emoji class="g-emoji" alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png"&gt;🌟&lt;/g-emoji&gt; to this project.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-一根火柴的n种打开方式谷粒文化" class="anchor" aria-hidden="true" href="#一根火柴的n种打开方式谷粒文化"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/meaning_of_gu_li.html" rel="nofollow"&gt;一根火柴的N种打开方式(谷粒文化)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/9ac21b8aea054eb48fc404fd429638bf.jpeg" alt="smartmockups_juunlhbe.jpg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dc9ab48d958843c98f2a4c9336cff748.png"&gt;&lt;img src="https://raw.githubusercontent.com/zhaoolee/GraphBed/master/ChromeAppHeroes/dc9ab48d958843c98f2a4c9336cff748.png" alt="2.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-项目相关阅读" class="anchor" aria-hidden="true" href="#项目相关阅读"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目相关阅读&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://zhaoolee.com/ChromeAppHeroes/chrome_extended_resources_site.html" rel="nofollow"&gt;Chrome扩展资源站点推荐&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zhaoolee</author><guid isPermaLink="false">https://github.com/zhaoolee/ChromeAppHeroes</guid><pubDate>Wed, 20 Nov 2019 00:02:00 GMT</pubDate></item><item><title>Kayzaks/HackingNeuralNetworks #3 in Python, Today</title><link>https://github.com/Kayzaks/HackingNeuralNetworks</link><description>&lt;p&gt;&lt;i&gt;A small course on exploiting and defending neural networks&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-hacking-neural-networks-a-short-introduction" class="anchor" aria-hidden="true" href="#hacking-neural-networks-a-short-introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hacking Neural Networks: A Short Introduction&lt;/h1&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Disclaimer: This article and all the associated exercises are for educational purposes only.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is a short introduction on methods that use neural networks in an offensive manner (bug hunting, shellcode obfuscation, etc.) and how to exploit neural networks found in the wild (information extraction, malware injection, backdooring, etc.).&lt;/p&gt;
&lt;p&gt;Most of the methods presented are accompanied by an exercise found in this repo. The full article can be found here in '&lt;a href="Article.pdf"&gt;Article.pdf&lt;/a&gt;' or on arXiv (&lt;a href="https://arxiv.org/pdf/1911.07658.pdf" rel="nofollow"&gt;arXiv:1911.07658&lt;/a&gt;).&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-python-and-pip" class="anchor" aria-hidden="true" href="#python-and-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python and pip&lt;/h3&gt;
&lt;p&gt;Download and install Python3 and its package installer pip using a package manager or directly from the website &lt;a href="https://www.python.org/downloads/" rel="nofollow"&gt;https://www.python.org/downloads/&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-editor" class="anchor" aria-hidden="true" href="#editor"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Editor&lt;/h3&gt;
&lt;p&gt;An editor is required to work with the code, preferably one that allows code highlighting for Python. Vim/Emacs will do. As a reference, all exercises were prepared using Visual Studio Code &lt;a href="https://code.visualstudio.com/docs/python/python-tutorial" rel="nofollow"&gt;https://code.visualstudio.com/docs/python/python-tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-packages" class="anchor" aria-hidden="true" href="#packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Packages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Keras&lt;/strong&gt;: Installing Keras can be tricky. We refer to the official installation guide at &lt;a href="https://keras.io/#installation" rel="nofollow"&gt;https://keras.io/#installation&lt;/a&gt; and suggest TensorFlow as a backend (using the GPU-enabled version, if one is available on the machine).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NumPy&lt;/strong&gt; and &lt;strong&gt;SciPy&lt;/strong&gt;: NumPy and SciPy are excellent helper packages, which are used throughout all exercises. Following the official SciPy instructions should also install NumPy &lt;a href="https://www.scipy.org/install.html" rel="nofollow"&gt;https://www.scipy.org/install.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyCuda&lt;/strong&gt;: PyCuda is required for the GPU-based attack exercise. If no nVidia GPU is available on the machine, this can be skipped. &lt;a href="https://wiki.tiker.net/PyCuda/Installation" rel="nofollow"&gt;https://wiki.tiker.net/PyCuda/Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NLTK&lt;/strong&gt;: NLTK provides functionalities for natural language processing and is very helpful for some of the exercises. &lt;a href="https://www.nltk.org/install.html" rel="nofollow"&gt;https://www.nltk.org/install.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-the-exercises" class="anchor" aria-hidden="true" href="#the-exercises"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The exercises&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;0 - Last Layer Attack&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;1 - Backdooring&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;2 - Extracting Information&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;3 - Brute Forcing&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;4 - Neural Overflow&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;5 - Malware Injection&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;6 - Neural Obfuscation&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;7 - Bug Hunting&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;8 - GPU Attack&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For instructions, please read the 'README.md' file in each of the exercise directories.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-further-reading--watching" class="anchor" aria-hidden="true" href="#further-reading--watching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Further Reading / Watching&lt;/h2&gt;
&lt;p&gt;Check out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Isao Takaesu's course on &lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Security_and_MachineLearning"&gt;Security and Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Will Pearce and Nick Landers' &lt;a href="https://www.youtube.com/watch?v=CsvkYoxtexQ" rel="nofollow"&gt;Talk at Derbycon 2019&lt;/a&gt; on Offensive Machine Learning techniques.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-what-else" class="anchor" aria-hidden="true" href="#what-else"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What else?&lt;/h2&gt;
&lt;p&gt;The neural networks found in the exercises are based on the examples provided by &lt;a href="https://keras.io/" rel="nofollow"&gt;keras&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you find that there are errors or missing references, feel free to make a PR or contact me.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Kayzaks</author><guid isPermaLink="false">https://github.com/Kayzaks/HackingNeuralNetworks</guid><pubDate>Wed, 20 Nov 2019 00:03:00 GMT</pubDate></item><item><title>modin-project/modin #4 in Python, Today</title><link>https://github.com/modin-project/modin</link><description>&lt;p&gt;&lt;i&gt;Modin: Speed up your Pandas workflows by changing a single line of code&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;&lt;a href="https://modin.readthedocs.io" rel="nofollow"&gt;&lt;img width="77%" alt="" src="https://github.com/modin-project/modin/raw/3d6368edf311995ad231ec5342a51cd9e4e3dc20/docs/img/MODIN_ver2_hrz.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 align="center"&gt;&lt;a id="user-content-scale-your-pandas-workflows-by-changing-one-line-of-code" class="anchor" aria-hidden="true" href="#scale-your-pandas-workflows-by-changing-one-line-of-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scale your pandas workflows by changing one line of code&lt;/h2&gt;
&lt;p align="center"&gt;
&lt;a href="https://discuss.modin.org" rel="nofollow"&gt;&lt;img alt="" src="https://camo.githubusercontent.com/6cc9f05fe09a8ebcba0aa3f33fdca8309d766b8e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f757273652d666f72756d2d707572706c652e7376673f6c6f676f3d646973636f75727365266c6f676f436f6c6f723d7768697465" align="center" data-canonical-src="https://img.shields.io/badge/discourse-forum-purple.svg?logo=discourse&amp;amp;logoColor=white" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/modin-project/modin" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/88a250fb24777d5d5ed61bb529af58364455c168/68747470733a2f2f636f6465636f762e696f2f67682f6d6f64696e2d70726f6a6563742f6d6f64696e2f6272616e63682f6d61737465722f67726170682f62616467652e737667" align="center" data-canonical-src="https://codecov.io/gh/modin-project/modin/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/modin-project/modin/actions"&gt;&lt;img src="https://github.com/modin-project/modin/workflows/Modin_CI/badge.svg" align="center" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://modin.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img alt="" src="https://camo.githubusercontent.com/0fc8d6d44205d9e22194150d5dd93540476e196a/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6d6f64696e2f62616467652f3f76657273696f6e3d6c6174657374" align="center" data-canonical-src="https://readthedocs.org/projects/modin/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://modin.readthedocs.io/en/latest/pandas_supported.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1b407ae701085ca3e88680f6f5eb24043675c897/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70616e646173253230617069253230636f7665726167652d37312e37372532352d6f72616e67652e737667" align="center" data-canonical-src="https://img.shields.io/badge/pandas%20api%20coverage-71.77%25-orange.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/modin/" rel="nofollow"&gt;&lt;img alt="" src="https://camo.githubusercontent.com/8c41d5714e8c7f91e2b30b58e24991b15e66cc7c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692d302e362e332d626c75652e737667" align="center" data-canonical-src="https://img.shields.io/badge/pypi-0.6.3-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align="center"&gt;&lt;b&gt;To use Modin, replace the pandas import:&lt;/b&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; import pandas as pd&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;p&gt;Modin can be installed from PyPI:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install modin&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you don't have &lt;a href="https://github.com/ray-project/ray"&gt;Ray&lt;/a&gt; or
&lt;a href="https://github.com/dask/dask"&gt;Dask&lt;/a&gt; installed, you will need to install Modin with one
of the targets:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install modin[ray] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Install Modin dependencies and Ray to run on Ray&lt;/span&gt;
pip install modin[dask] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Install Modin dependencies and Dask to run on Dask&lt;/span&gt;
pip install modin[all] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Install all of the above&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Modin will automatically detect which engine you have installed and use that for
scheduling computation!&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-choosing-a-compute-engine" class="anchor" aria-hidden="true" href="#choosing-a-compute-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Choosing a Compute Engine&lt;/h5&gt;
&lt;p&gt;If you want to choose a specific compute engine to run on, you can set the environment
variable &lt;code&gt;MODIN_ENGINE&lt;/code&gt; and Modin will do computation with that engine:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; MODIN_ENGINE=ray  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Ray&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; MODIN_ENGINE=dask  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Dask&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This can also be done within a notebook/interpreter before you import Modin:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; os

os.environ[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MODIN_ENGINE&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;ray&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Ray&lt;/span&gt;
os.environ[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MODIN_ENGINE&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dask&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Modin will use Dask&lt;/span&gt;

&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note: You should not change the engine after you have imported Modin as it will result in undefined behavior&lt;/strong&gt;&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-which-engine-should-i-use" class="anchor" aria-hidden="true" href="#which-engine-should-i-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Which engine should I use?&lt;/h5&gt;
&lt;p&gt;If you are on Windows, you must use Dask. Ray does not support Windows. If you are on
Linux or Mac OS, you can install and use either engine.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-full-documentation" class="anchor" aria-hidden="true" href="#full-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Full Documentation&lt;/h3&gt;
&lt;p&gt;Visit the complete documentation on readthedocs: &lt;a href="https://modin.readthedocs.io" rel="nofollow"&gt;https://modin.readthedocs.io&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-scale-your-pandas-workflow-by-changing-a-single-line-of-code" class="anchor" aria-hidden="true" href="#scale-your-pandas-workflow-by-changing-a-single-line-of-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scale your pandas workflow by changing a single line of code.&lt;/h3&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd
&lt;span class="pl-k"&gt;import&lt;/span&gt; numpy &lt;span class="pl-k"&gt;as&lt;/span&gt; np

frame_data &lt;span class="pl-k"&gt;=&lt;/span&gt; np.random.randint(&lt;span class="pl-c1"&gt;0&lt;/span&gt;, &lt;span class="pl-c1"&gt;100&lt;/span&gt;, &lt;span class="pl-v"&gt;size&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;10&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;&lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-c1"&gt;8&lt;/span&gt;))
df &lt;span class="pl-k"&gt;=&lt;/span&gt; pd.DataFrame(frame_data)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To use Modin, you do not need to know how many cores your system has and you do not need
to  specify how to distribute the data. In fact, you can continue using your previous
pandas notebooks while experiencing a considerable speedup from Modin, even on a single
machine. Once you’ve changed your import statement, you’re ready to use Modin just like
you would pandas.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-faster-pandas-even-on-your-laptop" class="anchor" aria-hidden="true" href="#faster-pandas-even-on-your-laptop"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Faster pandas, even on your laptop&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/modin-project/modin/blob/master/docs/img/read_csv_benchmark.png?raw=true"&gt;&lt;img align="right" height="350" width="300" src="https://github.com/modin-project/modin/raw/master/docs/img/read_csv_benchmark.png?raw=true" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;modin.pandas&lt;/code&gt; DataFrame is an extremely light-weight parallel DataFrame. Modin
transparently distributes the data and computation so that all you need to do is
continue using the pandas API as you were before installing Modin. Unlike other parallel
DataFrame systems, Modin is an extremely light-weight, robust DataFrame. Because it is
so light-weight, Modin provides speed-ups of up to 4x on a laptop with 4 physical cores.&lt;/p&gt;
&lt;p&gt;In pandas, you are only able to use one core at a time when you are doing computation of
any kind. With Modin, you are able to use all of the CPU cores on your machine. Even in
&lt;code&gt;read_csv&lt;/code&gt;, we see large gains by efficiently distributing the work across your entire
machine.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; modin.pandas &lt;span class="pl-k"&gt;as&lt;/span&gt; pd

df &lt;span class="pl-k"&gt;=&lt;/span&gt; pd.read_csv(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;my_dataset.csv&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-modin-is-a-dataframe-designed-for-datasets-from-1mb-to-1tb" class="anchor" aria-hidden="true" href="#modin-is-a-dataframe-designed-for-datasets-from-1mb-to-1tb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Modin is a DataFrame designed for datasets from 1MB to 1TB+&lt;/h4&gt;
&lt;p&gt;We have focused heavily on bridging the solutions between DataFrames for small data
(e.g. pandas) and large data. Often data scientists require different tools for doing
the same thing on different sizes of data. The DataFrame solutions that exist for 1KB do
not scale to 1TB+, and the overheads of the solutions for 1TB+ are too costly for
datasets in the 1KB range. With Modin, because of its light-weight, robust, and scalable
nature, you get a fast DataFrame at small and large data. With preliminary &lt;a href="https://modin.readthedocs.io/en/latest/using_modin.html#using-modin-on-a-cluster" rel="nofollow"&gt;cluster&lt;/a&gt;
and &lt;a href="https://modin.readthedocs.io/en/latest/out_of_core.html" rel="nofollow"&gt;out of core&lt;/a&gt;
support, Modin is a DataFrame library with great single-node performance and high
scalability in a cluster.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-modin-architecture" class="anchor" aria-hidden="true" href="#modin-architecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Modin Architecture&lt;/h4&gt;
&lt;p&gt;We designed Modin to be modular so we can plug in different components as they develop
and improve:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/img/modin_architecture.png"&gt;&lt;img src="docs/img/modin_architecture.png" alt="Architecture" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Visit the &lt;a href="https://modin.readthedocs.io/en/latest/architecture.html" rel="nofollow"&gt;Documentation&lt;/a&gt; for
more information!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;modin.pandas&lt;/code&gt; is currently under active development. Requests and contributions are welcome!&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-more-information-and-getting-involved" class="anchor" aria-hidden="true" href="#more-information-and-getting-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More information and Getting Involved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://modin.readthedocs.io/en/latest/" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ask questions or participate in discussions on our &lt;a href="https://discuss.modin.org" rel="nofollow"&gt;Discourse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Join our mailing list &lt;a href="https://groups.google.com/forum/#!forum/modin-dev" rel="nofollow"&gt;modin-dev@googlegroups.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Submit bug reports to our &lt;a href="https://github.com/modin-project/modin/issues"&gt;GitHub Issues Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Contributions are welcome! Open a &lt;a href="https://github.com/modin-project/modin/pulls"&gt;pull request&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>modin-project</author><guid isPermaLink="false">https://github.com/modin-project/modin</guid><pubDate>Wed, 20 Nov 2019 00:04:00 GMT</pubDate></item><item><title>ct-Open-Source/tuya-convert #5 in Python, Today</title><link>https://github.com/ct-Open-Source/tuya-convert</link><description>&lt;p&gt;&lt;i&gt;A collection of scripts to flash Tuya IoT devices to alternative firmwares&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tuya-convert" class="anchor" aria-hidden="true" href="#tuya-convert"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TUYA-CONVERT&lt;/h1&gt;
&lt;p&gt;A Chinese company named Tuya offers a free-to-brand turnkey smart home solution to anyone. Using their offer is dead-simple, since everything can be done by clicking through the &lt;a href="https://en.tuya.com/" rel="nofollow"&gt;Tuya web page&lt;/a&gt;, from choosing your pre-designed products or pre-programmed wifi-modules (mostly ESP8266) to building your own app. In the end, this has resulted in as they claim over 11 000 devices 'made' by over 10 000 vendors using Tuyas firmware and cloud services.&lt;/p&gt;
&lt;p&gt;Aside from that, they claim their cloud solution has 'military grade security'. Michael Steigerwald, founder of the German IT security startup VTRUST, was able to disprove this claim and presented his results in the "Smart home - Smart hack" talk at 35C3 in Leipzig: &lt;a href="https://media.ccc.de/v/35c3-9723-smart_home_-_smart_hack" rel="nofollow"&gt;https://media.ccc.de/v/35c3-9723-smart_home_-_smart_hack&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the following days, VTRUST and the German tech magazine c't decided to work together. Since reflashing devices using the ESP8266/85 is widespread among DIY smart home enthusiasts, we wanted to provide an easy way for everyone to free their devices from the cloud without the need for a soldering iron.&lt;/p&gt;
&lt;p&gt;Please make sure to visit VTRUST (&lt;a href="https://www.vtrust.de/" rel="nofollow"&gt;https://www.vtrust.de/&lt;/a&gt;), since the hack is their work.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-warning" class="anchor" aria-hidden="true" href="#warning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="rotating_light" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a8.png"&gt;🚨&lt;/g-emoji&gt;WARNING&lt;g-emoji class="g-emoji" alias="rotating_light" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f6a8.png"&gt;🚨&lt;/g-emoji&gt;&lt;/h2&gt;
&lt;p&gt;Please be sure that you understand what you're doing before using this software. Flashing an alternative firmware can lead to unexpected behavior and/or render the device unusable, so that it might be permanently damaged (highly unlikely) or require soldering a serial connection to the processor in order to reflash it (likely).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-️-be-aware-that-you-use-this-software-at-your-own-risk-so-neither-vtrust-nor-ctheise-can-be-held-accountable-for-any-damage-done-or-loss-of-functionality-️" class="anchor" aria-hidden="true" href="#️-be-aware-that-you-use-this-software-at-your-own-risk-so-neither-vtrust-nor-ctheise-can-be-held-accountable-for-any-damage-done-or-loss-of-functionality-️"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png"&gt;⚠️&lt;/g-emoji&gt; Be aware that you use this software at your own risk so neither VTRUST nor c't/heise can be held accountable for any damage done or loss of functionality. &lt;g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png"&gt;⚠️&lt;/g-emoji&gt;&lt;/h3&gt;
&lt;p&gt;TUYA-CONVERT only provides with the means to backup the original and flash an alternative firmware. Please do not ask for hardware support for your favorite alternative firmware in this repository, rather open an issue in the corresponding repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DOCUMENTATION&lt;/h2&gt;
&lt;p&gt;Since Tuya devices are spread around the world with likely a vast amount of different brand names, please tell the community if you find one! There is a device list in the wiki that you can help extend. Please at least add the device model number, brand name, geographical area where you have bought the device and its flash mode (as seen in the device information). Add the GPIO assignments as well if you have found them to save the developers of alternative firmwares some time. Please note that we do not develop or maintain alternative firmwares and so post installation issues should be directed to the respective project.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://asciinema.org/a/2aDZweVGfliwc9TjB1ncwmKvm" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3136d6f61b012a424773993ef2f9b500958a000c/68747470733a2f2f61736369696e656d612e6f72672f612f3261445a77655647666c69776339546a42316e63776d4b766d2e706e67" alt="asciicast" data-canonical-src="https://asciinema.org/a/2aDZweVGfliwc9TjB1ncwmKvm.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;REQUIREMENTS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linux computer with a wifi adapter&lt;/li&gt;
&lt;li&gt;Secondary wifi device (e.g. smartphone)&lt;/li&gt;
&lt;li&gt;Dependencies will be installed by &lt;code&gt;install_prereq.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These scripts were tested in&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kali-Linux 2018.4 in VMWARE&lt;/li&gt;
&lt;li&gt;a Raspberry Pi 3B / 3B+ with Raspbian Stretch and its internal Wifi chip&lt;/li&gt;
&lt;li&gt;a Raspberry Pi 3B+ + USB-WIFI with this image from &lt;a href="https://www.offensive-security.com/kali-linux-arm-images/" rel="nofollow"&gt;here&lt;/a&gt;
&lt;a href="https://images.offensive-security.com/arm-images/kali-linux-2018.4a-rpi3-nexmon-64.img.xz" rel="nofollow"&gt;https://images.offensive-security.com/arm-images/kali-linux-2018.4a-rpi3-nexmon-64.img.xz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any Linux with a Wifi adapter which can act as an Access Point should also work. Please note that we have tested the Raspberry Pi with clean installations only. If you use your Raspberry Pi for anything else, we recommend using another SD card with a clean installation.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-procedure" class="anchor" aria-hidden="true" href="#procedure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PROCEDURE&lt;/h2&gt;
&lt;p&gt;On January 28th, 2019, Tuya started &lt;a href="https://www.heise.de/newsticker/meldung/Smart-Home-Hack-Tuya-veroeffentlicht-Sicherheitsupdate-4292028.html" rel="nofollow"&gt;distributing a patch&lt;/a&gt; that prevented older versions of tuya-convert from completing successfully. We have since developed a work around to enable OTA flashing once again, but there is always the possibility that Tuya will respond with yet another patch. To ensure the best chance of success, &lt;strong&gt;do not connect your device with the official app&lt;/strong&gt; as it may automatically update the device, preventing you from flashing with tuya-convert. It is up to the individual brands to update their firmware, so some devices may be affected sooner than others.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;INSTALLATION&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;# git clone https://github.com/ct-Open-Source/tuya-convert
# cd tuya-convert
# ./install_prereq.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-flash-loader-firmware--backup" class="anchor" aria-hidden="true" href="#flash-loader-firmware--backup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;flash loader firmware + backup&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;# ./start_flash.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Follow the instructions in the start_flash script. It will install our flash loader onto the ESP and connect to the access point created by your wifi adapter.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;WIFI: vtrust-flash
IP: 10.42.42.42
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A backup of the original firmware will be created and stored locally&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-device-information" class="anchor" aria-hidden="true" href="#device-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Device information&lt;/h3&gt;
&lt;p&gt;After the firmware backup procedure, the retrieved device information will be shown.
Please make sure to write down your devices flash mode and size!
You can show this information again by executing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl http://10.42.42.42
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-backup-only-and-undo" class="anchor" aria-hidden="true" href="#backup-only-and-undo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BACKUP only and UNDO&lt;/h3&gt;
&lt;p&gt;You can use the flash loader to create a backup only.
If you want to delete the FLASH loader out of the flash again and go back to the stock software just do following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl http://10.42.42.42/undo
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-flash-loader-to-user2" class="anchor" aria-hidden="true" href="#flash-loader-to-user2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FLASH loader to user2&lt;/h3&gt;
&lt;p&gt;The FLASH loader only allows flashing the third party firmware if the loader is running in the userspace user2 starting from 0x81000.
This will flash the FLASH loader in user2 if it is not already there.
It will destroy your ability to undo and go back to the original firmware&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl http://10.42.42.42/flash2
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-flash-third-party-firmware" class="anchor" aria-hidden="true" href="#flash-third-party-firmware"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FLASH third-party firmware&lt;/h3&gt;
&lt;p&gt;BE SURE THE FIRMWARE FITS YOUR DEVICE!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Place or link your binary file to ./files/thirdparty.bin.&lt;/p&gt;
&lt;p&gt;Currently a Tasmota &lt;a href="https://github.com/arendst/Tasmota/releases"&gt;v7.0.0.3&lt;/a&gt; &lt;code&gt;tasmota-wifiman.bin&lt;/code&gt; build is included. You can update to a &lt;a href="http://thehackbox.org/tasmota" rel="nofollow"&gt;current version&lt;/a&gt; via OTA after the Tuya-Convert process completes successfully. Please note that while we include this for your convenience, we are not affiliated with the Tasmota project and cannot provide support for post installation issues. Please refer to &lt;a href="https://github.com/arendst/Tasmota"&gt;the respective project&lt;/a&gt; for configuration and support.&lt;/p&gt;
&lt;p&gt;An ESPurna &lt;a href="https://github.com/xoseperez/espurna/releases/tag/1.13.5"&gt;1.13.5&lt;/a&gt; binary is also included (&lt;code&gt;espurna-base.bin&lt;/code&gt;). Like before, the binary included does not have any specific hardware defined. Once flashed using Tuya-Convert you can update to the device-specific version via any of the means that ESPurna provides (OTA, web interface update, update via telnet or MQTT). Please refer to the &lt;a href="http://espurna.io" rel="nofollow"&gt;ESPurna project page&lt;/a&gt; for more info and support.&lt;/p&gt;
&lt;p&gt;Binary requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;full binary including first-stage bootloader&lt;/li&gt;
&lt;li&gt;maximum filesize 512KB for first flash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start flashing process&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; # curl http://10.42.42.42/flash3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively you can request a certain file to be requested and flashed by the device:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; # curl http://10.42.42.42/flash3?url=http://10.42.42.1/files/certain_file.bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Initial Configuration&lt;/p&gt;
&lt;p&gt;If you flashed the included Tasmota firmware file, it will broadcast a &lt;code&gt;tasmota-xxxx&lt;/code&gt; access point (AP) when the device boots. Connect to this AP and open the browser to 192.168.4.1 to configure the device's Wi-Fi credentials. When entering the Wi-Fi password, click the checkbox to view the password you enter to ensure that it is correct and that your mobile device has not inadvertently capitalized the first letter if it is supposed to be lower case nor autocorrected what you entered. &lt;del&gt;Double&lt;/del&gt; &lt;strong&gt;Triple check the Wi-Fi credentials&lt;/strong&gt; before clicking &lt;strong&gt;Save&lt;/strong&gt; to apply the settings.&lt;/p&gt;
&lt;p&gt;If you flashed the included ESPurna firmware file, the procedure will be very similar. The device will broadcast a &lt;code&gt;ESPURNA-XXXXXX&lt;/code&gt; access point. You will have to connect to it using the default password: &lt;code&gt;fibonacci&lt;/code&gt;. Once connected open the browser to 192.168.4.1 and follow the initial configuration instructions. Then go to the WIFI tab and configure your home WiFi connection (remember to save) or go to the ADMIN tab to upgrade the firmware to the device-specific image.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CONTRIBUTING&lt;/h2&gt;
&lt;p&gt;This project is currently maintained by Colin Kuebler @kueblc&lt;/p&gt;
&lt;p&gt;Significant time and resources are devoted to supporting and maintaining this project. Research, development, and testing requires obtaining and often breaking IoT devices and related hardware. To help offset costs and support the developers who make this project possible, please consider making a one-time or recurring donation. This allows us to spend less time worrying about putting food on the table and more time making great software accessible to everyone.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.patreon.com/kueblc" rel="nofollow"&gt;Become a Patron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.buymeacoffee.com/kueblc" rel="nofollow"&gt;Buy Me A Coffee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://paypal.me/kueblc" rel="nofollow"&gt;PayPal&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also give back by providing or improving documentation, tutorials, issue support, bug reports, feature requests, and pull requests. When planning to contribute major code changes, please post your intention beforehand so we can coordinate, avoid redundant contributions and ensure the changes match project philosophy. Any major PR should be made against the &lt;code&gt;development&lt;/code&gt; branch.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-related-works" class="anchor" aria-hidden="true" href="#related-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RELATED WORKS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/codetheweb/tuyapi"&gt;TuyAPI&lt;/a&gt; NPM library for LAN control of Tuya devices with stock firmware&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SynAckFin/TuyOTA"&gt;TuyOTA&lt;/a&gt; Perl based Tuya flashing script using a similar strategy&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kueblc/mocktuyacloud"&gt;MockTuyaCloud&lt;/a&gt; Framework replicating much of the Tuya cloud functionality&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ct-Open-Source</author><guid isPermaLink="false">https://github.com/ct-Open-Source/tuya-convert</guid><pubDate>Wed, 20 Nov 2019 00:05:00 GMT</pubDate></item><item><title>tensorflow/models #6 in Python, Today</title><link>https://github.com/tensorflow/models</link><description>&lt;p&gt;&lt;i&gt;Models and examples built with TensorFlow&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-models" class="anchor" aria-hidden="true" href="#tensorflow-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow Models&lt;/h1&gt;
&lt;p&gt;This repository contains a number of different models implemented in &lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;The &lt;a href="official"&gt;official models&lt;/a&gt; are a collection of example models that use TensorFlow's high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest stable TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read. We especially recommend newer TensorFlow users to start here.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/tensorflow/models/tree/master/research"&gt;research models&lt;/a&gt; are a large collection of models implemented in TensorFlow by researchers. They are not officially supported or available in release branches; it is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.&lt;/p&gt;
&lt;p&gt;The &lt;a href="samples"&gt;samples folder&lt;/a&gt; contains code snippets and smaller models that demonstrate features of TensorFlow, including code presented in various blog posts.&lt;/p&gt;
&lt;p&gt;The &lt;a href="tutorials"&gt;tutorials folder&lt;/a&gt; is a collection of models described in the &lt;a href="https://www.tensorflow.org/tutorials/" rel="nofollow"&gt;TensorFlow tutorials&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to models, be sure to review the &lt;a href="CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tensorflow</author><guid isPermaLink="false">https://github.com/tensorflow/models</guid><pubDate>Wed, 20 Nov 2019 00:06:00 GMT</pubDate></item><item><title>streamlit/streamlit #7 in Python, Today</title><link>https://github.com/streamlit/streamlit</link><description>&lt;p&gt;&lt;i&gt;Streamlit — The fastest way to build custom ML tools&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-welcome-to-streamlit-wave" class="anchor" aria-hidden="true" href="#welcome-to-streamlit-wave"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to Streamlit &lt;g-emoji class="g-emoji" alias="wave" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44b.png"&gt;👋&lt;/g-emoji&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The fastest way to build custom ML tools.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Streamlit lets you create apps for your machine learning projects with deceptively simple Python scripts. It supports hot-reloading, so your app updates live as you edit and save your file. No need to mess with HTTP requests, HTML, JavaScript, etc. All you need is your favorite editor and a browser. Take a look at Streamlit in action:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5ae1dcfd188be26bbb0648fb62e9d6d593dbb6f5/68747470733a2f2f617773312e646973636f757273652d63646e2e636f6d2f7374616e6461726431302f75706c6f6164732f73747265616d6c69742f6f726967696e616c2f31582f323932653938356637663735656637626566386332376235383939663731663736636435373765302e676966"&gt;&lt;img src="https://camo.githubusercontent.com/5ae1dcfd188be26bbb0648fb62e9d6d593dbb6f5/68747470733a2f2f617773312e646973636f757273652d63646e2e636f6d2f7374616e6461726431302f75706c6f6164732f73747265616d6c69742f6f726967696e616c2f31582f323932653938356637663735656637626566386332376235383939663731663736636435373765302e676966" alt="Example of live coding a dashboard in Streamlit|635x380" data-canonical-src="https://aws1.discourse-cdn.com/standard10/uploads/streamlit/original/1X/292e985f7f75ef7bef8c27b5899f71f76cd577e0.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check out our &lt;a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace" rel="nofollow"&gt;launch blog post&lt;/a&gt;!!&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install streamlit
streamlit hello&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;p&gt;Streamlit lets you build interactive apps ridiculously easily:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; streamlit &lt;span class="pl-k"&gt;as&lt;/span&gt; st

x &lt;span class="pl-k"&gt;=&lt;/span&gt; st.slider(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Select a value&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
st.write(x, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;squared is&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, x &lt;span class="pl-k"&gt;*&lt;/span&gt; x)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1e18efff3f06946e9d1559712cea0cb76364f004/68747470733a2f2f73747265616d6c69742d64656d6f2d646174612e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f737175617265642d696d6167652d666f722d6769746875622d726561646d652d322e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1e18efff3f06946e9d1559712cea0cb76364f004/68747470733a2f2f73747265616d6c69742d64656d6f2d646174612e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f737175617265642d696d6167652d666f722d6769746875622d726561646d652d322e706e67" width="490/" data-canonical-src="https://streamlit-demo-data.s3-us-west-2.amazonaws.com/squared-image-for-github-readme-2.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-a-bigger-example" class="anchor" aria-hidden="true" href="#a-bigger-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Bigger Example&lt;/h2&gt;
&lt;p&gt;Despite its simplicity Streamlit lets you build incredibly rich and powerful tools. &lt;a href="https://github.com/streamlit/demo-self-driving"&gt;This demo project&lt;/a&gt; lets you browse the entire &lt;a href="https://github.com/udacity/self-driving-car"&gt;Udacity self-driving-car dataset&lt;/a&gt; and run inference in real time using the &lt;a href="https://pjreddie.com/darknet/yolo" rel="nofollow"&gt;YOLO object detection net&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/streamlit/demo-self-driving/master/av_final_optimized.gif"&gt;&lt;img src="https://raw.githubusercontent.com/streamlit/demo-self-driving/master/av_final_optimized.gif" alt="Making-of Animation" title="Making-of Animation" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The complete demo is implemented in less than 300 lines of Python. In fact, the app contains &lt;a href="https://github.com/streamlit/demo-self-driving/blob/master/app.py"&gt;only 23 Streamlit calls&lt;/a&gt; which illustrates all the major building blocks of Streamlit. You can try it right now with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install --upgrade streamlit opencv-python
streamlit run https://raw.githubusercontent.com/streamlit/demo-self-driving/master/app.py&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-more-information" class="anchor" aria-hidden="true" href="#more-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Our &lt;a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace" rel="nofollow"&gt;launch post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Our lovely &lt;a href="https://discuss.streamlit.io/" rel="nofollow"&gt;community&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Streamlit &lt;a href="https://streamlit.io/docs" rel="nofollow"&gt;documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More &lt;a href="https://github.com/streamlit/"&gt;demo projects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If you would like to contribute, see &lt;a href="https://github.com/streamlit/streamlit/wiki/Contributing"&gt;instructions here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-streamlit-for-teams" class="anchor" aria-hidden="true" href="#streamlit-for-teams"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Streamlit for Teams&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://streamlit.io/forteams/" rel="nofollow"&gt;Streamlit for Teams&lt;/a&gt; is our enterprise edition, with single-click deploy, authentication, web editing, versioning, and more. Please contact us if you would like to learn more.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Streamlit is completely free and open source and licensed under the &lt;a href="https://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;Apache 2.0&lt;/a&gt; license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>streamlit</author><guid isPermaLink="false">https://github.com/streamlit/streamlit</guid><pubDate>Wed, 20 Nov 2019 00:07:00 GMT</pubDate></item><item><title>eastlakeside/interpy-zh #8 in Python, Today</title><link>https://github.com/eastlakeside/interpy-zh</link><description>&lt;p&gt;&lt;i&gt;📘《Python进阶》（Intermediate Python 中文版）&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-python进阶" class="anchor" aria-hidden="true" href="#python进阶"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python进阶&lt;/h1&gt;
&lt;p&gt;《Python进阶》是《Intermediate Python》的中文译本, 谨以此献给进击的 Python 和 Python 程序员们!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-快速阅读传送门" class="anchor" aria-hidden="true" href="#快速阅读传送门"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;快速阅读传送门&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Github快速阅读任一章节：&lt;a href="https://github.com/eastlakeside/interpy-zh/blob/master/SUMMARY.md"&gt;进入目录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gitbook完整顺序地阅读：&lt;a href="https://eastlakeside.gitbooks.io/interpy-zh/content/" rel="nofollow"&gt;进入Gitbook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;本地或kindle上阅读：&lt;a href="https://github.com/eastlakeside/interpy-zh/releases"&gt;下载pdf/epub/mobi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;国内推荐镜像（实时同步）：&lt;a href="http://wiki.jikexueyuan.com/project/interpy-zh/" rel="nofollow"&gt;极客学院收录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;其他镜像（不定期同步）：&lt;a href="http://docs.pythontab.com/interpy/" rel="nofollow"&gt;Pythontab收录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;纯代码阅读和演示：&lt;a href="https://github.com/eastlakeside/interpy-zh/tree/master/code/"&gt;进入code目录&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-前言" class="anchor" aria-hidden="true" href="#前言"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;前言&lt;/h1&gt;
&lt;p&gt;Python，作为一个"老练"、"小清新"的开发语言，已受到广大才男俊女的喜爱。我们也从最基础的Python粉，经过时间的摧残慢慢的变成了Python老鬼。&lt;/p&gt;
&lt;p&gt;IntermediatePython这本书具有如下几个优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;简单&lt;/li&gt;
&lt;li&gt;易读&lt;/li&gt;
&lt;li&gt;易译&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些都不是重点，重点是：&lt;strong&gt;它是一本开脑洞的书&lt;/strong&gt;。无论你是Python初学者，还是Python高手，它显现给你的永远是Python里最美好的事物。&lt;/p&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;世上语言千万种
美好事物藏其中&lt;/p&gt;
&lt;p&gt;译者在翻译过程中，慢慢发现，本书作者的行文方式有着科普作家的风范，--那就是能将晦涩难懂的技术用比较清晰简洁的方式进行呈现，深入浅出的风格在每个章节的讨论中都得到了体现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个章节都非常精简，5分钟就能看完，用最简洁的例子精辟地展现了原理&lt;/li&gt;
&lt;li&gt;每个章节都会通过疑问，来引导读者主动思考答案&lt;/li&gt;
&lt;li&gt;每个章节都引导读者做延伸阅读，让有兴趣的读者能进一步举一反三&lt;/li&gt;
&lt;li&gt;每个章节都是独立的，你可以挑选任意的章节开始阅读，而不受影响&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总之，这本书非常方便随时选取一个章节进行阅读，而且每次阅读一个章节，你都可能会有一些新的发现。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-原书作者" class="anchor" aria-hidden="true" href="#原书作者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;原书作者&lt;/h2&gt;
&lt;p&gt;感谢英文原著作者 @yasoob《&lt;a href="https://github.com/yasoob/intermediatePython"&gt;Intermediate Python&lt;/a&gt;》，有了他才有了这里的一切&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-译者" class="anchor" aria-hidden="true" href="#译者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;译者&lt;/h2&gt;
&lt;p&gt;总顾问+审校: 刘宇 @liuyu&lt;br&gt;
主译: PyCon老高 @spawnris&lt;br&gt;
主译: 大牙matt @suqi&lt;br&gt;
参译: 明源 @muxueqz&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-欢迎建议指正或直接贡献代码" class="anchor" aria-hidden="true" href="#欢迎建议指正或直接贡献代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;欢迎建议指正或直接贡献代码&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/eastlakeside/interpy-zh/issues"&gt;https://github.com/eastlakeside/interpy-zh/issues&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-微信交流群" class="anchor" aria-hidden="true" href="#微信交流群"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;微信交流群&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/096898f5a8cad462c01aee9847014e43413a86a7/687474703a2f2f77656978696e2e71712e636f6d2f6367692d62696e2f7172636f64653f747970653d75736572266172673d6a6876364e344d494b3949444734457361576d6e786d4e65785675423233253246685036305662765573524538253344"&gt;&lt;img src="https://camo.githubusercontent.com/096898f5a8cad462c01aee9847014e43413a86a7/687474703a2f2f77656978696e2e71712e636f6d2f6367692d62696e2f7172636f64653f747970653d75736572266172673d6a6876364e344d494b3949444734457361576d6e786d4e65785675423233253246685036305662765573524538253344" alt="微信群" data-canonical-src="http://weixin.qq.com/cgi-bin/qrcode?type=user&amp;amp;arg=jhv6N4MIK9IDG4EsaWmnxmNexVuB23%2FhP60VbvUsRE8%3D" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-微信打赏支持" class="anchor" aria-hidden="true" href="#微信打赏支持"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;微信打赏支持：&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="__img/donate.png"&gt;&lt;img src="__img/donate.png" alt="wechat_donate" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>eastlakeside</author><guid isPermaLink="false">https://github.com/eastlakeside/interpy-zh</guid><pubDate>Wed, 20 Nov 2019 00:08:00 GMT</pubDate></item><item><title>donnemartin/system-design-primer #9 in Python, Today</title><link>https://github.com/donnemartin/system-design-primer</link><description>&lt;p&gt;&lt;i&gt;Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;em&gt;&lt;a href="README.md"&gt;English&lt;/a&gt; ∙ &lt;a href="README-ja.md"&gt;日本語&lt;/a&gt; ∙ &lt;a href="README-zh-Hans.md"&gt;简体中文&lt;/a&gt; ∙ &lt;a href="README-zh-TW.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/170"&gt;العَرَبِيَّة‎&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/220"&gt;বাংলা&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/40"&gt;Português do Brasil&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/186"&gt;Deutsch&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/130"&gt;ελληνικά&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/272"&gt;עברית&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/104"&gt;Italiano&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/102"&gt;韓國語&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/110"&gt;فارسی&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/68"&gt;Polski&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/87"&gt;русский язык&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/136"&gt;Español&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/187"&gt;ภาษาไทย&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/39"&gt;Türkçe&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/127"&gt;tiếng Việt&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/250"&gt;Français&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-the-system-design-primer" class="anchor" aria-hidden="true" href="#the-system-design-primer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The System Design Primer&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67" data-canonical-src="http://i.imgur.com/jj3A5N8.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt;
&lt;p&gt;Prep for the system design interview.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-learn-how-to-design-large-scale-systems" class="anchor" aria-hidden="true" href="#learn-how-to-design-large-scale-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn how to design large-scale systems&lt;/h3&gt;
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt;
&lt;p&gt;System design is a broad topic.  There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt;
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learn-from-the-open-source-community" class="anchor" aria-hidden="true" href="#learn-from-the-open-source-community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn from the open source community&lt;/h3&gt;
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt;
&lt;p&gt;&lt;a href="#contributing"&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-prep-for-the-system-design-interview" class="anchor" aria-hidden="true" href="#prep-for-the-system-design-interview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prep for the system design interview&lt;/h3&gt;
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#study-guide"&gt;Study guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-anki-flashcards" class="anchor" aria-hidden="true" href="#anki-flashcards"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Anki flashcards&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/75b5cf737556050871218226ea211256f19f3a40/687474703a2f2f692e696d6775722e636f6d2f7a6443416b42332e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/75b5cf737556050871218226ea211256f19f3a40/687474703a2f2f692e696d6775722e636f6d2f7a6443416b42332e706e67" data-canonical-src="http://i.imgur.com/zdCAkB3.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;The provided &lt;a href="https://apps.ankiweb.net/" rel="nofollow"&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg"&gt;System design deck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg"&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg"&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-coding-resource-interactive-coding-challenges" class="anchor" aria-hidden="true" href="#coding-resource-interactive-coding-challenges"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt;
&lt;p&gt;Looking for resources to help you prep for the &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/473700c20356af5875155f24d3a26b57ae940bdc/687474703a2f2f692e696d6775722e636f6d2f6234597441454e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/473700c20356af5875155f24d3a26b57ae940bdc/687474703a2f2f692e696d6775722e636f6d2f6234597441454e2e706e67" data-canonical-src="http://i.imgur.com/b4YtAEN.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;Check out the sister repo &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg"&gt;Coding deck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn from the community.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fix errors&lt;/li&gt;
&lt;li&gt;Improve sections&lt;/li&gt;
&lt;li&gt;Add new sections&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Translate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Content that needs some polishing is placed &lt;a href="#under-development"&gt;under development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Review the &lt;a href="CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-index-of-system-design-topics" class="anchor" aria-hidden="true" href="#index-of-system-design-topics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index of system design topics&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Summaries of various system design topics, including pros and cons.  &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67" data-canonical-src="http://i.imgur.com/jrUBAF7.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#system-design-topics-start-here"&gt;System design topics: start here&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#step-1-review-the-scalability-video-lecture"&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#step-2-review-the-scalability-article"&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#next-steps"&gt;Next steps&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#performance-vs-scalability"&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-vs-throughput"&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-vs-consistency"&gt;Availability vs consistency&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cap-theorem"&gt;CAP theorem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cp---consistency-and-partition-tolerance"&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ap---availability-and-partition-tolerance"&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#consistency-patterns"&gt;Consistency patterns&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#weak-consistency"&gt;Weak consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eventual-consistency"&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#strong-consistency"&gt;Strong consistency&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-patterns"&gt;Availability patterns&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#fail-over"&gt;Fail-over&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#replication"&gt;Replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-in-numbers"&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#domain-name-system"&gt;Domain name system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#content-delivery-network"&gt;Content delivery network&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#push-cdns"&gt;Push CDNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pull-cdns"&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#load-balancer"&gt;Load balancer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#active-passive"&gt;Active-passive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#active-active"&gt;Active-active&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-4-load-balancing"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-7-load-balancing"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#horizontal-scaling"&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#reverse-proxy-web-server"&gt;Reverse proxy (web server)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#load-balancer-vs-reverse-proxy"&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#application-layer"&gt;Application layer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#microservices"&gt;Microservices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#service-discovery"&gt;Service discovery&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#database"&gt;Database&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#relational-database-management-system-rdbms"&gt;Relational database management system (RDBMS)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sharding"&gt;Sharding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sql-tuning"&gt;SQL tuning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#nosql"&gt;NoSQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#key-value-store"&gt;Key-value store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#document-store"&gt;Document store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wide-column-store"&gt;Wide column store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#graph-database"&gt;Graph Database&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#cache"&gt;Cache&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#client-caching"&gt;Client caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cdn-caching"&gt;CDN caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-server-caching"&gt;Web server caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database-caching"&gt;Database caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#application-caching"&gt;Application caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching-at-the-database-query-level"&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching-at-the-object-level"&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#when-to-update-the-cache"&gt;When to update the cache&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cache-aside"&gt;Cache-aside&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#write-through"&gt;Write-through&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#write-behind-write-back"&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#refresh-ahead"&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#asynchronism"&gt;Asynchronism&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#message-queues"&gt;Message queues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#task-queues"&gt;Task queues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#back-pressure"&gt;Back pressure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#communication"&gt;Communication&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#transmission-control-protocol-tcp"&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#user-datagram-protocol-udp"&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#remote-procedure-call-rpc"&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#representational-state-transfer-rest"&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#security"&gt;Security&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#appendix"&gt;Appendix&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#company-architectures"&gt;Company architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#under-development"&gt;Under development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#credits"&gt;Credits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact-info"&gt;Contact info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-study-guide" class="anchor" aria-hidden="true" href="#study-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Study guide&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eb92600aa3bb1314b33edd0204da8428d4d3a493/687474703a2f2f692e696d6775722e636f6d2f4f66566c6c65782e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/eb92600aa3bb1314b33edd0204da8428d4d3a493/687474703a2f2f692e696d6775722e636f6d2f4f66566c6c65782e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/OfVllex.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A: No, you don't need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How much experience you have&lt;/li&gt;
&lt;li&gt;What your technical background is&lt;/li&gt;
&lt;li&gt;What positions you are interviewing for&lt;/li&gt;
&lt;li&gt;Which companies you are interviewing with&lt;/li&gt;
&lt;li&gt;Luck&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More experienced candidates are generally expected to know more about system design.  Architects or team leads might be expected to know more than individual contributors.  Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt;
&lt;p&gt;Start broad and go deeper in a few areas.  It helps to know a little about various key system design topics.  Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Short&lt;/th&gt;
&lt;th&gt;Medium&lt;/th&gt;
&lt;th&gt;Long&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Read through the &lt;a href="#index-of-system-design-topics"&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read through a few articles in the &lt;a href="#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read through a few &lt;a href="#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Review &lt;a href="#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Work through &lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Work through &lt;a href="#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Review &lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-approach-a-system-design-interview-question" class="anchor" aria-hidden="true" href="#how-to-approach-a-system-design-interview-question"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to approach a system design interview question&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;How to tackle a system design interview question.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;.  You are expected to lead it.&lt;/p&gt;
&lt;p&gt;You can use the following steps to guide the discussion.  To help solidify this process, work through the &lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-outline-use-cases-constraints-and-assumptions" class="anchor" aria-hidden="true" href="#step-1-outline-use-cases-constraints-and-assumptions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt;
&lt;p&gt;Gather requirements and scope the problem.  Ask questions to clarify use cases and constraints.  Discuss assumptions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who is going to use it?&lt;/li&gt;
&lt;li&gt;How are they going to use it?&lt;/li&gt;
&lt;li&gt;How many users are there?&lt;/li&gt;
&lt;li&gt;What does the system do?&lt;/li&gt;
&lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt;
&lt;li&gt;How much data do we expect to handle?&lt;/li&gt;
&lt;li&gt;How many requests per second do we expect?&lt;/li&gt;
&lt;li&gt;What is the expected read to write ratio?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-create-a-high-level-design" class="anchor" aria-hidden="true" href="#step-2-create-a-high-level-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2: Create a high level design&lt;/h3&gt;
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sketch the main components and connections&lt;/li&gt;
&lt;li&gt;Justify your ideas&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-3-design-core-components" class="anchor" aria-hidden="true" href="#step-3-design-core-components"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3: Design core components&lt;/h3&gt;
&lt;p&gt;Dive into details for each core component.  For example, if you were asked to &lt;a href="solutions/system_design/pastebin/README.md"&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generating and storing a hash of the full url
&lt;ul&gt;
&lt;li&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;MD5&lt;/a&gt; and &lt;a href="solutions/system_design/pastebin/README.md"&gt;Base62&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hash collisions&lt;/li&gt;
&lt;li&gt;SQL or NoSQL&lt;/li&gt;
&lt;li&gt;Database schema&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Translating a hashed url to the full url
&lt;ul&gt;
&lt;li&gt;Database lookup&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API and object-oriented design&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-4-scale-the-design" class="anchor" aria-hidden="true" href="#step-4-scale-the-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 4: Scale the design&lt;/h3&gt;
&lt;p&gt;Identify and address bottlenecks, given the constraints.  For example, do you need the following to address scalability issues?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Load balancer&lt;/li&gt;
&lt;li&gt;Horizontal scaling&lt;/li&gt;
&lt;li&gt;Caching&lt;/li&gt;
&lt;li&gt;Database sharding&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Discuss potential solutions and trade-offs.  Everything is a trade-off.  Address bottlenecks using &lt;a href="#index-of-system-design-topics"&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-back-of-the-envelope-calculations" class="anchor" aria-hidden="true" href="#back-of-the-envelope-calculations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Back-of-the-envelope calculations&lt;/h3&gt;
&lt;p&gt;You might be asked to do some estimates by hand.  Refer to the &lt;a href="#appendix"&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html" rel="nofollow"&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading" class="anchor" aria-hidden="true" href="#sources-and-further-reading"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/" rel="nofollow"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design" rel="nofollow"&gt;The system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZgdS0EUmn70" rel="nofollow"&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-system-design-interview-questions-with-solutions" class="anchor" aria-hidden="true" href="#system-design-interview-questions-with-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System design interview questions with solutions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/twitter/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a web crawler&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/web_crawler/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Mint.com&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/mint/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the data structures for a social network&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/social_graph/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a key-value store for a search engine&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/query_cache/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Amazon's sales ranking by category feature&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/sales_rank/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/scaling_aws/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add a system design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-design-pastebincom-or-bitly" class="anchor" aria-hidden="true" href="#design-pastebincom-or-bitly"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4aee2d26ebedc20e7fa07a2c30780e332fa29f2c/687474703a2f2f692e696d6775722e636f6d2f346564584730542e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/4aee2d26ebedc20e7fa07a2c30780e332fa29f2c/687474703a2f2f692e696d6775722e636f6d2f346564584730542e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/4edXG0T.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-the-twitter-timeline-and-search-or-facebook-feed-and-search" class="anchor" aria-hidden="true" href="#design-the-twitter-timeline-and-search-or-facebook-feed-and-search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/twitter/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/jrUBAF7.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-web-crawler" class="anchor" aria-hidden="true" href="#design-a-web-crawler"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a web crawler&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/web_crawler/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba21a95852d1cf7bb64c8c4622a79d1d5a20d344/687474703a2f2f692e696d6775722e636f6d2f625778507451412e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba21a95852d1cf7bb64c8c4622a79d1d5a20d344/687474703a2f2f692e696d6775722e636f6d2f625778507451412e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/bWxPtQA.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-mintcom" class="anchor" aria-hidden="true" href="#design-mintcom"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Mint.com&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/mint/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/12fea5f9324f74189a9cd983b02239c68615b67e/687474703a2f2f692e696d6775722e636f6d2f563571353776552e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/12fea5f9324f74189a9cd983b02239c68615b67e/687474703a2f2f692e696d6775722e636f6d2f563571353776552e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/V5q57vU.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-the-data-structures-for-a-social-network" class="anchor" aria-hidden="true" href="#design-the-data-structures-for-a-social-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design the data structures for a social network&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/social_graph/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/16d78e51c2e2949e23122f4c26afe5886f82a96f/687474703a2f2f692e696d6775722e636f6d2f636443763567372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/16d78e51c2e2949e23122f4c26afe5886f82a96f/687474703a2f2f692e696d6775722e636f6d2f636443763567372e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/cdCv5g7.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-key-value-store-for-a-search-engine" class="anchor" aria-hidden="true" href="#design-a-key-value-store-for-a-search-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a key-value store for a search engine&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/query_cache/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b6439861687b9a0fc62d0149a364082643ebaf86/687474703a2f2f692e696d6775722e636f6d2f346a39396d68652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b6439861687b9a0fc62d0149a364082643ebaf86/687474703a2f2f692e696d6775722e636f6d2f346a39396d68652e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/4j99mhe.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-amazons-sales-ranking-by-category-feature" class="anchor" aria-hidden="true" href="#design-amazons-sales-ranking-by-category-feature"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Amazon's sales ranking by category feature&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/sales_rank/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a56f5600f7ae29dc0c2e436b8e4e4b55c44d6894/687474703a2f2f692e696d6775722e636f6d2f4d7a45785030362e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a56f5600f7ae29dc0c2e436b8e4e4b55c44d6894/687474703a2f2f692e696d6775722e636f6d2f4d7a45785030362e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/MzExP06.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-system-that-scales-to-millions-of-users-on-aws" class="anchor" aria-hidden="true" href="#design-a-system-that-scales-to-millions-of-users-on-aws"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/scaling_aws/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/jj3A5N8.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-object-oriented-design-interview-questions-with-solutions" class="anchor" aria-hidden="true" href="#object-oriented-design-interview-questions-with-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Object-oriented design interview questions with solutions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design a hash map&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/hash_table/hash_map.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a least recently used cache&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/lru_cache/lru_cache.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a call center&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/call_center/call_center.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a deck of cards&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a parking lot&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/parking_lot/parking_lot.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a chat server&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/online_chat/online_chat.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a circular array&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add an object-oriented design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-system-design-topics-start-here" class="anchor" aria-hidden="true" href="#system-design-topics-start-here"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System design topics: start here&lt;/h2&gt;
&lt;p&gt;New to system design?&lt;/p&gt;
&lt;p&gt;First, you'll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-review-the-scalability-video-lecture" class="anchor" aria-hidden="true" href="#step-1-review-the-scalability-video-lecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Review the scalability video lecture&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4" rel="nofollow"&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topics covered:
&lt;ul&gt;
&lt;li&gt;Vertical scaling&lt;/li&gt;
&lt;li&gt;Horizontal scaling&lt;/li&gt;
&lt;li&gt;Caching&lt;/li&gt;
&lt;li&gt;Load balancing&lt;/li&gt;
&lt;li&gt;Database replication&lt;/li&gt;
&lt;li&gt;Database partitioning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-review-the-scalability-article" class="anchor" aria-hidden="true" href="#step-2-review-the-scalability-article"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2: Review the scalability article&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.lecloud.net/tagged/scalability/chrono" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topics covered:
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones" rel="nofollow"&gt;Clones&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database" rel="nofollow"&gt;Databases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache" rel="nofollow"&gt;Caches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism" rel="nofollow"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-next-steps" class="anchor" aria-hidden="true" href="#next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next steps&lt;/h3&gt;
&lt;p&gt;Next, we'll look at high-level trade-offs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Then we'll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-performance-vs-scalability" class="anchor" aria-hidden="true" href="#performance-vs-scalability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance vs scalability&lt;/h2&gt;
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html" rel="nofollow"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt;
&lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-1" class="anchor" aria-hidden="true" href="#sources-and-further-reading-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html" rel="nofollow"&gt;A word on scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-latency-vs-throughput" class="anchor" aria-hidden="true" href="#latency-vs-throughput"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency vs throughput&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt;
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-2" class="anchor" aria-hidden="true" href="#sources-and-further-reading-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://community.cadence.com/cadence_blogs_8/b/sd/archive/2010/09/13/understanding-latency-vs-throughput" rel="nofollow"&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-availability-vs-consistency" class="anchor" aria-hidden="true" href="#availability-vs-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability vs consistency&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-cap-theorem" class="anchor" aria-hidden="true" href="#cap-theorem"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CAP theorem&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/13719354da7dcd34cd79ff5f8b6306a67bc18261/687474703a2f2f692e696d6775722e636f6d2f62674c4d4932752e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/13719354da7dcd34cd79ff5f8b6306a67bc18261/687474703a2f2f692e696d6775722e636f6d2f62674c4d4932752e706e67" data-canonical-src="http://i.imgur.com/bgLMI2u.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited" rel="nofollow"&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Networks aren't reliable, so you'll need to support partition tolerance.  You'll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-cp---consistency-and-partition-tolerance" class="anchor" aria-hidden="true" href="#cp---consistency-and-partition-tolerance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CP - consistency and partition tolerance&lt;/h4&gt;
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error.  CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-ap---availability-and-partition-tolerance" class="anchor" aria-hidden="true" href="#ap---availability-and-partition-tolerance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AP - availability and partition tolerance&lt;/h4&gt;
&lt;p&gt;Responses return the most recent version of the data available on a node, which might not be the latest.  Writes might take some time to propagate when the partition is resolved.&lt;/p&gt;
&lt;p&gt;AP is a good choice if the business needs allow for &lt;a href="#eventual-consistency"&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-3" class="anchor" aria-hidden="true" href="#sources-and-further-reading-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/" rel="nofollow"&gt;CAP theorem revisited&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem/" rel="nofollow"&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/henryr/cap-faq"&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-consistency-patterns" class="anchor" aria-hidden="true" href="#consistency-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Consistency patterns&lt;/h2&gt;
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data.  Recall the definition of consistency from the &lt;a href="#cap-theorem"&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-weak-consistency" class="anchor" aria-hidden="true" href="#weak-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Weak consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads may or may not see it.  A best effort approach is taken.&lt;/p&gt;
&lt;p&gt;This approach is seen in systems such as memcached.  Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games.  For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-eventual-consistency" class="anchor" aria-hidden="true" href="#eventual-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eventual consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds).  Data is replicated asynchronously.&lt;/p&gt;
&lt;p&gt;This approach is seen in systems such as DNS and email.  Eventual consistency works well in highly available systems.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-strong-consistency" class="anchor" aria-hidden="true" href="#strong-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Strong consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads will see it.  Data is replicated synchronously.&lt;/p&gt;
&lt;p&gt;This approach is seen in file systems and RDBMSes.  Strong consistency works well in systems that need transactions.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-4" class="anchor" aria-hidden="true" href="#sources-and-further-reading-4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://snarfed.org/transactions_across_datacenters_io.html" rel="nofollow"&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-availability-patterns" class="anchor" aria-hidden="true" href="#availability-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability patterns&lt;/h2&gt;
&lt;p&gt;There are two main patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-fail-over" class="anchor" aria-hidden="true" href="#fail-over"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fail-over&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-active-passive" class="anchor" aria-hidden="true" href="#active-passive"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Active-passive&lt;/h4&gt;
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby.  If the heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.&lt;/p&gt;
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in 'hot' standby or whether it needs to start up from 'cold' standby.  Only the active server handles traffic.&lt;/p&gt;
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-active-active" class="anchor" aria-hidden="true" href="#active-active"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Active-active&lt;/h4&gt;
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt;
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers.  If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt;
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-failover" class="anchor" aria-hidden="true" href="#disadvantages-failover"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): failover&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt;
&lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-replication" class="anchor" aria-hidden="true" href="#replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Replication&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-master-slave-and-master-master" class="anchor" aria-hidden="true" href="#master-slave-and-master-master"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-slave and master-master&lt;/h4&gt;
&lt;p&gt;This topic is further discussed in the &lt;a href="#database"&gt;Database&lt;/a&gt; section:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-availability-in-numbers" class="anchor" aria-hidden="true" href="#availability-in-numbers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability in numbers&lt;/h3&gt;
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available.  Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-999-availability---three-9s" class="anchor" aria-hidden="true" href="#999-availability---three-9s"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;99.9% availability - three 9s&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Acceptable downtime&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per year&lt;/td&gt;
&lt;td&gt;8h 45min 57s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per month&lt;/td&gt;
&lt;td&gt;43m 49.7s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per week&lt;/td&gt;
&lt;td&gt;10m 4.8s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per day&lt;/td&gt;
&lt;td&gt;1m 26.4s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-9999-availability---four-9s" class="anchor" aria-hidden="true" href="#9999-availability---four-9s"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;99.99% availability - four 9s&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Acceptable downtime&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per year&lt;/td&gt;
&lt;td&gt;52min 35.7s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per month&lt;/td&gt;
&lt;td&gt;4m 23s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per week&lt;/td&gt;
&lt;td&gt;1m 5s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per day&lt;/td&gt;
&lt;td&gt;8.6s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-availability-in-parallel-vs-in-sequence" class="anchor" aria-hidden="true" href="#availability-in-parallel-vs-in-sequence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability in parallel vs in sequence&lt;/h4&gt;
&lt;p&gt;If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt;
&lt;h6&gt;&lt;a id="user-content-in-sequence" class="anchor" aria-hidden="true" href="#in-sequence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In sequence&lt;/h6&gt;
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt;
&lt;h6&gt;&lt;a id="user-content-in-parallel" class="anchor" aria-hidden="true" href="#in-parallel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In parallel&lt;/h6&gt;
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-domain-name-system" class="anchor" aria-hidden="true" href="#domain-name-system"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Domain name system&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fae27d1291ed38dd120595d692eacd2505cd3a9c/687474703a2f2f692e696d6775722e636f6d2f494f794c6a34692e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/fae27d1291ed38dd120595d692eacd2505cd3a9c/687474703a2f2f692e696d6775722e636f6d2f494f794c6a34692e6a7067" data-canonical-src="http://i.imgur.com/IOyLj4i.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/srikrupa5/dns-security-presentation-issa" rel="nofollow"&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href="http://www.example.com" rel="nofollow"&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt;
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level.  Your router or ISP provides information about which DNS server(s) to contact when doing a lookup.  Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays.  DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href="https://en.wikipedia.org/wiki/Time_to_live" rel="nofollow"&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href="http://www.example.com" rel="nofollow"&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Services such as &lt;a href="https://www.cloudflare.com/dns/" rel="nofollow"&gt;CloudFlare&lt;/a&gt; and &lt;a href="https://aws.amazon.com/route53/" rel="nofollow"&gt;Route 53&lt;/a&gt; provide managed DNS services.  Some DNS services can route traffic through various methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://g33kinfo.com/info/archives/2657" rel="nofollow"&gt;Weighted round robin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt;
&lt;li&gt;Balance between varying cluster sizes&lt;/li&gt;
&lt;li&gt;A/B testing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Latency-based&lt;/li&gt;
&lt;li&gt;Geolocation-based&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-dns" class="anchor" aria-hidden="true" href="#disadvantages-dns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): DNS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt;
&lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href="http://superuser.com/questions/472695/who-controls-the-dns-servers/472729" rel="nofollow"&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;DNS services have recently come under &lt;a href="http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/" rel="nofollow"&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter's IP address(es).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-5" class="anchor" aria-hidden="true" href="#sources-and-further-reading-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx" rel="nofollow"&gt;DNS architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Domain_Name_System" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://support.dnsimple.com/categories/dns/" rel="nofollow"&gt;DNS articles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-content-delivery-network" class="anchor" aria-hidden="true" href="#content-delivery-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content delivery network&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/853a8603651149c686bf3c504769fc594ff08849/687474703a2f2f692e696d6775722e636f6d2f683954417547492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/853a8603651149c686bf3c504769fc594ff08849/687474703a2f2f692e696d6775722e636f6d2f683954417547492e6a7067" data-canonical-src="http://i.imgur.com/h9TAuGI.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/" rel="nofollow"&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user.  Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content.  The site's DNS resolution will tell clients which server to contact.&lt;/p&gt;
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users receive content at data centers close to them&lt;/li&gt;
&lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-push-cdns" class="anchor" aria-hidden="true" href="#push-cdns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Push CDNs&lt;/h3&gt;
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server.  You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN.  You can configure when content expires and when it is updated.  Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt;
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs.  Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pull-cdns" class="anchor" aria-hidden="true" href="#pull-cdns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pull CDNs&lt;/h3&gt;
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content.  You leave the content on your server and rewrite URLs to point to the CDN.  This results in a slower request until the content is cached on the CDN.&lt;/p&gt;
&lt;p&gt;A &lt;a href="https://en.wikipedia.org/wiki/Time_to_live" rel="nofollow"&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached.  Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt;
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-cdn" class="anchor" aria-hidden="true" href="#disadvantages-cdn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): CDN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt;
&lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt;
&lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-6" class="anchor" aria-hidden="true" href="#sources-and-further-reading-6"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972" rel="nofollow"&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/" rel="nofollow"&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-load-balancer" class="anchor" aria-hidden="true" href="#load-balancer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load balancer&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/21caea3d7f67f451630012f657ae59a56709365c/687474703a2f2f692e696d6775722e636f6d2f6838316e39694b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/21caea3d7f67f451630012f657ae59a56709365c/687474703a2f2f692e696d6775722e636f6d2f6838316e39694b2e706e67" data-canonical-src="http://i.imgur.com/h81n9iK.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases.  In each case, the load balancer returns the response from the computing resource to the appropriate client.  Load balancers are effective at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt;
&lt;li&gt;Preventing overloading resources&lt;/li&gt;
&lt;li&gt;Helping eliminate single points of failure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt;
&lt;p&gt;Additional benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
&lt;ul&gt;
&lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509" rel="nofollow"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To protect against failures, it's common to set up multiple load balancers, either in &lt;a href="#active-passive"&gt;active-passive&lt;/a&gt; or &lt;a href="#active-active"&gt;active-active&lt;/a&gt; mode.&lt;/p&gt;
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Random&lt;/li&gt;
&lt;li&gt;Least loaded&lt;/li&gt;
&lt;li&gt;Session/cookies&lt;/li&gt;
&lt;li&gt;&lt;a href="http://g33kinfo.com/info/archives/2657" rel="nofollow"&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-4-load-balancing"&gt;Layer 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-7-load-balancing"&gt;Layer 7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-layer-4-load-balancing" class="anchor" aria-hidden="true" href="#layer-4-load-balancing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Layer 4 load balancing&lt;/h3&gt;
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href="#communication"&gt;transport layer&lt;/a&gt; to decide how to distribute requests.  Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet.  Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/" rel="nofollow"&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-layer-7-load-balancing" class="anchor" aria-hidden="true" href="#layer-7-load-balancing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Layer 7 load balancing&lt;/h3&gt;
&lt;p&gt;Layer 7 load balancers look at the &lt;a href="#communication"&gt;application layer&lt;/a&gt; to decide how to distribute requests.  This can involve contents of the header, message, and cookies.  Layer 7 load balancers terminates network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server.  For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt;
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-horizontal-scaling" class="anchor" aria-hidden="true" href="#horizontal-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Horizontal scaling&lt;/h3&gt;
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability.  Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;.  It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-horizontal-scaling" class="anchor" aria-hidden="true" href="#disadvantages-horizontal-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers
&lt;ul&gt;
&lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt;
&lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href="#database"&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href="#cache"&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-load-balancer" class="anchor" aria-hidden="true" href="#disadvantages-load-balancer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): load balancer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt;
&lt;li&gt;Introducing a load balancer to help eliminate single points of failure results in increased complexity.&lt;/li&gt;
&lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-7" class="anchor" aria-hidden="true" href="#sources-and-further-reading-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" rel="nofollow"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt" rel="nofollow"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Load_balancing_(computing)" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/" rel="nofollow"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/" rel="nofollow"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html" rel="nofollow"&gt;ELB listener config&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reverse-proxy-web-server" class="anchor" aria-hidden="true" href="#reverse-proxy-web-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reverse proxy (web server)&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e88216d0999853426f72b28e41223f43977d22b7/687474703a2f2f692e696d6775722e636f6d2f6e3431417a66662e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e88216d0999853426f72b28e41223f43977d22b7/687474703a2f2f692e696d6775722e636f6d2f6e3431417a66662e706e67" data-canonical-src="http://i.imgur.com/n41Azff.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg" rel="nofollow"&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public.  Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.&lt;/p&gt;
&lt;p&gt;Additional benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy's IP, allowing you to scale servers or change their configuration&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
&lt;ul&gt;
&lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509" rel="nofollow"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly
&lt;ul&gt;
&lt;li&gt;HTML/CSS/JS&lt;/li&gt;
&lt;li&gt;Photos&lt;/li&gt;
&lt;li&gt;Videos&lt;/li&gt;
&lt;li&gt;Etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-load-balancer-vs-reverse-proxy" class="anchor" aria-hidden="true" href="#load-balancer-vs-reverse-proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load balancer vs reverse proxy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deploying a load balancer is useful when you have multiple servers.  Often, load balancers  route traffic to a set of servers serving the same function.&lt;/li&gt;
&lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt;
&lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-reverse-proxy" class="anchor" aria-hidden="true" href="#disadvantages-reverse-proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): reverse proxy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt;
&lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href="https://en.wikipedia.org/wiki/Failover" rel="nofollow"&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-8" class="anchor" aria-hidden="true" href="#sources-and-further-reading-8"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/" rel="nofollow"&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" rel="nofollow"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt" rel="nofollow"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Reverse_proxy" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-application-layer" class="anchor" aria-hidden="true" href="#application-layer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Application layer&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/feeb549c5b6e94f65c613635f7166dc26e0c7de7/687474703a2f2f692e696d6775722e636f6d2f7942355359776d2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/feeb549c5b6e94f65c613635f7166dc26e0c7de7/687474703a2f2f692e696d6775722e636f6d2f7942355359776d2e706e67" data-canonical-src="http://i.imgur.com/yB5SYwm.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer" rel="nofollow"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently.  Adding a new API results in adding application servers without necessarily adding additional web servers.  The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together.  Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt;
&lt;p&gt;Workers in the application layer also help enable &lt;a href="#asynchronism"&gt;asynchronism&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-microservices" class="anchor" aria-hidden="true" href="#microservices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Microservices&lt;/h3&gt;
&lt;p&gt;Related to this discussion are &lt;a href="https://en.wikipedia.org/wiki/Microservices" rel="nofollow"&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services.  Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href="https://smartbear.com/learn/api-design/what-are-microservices" rel="nofollow"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-service-discovery" class="anchor" aria-hidden="true" href="#service-discovery"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Service Discovery&lt;/h3&gt;
&lt;p&gt;Systems such as &lt;a href="https://www.consul.io/docs/index.html" rel="nofollow"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/docs/latest" rel="nofollow"&gt;Etcd&lt;/a&gt;, and &lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports.  &lt;a href="https://www.consul.io/intro/getting-started/checks.html" rel="nofollow"&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href="#hypertext-transfer-protocol-http"&gt;HTTP&lt;/a&gt; endpoint.  Both Consul and Etcd have a built in &lt;a href="#key-value-store"&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-application-layer" class="anchor" aria-hidden="true" href="#disadvantages-application-layer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): application layer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt;
&lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-9" class="anchor" aria-hidden="true" href="#sources-and-further-reading-9"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale" rel="nofollow"&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Service-oriented_architecture" rel="nofollow"&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/" rel="nofollow"&gt;Here's what you need to know about building microservices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-database" class="anchor" aria-hidden="true" href="#database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/15a7553727e6da98d0de5e9ca3792f6d2b5e92d4/687474703a2f2f692e696d6775722e636f6d2f586b6d3543587a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/15a7553727e6da98d0de5e9ca3792f6d2b5e92d4/687474703a2f2f692e696d6775722e636f6d2f586b6d3543587a2e706e67" data-canonical-src="http://i.imgur.com/Xkm5CXz.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-relational-database-management-system-rdbms" class="anchor" aria-hidden="true" href="#relational-database-management-system-rdbms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Relational database management system (RDBMS)&lt;/h3&gt;
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href="https://en.wikipedia.org/wiki/Database_transaction" rel="nofollow"&gt;transactions&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-master-slave-replication" class="anchor" aria-hidden="true" href="#master-slave-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-slave replication&lt;/h4&gt;
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads.  Slaves can also replicate to additional slaves in a tree-like fashion.  If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6a097809b9690236258747d969b1d3e0d93bb8ca/687474703a2f2f692e696d6775722e636f6d2f4339696f47746e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6a097809b9690236258747d969b1d3e0d93bb8ca/687474703a2f2f692e696d6775722e636f6d2f4339696f47746e2e706e67" data-canonical-src="http://i.imgur.com/C9ioGtn.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-master-slave-replication" class="anchor" aria-hidden="true" href="#disadvantages-master-slave-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): master-slave replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt;
&lt;li&gt;See &lt;a href="#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-master-master-replication" class="anchor" aria-hidden="true" href="#master-master-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-master replication&lt;/h4&gt;
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes.  If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5862604b102ee97d85f86f89edda44bde85a5b7f/687474703a2f2f692e696d6775722e636f6d2f6b7241484c47672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/5862604b102ee97d85f86f89edda44bde85a5b7f/687474703a2f2f692e696d6775722e636f6d2f6b7241484c47672e706e67" data-canonical-src="http://i.imgur.com/krAHLGg.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-master-master-replication" class="anchor" aria-hidden="true" href="#disadvantages-master-master-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): master-master replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;You'll need a load balancer or you'll need to make changes to your application logic to determine where to write.&lt;/li&gt;
&lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt;
&lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt;
&lt;li&gt;See &lt;a href="#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-replication" class="anchor" aria-hidden="true" href="#disadvantages-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt;
&lt;li&gt;Writes are replayed to the read replicas.  If there are a lot of writes, the read replicas can get bogged down with replaying writes and can't do as many reads.&lt;/li&gt;
&lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt;
&lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt;
&lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-replication" class="anchor" aria-hidden="true" href="#sources-and-further-reading-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication" rel="nofollow"&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-federation" class="anchor" aria-hidden="true" href="#federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Federation&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6eb6570a8b6b4e1d52e3d7cc07e7959ea5dac75f/687474703a2f2f692e696d6775722e636f6d2f553371563333652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6eb6570a8b6b4e1d52e3d7cc07e7959ea5dac75f/687474703a2f2f692e696d6775722e636f6d2f553371563333652e706e67" data-canonical-src="http://i.imgur.com/U3qV33e.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Federation (or functional partitioning) splits up databases by function.  For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag.  Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality.  With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-federation" class="anchor" aria-hidden="true" href="#disadvantages-federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): federation&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt;
&lt;li&gt;You'll need to update your application logic to determine which database to read and write.&lt;/li&gt;
&lt;li&gt;Joining data from two databases is more complex with a &lt;a href="http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers" rel="nofollow"&gt;server link&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-federation" class="anchor" aria-hidden="true" href="#sources-and-further-reading-federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: federation&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sharding" class="anchor" aria-hidden="true" href="#sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sharding&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1df78be67b749171569a0e11a51aa76b3b678d4f/687474703a2f2f692e696d6775722e636f6d2f775538783549642e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1df78be67b749171569a0e11a51aa76b3b678d4f/687474703a2f2f692e696d6775722e636f6d2f775538783549642e706e67" data-canonical-src="http://i.imgur.com/wU8x5Id.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data.  Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt;
&lt;p&gt;Similar to the advantages of &lt;a href="#federation"&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits.  Index size is also reduced, which generally improves performance with faster queries.  If one shard goes down, the other shards are still operational, although you'll want to add some form of replication to avoid data loss.  Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt;
&lt;p&gt;Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-sharding" class="anchor" aria-hidden="true" href="#disadvantages-sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): sharding&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;You'll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt;
&lt;li&gt;Data distribution can become lopsided in a shard.  For example, a set of power users on a shard could result in increased load to that shard compared to others.
&lt;ul&gt;
&lt;li&gt;Rebalancing adds additional complexity.  A sharding function based on &lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" rel="nofollow"&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt;
&lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sharding" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: sharding&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html" rel="nofollow"&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)" rel="nofollow"&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" rel="nofollow"&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-denormalization" class="anchor" aria-hidden="true" href="#denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Denormalization&lt;/h4&gt;
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance.  Redundant copies of the data are written in multiple tables to avoid expensive joins.  Some RDBMS such as &lt;a href="https://en.wikipedia.org/wiki/PostgreSQL" rel="nofollow"&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href="https://en.wikipedia.org/wiki/Materialized_view" rel="nofollow"&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt;
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href="#federation"&gt;federation&lt;/a&gt; and &lt;a href="#sharding"&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity.  Denormalization might circumvent the need for such complex joins.&lt;/p&gt;
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1.  A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-denormalization" class="anchor" aria-hidden="true" href="#disadvantages-denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): denormalization&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Data is duplicated.&lt;/li&gt;
&lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt;
&lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6&gt;&lt;a id="user-content-sources-and-further-reading-denormalization" class="anchor" aria-hidden="true" href="#sources-and-further-reading-denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: denormalization&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Denormalization" rel="nofollow"&gt;Denormalization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sql-tuning" class="anchor" aria-hidden="true" href="#sql-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQL tuning&lt;/h4&gt;
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href="https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning" rel="nofollow"&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt;
&lt;p&gt;It's important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href="http://httpd.apache.org/docs/2.2/programs/ab.html" rel="nofollow"&gt;ab&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html" rel="nofollow"&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-tighten-up-the-schema" class="anchor" aria-hidden="true" href="#tighten-up-the-schema"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tighten up the schema&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts.  &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches.  Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt;
&lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search" rel="nofollow"&gt;improve search performance&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-use-good-indices" class="anchor" aria-hidden="true" href="#use-good-indices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use good indices&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt;
&lt;li&gt;Indices are usually represented as self-balancing &lt;a href="https://en.wikipedia.org/wiki/B-tree" rel="nofollow"&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt;
&lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt;
&lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt;
&lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-avoid-expensive-joins" class="anchor" aria-hidden="true" href="#avoid-expensive-joins"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Avoid expensive joins&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#denormalization"&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-partition-tables" class="anchor" aria-hidden="true" href="#partition-tables"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Partition tables&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-tune-the-query-cache" class="anchor" aria-hidden="true" href="#tune-the-query-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tune the query cache&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;In some cases, the &lt;a href="https://dev.mysql.com/doc/refman/5.7/en/query-cache.html" rel="nofollow"&gt;query cache&lt;/a&gt; could lead to &lt;a href="https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/" rel="nofollow"&gt;performance issues&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sql-tuning" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sql-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/" rel="nofollow"&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l" rel="nofollow"&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search" rel="nofollow"&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html" rel="nofollow"&gt;Slow query log&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-nosql" class="anchor" aria-hidden="true" href="#nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NoSQL&lt;/h3&gt;
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;.  Data is denormalized, and joins are generally done in the application code.  Most NoSQL stores lack true ACID transactions and favor &lt;a href="#eventual-consistency"&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases.  In comparison with the &lt;a href="#cap-theorem"&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn't receive input during that period.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to choosing between &lt;a href="#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s).  We'll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-key-value-store" class="anchor" aria-hidden="true" href="#key-value-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Key-value store&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: hash table&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD.  Data stores can maintain keys in &lt;a href="https://en.wikipedia.org/wiki/Lexicographical_order" rel="nofollow"&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges.  Key-value stores can allow for storing of metadata with a value.&lt;/p&gt;
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer.  Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt;
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-key-value-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-key-value-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: key-value store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Key-value_database" rel="nofollow"&gt;Key-value database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or" rel="nofollow"&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qnimate.com/overview-of-redis-architecture/" rel="nofollow"&gt;Redis architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.adayinthelifeof.nl/2011/02/06/memcache-internals/" rel="nofollow"&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-document-store" class="anchor" aria-hidden="true" href="#document-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Document store&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object.  Document stores provide APIs or a query language to query based on the internal structure of the document itself.  &lt;em&gt;Note, many key-value stores include features for working with a value's metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories.  Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt;
&lt;p&gt;Some document stores like &lt;a href="https://www.mongodb.com/mongodb-architecture" rel="nofollow"&gt;MongoDB&lt;/a&gt; and &lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/" rel="nofollow"&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries.  &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf" rel="nofollow"&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt;
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-document-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-document-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: document store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Document-oriented_database" rel="nofollow"&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mongodb.com/mongodb-architecture" rel="nofollow"&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/" rel="nofollow"&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up" rel="nofollow"&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-wide-column-store" class="anchor" aria-hidden="true" href="#wide-column-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Wide column store&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/823668b07b4bff50574e934273c9244e4e5017d6/687474703a2f2f692e696d6775722e636f6d2f6e3136694f476b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/823668b07b4bff50574e934273c9244e4e5017d6/687474703a2f2f692e696d6775722e636f6d2f6e3136694f476b2e706e67" data-canonical-src="http://i.imgur.com/n16iOGk.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html" rel="nofollow"&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A wide column store's basic unit of data is a column (name/value pair).  A column can be grouped in column families (analogous to a SQL table).  Super column families further group column families.  You can access each column independently with a row key, and columns with the same row key form a row.  Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt;
&lt;p&gt;Google introduced &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" rel="nofollow"&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html" rel="nofollow"&gt;Cassandra&lt;/a&gt; from Facebook.  Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt;
&lt;p&gt;Wide column stores offer high availability and high scalability.  They are often used for very large data sets.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-wide-column-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-wide-column-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: wide column store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html" rel="nofollow"&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" rel="nofollow"&gt;HBase architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html" rel="nofollow"&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-graph-database" class="anchor" aria-hidden="true" href="#graph-database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Graph database&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bf6508b65e98a7210d9861515833afa0d9434436/687474703a2f2f692e696d6775722e636f6d2f664e636c3635672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/bf6508b65e98a7210d9861515833afa0d9434436/687474703a2f2f692e696d6775722e636f6d2f664e636c3635672e706e67" data-canonical-src="http://i.imgur.com/fNcl65g.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png" rel="nofollow"&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: graph&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes.  Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt;
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network.  They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources.  Many graphs can only be accessed with &lt;a href="#representational-state-transfer-rest"&gt;REST APIs&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-graph" class="anchor" aria-hidden="true" href="#sources-and-further-reading-graph"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: graph&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database" rel="nofollow"&gt;Graph database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://neo4j.com/" rel="nofollow"&gt;Neo4j&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.twitter.com/2010/introducing-flockdb" rel="nofollow"&gt;FlockDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-nosql" class="anchor" aria-hidden="true" href="#sources-and-further-reading-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: NoSQL&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/3342497/explanation-of-base-terminology" rel="nofollow"&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq" rel="nofollow"&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qI_g07C_Q5I" rel="nofollow"&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html" rel="nofollow"&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sql-or-nosql" class="anchor" aria-hidden="true" href="#sql-or-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQL or NoSQL&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a6e2e844765c9d5382d9c9b64ef7693977981646/687474703a2f2f692e696d6775722e636f6d2f775847714735662e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a6e2e844765c9d5382d9c9b64ef7693977981646/687474703a2f2f692e696d6775722e636f6d2f775847714735662e706e67" data-canonical-src="http://i.imgur.com/wXGqG5f.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.infoq.com/articles/Transition-RDBMS-NoSQL/" rel="nofollow"&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Structured data&lt;/li&gt;
&lt;li&gt;Strict schema&lt;/li&gt;
&lt;li&gt;Relational data&lt;/li&gt;
&lt;li&gt;Need for complex joins&lt;/li&gt;
&lt;li&gt;Transactions&lt;/li&gt;
&lt;li&gt;Clear patterns for scaling&lt;/li&gt;
&lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt;
&lt;li&gt;Lookups by index are very fast&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semi-structured data&lt;/li&gt;
&lt;li&gt;Dynamic or flexible schema&lt;/li&gt;
&lt;li&gt;Non-relational data&lt;/li&gt;
&lt;li&gt;No need for complex joins&lt;/li&gt;
&lt;li&gt;Store many TB (or PB) of data&lt;/li&gt;
&lt;li&gt;Very data intensive workload&lt;/li&gt;
&lt;li&gt;Very high throughput for IOPS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt;
&lt;li&gt;Leaderboard or scoring data&lt;/li&gt;
&lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt;
&lt;li&gt;Frequently accessed ('hot') tables&lt;/li&gt;
&lt;li&gt;Metadata/lookup tables&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sql-or-nosql" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sql-or-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sitepoint.com/sql-vs-nosql-differences/" rel="nofollow"&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-cache" class="anchor" aria-hidden="true" href="#cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cache&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7acedde6aa7853baf2eb4a53f88e2595ebe43756/687474703a2f2f692e696d6775722e636f6d2f51367a32344c612e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/7acedde6aa7853baf2eb4a53f88e2595ebe43756/687474703a2f2f692e696d6775722e636f6d2f51367a32344c612e706e67" data-canonical-src="http://i.imgur.com/Q6z24La.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases.  In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt;
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions.  Popular items can skew the distribution, causing bottlenecks.  Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-client-caching" class="anchor" aria-hidden="true" href="#client-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Client caching&lt;/h3&gt;
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href="#reverse-proxy-web-server"&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-cdn-caching" class="anchor" aria-hidden="true" href="#cdn-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CDN caching&lt;/h3&gt;
&lt;p&gt;&lt;a href="#content-delivery-network"&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-web-server-caching" class="anchor" aria-hidden="true" href="#web-server-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web server caching&lt;/h3&gt;
&lt;p&gt;&lt;a href="#reverse-proxy-web-server"&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href="https://www.varnish-cache.org/" rel="nofollow"&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly.  Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-database-caching" class="anchor" aria-hidden="true" href="#database-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database caching&lt;/h3&gt;
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case.  Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-application-caching" class="anchor" aria-hidden="true" href="#application-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Application caching&lt;/h3&gt;
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage.  Since the data is held in RAM, it is much faster than typical databases where data is stored on disk.  RAM is more limited than disk, so &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms" rel="nofollow"&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used" rel="nofollow"&gt;least recently used (LRU)&lt;/a&gt; can help invalidate 'cold' entries and keep 'hot' data in RAM.&lt;/p&gt;
&lt;p&gt;Redis has the following additional features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Persistence option&lt;/li&gt;
&lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Row level&lt;/li&gt;
&lt;li&gt;Query-level&lt;/li&gt;
&lt;li&gt;Fully-formed serializable objects&lt;/li&gt;
&lt;li&gt;Fully-rendered HTML&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-caching-at-the-database-query-level" class="anchor" aria-hidden="true" href="#caching-at-the-database-query-level"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching at the database query level&lt;/h3&gt;
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache.  This approach suffers from expiration issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt;
&lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-caching-at-the-object-level" class="anchor" aria-hidden="true" href="#caching-at-the-object-level"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching at the object level&lt;/h3&gt;
&lt;p&gt;See your data as an object, similar to what you do with your application code.  Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt;
&lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User sessions&lt;/li&gt;
&lt;li&gt;Fully rendered web pages&lt;/li&gt;
&lt;li&gt;Activity streams&lt;/li&gt;
&lt;li&gt;User graph data&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-when-to-update-the-cache" class="anchor" aria-hidden="true" href="#when-to-update-the-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;When to update the cache&lt;/h3&gt;
&lt;p&gt;Since you can only store a limited amount of data in cache, you'll need to determine which cache update strategy works best for your use case.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-cache-aside" class="anchor" aria-hidden="true" href="#cache-aside"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cache-aside&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7f5934e49a678b67f65e5ed53134bc258b007ebb/687474703a2f2f692e696d6775722e636f6d2f4f4e6a4f52716b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/7f5934e49a678b67f65e5ed53134bc258b007ebb/687474703a2f2f692e696d6775722e636f6d2f4f4e6a4f52716b2e706e67" data-canonical-src="http://i.imgur.com/ONjORqk.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;The application is responsible for reading and writing from storage.  The cache does not interact with storage directly.  The application does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt;
&lt;li&gt;Load entry from the database&lt;/li&gt;
&lt;li&gt;Add entry to cache&lt;/li&gt;
&lt;li&gt;Return entry&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;get_user&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;user_id&lt;/span&gt;):
    user &lt;span class="pl-k"&gt;=&lt;/span&gt; cache.get(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;user.&lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id)
    &lt;span class="pl-k"&gt;if&lt;/span&gt; user &lt;span class="pl-k"&gt;is&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;:
        user &lt;span class="pl-k"&gt;=&lt;/span&gt; db.query(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;SELECT * FROM users WHERE user_id = &lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id)
        &lt;span class="pl-k"&gt;if&lt;/span&gt; user &lt;span class="pl-k"&gt;is&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;:
            key &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;user.&lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;.format(user_id)
            cache.set(key, json.dumps(user))
    &lt;span class="pl-k"&gt;return&lt;/span&gt; user&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://memcached.org/" rel="nofollow"&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt;
&lt;p&gt;Subsequent reads of data added to cache are fast.  Cache-aside is also referred to as lazy loading.  Only requested data is cached, which avoids filling up the cache with data that isn't requested.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-cache-aside" class="anchor" aria-hidden="true" href="#disadvantages-cache-aside"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): cache-aside&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt;
&lt;li&gt;Data can become stale if it is updated in the database.  This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt;
&lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-write-through" class="anchor" aria-hidden="true" href="#write-through"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Write-through&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/56b870f4d199335ccdbc98b989ef6511ed14f0e2/687474703a2f2f692e696d6775722e636f6d2f3076426330684e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/56b870f4d199335ccdbc98b989ef6511ed14f0e2/687474703a2f2f692e696d6775722e636f6d2f3076426330684e2e706e67" data-canonical-src="http://i.imgur.com/0vBc0hN.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application adds/updates entry in cache&lt;/li&gt;
&lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt;
&lt;li&gt;Return&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Application code:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;set_user(&lt;span class="pl-c1"&gt;12345&lt;/span&gt;, {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;foo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;:&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;bar&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;})&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Cache code:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;set_user&lt;/span&gt;(&lt;span class="pl-smi"&gt;user_id&lt;/span&gt;, &lt;span class="pl-smi"&gt;values&lt;/span&gt;):
    user &lt;span class="pl-k"&gt;=&lt;/span&gt; db.query(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;UPDATE Users WHERE id = &lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id, values)
    cache.set(user_id, user)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast.  Users are generally more tolerant of latency when updating data than reading data.  Data in the cache is not stale.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-write-through" class="anchor" aria-hidden="true" href="#disadvantages-write-through"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): write through&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database.  Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt;
&lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-write-behind-write-back" class="anchor" aria-hidden="true" href="#write-behind-write-back"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Write-behind (write-back)&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8aa9f1a2f050c1422898bb5e82f1f01773334e22/687474703a2f2f692e696d6775722e636f6d2f72675372766a472e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/8aa9f1a2f050c1422898bb5e82f1f01773334e22/687474703a2f2f692e696d6775722e636f6d2f72675372766a472e706e67" data-canonical-src="http://i.imgur.com/rgSrvjG.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add/update entry in cache&lt;/li&gt;
&lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-write-behind" class="anchor" aria-hidden="true" href="#disadvantages-write-behind"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): write-behind&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt;
&lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-refresh-ahead" class="anchor" aria-hidden="true" href="#refresh-ahead"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Refresh-ahead&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/49dcb54307763b4f56d61a4a1369826e2e7d52e4/687474703a2f2f692e696d6775722e636f6d2f6b78746a7167452e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/49dcb54307763b4f56d61a4a1369826e2e7d52e4/687474703a2f2f692e696d6775722e636f6d2f6b78746a7167452e706e67" data-canonical-src="http://i.imgur.com/kxtjqgE.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt;
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-refresh-ahead" class="anchor" aria-hidden="true" href="#disadvantages-refresh-ahead"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-cache" class="anchor" aria-hidden="true" href="#disadvantages-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): cache&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms" rel="nofollow"&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt;
&lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-10" class="anchor" aria-hidden="true" href="#sources-and-further-reading-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/" rel="nofollow"&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html" rel="nofollow"&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cache_(computing)" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-asynchronism" class="anchor" aria-hidden="true" href="#asynchronism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Asynchronism&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c01ec137453216bbc188e3a8f16da39ec9131234/687474703a2f2f692e696d6775722e636f6d2f353447597353782e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c01ec137453216bbc188e3a8f16da39ec9131234/687474703a2f2f692e696d6775722e636f6d2f353447597353782e706e67" data-canonical-src="http://i.imgur.com/54GYsSx.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer" rel="nofollow"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line.  They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-message-queues" class="anchor" aria-hidden="true" href="#message-queues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Message queues&lt;/h3&gt;
&lt;p&gt;Message queues receive, hold, and deliver messages.  If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt;
&lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The user is not blocked and the job is processed in the background.  During this time, the client might optionally do a small amount of processing to make it seem like the task has completed.  For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://redis.io/" rel="nofollow"&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.rabbitmq.com/" rel="nofollow"&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the 'AMQP' protocol and manage your own nodes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/sqs/" rel="nofollow"&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-task-queues" class="anchor" aria-hidden="true" href="#task-queues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Task queues&lt;/h3&gt;
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results.  They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Celery&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-back-pressure" class="anchor" aria-hidden="true" href="#back-pressure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Back pressure&lt;/h3&gt;
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance.  &lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html" rel="nofollow"&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue.  Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later.  Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff" rel="nofollow"&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-asynchronism" class="anchor" aria-hidden="true" href="#disadvantages-asynchronism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): asynchronism&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-11" class="anchor" aria-hidden="true" href="#sources-and-further-reading-11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1KRYH75wgy4" rel="nofollow"&gt;It's all a numbers game&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html" rel="nofollow"&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Little%27s_law" rel="nofollow"&gt;Little's law&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function" rel="nofollow"&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-communication" class="anchor" aria-hidden="true" href="#communication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Communication&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1d761d5688d28ce1fb12a0f1c8191bca96eece4c/687474703a2f2f692e696d6775722e636f6d2f354b656f6351732e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/1d761d5688d28ce1fb12a0f1c8191bca96eece4c/687474703a2f2f692e696d6775722e636f6d2f354b656f6351732e6a7067" data-canonical-src="http://i.imgur.com/5KeocQs.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.escotal.com/osilayer.html" rel="nofollow"&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-hypertext-transfer-protocol-http" class="anchor" aria-hidden="true" href="#hypertext-transfer-protocol-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt;
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server.  It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request.  HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt;
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint).  Below are common HTTP verbs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Verb&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Idempotent*&lt;/th&gt;
&lt;th&gt;Safe&lt;/th&gt;
&lt;th&gt;Cacheable&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GET&lt;/td&gt;
&lt;td&gt;Reads a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;POST&lt;/td&gt;
&lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Yes if response contains freshness info&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUT&lt;/td&gt;
&lt;td&gt;Creates or replace a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PATCH&lt;/td&gt;
&lt;td&gt;Partially updates a resource&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Yes if response contains freshness info&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DELETE&lt;/td&gt;
&lt;td&gt;Deletes a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt;
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-http" class="anchor" aria-hidden="true" href="#sources-and-further-reading-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: HTTP&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/http/" rel="nofollow"&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol" rel="nofollow"&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1" rel="nofollow"&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-transmission-control-protocol-tcp" class="anchor" aria-hidden="true" href="#transmission-control-protocol-tcp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transmission control protocol (TCP)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/821620cf6aa83566f4def561e754e5991480ca8d/687474703a2f2f692e696d6775722e636f6d2f4a6441736476472e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/821620cf6aa83566f4def561e754e5991480ca8d/687474703a2f2f692e696d6775722e636f6d2f4a6441736476472e6a7067" data-canonical-src="http://i.imgur.com/JdAsdvG.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/" rel="nofollow"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href="https://en.wikipedia.org/wiki/Internet_Protocol" rel="nofollow"&gt;IP network&lt;/a&gt;.  Connection is established and terminated using a &lt;a href="https://en.wikipedia.org/wiki/Handshaking" rel="nofollow"&gt;handshake&lt;/a&gt;.  All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequence numbers and &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation" rel="nofollow"&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)" rel="nofollow"&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets.  If there are multiple timeouts, the connection is dropped.  TCP also implements &lt;a href="https://en.wikipedia.org/wiki/Flow_control_(data)" rel="nofollow"&gt;flow control&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Network_congestion#Congestion_control" rel="nofollow"&gt;congestion control&lt;/a&gt;.  These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt;
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage.  It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href="https://memcached.org/" rel="nofollow"&gt;memcached&lt;/a&gt; server.  &lt;a href="https://en.wikipedia.org/wiki/Connection_pool" rel="nofollow"&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt;
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical.  Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt;
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need all of the data to arrive intact&lt;/li&gt;
&lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-user-datagram-protocol-udp" class="anchor" aria-hidden="true" href="#user-datagram-protocol-udp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;User datagram protocol (UDP)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/47eb14c0a2dff2166f8781a6ce8c7f33d4c33da8/687474703a2f2f692e696d6775722e636f6d2f797a44724a74412e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/47eb14c0a2dff2166f8781a6ce8c7f33d4c33da8/687474703a2f2f692e696d6775722e636f6d2f797a44724a74412e6a7067" data-canonical-src="http://i.imgur.com/yzDrJtA.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/" rel="nofollow"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;UDP is connectionless.  Datagrams (analogous to packets) are guaranteed only at the datagram level.  Datagrams might reach their destination out of order or not at all.  UDP does not support congestion control.  Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt;
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet.  This is useful with &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol" rel="nofollow"&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt;
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt;
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need the lowest latency&lt;/li&gt;
&lt;li&gt;Late data is worse than loss of data&lt;/li&gt;
&lt;li&gt;You want to implement your own error correction&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-tcp-and-udp" class="anchor" aria-hidden="true" href="#sources-and-further-reading-tcp-and-udp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/" rel="nofollow"&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/" rel="nofollow"&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp" rel="nofollow"&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol" rel="nofollow"&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol" rel="nofollow"&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf" rel="nofollow"&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-remote-procedure-call-rpc" class="anchor" aria-hidden="true" href="#remote-procedure-call-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Remote procedure call (RPC)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a3d7771c0b0a7816d0533fffeb6eeeb442d9945/687474703a2f2f692e696d6775722e636f6d2f6946344d6b62352e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1a3d7771c0b0a7816d0533fffeb6eeeb442d9945/687474703a2f2f692e696d6775722e636f6d2f6946344d6b62352e706e67" data-canonical-src="http://i.imgur.com/iF4Mkb5.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server.  The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program.  Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls.  Popular RPC frameworks include &lt;a href="https://developers.google.com/protocol-buffers/" rel="nofollow"&gt;Protobuf&lt;/a&gt;, &lt;a href="https://thrift.apache.org/" rel="nofollow"&gt;Thrift&lt;/a&gt;, and &lt;a href="https://avro.apache.org/docs/current/" rel="nofollow"&gt;Avro&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure.  The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; -  Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt;
&lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample RPC calls:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  "data":"anId";
  "anotherdata": "another value"
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RPC is focused on exposing behaviors.  RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt;
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You know your target platform.&lt;/li&gt;
&lt;li&gt;You want to control how your "logic" is accessed.&lt;/li&gt;
&lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt;
&lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-rpc" class="anchor" aria-hidden="true" href="#disadvantages-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): RPC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt;
&lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt;
&lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt;
&lt;li&gt;You might not be able to leverage existing technologies out of the box.  For example, it might require additional effort to ensure &lt;a href="http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/" rel="nofollow"&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href="http://www.squid-cache.org/" rel="nofollow"&gt;Squid&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-representational-state-transfer-rest" class="anchor" aria-hidden="true" href="#representational-state-transfer-rest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Representational state transfer (REST)&lt;/h3&gt;
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server.  The server provides a representation of resources and actions that can either manipulate or get a new representation of resources.  All communication must be stateless and cacheable.&lt;/p&gt;
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don't reinvent the wheel.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="http://restcookbook.com/Basics/hateoas/" rel="nofollow"&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample REST calls:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{"anotherdata": "another value"}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;REST is focused on exposing data.  It minimizes the coupling between client/server and is often used for public HTTP APIs.  REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href="https://github.com/for-GET/know-your-http-well/blob/master/headers.md"&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH.  Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-rest" class="anchor" aria-hidden="true" href="#disadvantages-rest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): REST&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy.  For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path.  With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt;
&lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn't fit your use case.  For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt;
&lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt;
&lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rpc-and-rest-calls-comparison" class="anchor" aria-hidden="true" href="#rpc-and-rest-calls-comparison"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RPC and REST calls comparison&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operation&lt;/th&gt;
&lt;th&gt;RPC&lt;/th&gt;
&lt;th&gt;REST&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Signup&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resign&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br&gt;{&lt;br&gt;"personid": "1234"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read a person&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read a person’s items list&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add an item to a person’s items&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br&gt;{&lt;br&gt;"personid": "1234";&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Update an item&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br&gt;{&lt;br&gt;"itemid": "456";&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br&gt;{&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Delete an item&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align="center"&gt;
  &lt;i&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/" rel="nofollow"&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-rest-and-rpc" class="anchor" aria-hidden="true" href="#sources-and-further-reading-rest-and-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/" rel="nofollow"&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://programmers.stackexchange.com/a/181186" rel="nofollow"&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15056878/rest-vs-json-rpc" rel="nofollow"&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/" rel="nofollow"&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs" rel="nofollow"&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.facebook.com/posts/1468950976659943/" rel="nofollow"&gt;Thrift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arstechnica.com/civis/viewtopic.php?t=1190508" rel="nofollow"&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-security" class="anchor" aria-hidden="true" href="#security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Security&lt;/h2&gt;
&lt;p&gt;This section could use some updates.  Consider &lt;a href="#contributing"&gt;contributing&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Security is a broad topic.  Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won't need to know more than the basics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt;
&lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting" rel="nofollow"&gt;XSS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/SQL_injection" rel="nofollow"&gt;SQL injection&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt;
&lt;li&gt;Use the principle of &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege" rel="nofollow"&gt;least privilege&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-12" class="anchor" aria-hidden="true" href="#sources-and-further-reading-12"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/shieldfy/API-Security-Checklist"&gt;API security checklist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/FallibleInc/security-guide-for-developers"&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet" rel="nofollow"&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-appendix" class="anchor" aria-hidden="true" href="#appendix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Appendix&lt;/h2&gt;
&lt;p&gt;You'll sometimes be asked to do 'back-of-the-envelope' estimates.  For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take.  The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-powers-of-two-table" class="anchor" aria-hidden="true" href="#powers-of-two-table"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Powers of two table&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-13" class="anchor" aria-hidden="true" href="#sources-and-further-reading-13"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Power_of_two" rel="nofollow"&gt;Powers of two&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-latency-numbers-every-programmer-should-know" class="anchor" aria-hidden="true" href="#latency-numbers-every-programmer-should-know"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency numbers every programmer should know&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read sequentially from disk at 30 MB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt;
&lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt;
&lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-latency-numbers-visualized" class="anchor" aria-hidden="true" href="#latency-numbers-visualized"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency numbers visualized&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-14" class="anchor" aria-hidden="true" href="#sources-and-further-reading-14"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf" rel="nofollow"&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf" rel="nofollow"&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-additional-system-design-interview-questions" class="anchor" aria-hidden="true" href="#additional-system-design-interview-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional system design interview questions&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc" rel="nofollow"&gt;youtube.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a search engine like Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://queue.acm.org/detail.cfm?id=988407" rel="nofollow"&gt;queue.acm.org&lt;/a&gt;&lt;br&gt;&lt;a href="http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search" rel="nofollow"&gt;stackexchange.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.ardendertat.com/2012/01/11/implementing-search-engines/" rel="nofollow"&gt;ardendertat.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://infolab.stanford.edu/~backrub/google.html" rel="nofollow"&gt;stanford.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Google docs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://code.google.com/p/google-mobwrite/" rel="nofollow"&gt;code.google.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://neil.fraser.name/writing/sync/" rel="nofollow"&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a key-value store like Redis&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a cache system like Memcached&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a recommendation system like Amazon's&lt;/td&gt;
&lt;td&gt;&lt;a href="https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html" rel="nofollow"&gt;hulu.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf" rel="nofollow"&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt;
&lt;td&gt;&lt;a href="http://n00tc0d3r.blogspot.com/" rel="nofollow"&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook news feed function&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook timeline function&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.facebook.com/note.php?note_id=10150468255628920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook chat function&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf" rel="nofollow"&gt;erlang-factory.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a graph search function like Facebook's&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt;
&lt;td&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972" rel="nofollow"&gt;figshare.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a trending topic system like Twitter's&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/" rel="nofollow"&gt;michael-noll.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/" rel="nofollow"&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a random ID generation system&lt;/td&gt;
&lt;td&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake" rel="nofollow"&gt;blog.twitter.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/twitter/snowflake/"&gt;github.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Return the top k requests during a time interval&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cs.ucsb.edu/sites/cs.ucsb.edu/files/docs/reports/2005-23.pdf" rel="nofollow"&gt;cs.ucsb.edu&lt;/a&gt;&lt;br&gt;&lt;a href="http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf" rel="nofollow"&gt;wpi.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design an online multiplayer card game&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html" rel="nofollow"&gt;indieflashblog.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://buildnewgames.com/real-time-multiplayer/" rel="nofollow"&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a garbage collection system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/" rel="nofollow"&gt;stuffwithstuff.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf" rel="nofollow"&gt;washington.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design an API rate limiter&lt;/td&gt;
&lt;td&gt;&lt;a href="https://stripe.com/blog/rate-limiters" rel="nofollow"&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add a system design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-real-world-architectures" class="anchor" aria-hidden="true" href="#real-world-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Real world architectures&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b7c71be73fb466344c2d773178ae74e3fbb1dcc6/687474703a2f2f692e696d6775722e636f6d2f5463556f3266772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b7c71be73fb466344c2d773178ae74e3fbb1dcc6/687474703a2f2f692e696d6775722e636f6d2f5463556f3266772e706e67" data-canonical-src="http://i.imgur.com/TcUo2fw.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability" rel="nofollow"&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don't focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt;
&lt;li&gt;Study what problems are solved by each component, where it works, where it doesn't&lt;/li&gt;
&lt;li&gt;Review the lessons learned&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/AGrishchenko/apache-spark-architecture" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/previa/storm-16094009" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/alexbaranau/intro-to-hbase" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf" rel="nofollow"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/mdirolf/introduction-to-mongodb" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://research.google.com/archive/spanner-osdi2012.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File system&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File system&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt;
&lt;td&gt;&lt;a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" rel="nofollow"&gt;apache.org&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/mumrah/kafka-talk-tri-hug" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Add an architecture&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-company-architectures" class="anchor" aria-hidden="true" href="#company-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Company architectures&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Company&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Amazon&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/amazon-architecture" rel="nofollow"&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cinchcast&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html" rel="nofollow"&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DataSift&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html" rel="nofollow"&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DropBox&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc" rel="nofollow"&gt;How we've scaled Dropbox&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ESPN&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html" rel="nofollow"&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/google-architecture" rel="nofollow"&gt;Google architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Instagram&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html" rel="nofollow"&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br&gt;&lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances" rel="nofollow"&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Justin.tv&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html" rel="nofollow"&gt;Justin.Tv's live video broadcasting architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Facebook&lt;/td&gt;
&lt;td&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf" rel="nofollow"&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf" rel="nofollow"&gt;TAO: Facebook’s distributed data store for the social graph&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf" rel="nofollow"&gt;Facebook’s photo storage&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html" rel="nofollow"&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Flickr&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture" rel="nofollow"&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mailbox&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html" rel="nofollow"&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Netflix&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html" rel="nofollow"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html" rel="nofollow"&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pinterest&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html" rel="nofollow"&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html" rel="nofollow"&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Playfish&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html" rel="nofollow"&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PlentyOfFish&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/plentyoffish-architecture" rel="nofollow"&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Salesforce&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html" rel="nofollow"&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stack Overflow&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html" rel="nofollow"&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TripAdvisor&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html" rel="nofollow"&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tumblr&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html" rel="nofollow"&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster" rel="nofollow"&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html" rel="nofollow"&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html" rel="nofollow"&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability" rel="nofollow"&gt;Timelines at scale&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI" rel="nofollow"&gt;Big and small data at Twitter&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=z8LU0Cj6BOU" rel="nofollow"&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html" rel="nofollow"&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Uber&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html" rel="nofollow"&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html" rel="nofollow"&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WhatsApp&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html" rel="nofollow"&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;YouTube&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=w5WVu624fY8" rel="nofollow"&gt;YouTube scalability&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/youtube-architecture" rel="nofollow"&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-company-engineering-blogs" class="anchor" aria-hidden="true" href="#company-engineering-blogs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Company engineering blogs&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt;
&lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://nerds.airbnb.com/" rel="nofollow"&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.atlassian.com/blog/" rel="nofollow"&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/aws/" rel="nofollow"&gt;AWS Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://word.bitly.com/" rel="nofollow"&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.box.com/blog/category/engineering" rel="nofollow"&gt;Box Blogs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.cloudera.com/" rel="nofollow"&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tech.dropbox.com/" rel="nofollow"&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.quora.com/" rel="nofollow"&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ebaytechblog.com/" rel="nofollow"&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.evernote.com/tech/" rel="nofollow"&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://codeascraft.com/" rel="nofollow"&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.facebook.com/Engineering" rel="nofollow"&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://code.flickr.net/" rel="nofollow"&gt;Flickr Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.foursquare.com/" rel="nofollow"&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://githubengineering.com/" rel="nofollow"&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://googleresearch.blogspot.com/" rel="nofollow"&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.groupon.com/" rel="nofollow"&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.heroku.com/" rel="nofollow"&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://product.hubspot.com/blog/topic/engineering" rel="nofollow"&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/" rel="nofollow"&gt;High Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://instagram-engineering.tumblr.com/" rel="nofollow"&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://software.intel.com/en-us/blogs/" rel="nofollow"&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.janestreet.com/category/ocaml/" rel="nofollow"&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.linkedin.com/blog" rel="nofollow"&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.microsoft.com/" rel="nofollow"&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.msdn.microsoft.com/pythonengineering/" rel="nofollow"&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://techblog.netflix.com/" rel="nofollow"&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://devblog.paypal.com/category/engineering/" rel="nofollow"&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@Pinterest_Engineering" rel="nofollow"&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.quora.com/" rel="nofollow"&gt;Quora Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.redditblog.com/" rel="nofollow"&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.salesforce.com/blogs/engineering/" rel="nofollow"&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://slack.engineering/" rel="nofollow"&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.spotify.com/" rel="nofollow"&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.twilio.com/engineering" rel="nofollow"&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.twitter.com/engineering/" rel="nofollow"&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eng.uber.com/" rel="nofollow"&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yahooeng.tumblr.com/" rel="nofollow"&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineeringblog.yelp.com/" rel="nofollow"&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zynga.com/blogs/engineering" rel="nofollow"&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-15" class="anchor" aria-hidden="true" href="#sources-and-further-reading-15"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;p&gt;Looking to add a blog?  To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kilimchoi/engineering-blogs"&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-under-development" class="anchor" aria-hidden="true" href="#under-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Under development&lt;/h2&gt;
&lt;p&gt;Interested in adding a section or helping complete one in-progress?  &lt;a href="#contributing"&gt;Contribute&lt;/a&gt;!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distributed computing with MapReduce&lt;/li&gt;
&lt;li&gt;Consistent hashing&lt;/li&gt;
&lt;li&gt;Scatter gather&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt;
&lt;p&gt;Special thanks to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/" rel="nofollow"&gt;Hired in tech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/dp/0984782850/" rel="nofollow"&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/" rel="nofollow"&gt;High scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shashank88/system_design"&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mmcgrana/services-engineering"&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f"&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dancres.github.io/Pages/" rel="nofollow"&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact-info" class="anchor" aria-hidden="true" href="#contact-info"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact info&lt;/h2&gt;
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt;
&lt;p&gt;My contact info can be found on my &lt;a href="https://github.com/donnemartin"&gt;GitHub page&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>donnemartin</author><guid isPermaLink="false">https://github.com/donnemartin/system-design-primer</guid><pubDate>Wed, 20 Nov 2019 00:09:00 GMT</pubDate></item><item><title>huggingface/transformers #10 in Python, Today</title><link>https://github.com/huggingface/transformers</link><description>&lt;p&gt;&lt;i&gt;🤗 Transformers: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;br&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png"&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;br&gt;
&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;&lt;p align="center"&gt;
    &lt;a href="https://circleci.com/gh/huggingface/transformers" rel="nofollow"&gt;
        &lt;img alt="Build" src="https://camo.githubusercontent.com/045b8639882280ff5cd38c403499977386c25134/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f6275696c642f6769746875622f68756767696e67666163652f7472616e73666f726d6572732f6d6173746572" data-canonical-src="https://img.shields.io/circleci/build/github/huggingface/transformers/master" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://github.com/huggingface/transformers/blob/master/LICENSE"&gt;
        &lt;img alt="GitHub" src="https://camo.githubusercontent.com/440e73b137335cc0088bb06e6c90cc7b503b14a2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f68756767696e67666163652f7472616e73666f726d6572732e7376673f636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://huggingface.co/transformers/index.html" rel="nofollow"&gt;
        &lt;img alt="Documentation" src="https://camo.githubusercontent.com/b104c21f478c4d4a37f63292ab2898047f19ee24/68747470733a2f2f696d672e736869656c64732e696f2f776562736974652f687474702f68756767696e67666163652e636f2f7472616e73666f726d6572732f696e6465782e68746d6c2e7376673f646f776e5f636f6c6f723d72656426646f776e5f6d6573736167653d6f66666c696e652675705f6d6573736167653d6f6e6c696e65" data-canonical-src="https://img.shields.io/website/http/huggingface.co/transformers/index.html.svg?down_color=red&amp;amp;down_message=offline&amp;amp;up_message=online" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://github.com/huggingface/transformers/releases"&gt;
        &lt;img alt="GitHub release" src="https://camo.githubusercontent.com/8409fd8716dd1a11afa7ab38e1218b34918164eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f68756767696e67666163652f7472616e73666f726d6572732e737667" data-canonical-src="https://img.shields.io/github/release/huggingface/transformers.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;h3 align="center"&gt;&lt;a id="user-content-state-of-the-art-natural-language-processing-for-tensorflow-20-and-pytorch" class="anchor" aria-hidden="true" href="#state-of-the-art-natural-language-processing-for-tensorflow-20-and-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;p&gt;State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch
&lt;/p&gt;&lt;/h3&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;🤗&lt;/g-emoji&gt; Transformers (formerly known as &lt;code&gt;pytorch-transformers&lt;/code&gt; and &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt;) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;As easy to use as pytorch-transformers&lt;/li&gt;
&lt;li&gt;As powerful and concise as Keras&lt;/li&gt;
&lt;li&gt;High performance on NLU and NLG tasks&lt;/li&gt;
&lt;li&gt;Low barrier to entry for educators and practitioners&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;State-of-the-art NLP for everyone&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deep learning researchers&lt;/li&gt;
&lt;li&gt;Hands-on practitioners&lt;/li&gt;
&lt;li&gt;AI/ML/NLP teachers and educators&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lower compute costs, smaller carbon footprint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Researchers can share trained models instead of always retraining&lt;/li&gt;
&lt;li&gt;Practitioners can reduce compute time and production costs&lt;/li&gt;
&lt;li&gt;10 architectures with over 30 pretrained models, some in more than 100 languages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Choose the right framework for every part of a model's lifetime&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Train state-of-the-art models in 3 lines of code&lt;/li&gt;
&lt;li&gt;Deep interoperability between TensorFlow 2.0 and PyTorch models&lt;/li&gt;
&lt;li&gt;Move a single model between TF2.0/PyTorch frameworks at will&lt;/li&gt;
&lt;li&gt;Seamlessly pick the right framework for training, evaluation, production&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Section&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;How to install the package&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#model-architectures"&gt;Model architectures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Architectures (with pretrained weights)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#online-demo"&gt;Online demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Experimenting with this repo’s text generation capabilities&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#quick-tour"&gt;Quick tour: Usage&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Tokenizers &amp;amp; models usage: Bert and GPT-2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Quick-tour-TF-20-training-and-PyTorch-interoperability"&gt;Quick tour: TF 2.0 and PyTorch &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Train a TF 2.0 model in 10 lines of code, load it in PyTorch&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#quick-tour-of-the-fine-tuningusage-scripts"&gt;Quick tour: Fine-tuning/usage scripts&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Using provided scripts: GLUE, SQuAD and Text generation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Migrating-from-pytorch-transformers-to-transformers"&gt;Migrating from pytorch-transformers to transformers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Migrating your code from pytorch-transformers to transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Migrating-from-pytorch-pretrained-bert-to-transformers"&gt;Migrating from pytorch-pretrained-bert to pytorch-transformers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Migrating your code from pytorch-pretrained-bert to transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;Documentation&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v2.1.1" rel="nofollow"&gt;(v2.1.1)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v2.0.0" rel="nofollow"&gt;(v2.0.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.2.0" rel="nofollow"&gt;(v1.2.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.1.0" rel="nofollow"&gt;(v1.1.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.0.0" rel="nofollow"&gt;(v1.0.0)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Full API documentation and more&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;This repo is tested on Python 2.7 and 3.5+ (examples are tested only on python 3.5+), PyTorch 1.0.0+ and TensorFlow 2.0.0-rc1&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-with-pip" class="anchor" aria-hidden="true" href="#with-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;With pip&lt;/h3&gt;
&lt;p&gt;First you need to install one of, or both, TensorFlow 2.0 and PyTorch.
Please refer to &lt;a href="https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available" rel="nofollow"&gt;TensorFlow installation page&lt;/a&gt; and/or &lt;a href="https://pytorch.org/get-started/locally/#start-locally" rel="nofollow"&gt;PyTorch installation page&lt;/a&gt; regarding the specific install command for your platform.&lt;/p&gt;
&lt;p&gt;When TensorFlow 2.0 and/or PyTorch has been installed, &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;🤗&lt;/g-emoji&gt; Transformers can be installed using pip as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install transformers&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-from-source" class="anchor" aria-hidden="true" href="#from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;From source&lt;/h3&gt;
&lt;p&gt;Here also, you first need to install one of, or both, TensorFlow 2.0 and PyTorch.
Please refer to &lt;a href="https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available" rel="nofollow"&gt;TensorFlow installation page&lt;/a&gt; and/or &lt;a href="https://pytorch.org/get-started/locally/#start-locally" rel="nofollow"&gt;PyTorch installation page&lt;/a&gt; regarding the specific install command for your platform.&lt;/p&gt;
&lt;p&gt;When TensorFlow 2.0 and/or PyTorch has been installed, you can install from source by cloning the repository and running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install [--editable] &lt;span class="pl-c1"&gt;.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h3&gt;
&lt;p&gt;A series of tests are included for the library and the example scripts. Library tests can be found in the &lt;a href="https://github.com/huggingface/transformers/tree/master/transformers/tests"&gt;tests folder&lt;/a&gt; and examples tests in the &lt;a href="https://github.com/huggingface/transformers/tree/master/examples"&gt;examples folder&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These tests can be run using &lt;code&gt;pytest&lt;/code&gt; (install pytest if needed with &lt;code&gt;pip install pytest&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Depending on which framework is installed (TensorFlow 2.0 and/or PyTorch), the irrelevant tests will be skipped. Ensure that both frameworks are installed if you want to execute all tests.&lt;/p&gt;
&lt;p&gt;You can run the tests from the root of the cloned repository with the commands:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m pytest -sv ./transformers/tests/
python -m pytest -sv ./examples/&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-do-you-want-to-run-a-transformer-model-on-a-mobile-device" class="anchor" aria-hidden="true" href="#do-you-want-to-run-a-transformer-model-on-a-mobile-device"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Do you want to run a Transformer model on a mobile device?&lt;/h3&gt;
&lt;p&gt;You should check out our &lt;a href="https://github.com/huggingface/swift-coreml-transformers"&gt;&lt;code&gt;swift-coreml-transformers&lt;/code&gt;&lt;/a&gt; repo.&lt;/p&gt;
&lt;p&gt;It contains a set of tools to convert PyTorch or TensorFlow 2.0 trained Transformer models (currently contains &lt;code&gt;GPT-2&lt;/code&gt;, &lt;code&gt;DistilGPT-2&lt;/code&gt;, &lt;code&gt;BERT&lt;/code&gt;, and &lt;code&gt;DistilBERT&lt;/code&gt;) to CoreML models that run on iOS devices.&lt;/p&gt;
&lt;p&gt;At some point in the future, you'll be able to seamlessly move from pre-training or fine-tuning models to productizing them in CoreML, or prototype a model or an app in CoreML then research its hyperparameters or architecture from TensorFlow 2.0 and/or PyTorch. Super exciting!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-architectures" class="anchor" aria-hidden="true" href="#model-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model architectures&lt;/h2&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;🤗&lt;/g-emoji&gt; Transformers currently provides 10 NLU/NLG architectures:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/google-research/bert"&gt;BERT&lt;/a&gt;&lt;/strong&gt; (from Google) released with the paper &lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt; by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/openai/finetune-transformer-lm"&gt;GPT&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href="https://blog.openai.com/language-unsupervised/" rel="nofollow"&gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt; by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://blog.openai.com/better-language-models/" rel="nofollow"&gt;GPT-2&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href="https://blog.openai.com/better-language-models/" rel="nofollow"&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt; by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/kimiyoung/transformer-xl"&gt;Transformer-XL&lt;/a&gt;&lt;/strong&gt; (from Google/CMU) released with the paper &lt;a href="https://arxiv.org/abs/1901.02860" rel="nofollow"&gt;Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context&lt;/a&gt; by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/zihangdai/xlnet/"&gt;XLNet&lt;/a&gt;&lt;/strong&gt; (from Google/CMU) released with the paper &lt;a href="https://arxiv.org/abs/1906.08237" rel="nofollow"&gt;​XLNet: Generalized Autoregressive Pretraining for Language Understanding&lt;/a&gt; by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/facebookresearch/XLM/"&gt;XLM&lt;/a&gt;&lt;/strong&gt; (from Facebook) released together with the paper &lt;a href="https://arxiv.org/abs/1901.07291" rel="nofollow"&gt;Cross-lingual Language Model Pretraining&lt;/a&gt; by Guillaume Lample and Alexis Conneau.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/pytorch/fairseq/tree/master/examples/roberta"&gt;RoBERTa&lt;/a&gt;&lt;/strong&gt; (from Facebook), released together with the paper a &lt;a href="https://arxiv.org/abs/1907.11692" rel="nofollow"&gt;Robustly Optimized BERT Pretraining Approach&lt;/a&gt; by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/huggingface/transformers/tree/master/examples/distillation"&gt;DistilBERT&lt;/a&gt;&lt;/strong&gt; (from HuggingFace), released together with the paper &lt;a href="https://arxiv.org/abs/1910.01108" rel="nofollow"&gt;DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter&lt;/a&gt; by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into &lt;a href="https://github.com/huggingface/transformers/tree/master/examples/distillation"&gt;DistilGPT2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/salesforce/ctrl/"&gt;CTRL&lt;/a&gt;&lt;/strong&gt; (from Salesforce) released with the paper &lt;a href="https://arxiv.org/abs/1909.05858" rel="nofollow"&gt;CTRL: A Conditional Transformer Language Model for Controllable Generation&lt;/a&gt; by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://camembert-model.fr" rel="nofollow"&gt;CamemBERT&lt;/a&gt;&lt;/strong&gt; (from Inria/Facebook/Sorbonne) released with the paper &lt;a href="https://arxiv.org/abs/1911.03894" rel="nofollow"&gt;CamemBERT: a Tasty French Language Model&lt;/a&gt; by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la Clergerie, Djamé Seddah and Benoît Sagot.&lt;/li&gt;
&lt;li&gt;Want to contribute a new model? We have added a &lt;strong&gt;detailed guide and templates&lt;/strong&gt; to guide you in the process of adding a new model. You can find them in the &lt;a href="./templates"&gt;&lt;code&gt;templates&lt;/code&gt;&lt;/a&gt; folder of the repository. Be sure to check the &lt;a href="./CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; and contact the maintainers or open an issue to collect feedbacks before starting your PR.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These implementations have been tested on several datasets (see the example scripts) and should match the performances of the original implementations (e.g. ~93 F1 on SQuAD for BERT Whole-Word-Masking, ~88 F1 on RocStories for OpenAI GPT, ~18.3 perplexity on WikiText 103 for Transformer-XL, ~0.916 Peason R coefficient on STS-B for XLNet). You can find more details on the performances in the Examples section of the &lt;a href="https://huggingface.co/transformers/examples.html" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-online-demo" class="anchor" aria-hidden="true" href="#online-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online demo&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://transformer.huggingface.co" rel="nofollow"&gt;Write With Transformer&lt;/a&gt;&lt;/strong&gt;, built by the Hugging Face team at transformer.huggingface.co, is the official demo of this repo’s text generation capabilities.
You can use it to experiment with completions generated by &lt;code&gt;GPT2Model&lt;/code&gt;, &lt;code&gt;TransfoXLModel&lt;/code&gt;, and &lt;code&gt;XLNetModel&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“&lt;g-emoji class="g-emoji" alias="unicorn" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f984.png"&gt;🦄&lt;/g-emoji&gt; Write with transformer is to writing what calculators are to calculus.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba91bf4a35939363eca4ca83f3ad3f83248bbc60/68747470733a2f2f7472616e73666f726d65722e68756767696e67666163652e636f2f66726f6e742f6173736574732f7468756d626e61696c2d6c617267652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba91bf4a35939363eca4ca83f3ad3f83248bbc60/68747470733a2f2f7472616e73666f726d65722e68756767696e67666163652e636f2f66726f6e742f6173736574732f7468756d626e61696c2d6c617267652e706e67" alt="write_with_transformer" data-canonical-src="https://transformer.huggingface.co/front/assets/thumbnail-large.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour" class="anchor" aria-hidden="true" href="#quick-tour"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour&lt;/h2&gt;
&lt;p&gt;Let's do a very quick overview of the model architectures in &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;🤗&lt;/g-emoji&gt; Transformers. Detailed examples for each model architecture (Bert, GPT, GPT-2, Transformer-XL, XLNet and XLM) can be found in the &lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;full documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; torch
&lt;span class="pl-k"&gt;from&lt;/span&gt; transformers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Transformers has a unified API&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; for 8 transformer architectures and 30 pretrained weights.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;          Model          | Tokenizer          | Pretrained weights shortcut&lt;/span&gt;
&lt;span class="pl-c1"&gt;MODELS&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [(BertModel,       BertTokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (OpenAIGPTModel,  OpenAIGPTTokenizer,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;openai-gpt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (GPT2Model,       GPT2Tokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gpt2&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (CTRLModel,       CTRLTokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctrl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (TransfoXLModel,  TransfoXLTokenizer,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;transfo-xl-wt103&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (XLNetModel,      XLNetTokenizer,      &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;xlnet-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (XLMModel,        XLMTokenizer,        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;xlm-mlm-enfr-1024&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (DistilBertModel, DistilBertTokenizer, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;distilbert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (RobertaModel,    RobertaTokenizer,    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;roberta-base&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Let's encode some text in a sequence of hidden-states using each model:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; model_class, tokenizer_class, pretrained_weights &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;MODELS&lt;/span&gt;:
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load pretrained model/tokenizer&lt;/span&gt;
    tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer_class.from_pretrained(pretrained_weights)
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Encode text&lt;/span&gt;
    input_ids &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.tensor([tokenizer.encode(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Here is some text to encode&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)])  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Add special tokens takes care of adding [CLS], [SEP], &amp;lt;s&amp;gt;... tokens in the right way for each model.&lt;/span&gt;
    &lt;span class="pl-k"&gt;with&lt;/span&gt; torch.no_grad():
        last_hidden_states &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models outputs are now tuples&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.&lt;/span&gt;
&lt;span class="pl-c1"&gt;BERT_MODEL_CLASSES&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,
                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; All the classes for an architecture can be initiated from pretrained weights for this architecture&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Note that additional weights added for fine-tuning are only initialized&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; and need to be trained on the down-stream task&lt;/span&gt;
pretrained_weights &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(pretrained_weights)
&lt;span class="pl-k"&gt;for&lt;/span&gt; model_class &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;BERT_MODEL_CLASSES&lt;/span&gt;:
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load pretrained model/tokenizer&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models can return full list of hidden-states &amp;amp; attentions weights at each layer&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights,
                                        &lt;span class="pl-v"&gt;output_hidden_states&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                                        &lt;span class="pl-v"&gt;output_attentions&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
    input_ids &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.tensor([tokenizer.encode(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Let's see all hidden-states and attentions on this text&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)])
    all_hidden_states, all_attentions &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids)[&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;:]

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models are compatible with Torchscript&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights, &lt;span class="pl-v"&gt;torchscript&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
    traced_model &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.jit.trace(model, (input_ids,))

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Simple serialization for models and tokenizers&lt;/span&gt;
    model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; save&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; re-load&lt;/span&gt;
    tokenizer.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; save&lt;/span&gt;
    tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; re-load&lt;/span&gt;

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; SOTA examples for GLUE, SQUAD, text generation...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour-tf-20-training-and-pytorch-interoperability" class="anchor" aria-hidden="true" href="#quick-tour-tf-20-training-and-pytorch-interoperability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour TF 2.0 training and PyTorch interoperability&lt;/h2&gt;
&lt;p&gt;Let's do a quick example of how a TensorFlow 2.0 model can be trained in 12 lines of code with &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;🤗&lt;/g-emoji&gt; Transformers and then loaded in PyTorch for fast inspection/tests.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow &lt;span class="pl-k"&gt;as&lt;/span&gt; tf
&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow_datasets
&lt;span class="pl-k"&gt;from&lt;/span&gt; transformers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load dataset, tokenizer, model from pretrained model/vocabulary&lt;/span&gt;
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
model &lt;span class="pl-k"&gt;=&lt;/span&gt; TFBertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data &lt;span class="pl-k"&gt;=&lt;/span&gt; tensorflow_datasets.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;glue/mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Prepare dataset for GLUE as a tf.data.Dataset instance&lt;/span&gt;
train_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; glue_convert_examples_to_features(data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;train&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], tokenizer, &lt;span class="pl-v"&gt;max_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;task&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
valid_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; glue_convert_examples_to_features(data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;validation&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], tokenizer, &lt;span class="pl-v"&gt;max_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;task&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
train_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; train_dataset.shuffle(&lt;span class="pl-c1"&gt;100&lt;/span&gt;).batch(&lt;span class="pl-c1"&gt;32&lt;/span&gt;).repeat(&lt;span class="pl-c1"&gt;2&lt;/span&gt;)
valid_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; valid_dataset.batch(&lt;span class="pl-c1"&gt;64&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule &lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.optimizers.Adam(&lt;span class="pl-v"&gt;learning_rate&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3e-5&lt;/span&gt;, &lt;span class="pl-v"&gt;epsilon&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1e-08&lt;/span&gt;, &lt;span class="pl-v"&gt;clipnorm&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1.0&lt;/span&gt;)
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.losses.SparseCategoricalCrossentropy(&lt;span class="pl-v"&gt;from_logits&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
metric &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.metrics.SparseCategoricalAccuracy(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
model.compile(&lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;optimizer, &lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;loss, &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[metric])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train and evaluate using tf.keras.Model.fit()&lt;/span&gt;
history &lt;span class="pl-k"&gt;=&lt;/span&gt; model.fit(train_dataset, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-v"&gt;steps_per_epoch&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;115&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_dataset, &lt;span class="pl-v"&gt;validation_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;7&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load the TensorFlow model in PyTorch for inspection&lt;/span&gt;
model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
pytorch_model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;from_tf&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Quickly test a few predictions - MRPC is a paraphrasing task, let's see if our model learned the task&lt;/span&gt;
sentence_0 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;This research was consistent with his findings.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
sentence_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;His findings were compatible with this research.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
sentence_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;His findings were not compatible with this research.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
inputs_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer.encode_plus(sentence_0, sentence_1, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-v"&gt;return_tensors&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
inputs_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer.encode_plus(sentence_0, sentence_2, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-v"&gt;return_tensors&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

pred_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; pytorch_model(inputs_1[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], &lt;span class="pl-v"&gt;token_type_ids&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;inputs_1[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;token_type_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].argmax().item()
pred_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; pytorch_model(inputs_2[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], &lt;span class="pl-v"&gt;token_type_ids&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;inputs_2[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;token_type_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].argmax().item()

&lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sentence_1 is&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; pred_1 &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;not a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;of sentence_0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sentence_2 is&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; pred_2 &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;not a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;of sentence_0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour-of-the-fine-tuningusage-scripts" class="anchor" aria-hidden="true" href="#quick-tour-of-the-fine-tuningusage-scripts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour of the fine-tuning/usage scripts&lt;/h2&gt;
&lt;p&gt;The library comprises several example scripts with SOTA performances for NLU and NLG tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;run_glue.py&lt;/code&gt;: an example fine-tuning Bert, XLNet and XLM on nine different GLUE tasks (&lt;em&gt;sequence-level classification&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_squad.py&lt;/code&gt;: an example fine-tuning Bert, XLNet and XLM on the question answering dataset SQuAD 2.0 (&lt;em&gt;token-level classification&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_generation.py&lt;/code&gt;: an example using GPT, GPT-2, CTRL, Transformer-XL and XLNet for conditional language generation&lt;/li&gt;
&lt;li&gt;other model-specific examples (see the documentation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are three quick usage examples for these scripts:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run_gluepy-fine-tuning-on-glue-tasks-for-sequence-classification" class="anchor" aria-hidden="true" href="#run_gluepy-fine-tuning-on-glue-tasks-for-sequence-classification"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_glue.py&lt;/code&gt;: Fine-tuning on GLUE tasks for sequence classification&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://gluebenchmark.com/" rel="nofollow"&gt;General Language Understanding Evaluation (GLUE) benchmark&lt;/a&gt; is a collection of nine sentence- or sentence-pair language understanding tasks for evaluating and analyzing natural language understanding systems.&lt;/p&gt;
&lt;p&gt;Before running anyone of these GLUE tasks you should download the
&lt;a href="https://gluebenchmark.com/tasks" rel="nofollow"&gt;GLUE data&lt;/a&gt; by running
&lt;a href="https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e"&gt;this script&lt;/a&gt;
and unpack it to some directory &lt;code&gt;$GLUE_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You should also install the additional packages required by the examples:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -r ./examples/requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue
&lt;span class="pl-k"&gt;export&lt;/span&gt; TASK_NAME=MRPC

python ./examples/run_glue.py \
    --model_type bert \
    --model_name_or_path bert-base-uncased \
    --task_name &lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt; \
    --do_train \
    --do_eval \
    --do_lower_case \
    --data_dir &lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/&lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt; \
    --max_seq_length 128 \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --learning_rate 2e-5 \
    --num_train_epochs 3.0 \
    --output_dir /tmp/&lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt;/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where task name can be one of CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, RTE, WNLI.&lt;/p&gt;
&lt;p&gt;The dev set results will be present within the text file 'eval_results.txt' in the specified output_dir. In case of MNLI, since there are two separate dev sets, matched and mismatched, there will be a separate output folder called '/tmp/MNLI-MM/' in addition to '/tmp/MNLI/'.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-fine-tuning-xlnet-model-on-the-sts-b-regression-task" class="anchor" aria-hidden="true" href="#fine-tuning-xlnet-model-on-the-sts-b-regression-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning XLNet model on the STS-B regression task&lt;/h4&gt;
&lt;p&gt;This example code fine-tunes XLNet on the STS-B corpus using parallel training on a server with 4 V100 GPUs.
Parallel training is a simple way to use several GPUs (but is slower and less flexible than distributed training, see below).&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue

python ./examples/run_glue.py \
    --model_type xlnet \
    --model_name_or_path xlnet-large-cased \
    --do_train  \
    --do_eval   \
    --task_name=sts-b     \
    --data_dir=&lt;span class="pl-smi"&gt;${GLUE_DIR}&lt;/span&gt;/STS-B  \
    --output_dir=./proc_data/sts-b-110   \
    --max_seq_length=128   \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --gradient_accumulation_steps=1 \
    --max_steps=1200  \
    --model_name=xlnet-large-cased   \
    --overwrite_output_dir   \
    --overwrite_cache \
    --warmup_steps=120&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On this machine we thus have a batch size of 32, please increase &lt;code&gt;gradient_accumulation_steps&lt;/code&gt; to reach the same batch size if you have a smaller machine. These hyper-parameters should result in a Pearson correlation coefficient of &lt;code&gt;+0.917&lt;/code&gt; on the development set.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-fine-tuning-bert-model-on-the-mrpc-classification-task" class="anchor" aria-hidden="true" href="#fine-tuning-bert-model-on-the-mrpc-classification-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning Bert model on the MRPC classification task&lt;/h4&gt;
&lt;p&gt;This example code fine-tunes the Bert Whole Word Masking model on the Microsoft Research Paraphrase Corpus (MRPC) corpus using distributed training on 8 V100 GPUs to reach a F1 &amp;gt; 92.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m torch.distributed.launch --nproc_per_node 8 ./examples/run_glue.py   \
    --model_type bert \
    --model_name_or_path bert-large-uncased-whole-word-masking \
    --task_name MRPC \
    --do_train   \
    --do_eval   \
    --do_lower_case   \
    --data_dir &lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC/   \
    --max_seq_length 128   \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --learning_rate 2e-5   \
    --num_train_epochs 3.0  \
    --output_dir /tmp/mrpc_output/ \
    --overwrite_output_dir   \
    --overwrite_cache \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Training with these hyper-parameters gave us the following results:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;  acc = 0.8823529411764706
  acc_and_f1 = 0.901702786377709
  eval_loss = 0.3418912578906332
  f1 = 0.9210526315789473
  global_step = 174
  loss = 0.07231863956341798&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-run_squadpy-fine-tuning-on-squad-for-question-answering" class="anchor" aria-hidden="true" href="#run_squadpy-fine-tuning-on-squad-for-question-answering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_squad.py&lt;/code&gt;: Fine-tuning on SQuAD for question-answering&lt;/h3&gt;
&lt;p&gt;This example code fine-tunes BERT on the SQuAD dataset using distributed training on 8 V100 GPUs and Bert Whole Word Masking uncased model to reach a F1 &amp;gt; 93 on SQuAD:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m torch.distributed.launch --nproc_per_node=8 ./examples/run_squad.py \
    --model_type bert \
    --model_name_or_path bert-large-uncased-whole-word-masking \
    --do_train \
    --do_eval \
    --do_lower_case \
    --train_file &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
    --predict_file &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
    --learning_rate 3e-5 \
    --num_train_epochs 2 \
    --max_seq_length 384 \
    --doc_stride 128 \
    --output_dir ../models/wwm_uncased_finetuned_squad/ \
    --per_gpu_eval_batch_size=3   \
    --per_gpu_train_batch_size=3   \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Training with these hyper-parameters gave us the following results:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/evaluate-v1.1.py &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json ../models/wwm_uncased_finetuned_squad/predictions.json
{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 86.91579943235573, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 93.1532499015869}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the model provided as &lt;code&gt;bert-large-uncased-whole-word-masking-finetuned-squad&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run_generationpy-text-generation-with-gpt-gpt-2-ctrl-transformer-xl-and-xlnet" class="anchor" aria-hidden="true" href="#run_generationpy-text-generation-with-gpt-gpt-2-ctrl-transformer-xl-and-xlnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_generation.py&lt;/code&gt;: Text generation with GPT, GPT-2, CTRL, Transformer-XL and XLNet&lt;/h3&gt;
&lt;p&gt;A conditional generation script is also included to generate text from a prompt.
The generation script includes the &lt;a href="https://github.com/rusiaaman/XLNet-gen#methodology"&gt;tricks&lt;/a&gt; proposed by Aman Rusia to get high-quality generation with memory models like Transformer-XL and XLNet (include a predefined text to make short inputs longer).&lt;/p&gt;
&lt;p&gt;Here is how to run the script with the small version of OpenAI GPT-2 model:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./examples/run_generation.py \
    --model_type=gpt2 \
    --length=20 \
    --model_name_or_path=gpt2 \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and from the Salesforce CTRL model:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./examples/run_generation.py \
    --model_type=ctrl \
    --length=20 \
    --model_name_or_path=ctrl \
    --temperature=0 \
    --repetition_penalty=1.2 \&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-migrating-from-pytorch-transformers-to-transformers" class="anchor" aria-hidden="true" href="#migrating-from-pytorch-transformers-to-transformers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Migrating from pytorch-transformers to transformers&lt;/h2&gt;
&lt;p&gt;Here is a quick summary of what you should take care of when migrating from &lt;code&gt;pytorch-transformers&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-positional-order-of-some-models-keywords-inputs-attention_mask-token_type_ids-changed" class="anchor" aria-hidden="true" href="#positional-order-of-some-models-keywords-inputs-attention_mask-token_type_ids-changed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Positional order of some models' keywords inputs (&lt;code&gt;attention_mask&lt;/code&gt;, &lt;code&gt;token_type_ids&lt;/code&gt;...) changed&lt;/h3&gt;
&lt;p&gt;To be able to use Torchscript (see #1010, #1204 and #1195) the specific order of some models &lt;strong&gt;keywords inputs&lt;/strong&gt; (&lt;code&gt;attention_mask&lt;/code&gt;, &lt;code&gt;token_type_ids&lt;/code&gt;...) has been changed.&lt;/p&gt;
&lt;p&gt;If you used to call the models with keyword names for keyword arguments, e.g. &lt;code&gt;model(inputs_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)&lt;/code&gt;, this should not cause any change.&lt;/p&gt;
&lt;p&gt;If you used to call the models with positional inputs for keyword arguments, e.g. &lt;code&gt;model(inputs_ids, attention_mask, token_type_ids)&lt;/code&gt;, you may have to double check the exact order of input arguments.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-migrating-from-pytorch-pretrained-bert-to-transformers" class="anchor" aria-hidden="true" href="#migrating-from-pytorch-pretrained-bert-to-transformers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Migrating from pytorch-pretrained-bert to transformers&lt;/h2&gt;
&lt;p&gt;Here is a quick summary of what you should take care of when migrating from &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-models-always-output-tuples" class="anchor" aria-hidden="true" href="#models-always-output-tuples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models always output &lt;code&gt;tuples&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The main breaking change when migrating from &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt; is that every model's forward method always outputs a &lt;code&gt;tuple&lt;/code&gt; with various elements depending on the model and the configuration parameters.&lt;/p&gt;
&lt;p&gt;The exact content of the tuples for each model is detailed in the models' docstrings and the &lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In pretty much every case, you will be fine by taking the first element of the output as the output you previously used in &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is a &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt; conversion example for a &lt;code&gt;BertForSequenceClassification&lt;/code&gt; classification model:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Let's load our model&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; If you used to have this line in pytorch-pretrained-bert:&lt;/span&gt;
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Now just use this line in transformers to extract the loss from the output tuple:&lt;/span&gt;
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; In transformers you can also have access to the logits:&lt;/span&gt;
loss, logits &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs[:&lt;span class="pl-c1"&gt;2&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; And even the attention weights if you configure the model to output them (and other outputs too, see the docstrings and documentation)&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_attentions&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)
loss, logits, attentions &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-using-hidden-states" class="anchor" aria-hidden="true" href="#using-hidden-states"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using hidden states&lt;/h3&gt;
&lt;p&gt;By enabling the configuration option &lt;code&gt;output_hidden_states&lt;/code&gt;, it was possible to retrieve the last hidden states of the encoder. In &lt;code&gt;pytorch-transformers&lt;/code&gt; as well as &lt;code&gt;transformers&lt;/code&gt; the return value has changed slightly: &lt;code&gt;all_hidden_states&lt;/code&gt; now also includes the hidden state of the embeddings in addition to those of the encoding layers. This allows users to easily access the embeddings final state.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-serialization" class="anchor" aria-hidden="true" href="#serialization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serialization&lt;/h3&gt;
&lt;p&gt;Breaking change in the &lt;code&gt;from_pretrained()&lt;/code&gt; method:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Models are now set in evaluation mode by default when instantiated with the &lt;code&gt;from_pretrained()&lt;/code&gt; method. To train them, don't forget to set them back in training mode (&lt;code&gt;model.train()&lt;/code&gt;) to activate the dropout modules.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The additional &lt;code&gt;*input&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; arguments supplied to the &lt;code&gt;from_pretrained()&lt;/code&gt; method used to be directly passed to the underlying model's class &lt;code&gt;__init__()&lt;/code&gt; method. They are now used to update the model configuration attribute instead, which can break derived model classes built based on the previous &lt;code&gt;BertForSequenceClassification&lt;/code&gt; examples. We are working on a way to mitigate this breaking change in &lt;a href="https://github.com/huggingface/transformers/pull/866"&gt;#866&lt;/a&gt; by forwarding the the model's &lt;code&gt;__init__()&lt;/code&gt; method (i) the provided positional arguments and (ii) the keyword arguments which do not match any configuration class attributes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Also, while not a breaking change, the serialization methods have been standardized and you probably should switch to the new method &lt;code&gt;save_pretrained(save_directory)&lt;/code&gt; if you were using any other serialization method before.&lt;/p&gt;
&lt;p&gt;Here is an example:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Let's load a model and tokenizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Do some stuff to our model and tokenizer&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Ex: add new tokens to the vocabulary and embeddings of our model&lt;/span&gt;
tokenizer.add_tokens([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;[SPECIAL_TOKEN_1]&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;[SPECIAL_TOKEN_2]&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
model.resize_token_embeddings(&lt;span class="pl-c1"&gt;len&lt;/span&gt;(tokenizer))
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train our model&lt;/span&gt;
train(model)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Now let's save our model and tokenizer to a directory&lt;/span&gt;
model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Reload the model and the tokenizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-optimizers-bertadam--openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules" class="anchor" aria-hidden="true" href="#optimizers-bertadam--openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimizers: BertAdam &amp;amp; OpenAIAdam are now AdamW, schedules are standard PyTorch schedules&lt;/h3&gt;
&lt;p&gt;The two optimizers previously included, &lt;code&gt;BertAdam&lt;/code&gt; and &lt;code&gt;OpenAIAdam&lt;/code&gt;, have been replaced by a single &lt;code&gt;AdamW&lt;/code&gt; optimizer which has a few differences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it only implements weights decay correction,&lt;/li&gt;
&lt;li&gt;schedules are now externals (see below),&lt;/li&gt;
&lt;li&gt;gradient clipping is now also external (see below).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The new optimizer &lt;code&gt;AdamW&lt;/code&gt; matches PyTorch &lt;code&gt;Adam&lt;/code&gt; optimizer API and let you use standard PyTorch or apex methods for the schedule and clipping.&lt;/p&gt;
&lt;p&gt;The schedules are now standard &lt;a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" rel="nofollow"&gt;PyTorch learning rate schedulers&lt;/a&gt; and not part of the optimizer anymore.&lt;/p&gt;
&lt;p&gt;Here is a conversion examples from &lt;code&gt;BertAdam&lt;/code&gt; with a linear warmup and decay schedule to &lt;code&gt;AdamW&lt;/code&gt; and the same schedule:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Parameters:&lt;/span&gt;
lr &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1e-3&lt;/span&gt;
max_grad_norm &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1.0&lt;/span&gt;
num_training_steps &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1000&lt;/span&gt;
num_warmup_steps &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt;
warmup_proportion &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;float&lt;/span&gt;(num_warmup_steps) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;float&lt;/span&gt;(num_training_steps)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 0.1&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Previously BertAdam optimizer was instantiated like this:&lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertAdam(model.parameters(), &lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;lr, &lt;span class="pl-v"&gt;schedule&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;warmup_linear&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;warmup&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;warmup_proportion, &lt;span class="pl-v"&gt;t_total&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_training_steps)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## and used like this:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; batch &lt;span class="pl-k"&gt;in&lt;/span&gt; train_data:
    loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(batch)
    loss.backward()
    optimizer.step()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## In Transformers, optimizer and schedules are splitted and instantiated like this:&lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; AdamW(model.parameters(), &lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;lr, &lt;span class="pl-v"&gt;correct_bias&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;False&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; To reproduce BertAdam specific behavior set correct_bias=False&lt;/span&gt;
scheduler &lt;span class="pl-k"&gt;=&lt;/span&gt; get_linear_schedule_with_warmup(optimizer, &lt;span class="pl-v"&gt;num_warmup_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_warmup_steps, &lt;span class="pl-v"&gt;num_training_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_training_steps)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; PyTorch scheduler&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## and used like this:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; batch &lt;span class="pl-k"&gt;in&lt;/span&gt; train_data:
    model.train()
    loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(batch)
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Gradient clipping is not in AdamW anymore (so you can use amp without issue)&lt;/span&gt;
    optimizer.step()
    scheduler.step()
    optimizer.zero_grad()&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;We now have a paper you can cite for the &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;🤗&lt;/g-emoji&gt; Transformers library:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>huggingface</author><guid isPermaLink="false">https://github.com/huggingface/transformers</guid><pubDate>Wed, 20 Nov 2019 00:10:00 GMT</pubDate></item><item><title>mzfr/rsh #11 in Python, Today</title><link>https://github.com/mzfr/rsh</link><description>&lt;p&gt;&lt;i&gt;generate reverse shell from CLI for linux and Windows.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="Readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://www.gnu.org/licenses/gpl-3.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ec385922fa349d9c349f34b7f3bf311843e35ba8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d626c75652e737667" alt="License: GPL v3" data-canonical-src="https://img.shields.io/badge/License-GPLv3-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://GitHub.com/mzfr/liffy/graphs/commit-activity"&gt;&lt;img src="https://camo.githubusercontent.com/0e6a3f975d68b438efec82fef1f9491600606df8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61696e7461696e65642533462d7965732d677265656e2e737667" alt="Maintenance" data-canonical-src="https://img.shields.io/badge/Maintained%3F-yes-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a id="user-content-rsh" class="anchor" aria-hidden="true" href="#rsh"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;rsh&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/rsh.png"&gt;&lt;img src="images/rsh.png" alt="rsh in action" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="#features"&gt;Introduction&lt;/a&gt; •
  &lt;a href="#usage"&gt;Usage&lt;/a&gt; •
  &lt;a href="#installation"&gt;Installation&lt;/a&gt; •
  &lt;a href="#gallery"&gt;Gallery&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;rsh is a tool purely written in python to easily generate reverse shell command for linux as well as windows.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h3&gt;
&lt;p&gt;This tools makes it easy for you to generate reverse shell command supported in both linux and windows, in the following languages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bash
&lt;ul&gt;
&lt;li&gt;netcat&lt;/li&gt;
&lt;li&gt;netcat OpenBSD&lt;/li&gt;
&lt;li&gt;nc.traditional&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;IPv4&lt;/li&gt;
&lt;li&gt;IPv6&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ruby&lt;/li&gt;
&lt;li&gt;Perl&lt;/li&gt;
&lt;li&gt;PHP&lt;/li&gt;
&lt;li&gt;PowerShell&lt;/li&gt;
&lt;li&gt;Node.JS&lt;/li&gt;
&lt;li&gt;TCLSH&lt;/li&gt;
&lt;li&gt;AWK&lt;/li&gt;
&lt;li&gt;JAVA&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;usage: revsh.py [-h] [-sh SH] lhost lport

positional arguments:
  lhost       Specify local host ip
  lport       Specify a local port

optional arguments:
  -h, --help  show this help message and exit
  -sh SH      Specify the language to generate the reverse shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using rsh is very simple. All you need to do is provide IP and Port and the type of shell that is to be generated.
EX:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;./rsh 192.168.56.1 4444 -sh bash&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./rsh 192.168.56.1 4444 -sh php&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./rsh 192.168.56.1 4444 -sh powershell&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;p&gt;You need python 3.5 or greater. Along with that rsh uses [pyfiglet] which you can install by running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install pyfiglet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nothing else is required to run rsh.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-gallery" class="anchor" aria-hidden="true" href="#gallery"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gallery&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Getting bash command&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/rsh.png"&gt;&lt;img src="images/rsh.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Options&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/options.png"&gt;&lt;img src="images/options.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Wrong IP&lt;/strong&gt; &lt;g-emoji class="g-emoji" alias="smile" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png"&gt;😄&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/ip-err.png"&gt;&lt;img src="images/ip-err.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Wrong PORT&lt;/strong&gt; &lt;g-emoji class="g-emoji" alias="smile" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png"&gt;😄&lt;/g-emoji&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/port-err.png"&gt;&lt;img src="images/port-err.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contribution" class="anchor" aria-hidden="true" href="#contribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Report a bug&lt;/li&gt;
&lt;li&gt;Fix something and open a pull request&lt;/li&gt;
&lt;li&gt;Add more reverse shell&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In any case feel free to open an issue&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;All the shell command are taken from &lt;a href="http://pentestmonkey.net/" rel="nofollow"&gt;pentestmonkey&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the GPLv3 License - see the &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file for details&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mzfr</author><guid isPermaLink="false">https://github.com/mzfr/rsh</guid><pubDate>Wed, 20 Nov 2019 00:11:00 GMT</pubDate></item><item><title>google-research/text-to-text-transfer-transformer #12 in Python, Today</title><link>https://github.com/google-research/text-to-text-transfer-transformer</link><description>&lt;p&gt;&lt;i&gt;Code for the paper "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-t5-text-to-text-transfer-transformer" class="anchor" aria-hidden="true" href="#t5-text-to-text-transfer-transformer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;T5: Text-To-Text Transfer Transformer&lt;/h1&gt;
&lt;p&gt;T5 serves primarily as code for reproducing the experiments in &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;&lt;em&gt;Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer&lt;/em&gt;&lt;/a&gt;.
The bulk of the code in this repository is used for loading, preprocessing, mixing, and evaluating datasets.
It also provides a way to fine-tune the &lt;a href="#released-model-checkpoints"&gt;pre-trained models&lt;/a&gt; released alongside the publication.&lt;/p&gt;
&lt;p&gt;T5 can be used as a library for future model development by providing useful modules for training and fine-tuning (potentially &lt;em&gt;huge&lt;/em&gt;) models on mixtures of text-to-text tasks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-organization" class="anchor" aria-hidden="true" href="#organization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Organization&lt;/h2&gt;
&lt;p&gt;T5 is organized into 3 core packages plus configurations for reproducing experiments from the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt;:&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-t5data" class="anchor" aria-hidden="true" href="#t5data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;t5.data&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;t5.data&lt;/code&gt; is a library for defining &lt;code&gt;Task&lt;/code&gt; objects that provide &lt;code&gt;tf.data.Dataset&lt;/code&gt;s. Each &lt;code&gt;Task&lt;/code&gt; references a dataset from &lt;a href="https://www.tensorflow.org/datasets" rel="nofollow"&gt;TensorFlow Datasets&lt;/a&gt; along with a preprocesssing function for converting the dataset into the appropriate format for a text-to-text model with fields for &lt;code&gt;inputs&lt;/code&gt; and &lt;code&gt;targets&lt;/code&gt;.  For example, the &lt;code&gt;translate&lt;/code&gt; preprocessor converts inputs in the form&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;de&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Das ist gut.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;en&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;That is good.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to the form&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;inputs&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;translate German to English: Das ist gut.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;targets&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;That is good.&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;Task&lt;/code&gt; objects also handle tokenization of strings, optional preprocessing of the token representation (e.g., corruptions for unsupservised training), and specification of associated metrics for evaluation.&lt;/p&gt;
&lt;p&gt;Finally, &lt;code&gt;t5.data&lt;/code&gt; contains a &lt;code&gt;Mixture&lt;/code&gt; class that can be instantiated to combine multiple &lt;code&gt;Task&lt;/code&gt; datasets for multi-task training using various functions for specifying the mixture rates.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-t5evaluation" class="anchor" aria-hidden="true" href="#t5evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;t5.evaluation&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;t5.evaluation&lt;/code&gt; contains two core components: a module for specifying metrics to be used during evaluation and utilities for applying these metrics at evaluation time.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-t5models" class="anchor" aria-hidden="true" href="#t5models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;t5.models&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;t5.models&lt;/code&gt; contains shims for connecting T5 &lt;code&gt;Tasks&lt;/code&gt; and &lt;code&gt;Mixtures&lt;/code&gt; to a model implementation for training, evaluation, and inference. Currently the only available shim is to the &lt;a href="https://github.com/tensorflow/mesh/tree/master/mesh_tensorflow/transformer"&gt;Mesh TensorFlow Transformer&lt;/a&gt;, which enables both data and model parallelism for training massive Transformer models. It also includes a binary for launching the model along with &lt;a href="https://github.com/google/gin-config"&gt;gin config&lt;/a&gt; files for setting various hyperparameters.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;Here we provide example usage for how to pre-train, fine-tune, evaluate, and decode from a model with our codebase. You can use these instructions to reproduce our results, fine-tune one of our released checkpoints with your own data and/or hyperparameters, or pre-train a model from scratch.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-datasets" class="anchor" aria-hidden="true" href="#datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Datasets&lt;/h3&gt;
&lt;p&gt;We use &lt;a href="https://www.tensorflow.org/datasets" rel="nofollow"&gt;TensorFlow Datasets (TFDS)&lt;/a&gt; as our dataset repository. When you select a dataset and run our training binary (see instructions below), the dataset will automatically be downloaded and prepared on its first use. After preparation is complete, the dataset is cached to your local storage to avoid this overhead in future runs.  If working in the cloud, we recommend you set the &lt;code&gt;--t5_tfds_data_dir&lt;/code&gt; flag to point to a persistent storage location, such as a &lt;a href="https://www.tensorflow.org/datasets/gcs" rel="nofollow"&gt;GCS bucket&lt;/a&gt;. This is a requirement when training on TPU.&lt;/p&gt;
&lt;p&gt;Note that the &lt;a href="https://www.tensorflow.org/datasets/catalog/c4" rel="nofollow"&gt;C4&lt;/a&gt; dataset we created for unsupervised pre-training requires a significant amount of bandwith for downloading the raw &lt;a href="https://commoncrawl.org" rel="nofollow"&gt;Common Crawl&lt;/a&gt; scrapes and compute for its preparation. We suggest you take advantage of the &lt;a href="https://beam.apache.org" rel="nofollow"&gt;Apache Beam&lt;/a&gt; support in TFDS, which enables distributed preprocessing of the dataset and can be run on &lt;a href="https://cloud.google.com/dataflow/" rel="nofollow"&gt;Google Cloud Dataflow&lt;/a&gt;. Otherwise, it is unlikely that you will be able to complete preprocessing in a human lifetime. Read more in the &lt;a href="https://www.tensorflow.org/datasets/beam_datasets" rel="nofollow"&gt;TFDS Beam instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;p&gt;To install the T5 package, simply run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install t5[gcp]&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-setting-up-tpus-on-gcp-for-training-and-evaluation" class="anchor" aria-hidden="true" href="#setting-up-tpus-on-gcp-for-training-and-evaluation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setting up TPUs on GCP for training and evaluation&lt;/h3&gt;
&lt;p&gt;You will first need to launch a Virtual Machine (VM) on Google Cloud. Details about launching the VM can be found at the &lt;a href="http://cloud/compute/docs/instances/create-start-instance" rel="nofollow"&gt;Google Cloud Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order to run training or eval on Cloud TPUs, you must set up the following variables based on your project, zone and GCS bucket appropriately. Please refer to the &lt;a href="https://cloud.google.com/tpu/docs/quickstart" rel="nofollow"&gt;Cloud TPU Quickstart&lt;/a&gt; guide for more details.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; PROJECT=your_project_name
&lt;span class="pl-k"&gt;export&lt;/span&gt; ZONE=your_project_zone
&lt;span class="pl-k"&gt;export&lt;/span&gt; BUCKET=gs://yourbucket/
&lt;span class="pl-k"&gt;export&lt;/span&gt; TPU_NAME=t5-tpu
&lt;span class="pl-k"&gt;export&lt;/span&gt; DATA_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/your_data_dir&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;export&lt;/span&gt; MODEL_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/your_model_dir&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Please use the following command to create a TPU device in the Cloud VM.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;ctpu up --name=&lt;span class="pl-smi"&gt;$TPU_NAME&lt;/span&gt; --project=&lt;span class="pl-smi"&gt;$PROJECT&lt;/span&gt; --zone=&lt;span class="pl-smi"&gt;$ZONE&lt;/span&gt; --tpu-size=v3-8  \
        --tpu-only   --tf-version=1.15 --noconf&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h3&gt;
&lt;p&gt;In the command below, we train a model on the &lt;a href="https://gluebenchmark.com/" rel="nofollow"&gt;GLUE Benchmark&lt;/a&gt; MRPC task from scratch. You can change the &lt;code&gt;MIXTURE_NAME&lt;/code&gt; gin parameter to use any of the tasks or mixtures provided in our package.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --t5_tfds_data_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dataset.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;models/bi_v1.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MIXTURE_NAME = 'glue_mrpc_v002'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The full list of tasks and mixtures can be obtained by running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -c &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;import t5; print(t5.data.MixtureRegistry.names())&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-fine-tuning" class="anchor" aria-hidden="true" href="#fine-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning&lt;/h3&gt;
&lt;p&gt;In order to fine-tune one of our &lt;a href="#released-model-checkpoints"&gt;pre-trained models&lt;/a&gt;, you need to pass the operative config of the pre-trained model to the training script. The operative config should be passed in as a &lt;code&gt;gin_file&lt;/code&gt; flag. It specifies the model architecture and other hyperparameters. In addition, you need to specify the mixture to fine-tune on. For example, to fine-tune the T5-small model on the &lt;code&gt;glue_mrpc_v002&lt;/code&gt; mixture, please run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --t5_tfds_data_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dataset.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MIXTURE_NAME = 'glue_mrpc_v002'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;gs://t5-data/pretrained_models/small/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The correct pre-trained checkpoint path is included in the operative config.&lt;/p&gt;
&lt;p&gt;Alternatively, you could fine-tune with a TSV file where each line is formatted as &lt;code&gt;&amp;lt;input&amp;gt;\t&amp;lt;target&amp;gt;&lt;/code&gt;. For example, you could try one of the paired translation datasets from WMT '19 &lt;a href="http://data.statmt.org/news-commentary/v14/training/" rel="nofollow"&gt;News Commentary 14&lt;/a&gt; training set
(e.g., &lt;a href="http://data.statmt.org/news-commentary/v14/training/" rel="nofollow"&gt;English-French&lt;/a&gt;). When using a TSV file, you would replace the &lt;code&gt;MIXTURE_NAME&lt;/code&gt; flag with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;--gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.run.train_dataset_fn = @t5.models.mesh_transformer.tsv_dataset_fn&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
--gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;tsv_dataset_fn.filename = 'gs:/path/to/tsv'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To fine-tune with the same hyperparameters we used in the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt; (using a constant learning rate of 0.001), you can pass in this gin file which is included in the T5 package:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_file="learning_rate_schedules/constant_0_001.gin"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The operative config for the pre-trained models are set so that there is effectively no limit on the number of train steps. If you'd like to train for a specific number of steps, you'll need to pass that in. Since the pre-trained model has already been trained for 1,000,000 steps, you should specify the total number of steps after pre-training and fine-tuning. For example, if you want to fine-tune for an additional 10,000 steps, you should pass&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param="run.train_steps = 1010000"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use a different batch size for fine-tuning. We set the batch size according to the total number of tokens in a batch. By default, a batch uses a sequence length of 512. To set the number of tokens in a batch, you should set&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param = "tokens_per_batch=1048576"
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-eval" class="anchor" aria-hidden="true" href="#eval"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eval&lt;/h3&gt;
&lt;p&gt;In order to evaluate a model in the T5 framework, you need to use the &lt;code&gt;eval.gin&lt;/code&gt; file, specify the model directory, decoding method, and which checkpoint step(s) to evaluate. So, to evaluate on the GLUE MRPC task using beam search on &lt;em&gt;all&lt;/em&gt; checkpoints, use the following command:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --t5_tfds_data_dir=&lt;span class="pl-smi"&gt;${DATA_DIR}&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;eval.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;beam_search.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MIXTURE_NAME = 'glue_mrpc_v002'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;eval_checkpoint_step = 'all'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To evaluate a specific checkpoint, simply set the &lt;code&gt;eval_checkpoint_step&lt;/code&gt; parameter to appropriate checkpoint.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param="eval_checkpoint_step = 100000"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use &lt;code&gt;greedy_decode.gin&lt;/code&gt; or &lt;code&gt;sample_decode.gin&lt;/code&gt; instead of &lt;code&gt;beam_search.gin&lt;/code&gt; in the command above.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-decode" class="anchor" aria-hidden="true" href="#decode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Decode&lt;/h4&gt;
&lt;p&gt;In order to produce predictions from a model in the T5 framework, you need to specify the model directory, decoding method, and which checkpoint step(s) to use for decoding. Assuming you have a text file of input sequences stored at &lt;code&gt;/path/to/intputs.txt&lt;/code&gt;, an example command would be:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;t5_mesh_transformer \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${MODEL_DIR}&lt;/span&gt;/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;infer.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sample_decode.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;input_filename = '/path/to/inputs.txt'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;\
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;output_filename = '/tmp/outputs.txt'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;\
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;\
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;infer_checkpoint_step = 'all'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To predict with a specific checkpoint, simply set the &lt;code&gt;infer_checkpoint_step&lt;/code&gt; parameter to appropriate checkpoint.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--gin_param="infer_checkpoint_step = 100000"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use &lt;code&gt;beam_search.gin&lt;/code&gt; or &lt;code&gt;greedy_decode.gin&lt;/code&gt; instead of &lt;code&gt;sample_decode.gin&lt;/code&gt; in the command above.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-reproducing-our-experiments" class="anchor" aria-hidden="true" href="#reproducing-our-experiments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reproducing our experiments&lt;/h3&gt;
&lt;p&gt;We provide operative configs for all of the experiments in the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt; in &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments" rel="nofollow"&gt;gs://t5-data/experiments&lt;/a&gt;.
The &lt;code&gt;experiments&lt;/code&gt; folder has different subdirectories corresponding to the different sections in our paper.
For example, &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives" rel="nofollow"&gt;gs://t5-data/experiments/objectives&lt;/a&gt; contains the experiments from Section 3.3 ("Unsupervised objectives").
Each subdirectory of the &lt;code&gt;objectives&lt;/code&gt; folder contains operative configs for some particular experiment (where loosely speaking an "experiment" is one of the rows in one of the tables in our paper).&lt;/p&gt;
&lt;p&gt;Let's say you want to reproduce the results for the "Prefix language modeling" objective (the first row in Table 4).
The operative configs for that experiment live in &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives/obj-prefix_lm" rel="nofollow"&gt;gs://t5-data/experiments/objectives/obj-prefix_lm&lt;/a&gt;.
In the base directory, there is an operative config for pre-training the model (&lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives/obj-prefix_lm/operative_config.gin" rel="nofollow"&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/operative_config.gin&lt;/a&gt;).
Then, there are subdirectories for each of the downstream fine-tuning mixtures we consider, each of which has its own operative config (for example, &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/experiments/objectives/obj-prefix_lm/cnn_dailymail_v002/operative_config.gin" rel="nofollow"&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/cnn_dailymail_v002/operative_config.gin&lt;/a&gt;).
To run this experiment, first pre-train a model with the pre-training operative config:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; PRETRAIN_MODEL_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/obj-prefix_lm&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PRETRAIN_MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, you can fine-tune the pre-trained model on CNN/Daily Mail like so:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; FINETUNE_MODEL_DIR=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${BUCKET}&lt;/span&gt;/obj-prefix_lm/cnn_dailymail_v002&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
t5_mesh_transformer  \
  --tpu=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${TPU_NAME}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gcp_project=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${PROJECT}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --tpu_zone=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${ZONE}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --model_dir=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-smi"&gt;${FINETUNE_MODEL_DIR}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;gs://t5-data/experiments/objectives/obj-prefix_lm/cnn_dailymail_v002/operative_config.gin&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;init_checkpoint = '&lt;span class="pl-smi"&gt;${PRETRAIN_MODEL_DIR}&lt;/span&gt;/model.ckpt-524288'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.model_parallelism = 1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  --gin_param=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;utils.tpu_mesh_shape.tpu_topology = '2x2'&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-released-model-checkpoints" class="anchor" aria-hidden="true" href="#released-model-checkpoints"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Released Model Checkpoints&lt;/h2&gt;
&lt;p&gt;We have released the following checkpoints for pre-trained models described in our &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;T5-Small&lt;/strong&gt; (60 million parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/small/" rel="nofollow"&gt;gs://t5-data/pretrained_models/small&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-Base&lt;/strong&gt; (220 million parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/base/" rel="nofollow"&gt;gs://t5-data/pretrained_models/base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-Large&lt;/strong&gt; (770 million parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/large/" rel="nofollow"&gt;gs://t5-data/pretrained_models/large&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-3B&lt;/strong&gt; (3 billion parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/3B/" rel="nofollow"&gt;gs://t5-data/pretrained_models/3B&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;T5-11B&lt;/strong&gt; (11 billion parameters): &lt;a href="https://console.cloud.google.com/storage/browser/t5-data/pretrained_models/11B/" rel="nofollow"&gt;gs://t5-data/pretrained_models/11B&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-cite" class="anchor" aria-hidden="true" href="#how-to-cite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to cite&lt;/h1&gt;
&lt;p&gt;If you extend or use this work, please cite the &lt;a href="https://arxiv.org/abs/1910.10683" rel="nofollow"&gt;paper&lt;/a&gt; where it was introduced:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{2019t5,
  author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {arXiv e-prints},
  year = {2019},
  archivePrefix = {arXiv},
  eprint = {1910.10683},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>google-research</author><guid isPermaLink="false">https://github.com/google-research/text-to-text-transfer-transformer</guid><pubDate>Wed, 20 Nov 2019 00:12:00 GMT</pubDate></item><item><title>CVxTz/image_search_engine #13 in Python, Today</title><link>https://github.com/CVxTz/image_search_engine</link><description>&lt;p&gt;&lt;i&gt;Image search engine&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h3&gt;&lt;a id="user-content-building-a-deep-image-search-engine-using-tfkeras" class="anchor" aria-hidden="true" href="#building-a-deep-image-search-engine-using-tfkeras"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building a Deep Image Search Engine using tf.Keras&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-motivation-" class="anchor" aria-hidden="true" href="#motivation-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation :&lt;/h3&gt;
&lt;p&gt;Imagine having a data collection of hundreds of thousands to millions of images
without any metadata describing the content of each image. How can we build a
system that is able to find a sub-set of those images that best answer a user’s
search query ?&lt;br&gt; What we will basically need is a search engine that is able
to rank image results given how well they correspond to the search query, which
can be either expressed in a natural language or by another query image.&lt;br&gt; The
way we will solve the problem in this post is by training a deep neural model
that learns a fixed length representation (or embedding) of any input image and
text and makes it so those representations are close in the euclidean space if
the pairs text-image or image-image are “similar”.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-data-set-" class="anchor" aria-hidden="true" href="#data-set-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data set :&lt;/h3&gt;
&lt;p&gt;I could not find a data-set of search result ranking that is big enough but I
was able to get this data-set :
&lt;a href="http://jmcauley.ucsd.edu/data/amazon/" rel="nofollow"&gt;http://jmcauley.ucsd.edu/data/amazon/&lt;/a&gt;
which links E-commerce item images to their title and description. We will use
this metadata as the supervision source to learn meaningful joined text-image
representations. The experiments were limited to fashion (Clothing, Shoes and
Jewelry) items and to 500,000 images in order to manage the computations and
storage costs.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-problem-setting-" class="anchor" aria-hidden="true" href="#problem-setting-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Problem setting :&lt;/h3&gt;
&lt;p&gt;The data-set we have links each image with a description written in natural
language. So we define a task in which we want to learn a joined, fixed length
representation for images and text so that each image representation is close to
the representation of its description.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5354060542215fdfb70956c6cf02c202f16a2ee1/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a5f7350345734366165763974787a59344f337a394f412e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/5354060542215fdfb70956c6cf02c202f16a2ee1/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a5f7350345734366165763974787a59344f337a394f412e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*_sP4W46aev9txzY4O3z9OA.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-model-" class="anchor" aria-hidden="true" href="#model-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model :&lt;/h3&gt;
&lt;p&gt;The model takes 3 inputs : The image (which is the anchor), the image
title+description ( the positive example) and the third input is some randomly
sampled text (the negative example).&lt;br&gt; Then we define two sub-models :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Image encoder : Resnet50 pre-trained on ImageNet+GlobalMaxpooling2D&lt;/li&gt;
&lt;li&gt;Text encoder : GRU+GlobalMaxpooling1D&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The image sub-model produces the embedding for the Anchor **E_a **and the text
sub-model outputs the embedding for the positive title+description &lt;strong&gt;E_p&lt;/strong&gt; and
the embedding for the negative text &lt;strong&gt;E_n&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We then train by optimizing the following triplet loss:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;L = max( d(E_a, E_p)-d(E_a, E_n)+alpha, 0)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Where d is the euclidean distance and alpha is a hyper parameter equal to 0.4 in
this experiment.&lt;/p&gt;
&lt;p&gt;Basically what this loss allows to do is to make **d(E_a, E_p) &lt;strong&gt;small and
make&lt;/strong&gt; d(E_a, E_n) **large, so that each image embedding is close to the
embedding of its description and far from the embedding of random text.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-visualization-results-" class="anchor" aria-hidden="true" href="#visualization-results-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Visualization Results :&lt;/h3&gt;
&lt;p&gt;Once we learned the image embedding model and text embedding model we can
visualize them by projecting them into two dimensions using tsne
(&lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="nofollow"&gt;https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html&lt;/a&gt;
).&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/69209789c63df2bc182555c793ab1d25498b8585/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313230302f312a3842552d4b3675436e4c4341674775386674363448772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/69209789c63df2bc182555c793ab1d25498b8585/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313230302f312a3842552d4b3675436e4c4341674775386674363448772e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/1200/1*8BU-K6uCnLCAgGu8ft64Hw.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;span&gt;Test Images and their corresponding text description are linked by green lines&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can see from the plot that generally, in the embedding space, images and
their corresponding descriptions are close. Which is what we would expect given
the training loss that was used.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-text-image-search-" class="anchor" aria-hidden="true" href="#text-image-search-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text-image Search :&lt;/h3&gt;
&lt;p&gt;Here we use few examples of text queries to search for the best matches in a set
of 70,000 images. We compute the text embedding for the query and then the
embedding for each image in the collection. We finally select the top 9 images
which are the closest to the query in the embedding space.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8152616b1b859ba9c94dde8acbb3edf484e3682e/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a384c6a75664c344733656b687455666e6739777735772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/8152616b1b859ba9c94dde8acbb3edf484e3682e/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a384c6a75664c344733656b687455666e6739777735772e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*8LjufL4G3ekhtUfng9ww5w.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e6fa2301805eae0246dd40a8ae8f75a20d53a6cc/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a46647a5365654877366578506b794f4e4a46637a59672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e6fa2301805eae0246dd40a8ae8f75a20d53a6cc/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a46647a5365654877366578506b794f4e4a46637a59672e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*FdzSeeHw6exPkyONJFczYg.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;These examples show that the embedding models are able to learn useful
representations of images and embeddings of simple composition of words.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-image-image-search-" class="anchor" aria-hidden="true" href="#image-image-search-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image-Image Search :&lt;/h3&gt;
&lt;p&gt;Here we will use an image as a query and then search in the database of 70,000
images for the examples that are most similar to it. The ranking is determined
by how close each pair of images are in the embedding space using the euclidean
distance.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba61620cbe46b468e7370dd52dbe8b7784dda596/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a75495864437a30346339676738366b6b6a3731467a512e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba61620cbe46b468e7370dd52dbe8b7784dda596/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a75495864437a30346339676738366b6b6a3731467a512e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*uIXdCz04c9gg86kkj71FzQ.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/9a5501c1899a79c7766cc41f20acebb53c8f1497/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a665635554955373955694a7233784d645f6e484a42672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/9a5501c1899a79c7766cc41f20acebb53c8f1497/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a665635554955373955694a7233784d645f6e484a42672e706e67" alt="" data-canonical-src="https://cdn-images-1.medium.com/max/800/1*fV5UIU79UiJr3xMd_nHJBg.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The results illustrate that the embeddings generated are high level
representations of images that capture the most important characteristics of the
objects represented without being excessively influenced by the orientation,
lighting or minor local details, without being trained explicitly to do so.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-conclusion-" class="anchor" aria-hidden="true" href="#conclusion-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conclusion :&lt;/h3&gt;
&lt;p&gt;In this project we worked on the Machine learning blocks that allow us to build
a keyword and image based search engine applied to a collection of images. The
basic idea is to learn a meaningful and joined embedding function for text and
image and then use the distance between items in the embedding space to rank
search results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References :&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.jmlr.org/papers/volume11/chechik10a/chechik10a.pdf" rel="nofollow"&gt;Large Scale Online Learning of Image Similarity Through
Ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cseweb.ucsd.edu/~jmcauley/pdfs/www16a.pdf" rel="nofollow"&gt;Ups and downs: Modeling the visual evolution of fashion trends with one-class
collaborative filtering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/KinWaiCheuk/Triplet-net-keras/blob/master/Triplet%20NN%20Test%20on%20MNIST.ipynb"&gt;https://github.com/KinWaiCheuk/Triplet-net-keras/blob/master/Triplet%20NN%20Test%20on%20MNIST.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>CVxTz</author><guid isPermaLink="false">https://github.com/CVxTz/image_search_engine</guid><pubDate>Wed, 20 Nov 2019 00:13:00 GMT</pubDate></item><item><title>13o-bbr-bbq/machine_learning_security #14 in Python, Today</title><link>https://github.com/13o-bbr-bbq/machine_learning_security</link><description>&lt;p&gt;&lt;i&gt;Source code about machine learning and security.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-machine-learning-and-security" class="anchor" aria-hidden="true" href="#machine-learning-and-security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning and Security&lt;/h1&gt;
&lt;p&gt;Source codes about machine learning and security.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-line-up" class="anchor" aria-hidden="true" href="#line-up"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Line up.&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Security_and_MachineLearning"&gt;Cyber security and Machine Learning course&lt;/a&gt;&lt;br&gt;
The elementary training course of Machine learning for security engineer.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Vulnerabilities_of_ML/"&gt;Vulnerabilties of Machine Learning&lt;/a&gt;&lt;br&gt;
Summary of Machine Learning vulnerability.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Analytics"&gt;Analytics&lt;/a&gt;&lt;br&gt;
Analyzing packet capture data using k-means.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/CNN_test"&gt;CNN_test&lt;/a&gt;&lt;br&gt;
Generate adversarial example against CNN.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/DeepExploit"&gt;Deep Exploit&lt;/a&gt;&lt;br&gt;
Fully automatic penetration test tool using Machine Learning.&lt;br&gt;
Deep Exploit was presented at &lt;strong&gt;&lt;a href="https://www.blackhat.com/us-18/arsenal/schedule/index.html#deep-exploit-11908" rel="nofollow"&gt;Black Hat USA 2018 Arsenal&lt;/a&gt;&lt;/strong&gt; , &lt;strong&gt;&lt;a href="https://www.blackhat.com/eu-18/arsenal/schedule/index.html#deep-exploit-fully-automatic-penetration-test-tool-using-machine-learning-13320" rel="nofollow"&gt;Black Hat EURO 2018 Arsenal&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://aivillage.org/posts/accepted-talks/" rel="nofollow"&gt;DEF CON 26! AI Village&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gyoisamurai/GyoiThon"&gt;GyoiThon&lt;/a&gt;&lt;br&gt;
Next generation penetration test tool.&lt;br&gt;
GyoiThon was presented at &lt;strong&gt;&lt;a href="https://www.blackhat.com/asia-18/arsenal/schedule/index.html#gyoithon-9651" rel="nofollow"&gt;Black Hat ASIA 2018 Arsenal&lt;/a&gt;&lt;/strong&gt; , &lt;strong&gt;&lt;a href="https://www.blackhat.com/asia-19/arsenal/schedule/index.html#gyoithon-penetration-testing-using-machine-learning-14359" rel="nofollow"&gt;Black Hat ASIA 2019 Arsenal&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://www.defcon.org/html/defcon-26/dc-26-demolabs.html" rel="nofollow"&gt;DEF CON 26! Demo Labs&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Generator"&gt;DeepGenerator&lt;/a&gt;&lt;br&gt;
Fully automatically generate numerous injection codes for web application assessment using Genetic Algorithm and Generative Adversarial Networks.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Recommender"&gt;Recommender&lt;/a&gt;&lt;br&gt;
Recommend optimal injection code for detecting web app vulnerabilities.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/13o-bbr-bbq/machine_learning_security/tree/master/Saivs"&gt;SAIVS (Spider Artificial Intelligence Vulnerability Scanner)&lt;/a&gt;&lt;br&gt;
SAIVS is an artificial intelligence to find vulnerabilities in Web applications.&lt;br&gt;
SAIVS was presented at &lt;strong&gt;&lt;a href="http://www.blackhat.com/asia-16/arsenal.html#saivs-spider-artificial-intelligence-vulnerability-scanner" rel="nofollow"&gt;Black Hat ASIA 2016 Arsenal&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact-us" class="anchor" aria-hidden="true" href="#contact-us"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact us&lt;/h2&gt;
&lt;p&gt;Isao Takaesu&lt;br&gt;
&lt;a href="mailto:takaesu235@gmail.com"&gt;takaesu235@gmail.com&lt;/a&gt;&lt;br&gt;
&lt;a href="https://twitter.com/bbr_bbq" rel="nofollow"&gt;https://twitter.com/bbr_bbq&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>13o-bbr-bbq</author><guid isPermaLink="false">https://github.com/13o-bbr-bbq/machine_learning_security</guid><pubDate>Wed, 20 Nov 2019 00:14:00 GMT</pubDate></item><item><title>plotly/dash #15 in Python, Today</title><link>https://github.com/plotly/dash</link><description>&lt;p&gt;&lt;i&gt;Analytical Web Apps for Python &amp; R. No JavaScript Required.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dash" class="anchor" aria-hidden="true" href="#dash"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dash&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/plotly/dash" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2488249996549b3d8197eb061e51975ede759cb6/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f70726f6a6563742f6769746875622f706c6f746c792f646173682f6d61737465722e737667" alt="CircleCI" data-canonical-src="https://img.shields.io/circleci/project/github/plotly/dash/master.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/plotly/dash/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/3cd42a5b87f7de7a0fe06c16c0de8403cce5ec1e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f706c6f746c792f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="GitHub" data-canonical-src="https://img.shields.io/github/license/plotly/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/dash/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/591a9710a9507f246482d0d57d33e473aef1bba7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/dash/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/09415013d09c9e287dcb0f00c5287fc57825efcd/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/plotly/dash/graphs/contributors"&gt;&lt;img src="https://camo.githubusercontent.com/2c0f084bce301be8501650815385bda2802e580e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f792f706c6f746c792f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="GitHub commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/y/plotly/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/plotly/dash/alerts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1c0f2f026b76562ac6828803af41b652a1c1c113/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f706c6f746c792f646173682e737667" alt="LGTM Alerts" data-canonical-src="https://img.shields.io/lgtm/alerts/g/plotly/dash.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/plotly/dash/context:python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ab2cb9245f5eed317879ce495d4e708c93cab8b7/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f706c6f746c792f646173682e737667" alt="LGTM Grade" data-canonical-src="https://img.shields.io/lgtm/grade/python/g/plotly/dash.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-dash-is-a-python-framework-for-building-analytical-web-applications-no-javascript-required" class="anchor" aria-hidden="true" href="#dash-is-a-python-framework-for-building-analytical-web-applications-no-javascript-required"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Dash is a Python framework for building analytical web applications. No JavaScript required&lt;/em&gt;.&lt;/h4&gt;
&lt;p&gt;Built on top of Plotly.js, React and Flask, Dash ties modern UI elements like dropdowns, sliders, and graphs directly to your analytical Python code. Read our tutorial proudly crafted &lt;g-emoji class="g-emoji" alias="heart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2764.png"&gt;❤️&lt;/g-emoji&gt; by Dash itself.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dash.plot.ly/getting-started" rel="nofollow"&gt;User Guide&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/plotly/dash-docs/blob/master/pdf-docs/Dash_User_Guide_and_Documentation.pdf"&gt;Offline (PDF) Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://dash-docs.herokuapp.com/" rel="nofollow"&gt;Dash Docs on Heroku&lt;/a&gt; (for corporate network that cannot access plot.ly)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-app-samples" class="anchor" aria-hidden="true" href="#app-samples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;App Samples&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;App&lt;/th&gt;
&lt;th align="center"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif" alt="Sample Dash App" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Here’s a simple example of a Dash App that ties a Dropdown to a D3.js Plotly Graph. As the user selects a value in the Dropdown, the application code dynamically exports data from Google Finance into a Pandas DataFrame. This app was written in just &lt;strong&gt;43&lt;/strong&gt; lines of code (&lt;a href="https://gist.github.com/chriddyp/3d2454905d8f01886d651f207e2419f0"&gt;view the source&lt;/a&gt;).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif" alt="Crossfiltering Dash App" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash app code is declarative and reactive, which makes it easy to build complex apps that contain many interactive elements. Here’s an example with 5 inputs, 3 outputs, and cross filtering. This app was composed in just 160 lines of code, all of which were Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif" alt="Dash App with Mapbox map showing walmart store openings" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash uses &lt;a href="https://github.com/plotly/plotly.js"&gt;Plotly.js&lt;/a&gt; for charting. Over 35 chart types are supported, including maps.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/plotly/dash-docs/blob/516f80c417051406210b94ea23a6d3b6cd84d146/assets/images/gallery/dash-financial-report.gif"&gt;&lt;img src="https://github.com/plotly/dash-docs/raw/516f80c417051406210b94ea23a6d3b6cd84d146/assets/images/gallery/dash-financial-report.gif" alt="Financial report" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash isn't just for dashboards. You have full control over the look and feel of your applications. Here's a Dash App that's styled to look like a PDF report.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To learn more about Dash, read the &lt;a href="https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503" rel="nofollow"&gt;extensive announcement letter&lt;/a&gt; or &lt;a href="https://plot.ly/dash" rel="nofollow"&gt;jump in with the user guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contact-and-support" class="anchor" aria-hidden="true" href="#contact-and-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact and Support&lt;/h3&gt;
&lt;p&gt;For companies with software budgets, Plotly offers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Dash Deployment Server&lt;/strong&gt;&lt;/a&gt; speeds your time-to-delivery while providing the right resources, security, and scalability you need to deliver production-quality apps&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Dash Design Kit&lt;/strong&gt;&lt;/a&gt; makes your internal dashboard awesome without expertise in JavaScript &amp;amp; CSS.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Snapshot Engine&lt;/strong&gt;&lt;/a&gt; seamlessly links your analytics and reporting workflows together, giving you a fast way to generate interactive reports of just the data you need&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href="https://plot.ly/dash/support" rel="nofollow"&gt;https://plot.ly/dash/support&lt;/a&gt; for ways to get in touch.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30084008-9fbc68fc-925e-11e7-891c-18a9b8f6ac6b.png"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30084008-9fbc68fc-925e-11e7-891c-18a9b8f6ac6b.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>plotly</author><guid isPermaLink="false">https://github.com/plotly/dash</guid><pubDate>Wed, 20 Nov 2019 00:15:00 GMT</pubDate></item><item><title>dragen1860/Deep-Learning-with-PyTorch-Tutorials #16 in Python, Today</title><link>https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials</link><description>&lt;p&gt;&lt;i&gt;深度学习与PyTorch入门实战视频教程 配套源代码和PPT&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pytorch安装指令" class="anchor" aria-hidden="true" href="#pytorch安装指令"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyTorch安装指令&lt;/h1&gt;
&lt;p&gt;请先安装Anaconda和CUDA 10.0。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配置国内源&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 配置国内源，方便安装Numpy,Matplotlib等&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;add channels https:&lt;span class="pl-k"&gt;//&lt;/span&gt;mirrors.tuna.tsinghua.edu.cn&lt;span class="pl-k"&gt;/&lt;/span&gt;anaconda&lt;span class="pl-k"&gt;/&lt;/span&gt;pkgs&lt;span class="pl-k"&gt;/&lt;/span&gt;free&lt;span class="pl-k"&gt;/&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;add channels https:&lt;span class="pl-k"&gt;//&lt;/span&gt;mirrors.tuna.tsinghua.edu.cn&lt;span class="pl-k"&gt;/&lt;/span&gt;anaconda&lt;span class="pl-k"&gt;/&lt;/span&gt;pkgs&lt;span class="pl-k"&gt;/&lt;/span&gt;main&lt;span class="pl-k"&gt;/&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 配置国内源，安装PyTorch用&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;add channels https:&lt;span class="pl-k"&gt;//&lt;/span&gt;mirrors.tuna.tsinghua.edu.cn&lt;span class="pl-k"&gt;/&lt;/span&gt;anaconda&lt;span class="pl-k"&gt;/&lt;/span&gt;cloud&lt;span class="pl-k"&gt;/&lt;/span&gt;pytorch&lt;span class="pl-k"&gt;/&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 显示源地址&lt;/span&gt;
conda config &lt;span class="pl-ii"&gt;--&lt;/span&gt;&lt;span class="pl-c1"&gt;set&lt;/span&gt; show_channel_urls yes&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;安装PyTorch&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 安装PyTorch，要使用国内源请去掉-c pytorch这个参数！！&lt;/span&gt;
conda install pytorch torchvision cudatoolkit&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;10.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;安装常用库&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;pip install numpy matplotlib pillow pandas&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;&lt;a id="user-content-课程链接" class="anchor" aria-hidden="true" href="#课程链接"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;课程链接&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;课程链接:&lt;/strong&gt; &lt;a href="https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=61a9e0a511f7409b92a08d4f4c964330" rel="nofollow"&gt;https://study.163.com/course/courseMain.htm?share=2&amp;amp;shareId=480000001847407&amp;amp;courseId=1208894818&amp;amp;_trace_c_p_k2_=61a9e0a511f7409b92a08d4f4c964330&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="res/版权声明.png"&gt;&lt;img width="700" src="res/版权声明.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;课程大纲:&lt;/strong&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="res/outline.png"&gt;&lt;img src="res/outline.png" alt="课程介绍" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dragen1860</author><guid isPermaLink="false">https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials</guid><pubDate>Wed, 20 Nov 2019 00:16:00 GMT</pubDate></item><item><title>TheAlgorithms/Python #17 in Python, Today</title><link>https://github.com/TheAlgorithms/Python</link><description>&lt;p&gt;&lt;i&gt;All Algorithms implemented in Python&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-the-algorithms---python" class="anchor" aria-hidden="true" href="#the-algorithms---python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The Algorithms - Python&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.paypal.me/TheAlgorithms/100" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6e317052a97af57d39fafda024dec0e418ed447a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e7376673f6c6f676f3d70617970616c267374796c653d666c61742d737175617265" alt="Donate" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg?logo=paypal&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; 
&lt;a href="https://travis-ci.com/TheAlgorithms/Python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ba096466b22c899fe7f5e02f25b5a4eb9c4981bf/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d5472617669732532304349266c6f676f3d747261766973267374796c653d666c61742d737175617265" alt="Build Status" data-canonical-src="https://img.shields.io/travis/TheAlgorithms/Python.svg?label=Travis%20CI&amp;amp;logo=travis&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; 
&lt;a href="https://lgtm.com/projects/g/TheAlgorithms/Python/alerts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5d3181d5ebb9d039f3db9c12cc98e4733966ad45/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f6769746875622f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d4c47544d266c6f676f3d4c47544d267374796c653d666c61742d737175617265" alt="LGTM" data-canonical-src="https://img.shields.io/lgtm/alerts/github/TheAlgorithms/Python.svg?label=LGTM&amp;amp;logo=LGTM&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; 
&lt;a href="https://gitter.im/TheAlgorithms" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f697eee68d1130a571859375f6e3cf3b666d3c50/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436861742d4769747465722d6666363962342e7376673f6c6162656c3d43686174266c6f676f3d676974746572267374796c653d666c61742d737175617265" alt="Gitter chat" data-canonical-src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; 
&lt;a href="https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md"&gt;&lt;img src="https://camo.githubusercontent.com/71dbcf9e251926ae5ab25476d1d449d107103fe7/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76312e7376673f6c6162656c3d436f6e747269627574696f6e73266d6573736167653d57656c636f6d6526636f6c6f723d303035396233267374796c653d666c61742d737175617265" alt="contributions welcome" data-canonical-src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; 
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/310362fb8e8936dc040af9adce51341ad65bf5d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f7265706f2d73697a652f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d5265706f25323073697a65267374796c653d666c61742d737175617265"&gt;&lt;img src="https://camo.githubusercontent.com/310362fb8e8936dc040af9adce51341ad65bf5d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f7265706f2d73697a652f546865416c676f726974686d732f507974686f6e2e7376673f6c6162656c3d5265706f25323073697a65267374796c653d666c61742d737175617265" alt="" data-canonical-src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; &lt;/p&gt;

&lt;h3&gt;&lt;a id="user-content-all-algorithms-implemented-in-python-for-education" class="anchor" aria-hidden="true" href="#all-algorithms-implemented-in-python-for-education"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;All algorithms implemented in Python (for education)&lt;/h3&gt;
&lt;p&gt;These implementations are for learning purposes. They may be less efficient than the implementations in the Python standard library.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution Guidelines&lt;/h2&gt;
&lt;p&gt;Read our &lt;a href="CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community-channel" class="anchor" aria-hidden="true" href="#community-channel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community Channel&lt;/h2&gt;
&lt;p&gt;We're on &lt;a href="https://gitter.im/TheAlgorithms" rel="nofollow"&gt;Gitter&lt;/a&gt;! Please join us.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-list-of-algorithms" class="anchor" aria-hidden="true" href="#list-of-algorithms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;List of Algorithms&lt;/h2&gt;
&lt;p&gt;See our &lt;a href="DIRECTORY.md"&gt;directory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6af3650e2f9523e898e3e314ab356b675875483e/68747470733a2f2f676974706f642e696f2f627574746f6e2f6f70656e2d696e2d676974706f642e7376673f7374796c653d666c61742d737175617265" alt="Open in Gitpod" data-canonical-src="https://gitpod.io/button/open-in-gitpod.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>TheAlgorithms</author><guid isPermaLink="false">https://github.com/TheAlgorithms/Python</guid><pubDate>Wed, 20 Nov 2019 00:17:00 GMT</pubDate></item><item><title>alegonz/baikal #18 in Python, Today</title><link>https://github.com/alegonz/baikal</link><description>&lt;p&gt;&lt;i&gt;A graph-based functional API for building complex scikit-learn pipelines.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-baikal" class="anchor" aria-hidden="true" href="#baikal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;baikal&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/alegonz/baikal/tree/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6ea59722c2eb9c5382ff534bf44de76955d667d3/68747470733a2f2f636972636c6563692e636f6d2f67682f616c65676f6e7a2f6261696b616c2f747265652f6d61737465722e7376673f7374796c653d73766726636972636c652d746f6b656e3d66623637656565643230363763333631393839643230393162396434643033653638393930313062" alt="build status" data-canonical-src="https://circleci.com/gh/alegonz/baikal/tree/master.svg?style=svg&amp;amp;circle-token=fb67eeed2067c361989d2091b9d4d03e6899010b" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/alegonz/baikal" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/66b2e25de741354c9cbbf397928468f9d24bc98b/68747470733a2f2f636f6465636f762e696f2f67682f616c65676f6e7a2f6261696b616c2f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d53536f655145544e6836" alt="coverage" data-canonical-src="https://codecov.io/gh/alegonz/baikal/branch/master/graph/badge.svg?token=SSoeQETNh6" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://camo.githubusercontent.com/28a51fe3a2c05048d8ca8ecd039d6b1619037326/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667" alt="code style" data-canonical-src="https://img.shields.io/badge/code%20style-black-000000.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/baikal" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/bba917857991c36014df0108e22a350eed438573/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6261696b616c2e737667" alt="latest release" data-canonical-src="https://img.shields.io/pypi/v/baikal.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/alegonz/baikal/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/1acc6e6dfaf131f05f170de0521461bafd9b62e8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6261696b616c2e737667" alt="license" data-canonical-src="https://img.shields.io/pypi/l/baikal.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A graph-based functional API for building complex scikit-learn pipelines.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;baikal&lt;/strong&gt; is written in pure Python. It supports Python 3.5 and above.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Contents:&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#quick-start-guide"&gt;Quick-start guide&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#user-guide"&gt;User guide&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#next-development-steps"&gt;Next development steps&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-what-is-baikal" class="anchor" aria-hidden="true" href="#what-is-baikal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is baikal?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;baikal is a graph-based, functional API for building complex machine learning pipelines of objects that implement the &lt;a href="https://scikit-learn.org/stable/developers/contributing.html#different-objects" rel="nofollow"&gt;scikit-learn API&lt;/a&gt;&lt;/strong&gt;. It is mostly inspired on the excellent &lt;a href="https://keras.io" rel="nofollow"&gt;Keras&lt;/a&gt; API for Deep Learning, and borrows a few concepts from the &lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;TensorFlow&lt;/a&gt; framework and the (perhaps lesser known) &lt;a href="https://github.com/yahoo/graphkit"&gt;graphkit&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;baikal&lt;/strong&gt; aims to provide an API that allows to build complex, non-linear machine learning pipelines that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="illustrations/multiple_input_nonlinear_pipeline_example_diagram.png"&gt;&lt;img src="illustrations/multiple_input_nonlinear_pipeline_example_diagram.png" alt="multiple_input_nonlinear_pipeline_example_diagram" title="An example of a multiple-input, nonlinear pipeline" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;with code that looks like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;x1 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
x2 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()

y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; ExtraTreesClassifier()(x1, y_t)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; RandomForestClassifier()(x2, y_t)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PowerTransformer()(x2)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PCA()(z)
y3 &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression()(z, y_t)

ensemble_features &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2, y3])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC()(ensemble_features, y_t)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model([x1, x2], y, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-what-can-i-do-with-it" class="anchor" aria-hidden="true" href="#what-can-i-do-with-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What can I do with it?&lt;/h3&gt;
&lt;p&gt;With &lt;strong&gt;baikal&lt;/strong&gt; you can&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;build non-linear pipelines effortlessly&lt;/li&gt;
&lt;li&gt;handle multiple inputs and outputs&lt;/li&gt;
&lt;li&gt;add steps that operate on targets as part of the pipeline&lt;/li&gt;
&lt;li&gt;nest pipelines&lt;/li&gt;
&lt;li&gt;use prediction probabilities (or any other kind of output) as inputs to other steps in the pipeline&lt;/li&gt;
&lt;li&gt;query intermediate outputs, easing debugging&lt;/li&gt;
&lt;li&gt;freeze steps that do not require fitting&lt;/li&gt;
&lt;li&gt;define and add custom steps easily&lt;/li&gt;
&lt;li&gt;plot pipelines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All with boilerplate-free, readable code.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-why-baikal" class="anchor" aria-hidden="true" href="#why-baikal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why baikal?&lt;/h3&gt;
&lt;p&gt;The pipeline above (to the best of the author's knowledge) cannot be easily built using &lt;a href="https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators" rel="nofollow"&gt;scikit-learn's composite estimators API&lt;/a&gt; as you encounter some limitations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is aimed at linear pipelines
&lt;ul&gt;
&lt;li&gt;You could add some step parallelism with the &lt;a href="https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data" rel="nofollow"&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; API, but this is limited to transformer objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Classifiers/Regressors can only be used at the end of the pipeline.
&lt;ul&gt;
&lt;li&gt;This means we cannot use the predicted labels (or their probabilities) as features to other classifiers/regressors.&lt;/li&gt;
&lt;li&gt;You could leverage mlxtend's &lt;a href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/#stackingclassifier" rel="nofollow"&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; and come up with some clever combination of the above composite estimators (&lt;code&gt;Pipeline&lt;/code&gt;s, &lt;code&gt;ColumnTransformer&lt;/code&gt;s, and &lt;code&gt;StackingClassifier&lt;/code&gt;s, etc), but you might end up with code that feels hard-to-follow and verbose.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cannot handle multiple input/multiple output models.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Perhaps you could instead define a big, composite estimator class that integrates each of the pipeline steps through composition. This, however, most likely will require&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;writing big &lt;code&gt;__init__&lt;/code&gt; methods to control each of the internal steps' knobs;&lt;/li&gt;
&lt;li&gt;being careful with &lt;code&gt;get_params&lt;/code&gt; and &lt;code&gt;set_params&lt;/code&gt; if you want to use, say, &lt;code&gt;GridSearchCV&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;and adding some boilerplate code if you want to access the outputs of intermediate steps for debugging.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By using &lt;strong&gt;baikal&lt;/strong&gt; as shown in the example above, code can be more readable, less verbose and closer to our mental representation of the pipeline. &lt;strong&gt;baikal&lt;/strong&gt; also provides an API to fit, predict with, and query the entire pipeline with single commands, as we will see below.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-key-concepts" class="anchor" aria-hidden="true" href="#key-concepts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Key concepts&lt;/h2&gt;
&lt;p&gt;The baikal API introduces three basic elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Step&lt;/strong&gt;: Steps are the building blocks of the API. Conceptually similar to TensorFlow's operations and Keras layers, each Step is a unit of computation (e.g. PCA, Logistic Regression) that take the data from preceding Steps and produce data to be used by other Steps further in the pipeline. Steps are defined by combining the &lt;code&gt;Step&lt;/code&gt; mixin class with a base class that implements the scikit-learn API. This is explained in more detail below.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DataPlaceholder&lt;/strong&gt;: The inputs and outputs of Steps. If Steps are like TensorFlow operations or Keras layers, then DataPlaceHolders are akin to tensors. Don't be misled though, DataPlaceholders are just minimal, low-weight auxiliary objects whose main purpose is to keep track of the input/output connectivity between steps, and serve as the keys to map the actual input data to their appropriate Step. They are not arrays/tensors, nor contain any shape/type information whatsoever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model&lt;/strong&gt;: A Model is a network (more precisely, a directed acyclic graph) of Steps, and it is defined from the input/output specification of the pipeline. Models have fit and predict routines that, together with graph-based engine, allow the automatic (feed-forward) computation of each of the pipeline steps when fed with data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install baikal&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;numpy&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start-guide" class="anchor" aria-hidden="true" href="#quick-start-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick-start guide&lt;/h2&gt;
&lt;p&gt;Without further ado, here's a short example of a simple SVC model built with &lt;strong&gt;baikal&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn.svm
&lt;span class="pl-k"&gt;from&lt;/span&gt; sklearn.datasets &lt;span class="pl-k"&gt;import&lt;/span&gt; load_breast_cancer
&lt;span class="pl-k"&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class="pl-k"&gt;import&lt;/span&gt; train_test_split

&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; make_step, Input, Model


&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 1. Define a step&lt;/span&gt;
&lt;span class="pl-c1"&gt;SVC&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; make_step(sklearn.svm.&lt;span class="pl-c1"&gt;SVC&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 2. Build the model&lt;/span&gt;
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC(&lt;span class="pl-v"&gt;C&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1.0&lt;/span&gt;, &lt;span class="pl-v"&gt;kernel&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;rbf&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;gamma&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0.5&lt;/span&gt;)(x, y_t)
model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 3. Train the model&lt;/span&gt;
dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; load_breast_cancer()
X_train, X_test, y_train, y_test &lt;span class="pl-k"&gt;=&lt;/span&gt; train_test_split(
    dataset.data, dataset.target, &lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;0&lt;/span&gt;
)

model.fit(X_train, y_train)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 4. Use the model&lt;/span&gt;
y_test_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(X_test)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-user-guide" class="anchor" aria-hidden="true" href="#user-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;User guide&lt;/h2&gt;
&lt;p&gt;As shown in the short example above, the &lt;strong&gt;baikal&lt;/strong&gt; API consists of four basic steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define the steps&lt;/li&gt;
&lt;li&gt;Build the model&lt;/li&gt;
&lt;li&gt;Train the model&lt;/li&gt;
&lt;li&gt;Use the model&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's take a look at each of them in detail. Full examples can be found in the project's &lt;a href="examples"&gt;examples&lt;/a&gt; folder.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-1-define-the-steps" class="anchor" aria-hidden="true" href="#1-define-the-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Define the steps&lt;/h3&gt;
&lt;p&gt;A step is defined very easily, just feed the provided &lt;code&gt;make_step&lt;/code&gt; function with the class you want to make a step from:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn.linear_model
&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; make_step

LogisticRegression &lt;span class="pl-k"&gt;=&lt;/span&gt; make_step(sklearn.linear_model.LogisticRegression)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can make a step from any class you like, so long that class implements the &lt;a href="https://scikit-learn.org/stable/developers/contributing.html#different-objects" rel="nofollow"&gt;scikit-learn API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What this function is doing under the hood, is to combine the given class with the &lt;code&gt;Step&lt;/code&gt; mixin class. The &lt;code&gt;Step&lt;/code&gt; mixin, among other things, endows the given class with a &lt;code&gt;__call__&lt;/code&gt; method, making the class callable on the outputs (&lt;code&gt;DataPlaceholder&lt;/code&gt; objects) of previous steps. If you prefer to do this manually, you only have to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define a class that inherits from both the &lt;code&gt;Step&lt;/code&gt; mixin and the class you wish to make a step of (in that order!).&lt;/li&gt;
&lt;li&gt;In the class &lt;code&gt;__init__&lt;/code&gt;, call &lt;code&gt;super().__init__(...)&lt;/code&gt; and pass the appropriate step parameters.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For example, to make a step for &lt;code&gt;sklearn.linear_model.LogisticRegression&lt;/code&gt; we do:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; sklearn.linear_model
&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; Step

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; The order of inheritance is important!&lt;/span&gt;
&lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;LogisticRegression&lt;/span&gt;(&lt;span class="pl-e"&gt;Step&lt;/span&gt;, &lt;span class="pl-e"&gt;sklearn&lt;/span&gt;.&lt;span class="pl-e"&gt;linear_model&lt;/span&gt;.&lt;span class="pl-e"&gt;LogisticRegression&lt;/span&gt;):
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;None&lt;/span&gt;, &lt;span class="pl-smi"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;None&lt;/span&gt;, &lt;span class="pl-smi"&gt;n_outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-smi"&gt;trainable&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-k"&gt;**&lt;/span&gt;&lt;span class="pl-smi"&gt;kwargs&lt;/span&gt;):
        &lt;span class="pl-c1"&gt;super&lt;/span&gt;().&lt;span class="pl-c1"&gt;__init__&lt;/span&gt;(
            &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;name,
            &lt;span class="pl-v"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;function,
            &lt;span class="pl-v"&gt;n_outputs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;n_outputs,
            &lt;span class="pl-v"&gt;trainable&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;trainable,
            &lt;span class="pl-k"&gt;**&lt;/span&gt;kwargs
        )&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Other steps are defined similarly (omitted here for brevity).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-build-the-model" class="anchor" aria-hidden="true" href="#2-build-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Build the model&lt;/h3&gt;
&lt;p&gt;Once we have defined the steps, we can make a model like shown below. First, you create the initial step, that serves as the entry-point to the model, by calling the &lt;code&gt;Input&lt;/code&gt; helper function. This outputs a DataPlaceholder representing one of the inputs to the model. Then, all you have to do is to instantiate the steps and call them on the outputs (DataPlaceholders from previous steps) as you deem appropriate. Finally, you instantiate the model with the inputs/outputs (also DataPlaceholders) that specify your pipeline.&lt;/p&gt;
&lt;p&gt;This style should feel familiar to users of Keras.&lt;/p&gt;
&lt;p&gt;Note that steps that require target data (like &lt;code&gt;ExtraTreesClassifier&lt;/code&gt;, &lt;code&gt;RandomForestClassifier&lt;/code&gt;, &lt;code&gt;LogisticRegression&lt;/code&gt; and &lt;code&gt;SVC&lt;/code&gt;) are called with two arguments. These arguments correspond to the inputs (e.g. &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;) and targets (e.g. &lt;code&gt;y_t&lt;/code&gt;) of the step. These targets are specified to the Model at instantiation via the third argument. &lt;strong&gt;baikal&lt;/strong&gt; pipelines are made of complex, heterogenous, non-differentiable steps (e.g. a whole RandomForestClassifier, with its own internal learning algorithm), so there's no some magic automatic differentiation that backpropagates the target information from the outputs to the appropriate steps, so we must specify which step needs which targets directly.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal &lt;span class="pl-k"&gt;import&lt;/span&gt; Input, Model
&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal.steps &lt;span class="pl-k"&gt;import&lt;/span&gt; Stack

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Assume the steps below were already defined&lt;/span&gt;
x1 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
x2 &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()

y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; ExtraTreesClassifier()(x1, y_t)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; RandomForestClassifier()(x2, y_t)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PowerTransformer()(x2)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; PCA()(z)
y3 &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression()(z, y_t)

ensemble_features &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2, y3])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC()(ensemble_features, y_t)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model([x1, x2], y, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(*) Steps are called on and output DataPlaceHolders. DataPlaceholders are produced and consumed exclusively by Steps, so you do not need to instantiate these yourself.&lt;/p&gt;
&lt;p&gt;Note: Currently, calling the same step on different inputs and targets to reuse the step (similar to the concept of shared layers and nodes in Keras) is not supported. Calling a step twice on different inputs will override the connectivity from the first call. Support for shareable steps might be added in future releases.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-3-train-the-model" class="anchor" aria-hidden="true" href="#3-train-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Train the model&lt;/h3&gt;
&lt;p&gt;Now that we have built a model, we are ready to train it. The model also follows the scikit-learn API, as it has a fit method:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;model.fit(&lt;span class="pl-v"&gt;X&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[X1_train, X2_train], &lt;span class="pl-v"&gt;y&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;y_train)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The model will automatically propagate the data through the pipeline and fit any internal steps that require training.&lt;/p&gt;
&lt;p&gt;The fit function takes three arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;X&lt;/code&gt;: Input data (independent variables).
&lt;ul&gt;
&lt;li&gt;It can be either of the following:
&lt;ul&gt;
&lt;li&gt;A single array-like object (in the case of a single input)&lt;/li&gt;
&lt;li&gt;A list of array-like objects (in the case of multiple inputs)&lt;/li&gt;
&lt;li&gt;A dictionary mapping DataPlaceholders (or their names) to array-like objects. The keys must be among the inputs passed at instantiation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt; (optional): Target data (dependent variables).
&lt;ul&gt;
&lt;li&gt;It can either of the following:
&lt;ul&gt;
&lt;li&gt;None (in the case all steps are either non-trainable and/or unsupervised learning steps)&lt;/li&gt;
&lt;li&gt;A single array-like object (in the case of a single target)&lt;/li&gt;
&lt;li&gt;A list of array-like objects (in the case of multiple targets)&lt;/li&gt;
&lt;li&gt;A dictionary mapping DataPlaceholders (or their names) to array-like objects. The keys must be among the targets passed at instantiation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-4-use-the-model" class="anchor" aria-hidden="true" href="#4-use-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Use the model&lt;/h3&gt;
&lt;p&gt;To predict with model, just pass the input data like you would for the fit method. The model will automatically propagate the inputs through all the steps and produce the outputs specified at instantiation.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;y_test_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict([X1_test, X2_test])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; This also works:&lt;/span&gt;
y_test_pred &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict({x1: X1_test, x2: X2_test})&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Models are query-able&lt;/strong&gt;. That is, you can request other outputs other than those specified at model instantiation. This allows querying intermediate outputs and ease debugging. For example, to get both the output from PCA and the ExtraTreesClassifier:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;outs &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict(
    [X1_test, X2_test], &lt;span class="pl-v"&gt;output_names&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;ExtraTreesClassifier_0/0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;PCA_0/0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;]
)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You don't need to pass inputs that are not required to compute the queried output. For example, if we just want the output of &lt;code&gt;PowerTransformer&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;outs &lt;span class="pl-k"&gt;=&lt;/span&gt; model.predict({x2: X2_data}, &lt;span class="pl-v"&gt;output_names&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;PowerTransformer_0/0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Models are also nestable&lt;/strong&gt;. In fact, Models are steps, too. This allows composing smaller models into bigger ones, like so:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Assume we have two previously built complex&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; classifier models, perhaps loaded from a file.&lt;/span&gt;
submodel1 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;...&lt;/span&gt;
submodel2 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;...&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Now we make an stacked classifier from both submodels&lt;/span&gt;
x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; submodel1(x)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; submodel2(x, y_t)
z &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; SVC()(z, y_t)
bigmodel &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-persisting-the-model" class="anchor" aria-hidden="true" href="#persisting-the-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Persisting the model&lt;/h3&gt;
&lt;p&gt;Like sklearn objects, models can be serialized with pickle or joblib without any extra setup:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; joblib
joblib.dump(model, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;model.pkl&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
model_reloaded &lt;span class="pl-k"&gt;=&lt;/span&gt; joblib.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;model.pkl&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Keep in mind, however, the &lt;a href="https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations" rel="nofollow"&gt;security and maintainability limitations&lt;/a&gt; of these formats.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-utilities" class="anchor" aria-hidden="true" href="#utilities"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Utilities&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-sklearn-wrapper-for-gridsearchcv" class="anchor" aria-hidden="true" href="#sklearn-wrapper-for-gridsearchcv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;sklearn wrapper for &lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Currently, &lt;strong&gt;baikal&lt;/strong&gt; also provides a wrapper utility class that allows models to used in scikit-learn's &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn-model-selection-gridsearchcv" rel="nofollow"&gt;&lt;code&gt;GridSearchCV&lt;/code&gt; API&lt;/a&gt;. Below there's a code snippet showing its usage. It follows the style of Keras' own wrapper. &lt;a href="examples/gridsearchcv_sklearn_wrapper.py"&gt;Here&lt;/a&gt; is an example script of this utility.&lt;/p&gt;
&lt;p&gt;A future release of &lt;strong&gt;baikal&lt;/strong&gt; plans to include a custom &lt;code&gt;GridSearchCV&lt;/code&gt; API, based on the original scikit-learn implementation, that can handle baikal models natively, avoiding a couple of gotchas with the current wrapper implementation (mentioned below).&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 1. Define a function that returns your baikal model&lt;/span&gt;
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;build_fn&lt;/span&gt;():
    x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
    y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
    h &lt;span class="pl-k"&gt;=&lt;/span&gt; PCA(&lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;random_state, &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pca&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(x)
    y &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression(&lt;span class="pl-v"&gt;random_state&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;random_state, &lt;span class="pl-v"&gt;name&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(h, y_t)
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)
    &lt;span class="pl-k"&gt;return&lt;/span&gt; model

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 2. Define a parameter grid&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - keys have the [step-name]__[parameter-name] format, similar to sklearn Pipelines&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; - You can also search over the steps themselves using [step-name] keys&lt;/span&gt;
param_grid &lt;span class="pl-k"&gt;=&lt;/span&gt; [
    {
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [LogisticRegression()],
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier__C&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [&lt;span class="pl-c1"&gt;0.01&lt;/span&gt;, &lt;span class="pl-c1"&gt;0.1&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;],
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;pca__n_components&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;4&lt;/span&gt;],
    },
    {
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [RandomForestClassifier()],
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;classifier__n_estimators&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: [&lt;span class="pl-c1"&gt;10&lt;/span&gt;, &lt;span class="pl-c1"&gt;50&lt;/span&gt;, &lt;span class="pl-c1"&gt;100&lt;/span&gt;],
    },
]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 3. Instantiate the wrapper&lt;/span&gt;
sk_model &lt;span class="pl-k"&gt;=&lt;/span&gt; SKLearnWrapper(build_fn)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 4. Use GridSearchCV as usual&lt;/span&gt;
gscv_baikal &lt;span class="pl-k"&gt;=&lt;/span&gt; GridSearchCV(sk_model, param_grid)
gscv_baikal.fit(x_data, y_data)
best_model &lt;span class="pl-k"&gt;=&lt;/span&gt; gscv_baikal.best_estimator_.model&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Currently there are a couple of gotchas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;cv&lt;/code&gt; argument of &lt;code&gt;GridSearchCV&lt;/code&gt; will default to KFold if the estimator is a baikal Model, so you have to specify an appropriate splitter directly if you need another splitting scheme.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GridSearchCV&lt;/code&gt; cannot handle models with multiple inputs/outputs. A way to work around this is to split the input data and merge the outputs within the model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-plotting-your-model" class="anchor" aria-hidden="true" href="#plotting-your-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Plotting your model&lt;/h4&gt;
&lt;p&gt;The baikal package includes a plot utility:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; baikal.plot &lt;span class="pl-k"&gt;import&lt;/span&gt; plot_model
plot_model(model, &lt;span class="pl-v"&gt;filename&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;model.png&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For the example above, it produces this:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="illustrations/multiple_input_nonlinear_pipeline_example_plot.png"&gt;&lt;img src="illustrations/multiple_input_nonlinear_pipeline_example_plot.png" height="600" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In order to use the plot utility, you need to install &lt;a href="https://pypi.org/project/pydot" rel="nofollow"&gt;pydot&lt;/a&gt; and &lt;a href="https://graphviz.gitlab.io" rel="nofollow"&gt;graphviz&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-stacked-classifiers" class="anchor" aria-hidden="true" href="#stacked-classifiers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stacked classifiers&lt;/h3&gt;
&lt;p&gt;Similar to the the example in the quick-start above, stacks of classifiers (or regressors) can be built like shown below. Note that you can specify the function the step should use for computation, in this case &lt;code&gt;function='predict_proba'&lt;/code&gt; to use the label probabilities as the features of the meta-classifier.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y1 &lt;span class="pl-k"&gt;=&lt;/span&gt; LogisticRegression(&lt;span class="pl-v"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;predict_proba&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(x, y_t)
y2 &lt;span class="pl-k"&gt;=&lt;/span&gt; RandomForestClassifier(&lt;span class="pl-v"&gt;function&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;predict_proba&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)(x, y_t)
ensemble_features &lt;span class="pl-k"&gt;=&lt;/span&gt; Stack()([y1, y2])
y &lt;span class="pl-k"&gt;=&lt;/span&gt; ExtraTreesClassifier()(ensemble_features, y_t)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Click &lt;a href="examples/stacked_classifiers.py"&gt;here&lt;/a&gt; for a full example.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-classifier-chain" class="anchor" aria-hidden="true" href="#classifier-chain"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Classifier chain&lt;/h3&gt;
&lt;p&gt;The API also lends itself for more interesting configurations, such as that of &lt;a href="https://en.wikipedia.org/wiki/Classifier_chains" rel="nofollow"&gt;classifier chains&lt;/a&gt;. By leveraging the API and Python's own control flow, a classifier chain model can be built as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;x &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
y_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Input()
order &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;list&lt;/span&gt;(&lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_targets))
random.shuffle(order)

ys_t &lt;span class="pl-k"&gt;=&lt;/span&gt; Split(n_targets, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)(y_t)
ys_p &lt;span class="pl-k"&gt;=&lt;/span&gt; []
&lt;span class="pl-k"&gt;for&lt;/span&gt; j, k &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;enumerate&lt;/span&gt;(order):
    x_stacked &lt;span class="pl-k"&gt;=&lt;/span&gt; ColumnStack()([x, &lt;span class="pl-k"&gt;*&lt;/span&gt;ys_p[:j]])
    ys_t[k] &lt;span class="pl-k"&gt;=&lt;/span&gt; Lambda(np.squeeze, &lt;span class="pl-v"&gt;axis&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1&lt;/span&gt;)(ys_t[k])
    ys_p.append(LogisticRegression()(x_stacked, ys_t[k]))

ys_p &lt;span class="pl-k"&gt;=&lt;/span&gt; [ys_p[order.index(j)] &lt;span class="pl-k"&gt;for&lt;/span&gt; j &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;range&lt;/span&gt;(n_targets)]
y_p &lt;span class="pl-k"&gt;=&lt;/span&gt; ColumnStack()(ys_p)

model &lt;span class="pl-k"&gt;=&lt;/span&gt; Model(x, y_p, y_t)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Click &lt;a href="examples/classifier_chain.py"&gt;here&lt;/a&gt; for a full example.&lt;/p&gt;
&lt;p&gt;Sure, scikit-learn already does have &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html#sklearn.multioutput.ClassifierChain" rel="nofollow"&gt;&lt;code&gt;ClassifierChain&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.RegressorChain.html#sklearn.multioutput.RegressorChain" rel="nofollow"&gt;&lt;code&gt;RegressorChain&lt;/code&gt;&lt;/a&gt; classes for this. But with &lt;strong&gt;baikal&lt;/strong&gt; you could, for example, mix classifiers and regressors to predict multilabels that include both categorical and continuous labels.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-next-development-steps" class="anchor" aria-hidden="true" href="#next-development-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next development steps&lt;/h2&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Make a step class factory function.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; Treat targets as first-class citizens in the Model. Currently, targets are not treated like formal inputs of the graph, and the only way a Model handles them is via the &lt;code&gt;Model.fit&lt;/code&gt; interface, which makes difficult applying steps to them (e.g. log transformation on regression targets).&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; (&lt;strong&gt;in progress&lt;/strong&gt;) Add parallelization to &lt;code&gt;Model.fit&lt;/code&gt; and &lt;code&gt;Model.predict&lt;/code&gt; (using joblib &lt;code&gt;Parallel&lt;/code&gt; API).&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Add caching of intermediate results to &lt;code&gt;Model.fit&lt;/code&gt; and &lt;code&gt;Model.predict&lt;/code&gt; (using joblib &lt;code&gt;Memory&lt;/code&gt; API).&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Make a custom &lt;code&gt;GridSearchCV&lt;/code&gt; API, based on the original scikit-learn implementation, that can handle baikal models with multiple inputs and outputs natively.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Make steps shareable.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Add support for steps that can take extra options in their predict method.&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox"&gt; Grow the merge steps module and add support for data structures other than numpy arrays (e.g. pandas dataframes). Some steps that could be added are:
&lt;ul&gt;
&lt;li&gt;Single array aggregation (sum, average, maximum, minimum, etc).&lt;/li&gt;
&lt;li&gt;Element-wise aggregation of multiple arrays.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bug reports and fixes are always welcome!&lt;/li&gt;
&lt;li&gt;Contributions to extend/refactor/improve/document the API are also welcome! &lt;strong&gt;baikal&lt;/strong&gt; is currently a one-man operation, and it could benefit from more minds and hands working on it :)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-setting-up-the-development-environment" class="anchor" aria-hidden="true" href="#setting-up-the-development-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setting up the development environment&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Clone the project.&lt;/li&gt;
&lt;li&gt;From the project root folder run: &lt;code&gt;make setup_dev&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;This will create a virtualenv and install the package in development mode.&lt;/li&gt;
&lt;li&gt;It will also install a pre-commit hook for the black code formatter.&lt;/li&gt;
&lt;li&gt;You need Python 3.5 or above.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To run the tests use: &lt;code&gt;make test&lt;/code&gt;, or &lt;code&gt;make test-cov&lt;/code&gt; to include coverage.
&lt;ul&gt;
&lt;li&gt;The tests include a test for the plot utility, so you need to install graphviz.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>alegonz</author><guid isPermaLink="false">https://github.com/alegonz/baikal</guid><pubDate>Wed, 20 Nov 2019 00:18:00 GMT</pubDate></item><item><title>dagster-io/dagster #19 in Python, Today</title><link>https://github.com/dagster-io/dagster</link><description>&lt;p&gt;&lt;i&gt;A Python library for building data applications: ETL, ML, Data Pipelines, and more.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987382-7e294500-7a35-11e9-9c6a-f73e0f1d3a1c.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987382-7e294500-7a35-11e9-9c6a-f73e0f1d3a1c.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;br&gt;&lt;br&gt;
&lt;a href="https://badge.fury.io/py/dagster" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1e6441ac0fa4d3b9e968e8fef89d18a684fa183b/68747470733a2f2f62616467652e667572792e696f2f70792f646167737465722e737667" data-canonical-src="https://badge.fury.io/py/dagster.svg" style="max-width:100%;"&gt;
&lt;/a&gt;&lt;a href="https://coveralls.io/github/dagster-io/dagster?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0297bd3b6e7c67862d727860f76241f95b6f305a/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f646167737465722d696f2f646167737465722f62616467652e7376673f6272616e63683d6d6173746572" data-canonical-src="https://coveralls.io/repos/github/dagster-io/dagster/badge.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://buildkite.com/dagster/dagster" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ed41dd566dc2f127467ea249a2b539ee42c7e692/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f38383835343562656162383239653431653564373330336462313535323561326263336230663065333361373237353961632e7376673f6272616e63683d6d6173746572" data-canonical-src="https://badge.buildkite.com/888545beab829e41e5d7303db15525a2bc3b0f0e33a72759ac.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://dagster.readthedocs.io/en/master/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e81711b6e8b9cbc5c0509a009136cfa7488aa786/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f646167737465722f62616467652f3f76657273696f6e3d6d6173746572" data-canonical-src="https://readthedocs.org/projects/dagster/badge/?version=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Dagster is a system for building modern data applications.&lt;/p&gt;
&lt;p&gt;Combining an elegant programming model and beautiful tools, Dagster allows infrastructure engineers, data engineers, and data scientists to seamlessly collaborate to process and produce the trusted, reliable data needed in today's world.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h3&gt;
&lt;p&gt;To get started:
&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
&lt;code&gt;pip install dagster dagit&lt;/code&gt;
&lt;/p&gt;
&lt;br&gt;
This installs two modules:
&lt;br&gt;
&lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;dagster&lt;/strong&gt; | The core programming model and abstraction stack; stateless, single-node,
single-process and multi-process execution engines; and a CLI tool for driving those engines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dagit&lt;/strong&gt; | A UI and rich development environment for Dagster, including a DAG browser, a type-aware config editor, and a streaming execution interface.
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-learn" class="anchor" aria-hidden="true" href="#learn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn&lt;/h3&gt;
&lt;p&gt;Next, jump right into our &lt;a href="https://dagster.readthedocs.io/en/stable/sections/learn/tutorial/index.html" rel="nofollow"&gt;tutorial&lt;/a&gt;, or read our &lt;a href="https://dagster.readthedocs.io" rel="nofollow"&gt;complete documentation&lt;/a&gt;. If you're actively using Dagster or have questions on getting started, we'd love to hear from you:&lt;/p&gt;
&lt;br&gt;
&lt;p align="center"&gt;
&lt;a href="https://join.slack.com/t/dagster/shared_invite/enQtNjEyNjkzNTA2OTkzLTI0MzdlNjU0ODVhZjQyOTMyMGM1ZDUwZDQ1YjJmYjI3YzExZGViMDI1ZDlkNTY5OThmYWVlOWM1MWVjN2I3NjU" rel="nofollow"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/63558739-f60a7e00-c502-11e9-8434-c8a95b03ce62.png" width="160px;" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h3&gt;
&lt;p&gt;For details on contributing or running the project for development, check out our &lt;a href="https://dagster.readthedocs.io/en/stable/sections/community/contributing.html" rel="nofollow"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-integrations" class="anchor" aria-hidden="true" href="#integrations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Integrations&lt;/h1&gt;
&lt;p&gt;Dagster works with the tools and systems that you're already using with your data, including:&lt;/p&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr align="center"&gt;
			&lt;td colspan="2"&gt;&lt;b&gt;Integration&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;b&gt;Dagster Library&lt;/b&gt;&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987547-a7e36b80-7a37-11e9-95ae-4c4de2618e87.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987547-a7e36b80-7a37-11e9-95ae-4c4de2618e87.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Apache Airflow&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-airflow"&gt;dagster-airflow&lt;/a&gt;&lt;br&gt;Allows Dagster pipelines to be scheduled and executed, either containerized or uncontainerized, as &lt;a href="https://github.com/apache/airflow"&gt;Apache Airflow DAGs&lt;/a&gt;.&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987976-5ccc5700-7a3d-11e9-9fa5-1a51299b1ccb.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987976-5ccc5700-7a3d-11e9-9fa5-1a51299b1ccb.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Apache Spark&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-spark"&gt;dagster-spark&lt;/a&gt; · &lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-pyspark"&gt;dagster-pyspark&lt;/a&gt;
			&lt;br&gt;Libraries for interacting with Apache Spark and Pyspark.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/58348728-48f66b80-7e16-11e9-9e9f-1a0fea9a49b4.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/58348728-48f66b80-7e16-11e9-9e9f-1a0fea9a49b4.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Dask&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/dagster-dask"&gt;dagster-dask&lt;/a&gt;
			&lt;br&gt;Provides a Dagster integration with Dask / Dask.Distributed.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/58349731-f36f8e00-7e18-11e9-8a2e-86e086caab66.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/58349731-f36f8e00-7e18-11e9-8a2e-86e086caab66.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;DataDog&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-datadog"&gt;dagster-datadog&lt;/a&gt;
			&lt;br&gt;Provides a Dagster resource for publishing metrics to DataDog.
			&lt;/td&gt;
		&lt;/tr&gt;
        
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987809-bf245800-7a3b-11e9-8905-494ed99d0852.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987809-bf245800-7a3b-11e9-8905-494ed99d0852.png" style="max-width:100%;"&gt;&lt;/a&gt;
			 /  &lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987827-fa268b80-7a3b-11e9-8a18-b675d76c19aa.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987827-fa268b80-7a3b-11e9-8a18-b675d76c19aa.png" style="max-width:100%;"&gt;&lt;/a&gt;
			&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Jupyter / Papermill&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/dagstermill"&gt;dagstermill&lt;/a&gt;&lt;br&gt;Built on the &lt;a href="https://github.com/nteract/papermill"&gt;papermill library&lt;/a&gt;, dagstermill is meant for integrating productionized Jupyter notebooks into dagster pipelines.&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57988016-f431aa00-7a3d-11e9-8cb6-1309d4246b27.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57988016-f431aa00-7a3d-11e9-8cb6-1309d4246b27.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;PagerDuty&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-pagerduty"&gt;dagster-pagerduty&lt;/a&gt;
			&lt;br&gt;A library for creating PagerDuty alerts from Dagster workflows.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/58349397-fcac2b00-7e17-11e9-900c-9ab8cf7cb64a.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/58349397-fcac2b00-7e17-11e9-900c-9ab8cf7cb64a.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
			&lt;td&gt; &lt;b&gt;Snowflake&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-snowflake"&gt;dagster-snowflake&lt;/a&gt;
			&lt;br&gt;A library for interacting with the Snowflake Data Warehouse.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td colspan="2" align="center"&gt;&lt;b&gt;Cloud Providers&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;b&gt;&lt;/b&gt;&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987557-c2b5e000-7a37-11e9-9310-c274481a4682.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987557-c2b5e000-7a37-11e9-9310-c274481a4682.png" style="max-width:100%;"&gt;&lt;/a&gt; &lt;/td&gt;
			&lt;td&gt;&lt;b&gt;AWS&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-aws"&gt;dagster-aws&lt;/a&gt;
			&lt;br&gt;A library for interacting with Amazon Web Services. Provides integrations with S3, EMR, and (coming soon!) Redshift.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/609349/57987566-f98bf600-7a37-11e9-81fa-b8ca1ea6cc1e.png"&gt;&lt;img src="https://user-images.githubusercontent.com/609349/57987566-f98bf600-7a37-11e9-81fa-b8ca1ea6cc1e.png" style="max-width:100%;"&gt;&lt;/a&gt; &lt;/td&gt;
			&lt;td&gt;&lt;b&gt;GCP&lt;/b&gt;&lt;/td&gt;
			&lt;td&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/python_modules/libraries/dagster-gcp"&gt;dagster-gcp&lt;/a&gt;
			&lt;br&gt;A library for interacting with Google Cloud Platform. Provides integrations with BigQuery and Cloud Dataproc.
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This list is growing as we are actively building more integrations, and we welcome contributions!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-example-projects" class="anchor" aria-hidden="true" href="#example-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Projects&lt;/h1&gt;
&lt;p&gt;Several example projects are provided under the examples folder demonstrating how to use Dagster, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/examples/dagster_examples/airline_demo"&gt;&lt;strong&gt;examples/airline-demo&lt;/strong&gt;&lt;/a&gt;: A substantial demo project illustrating how these tools can be used together to manage a realistic data pipeline.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dagster-io/dagster/tree/master/examples/dagster_examples/event_pipeline_demo"&gt;&lt;strong&gt;examples/event-pipeline-demo&lt;/strong&gt;&lt;/a&gt;: An example illustrating a typical web event processing pipeline with S3, Scala Spark, and Snowflake.&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dagster-io</author><guid isPermaLink="false">https://github.com/dagster-io/dagster</guid><pubDate>Wed, 20 Nov 2019 00:19:00 GMT</pubDate></item><item><title>MorvanZhou/Reinforcement-learning-with-tensorflow #20 in Python, Today</title><link>https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow</link><description>&lt;p&gt;&lt;i&gt;Simple Reinforcement learning tutorials&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;a href="https://www.youtube.com/watch?v=pieI7rOXELI&amp;amp;list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba" rel="nofollow"&gt;
    &lt;img width="60%" src="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/raw/master/RL_cover.jpg" style="max-width:100%;"&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h1&gt;&lt;a id="user-content-reinforcement-learning-methods-and-tutorials" class="anchor" aria-hidden="true" href="#reinforcement-learning-methods-and-tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reinforcement Learning Methods and Tutorials&lt;/h1&gt;
&lt;p&gt;In these tutorials for reinforcement learning, it covers from the basic RL algorithms to advanced algorithms developed recent years.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you speak Chinese, visit &lt;a href="https://morvanzhou.github.io/tutorials/" rel="nofollow"&gt;莫烦 Python&lt;/a&gt; or my &lt;a href="https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg" rel="nofollow"&gt;Youtube channel&lt;/a&gt; for more.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;As many requests about making these tutorials available in English, please find them in this playlist:&lt;/strong&gt; (&lt;a href="https://www.youtube.com/playlist?list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba" rel="nofollow"&gt;https://www.youtube.com/playlist?list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba&lt;/a&gt;)&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Tutorials
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/1_command_line_reinforcement_learning"&gt;Simple entry example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/2_Q_Learning_maze"&gt;Q-learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/3_Sarsa_maze"&gt;Sarsa&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/4_Sarsa_lambda_maze"&gt;Sarsa(lambda)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network"&gt;Deep Q Network (DQN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/6_OpenAI_gym"&gt;Using OpenAI Gym&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN"&gt;Double DQN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.2_Prioritized_Replay_DQN"&gt;DQN with Prioitized Experience Replay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN"&gt;Dueling DQN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/7_Policy_gradient_softmax"&gt;Policy Gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage"&gt;Actor-Critic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG"&gt;Deep Deterministic Policy Gradient (DDPG)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C"&gt;A3C&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/11_Dyna_Q"&gt;Dyna-Q&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization"&gt;Proximal Policy Optimization (PPO)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/contents/Curiosity_Model"&gt;Curiosity Model&lt;/a&gt;, &lt;a href="/contents/Curiosity_Model/Random_Network_Distillation.py"&gt;Random Network Distillation (RND)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments"&gt;Some of my experiments&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/2D_car"&gt;2D Car&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Robot_arm"&gt;Robot arm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Solve_BipedalWalker"&gt;BipedalWalker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Solve_LunarLander"&gt;LunarLander&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-some-rl-networks" class="anchor" aria-hidden="true" href="#some-rl-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Some RL Networks&lt;/h1&gt;
&lt;h3&gt;&lt;a id="user-content-deep-q-network" class="anchor" aria-hidden="true" href="#deep-q-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network"&gt;Deep Q Network&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5_Deep_Q_Network"&gt;
    &lt;img src="https://camo.githubusercontent.com/9d349655665f1b25905c42a7b342827a7df1acc2/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f342d332d322e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/4-3-2.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-double-dqn" class="anchor" aria-hidden="true" href="#double-dqn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN"&gt;Double DQN&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.1_Double_DQN"&gt;
    &lt;img src="https://camo.githubusercontent.com/49c9d71143f31e8e561de3059c9ae8e08fe8c0a6/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f342d352d332e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/4-5-3.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-dueling-dqn" class="anchor" aria-hidden="true" href="#dueling-dqn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN"&gt;Dueling DQN&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/5.3_Dueling_DQN"&gt;
    &lt;img src="https://camo.githubusercontent.com/bb04e5c0fb7f9c46cfb898362faceaf733abff99/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f342d372d342e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/4-7-4.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-actor-critic" class="anchor" aria-hidden="true" href="#actor-critic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage"&gt;Actor Critic&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/8_Actor_Critic_Advantage"&gt;
    &lt;img src="https://camo.githubusercontent.com/a6c8f9c2ee63bcd5bee37a93f6488f8071066120/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d312d312e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-1-1.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-deep-deterministic-policy-gradient" class="anchor" aria-hidden="true" href="#deep-deterministic-policy-gradient"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG"&gt;Deep Deterministic Policy Gradient&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG"&gt;
    &lt;img src="https://camo.githubusercontent.com/14ecb4ed0905d3b7d9cda452d77385aa5967a418/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d322d322e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-2-2.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-a3c" class="anchor" aria-hidden="true" href="#a3c"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C"&gt;A3C&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/10_A3C"&gt;
    &lt;img src="https://camo.githubusercontent.com/ae5c679885277b64d5284d17a77ed3f5f305154e/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d332d322e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-3-2.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-proximal-policy-optimization-ppo" class="anchor" aria-hidden="true" href="#proximal-policy-optimization-ppo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization"&gt;Proximal Policy Optimization (PPO)&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/contents/12_Proximal_Policy_Optimization"&gt;
    &lt;img src="https://camo.githubusercontent.com/f0872e487fe5a62274acbe83b2f28ba90db63a38/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f726573756c74732f7265696e666f7263656d656e742d6c6561726e696e672f362d342d332e706e67" data-canonical-src="https://morvanzhou.github.io/static/results/reinforcement-learning/6-4-3.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-curiosity-model" class="anchor" aria-hidden="true" href="#curiosity-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="/contents/Curiosity_Model"&gt;Curiosity Model&lt;/a&gt;&lt;/h3&gt;
&lt;a href="/contents/Curiosity_Model"&gt;
    &lt;img src="/contents/Curiosity_Model/Curiosity.png" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h1&gt;&lt;a id="user-content-donation" class="anchor" aria-hidden="true" href="#donation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Donation&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;If this does help you, please consider donating to support me for better tutorials. Any contribution is greatly appreciated!&lt;/em&gt;&lt;/p&gt;
&lt;div&gt;
  &lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_donations&amp;amp;business=morvanzhou%40gmail%2ecom&amp;amp;lc=C2&amp;amp;item_name=MorvanPython&amp;amp;currency_code=AUD&amp;amp;bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/f75f395714327046e04cbadbee71103f87fd0aa1/68747470733a2f2f7777772e70617970616c6f626a656374732e636f6d2f7765627374617469632f656e5f55532f692f62746e2f706e672f73696c7665722d70696c6c2d70617970616c2d343470782e706e67" alt="Paypal" height="auto" data-canonical-src="https://www.paypalobjects.com/webstatic/en_US/i/btn/png/silver-pill-paypal-44px.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div&gt;
  &lt;a href="https://www.patreon.com/morvan" rel="nofollow"&gt;
    &lt;img src="https://camo.githubusercontent.com/af8133ce68a27bb72e44120b5ec14062fc42dc75/68747470733a2f2f6d6f7276616e7a686f752e6769746875622e696f2f7374617469632f696d672f737570706f72742f70617472656f6e2e6a7067" alt="Patreon" height="120" data-canonical-src="https://morvanzhou.github.io/static/img/support/patreon.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>MorvanZhou</author><guid isPermaLink="false">https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow</guid><pubDate>Wed, 20 Nov 2019 00:20:00 GMT</pubDate></item><item><title>python/cpython #21 in Python, Today</title><link>https://github.com/python/cpython</link><description>&lt;p&gt;&lt;i&gt;The Python programming language&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-this-is-python-version-390-alpha-0" class="anchor" aria-hidden="true" href="#this-is-python-version-390-alpha-0"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;This is Python version 3.9.0 alpha 0&lt;/h1&gt;
&lt;a href="https://travis-ci.org/python/cpython" rel="nofollow"&gt;&lt;img alt="CPython build status on Travis CI" src="https://camo.githubusercontent.com/1cf785564e67b5021bcfb04c9e9ba719e53ce233/68747470733a2f2f7472617669732d63692e6f72672f707974686f6e2f63707974686f6e2e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.org/python/cpython.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://dev.azure.com/python/cpython/_build/latest?definitionId=4&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img alt="CPython build status on Azure DevOps" src="https://camo.githubusercontent.com/f83305497e9e201829a929f97fdcbc85cb749208/68747470733a2f2f6465762e617a7572652e636f6d2f707974686f6e2f63707974686f6e2f5f617069732f6275696c642f7374617475732f417a757265253230506970656c696e657325323043493f6272616e63684e616d653d6d6173746572" data-canonical-src="https://dev.azure.com/python/cpython/_apis/build/status/Azure%20Pipelines%20CI?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/python/cpython" rel="nofollow"&gt;&lt;img alt="CPython code coverage on Codecov" src="https://camo.githubusercontent.com/8d830fe82af43496cf4e3c635576df2dc324f266/68747470733a2f2f636f6465636f762e696f2f67682f707974686f6e2f63707974686f6e2f6272616e63682f6d61737465722f67726170682f62616467652e737667" data-canonical-src="https://codecov.io/gh/python/cpython/branch/master/graph/badge.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://python.zulipchat.com" rel="nofollow"&gt;&lt;img alt="Python Zulip chat" src="https://camo.githubusercontent.com/11c063c06dacad518cf3aa987986e97ef2018727/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;p&gt;Copyright (c) 2001-2019 Python Software Foundation.  All rights reserved.&lt;/p&gt;
&lt;p&gt;See the end of this file for further copyright and license information.&lt;/p&gt;
&lt;div id="user-content-contents"&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#general-information" id="user-content-id1"&gt;General Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing-to-cpython" id="user-content-id2"&gt;Contributing to CPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-python" id="user-content-id3"&gt;Using Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#build-instructions" id="user-content-id4"&gt;Build Instructions&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#profile-guided-optimization" id="user-content-id5"&gt;Profile Guided Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#link-time-optimization" id="user-content-id6"&gt;Link Time Optimization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-s-new" id="user-content-id7"&gt;What's New&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation" id="user-content-id8"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#converting-from-python-2-x-to-3-x" id="user-content-id9"&gt;Converting From Python 2.x to 3.x&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing" id="user-content-id10"&gt;Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installing-multiple-versions" id="user-content-id11"&gt;Installing multiple versions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#issue-tracker-and-mailing-list" id="user-content-id12"&gt;Issue Tracker and Mailing List&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#proposals-for-enhancement" id="user-content-id13"&gt;Proposals for enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#release-schedule" id="user-content-id14"&gt;Release Schedule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#copyright-and-license-information" id="user-content-id15"&gt;Copyright and License Information&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;a name="user-content-general-information"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-general-information" class="anchor" aria-hidden="true" href="#general-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id1"&gt;General Information&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Website: &lt;a href="https://www.python.org" rel="nofollow"&gt;https://www.python.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Source code: &lt;a href="https://github.com/python/cpython"&gt;https://github.com/python/cpython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Issue tracker: &lt;a href="https://bugs.python.org" rel="nofollow"&gt;https://bugs.python.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Documentation: &lt;a href="https://docs.python.org" rel="nofollow"&gt;https://docs.python.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Developer's Guide: &lt;a href="https://devguide.python.org/" rel="nofollow"&gt;https://devguide.python.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-contributing-to-cpython"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing-to-cpython" class="anchor" aria-hidden="true" href="#contributing-to-cpython"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id2"&gt;Contributing to CPython&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For more complete instructions on contributing to CPython development,
see the &lt;a href="https://devguide.python.org/" rel="nofollow"&gt;Developer Guide&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-using-python"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-using-python" class="anchor" aria-hidden="true" href="#using-python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id3"&gt;Using Python&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Installable Python kits, and information about using Python, are available at
&lt;a href="https://www.python.org/" rel="nofollow"&gt;python.org&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-build-instructions"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-build-instructions" class="anchor" aria-hidden="true" href="#build-instructions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id4"&gt;Build Instructions&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On Unix, Linux, BSD, macOS, and Cygwin:&lt;/p&gt;
&lt;pre&gt;./configure
make
make test
sudo make install
&lt;/pre&gt;
&lt;p&gt;This will install Python as &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can pass many options to the configure script; run &lt;code&gt;./configure --help&lt;/code&gt;
to find out more.  On macOS case-insensitive file systems and on Cygwin,
the executable is called &lt;code&gt;python.exe&lt;/code&gt;; elsewhere it's just &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Building a complete Python installation requires the use of various
additional third-party libraries, depending on your build platform and
configure options.  Not all standard library modules are buildable or
useable on all platforms.  Refer to the
&lt;a href="https://devguide.python.org/setup/#install-dependencies" rel="nofollow"&gt;Install dependencies&lt;/a&gt;
section of the &lt;a href="https://devguide.python.org/" rel="nofollow"&gt;Developer Guide&lt;/a&gt; for current detailed information on
dependencies for various Linux distributions and macOS.&lt;/p&gt;
&lt;p&gt;On macOS, there are additional configure and build options related
to macOS framework and universal builds.  Refer to &lt;a href="https://github.com/python/cpython/blob/master/Mac/README.rst"&gt;Mac/README.rst&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On Windows, see &lt;a href="https://github.com/python/cpython/blob/master/PCbuild/readme.txt"&gt;PCbuild/readme.txt&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you wish, you can create a subdirectory and invoke configure from there.
For example:&lt;/p&gt;
&lt;pre&gt;mkdir debug
cd debug
../configure --with-pydebug
make
make test
&lt;/pre&gt;
&lt;p&gt;(This will fail if you &lt;em&gt;also&lt;/em&gt; built at the top-level directory.  You should do
a &lt;code&gt;make clean&lt;/code&gt; at the top-level first.)&lt;/p&gt;
&lt;p&gt;To get an optimized build of Python, &lt;code&gt;configure --enable-optimizations&lt;/code&gt;
before you run &lt;code&gt;make&lt;/code&gt;.  This sets the default make targets up to enable
Profile Guided Optimization (PGO) and may be used to auto-enable Link Time
Optimization (LTO) on some platforms.  For more details, see the sections
below.&lt;/p&gt;
&lt;a name="user-content-profile-guided-optimization"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-profile-guided-optimization" class="anchor" aria-hidden="true" href="#profile-guided-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id5"&gt;Profile Guided Optimization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;PGO takes advantage of recent versions of the GCC or Clang compilers.  If used,
either via &lt;code&gt;configure --enable-optimizations&lt;/code&gt; or by manually running
&lt;code&gt;make profile-opt&lt;/code&gt; regardless of configure flags, the optimized build
process will perform the following steps:&lt;/p&gt;
&lt;p&gt;The entire Python directory is cleaned of temporary files that may have
resulted from a previous compilation.&lt;/p&gt;
&lt;p&gt;An instrumented version of the interpreter is built, using suitable compiler
flags for each flavour. Note that this is just an intermediary step.  The
binary resulting from this step is not good for real life workloads as it has
profiling instructions embedded inside.&lt;/p&gt;
&lt;p&gt;After the instrumented interpreter is built, the Makefile will run a training
workload.  This is necessary in order to profile the interpreter execution.
Note also that any output, both stdout and stderr, that may appear at this step
is suppressed.&lt;/p&gt;
&lt;p&gt;The final step is to build the actual interpreter, using the information
collected from the instrumented one.  The end result will be a Python binary
that is optimized; suitable for distribution or production installation.&lt;/p&gt;
&lt;a name="user-content-link-time-optimization"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-link-time-optimization" class="anchor" aria-hidden="true" href="#link-time-optimization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id6"&gt;Link Time Optimization&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Enabled via configure's &lt;code&gt;--with-lto&lt;/code&gt; flag.  LTO takes advantage of the
ability of recent compiler toolchains to optimize across the otherwise
arbitrary &lt;code&gt;.o&lt;/code&gt; file boundary when building final executables or shared
libraries for additional performance gains.&lt;/p&gt;
&lt;a name="user-content-what-s-new"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-whats-new" class="anchor" aria-hidden="true" href="#whats-new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id7"&gt;What's New&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We have a comprehensive overview of the changes in the &lt;a href="https://docs.python.org/3.9/whatsnew/3.9.html" rel="nofollow"&gt;What's New in Python
3.9&lt;/a&gt; document.  For a more
detailed change log, read &lt;a href="https://github.com/python/cpython/blob/master/Misc/NEWS.d"&gt;Misc/NEWS&lt;/a&gt;, but a full
accounting of changes can only be gleaned from the &lt;a href="https://github.com/python/cpython/commits/master"&gt;commit history&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want to install multiple versions of Python, see the section below
entitled "Installing multiple versions".&lt;/p&gt;
&lt;a name="user-content-documentation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id8"&gt;Documentation&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3.9/" rel="nofollow"&gt;Documentation for Python 3.9&lt;/a&gt; is online,
updated daily.&lt;/p&gt;
&lt;p&gt;It can also be downloaded in many formats for faster access.  The documentation
is downloadable in HTML, PDF, and reStructuredText formats; the latter version
is primarily for documentation authors, translators, and people with special
formatting requirements.&lt;/p&gt;
&lt;p&gt;For information about building Python's documentation, refer to &lt;a href="https://github.com/python/cpython/blob/master/Doc/README.rst"&gt;Doc/README.rst&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-converting-from-python-2-x-to-3-x"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-converting-from-python-2x-to-3x" class="anchor" aria-hidden="true" href="#converting-from-python-2x-to-3x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id9"&gt;Converting From Python 2.x to 3.x&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Significant backward incompatible changes were made for the release of Python
3.0, which may cause programs written for Python 2 to fail when run with Python
3.  For more information about porting your code from Python 2 to Python 3, see
the &lt;a href="https://docs.python.org/3/howto/pyporting.html" rel="nofollow"&gt;Porting HOWTO&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-testing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id10"&gt;Testing&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To test the interpreter, type &lt;code&gt;make test&lt;/code&gt; in the top-level directory.  The
test set produces some output.  You can generally ignore the messages about
skipped tests due to optional features which can't be imported.  If a message
is printed about a failed test or a traceback or core dump is produced,
something is wrong.&lt;/p&gt;
&lt;p&gt;By default, tests are prevented from overusing resources like disk space and
memory.  To enable these tests, run &lt;code&gt;make testall&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If any tests fail, you can re-run the failing test(s) in verbose mode.  For
example, if &lt;code&gt;test_os&lt;/code&gt; and &lt;code&gt;test_gdb&lt;/code&gt; failed, you can run:&lt;/p&gt;
&lt;pre&gt;make test TESTOPTS="-v test_os test_gdb"
&lt;/pre&gt;
&lt;p&gt;If the failure persists and appears to be a problem with Python rather than
your environment, you can &lt;a href="https://bugs.python.org" rel="nofollow"&gt;file a bug report&lt;/a&gt; and
include relevant output from that command to show the issue.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://devguide.python.org/runtests/" rel="nofollow"&gt;Running &amp;amp; Writing Tests&lt;/a&gt;
for more on running tests.&lt;/p&gt;
&lt;a name="user-content-installing-multiple-versions"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installing-multiple-versions" class="anchor" aria-hidden="true" href="#installing-multiple-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id11"&gt;Installing multiple versions&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On Unix and Mac systems if you intend to install multiple versions of Python
using the same installation prefix (&lt;code&gt;--prefix&lt;/code&gt; argument to the configure
script) you must take care that your primary python executable is not
overwritten by the installation of a different version.  All files and
directories installed using &lt;code&gt;make altinstall&lt;/code&gt; contain the major and minor
version and can thus live side-by-side.  &lt;code&gt;make install&lt;/code&gt; also creates
&lt;code&gt;${prefix}/bin/python3&lt;/code&gt; which refers to &lt;code&gt;${prefix}/bin/pythonX.Y&lt;/code&gt;.  If you
intend to install multiple versions using the same prefix you must decide which
version (if any) is your "primary" version.  Install that version using &lt;code&gt;make
install&lt;/code&gt;.  Install all other versions using &lt;code&gt;make altinstall&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, if you want to install Python 2.7, 3.6, and 3.9 with 3.9 being the
primary version, you would execute &lt;code&gt;make install&lt;/code&gt; in your 3.9 build directory
and &lt;code&gt;make altinstall&lt;/code&gt; in the others.&lt;/p&gt;
&lt;a name="user-content-issue-tracker-and-mailing-list"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-issue-tracker-and-mailing-list" class="anchor" aria-hidden="true" href="#issue-tracker-and-mailing-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id12"&gt;Issue Tracker and Mailing List&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Bug reports are welcome!  You can use the &lt;a href="https://bugs.python.org" rel="nofollow"&gt;issue tracker&lt;/a&gt; to report bugs, and/or submit pull requests &lt;a href="https://github.com/python/cpython"&gt;on
GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can also follow development discussion on the &lt;a href="https://mail.python.org/mailman/listinfo/python-dev/" rel="nofollow"&gt;python-dev mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-proposals-for-enhancement"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-proposals-for-enhancement" class="anchor" aria-hidden="true" href="#proposals-for-enhancement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id13"&gt;Proposals for enhancement&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you have a proposal to change Python, you may want to send an email to the
comp.lang.python or &lt;a href="https://mail.python.org/mailman/listinfo/python-ideas/" rel="nofollow"&gt;python-ideas&lt;/a&gt; mailing lists for initial feedback.  A
Python Enhancement Proposal (PEP) may be submitted if your idea gains ground.
All current PEPs, as well as guidelines for submitting a new PEP, are listed at
&lt;a href="https://www.python.org/dev/peps/" rel="nofollow"&gt;python.org/dev/peps/&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-release-schedule"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-release-schedule" class="anchor" aria-hidden="true" href="#release-schedule"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id14"&gt;Release Schedule&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;See &lt;a href="http://www.python.org/dev/peps/pep-0596" rel="nofollow"&gt;PEP 596&lt;/a&gt; for Python 3.9 release details.&lt;/p&gt;
&lt;a name="user-content-copyright-and-license-information"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-copyright-and-license-information" class="anchor" aria-hidden="true" href="#copyright-and-license-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id15"&gt;Copyright and License Information&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Copyright (c) 2001-2019 Python Software Foundation.  All rights reserved.&lt;/p&gt;
&lt;p&gt;Copyright (c) 2000 BeOpen.com.  All rights reserved.&lt;/p&gt;
&lt;p&gt;Copyright (c) 1995-2001 Corporation for National Research Initiatives.  All
rights reserved.&lt;/p&gt;
&lt;p&gt;Copyright (c) 1991-1995 Stichting Mathematisch Centrum.  All rights reserved.&lt;/p&gt;
&lt;p&gt;See the file "LICENSE" for information on the history of this software, terms &amp;amp;
conditions for usage, and a DISCLAIMER OF ALL WARRANTIES.&lt;/p&gt;
&lt;p&gt;This Python distribution contains &lt;em&gt;no&lt;/em&gt; GNU General Public License (GPL) code,
so it may be used in proprietary projects.  There are interfaces to some GNU
code but these are entirely optional.&lt;/p&gt;
&lt;p&gt;All trademarks referenced herein are property of their respective holders.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>python</author><guid isPermaLink="false">https://github.com/python/cpython</guid><pubDate>Wed, 20 Nov 2019 00:21:00 GMT</pubDate></item><item><title>EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi #22 in Python, Today</title><link>https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi</link><description>&lt;p&gt;&lt;i&gt;A tutorial showing how to train, convert, and run TensorFlow Lite object detection models on Android devices, the Raspberry Pi, and more!&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-lite-object-detection-on-android-and-raspberry-pi" class="anchor" aria-hidden="true" href="#tensorflow-lite-object-detection-on-android-and-raspberry-pi"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi&lt;/h1&gt;
&lt;p&gt;A guide showing how to train TensorFlow Lite object detection models and run them on Android, the Raspberry Pi, and more!&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/BSR_demo.gif"&gt;&lt;img src="doc/BSR_demo.gif" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TensorFlow Lite is an optimized framework for deploying lightweight deep learning models on resource-constrained edge devices. TensorFlow Lite models have faster inference time and require less processing power, so they can be used to obtain faster performance in realtime applications. This guide provides step-by-step instructions for how train a custom TensorFlow Object Detection model, convert it into an optimized format that can be used by TensorFlow Lite, and run it on Android phones or the Raspberry Pi.&lt;/p&gt;
&lt;p&gt;The guide is broken into three major portions. Each portion will have its own dedicated README file in this repository.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to Train, Convert, and Run Custom TensorFlow Lite Object Detection Models on Windows 10  &lt;em&gt;&amp;lt;--- You are here!&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md"&gt;How to Run TensorFlow Lite Object Detection Models on the Raspberry Pi (with optional Coral USB Accelerator)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How to Run TensorFlow Lite Object Detection Models on Android Devices
(Expected completion: 11/30/19)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This repository also contains Python code for running the newly converted TensorFlow Lite model to perform detection on images, videos, or webcam feeds.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-a-note-on-versions" class="anchor" aria-hidden="true" href="#a-note-on-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Note on Versions&lt;/h3&gt;
&lt;p&gt;I used TensorFlow v1.13 while creating this guide, because TF v1.13 is a stable version that has great support from Anaconda. I will periodically update the guide to make sure it works with newer versions of TensorFlow.&lt;/p&gt;
&lt;p&gt;The TensorFlow team is always hard at work releasing updated versions of TensorFlow. I recommend picking one version and sticking with it for all your TensorFlow projects. Every part of this guide should work with newer or older versions, but you may need to use different versions of the tools needed to run or build TensorFlow (CUDA, cuDNN, bazel, etc). Google has provided a list of build configurations for &lt;a href="https://www.tensorflow.org/install/source#linux" rel="nofollow"&gt;Linux&lt;/a&gt;, &lt;a href="https://www.tensorflow.org/install/source#macos" rel="nofollow"&gt;macOS&lt;/a&gt;, and &lt;a href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="nofollow"&gt;Windows&lt;/a&gt; that show which tool versions were used to build and run each version of TensorFlow.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-part-1---how-to-train-convert-and-run-custom-tensorflow-lite-object-detection-models-on-windows-10" class="anchor" aria-hidden="true" href="#part-1---how-to-train-convert-and-run-custom-tensorflow-lite-object-detection-models-on-windows-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Part 1 - How to Train, Convert, and Run Custom TensorFlow Lite Object Detection Models on Windows 10&lt;/h2&gt;
&lt;p&gt;Part 1 of this guide gives instructions for training and deploying your own custom TensorFlow Lite object detection model on a Windows 10 PC. The guide is based off the &lt;a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md"&gt;tutorial in the TensorFlow Object Detection repository&lt;/a&gt;, but it gives more detailed instructions and is written specifically for Windows. (It will work on Linux too with some minor changes, which I leave as an exercise for the Linux user.)&lt;/p&gt;
&lt;p&gt;There are three primary steps to training and deploying a TensorFlow Lite model:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph"&gt;Train a quantized SSD-MobileNet model using TensorFlow, and export frozen graph for TensorFlow Lite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-2-build-tensorflow-from-source"&gt;Build TensorFlow from source on your PC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-3-use-toco-to-create-optimzed-tensorflow-lite-model"&gt;Use TensorFlow Lite Optimizing Converter (TOCO) to create optimzed TensorFlow Lite model&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This portion is a continuation of my previous guide: &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;How To Train an Object Detection Model Using TensorFlow on Windows 10&lt;/a&gt;. I'll assume you have already set up TensorFlow to train a custom object detection model as described in that guide, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setting up an Anaconda virtual environment for training&lt;/li&gt;
&lt;li&gt;Setting up TensorFlow directory structure&lt;/li&gt;
&lt;li&gt;Gathering and labeling training images&lt;/li&gt;
&lt;li&gt;Preparing training data (generating TFRecords and label map)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial uses the same Anaconda virtual environment, files, and directory structure that was set up in the previous one.&lt;/p&gt;
&lt;p&gt;Through the course of the guide, I'll use a bird, squirrel, and raccoon detector model I've been working on as an example. The intent of this detection model is to watch a bird feeder, and record videos of birds while triggering an alarm if a squirrel or raccoon is stealing from it! I'll show the steps needed to train, convert, and run a quantized TensorFlow Lite version of the bird/squirrel/raccoon detector.&lt;/p&gt;
&lt;p&gt;Parts 2 and 3 of this guide will go on to show how to deploy this newly trained TensorFlow Lite model on the Raspberry Pi or an Android device. If you're not feeling up to training and converting your own TensorFlow Lite model, you can skip Part 1 and use my custom-trained TFLite BSR detection model (link to be added later) or use the &lt;a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip" rel="nofollow"&gt;TF Lite starter detection model&lt;/a&gt; (taken from &lt;a href="https://www.tensorflow.org/lite/models/object_detection/overview" rel="nofollow"&gt;https://www.tensorflow.org/lite/models/object_detection/overview&lt;/a&gt;) for Part 2 or Part 3.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph" class="anchor" aria-hidden="true" href="#step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Train Quantized SSD-MobileNet Model and Export Frozen TensorFlow Lite Graph&lt;/h3&gt;
&lt;p&gt;First, we’ll use transfer learning to train a “quantized” SSD-MobileNet model. Quantized models use 8-bit integer values instead of 32-bit floating values within the neural network, allowing them to run much more efficiently on GPUs or specialized TPUs (TensorFlow Processing Units).&lt;/p&gt;
&lt;p&gt;You can also use a standard SSD-MobileNet model (V1 or V2), but it will not run quite as fast as the quantized model. Also, you will not be able to run it on the Google Coral TPU Accelerator. If you’re using an SSD-MobileNet model that has already been trained, you can skip to &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1d-export-frozen-inference-graph-for-tensorflow-lite"&gt;Step 1d&lt;/a&gt; of this guide.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you get any errors during this process, please look at the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ section&lt;/a&gt; at the bottom of this guide! It gives solutions to common errors that occur.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned prevoiusly, this guide assumes you have already followed my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous TensorFlow tutorial&lt;/a&gt; and set up the Anaconda virtual environment and full directory structure needed for using the TensorFlow Object Detection API. If you've done so, you should have a folder at C:\tensorflow1\models\research\object_detection that has everything needed for training. (If you used a different base folder name than "tensorflow1", that's fine - just make sure you continue to use that name throughout this guide.)&lt;/p&gt;
&lt;p&gt;Here's what your \object_detection folder should look like:&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/object_detection_folder.png"&gt;&lt;img src="doc/object_detection_folder.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;If you don't have this folder, please go to my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous tutorial&lt;/a&gt; and work through at least Steps 1 and 2. If you'd like to train your own model to detect custom objects, you'll also need to work through Steps 3, 4, and 5. If you don't want to train your own model but want to practice the process for converting a model to TensorFlow Lite, you can download the quantized MobileNet-SSD model (see next paragraph) and then skip to &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1d-export-frozen-inference-graph-for-tensorflow-lite"&gt;Step 1d&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1a-download-and-extract-quantized-ssd-mobilenet-model" class="anchor" aria-hidden="true" href="#step-1a-download-and-extract-quantized-ssd-mobilenet-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1a. Download and extract quantized SSD-MobileNet model&lt;/h4&gt;
&lt;p&gt;Google provides several quantized object detection models in their &lt;a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"&gt;detection model zoo&lt;/a&gt;. This tutorial will use the SSD-MobileNet-V2-Quantized-COCO model. Download the model &lt;a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz" rel="nofollow"&gt;here&lt;/a&gt;. &lt;strong&gt;Note: TensorFlow Lite does NOT support RCNN models such as Faster-RCNN! It only supports SSD models.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Move the downloaded .tar.gz file to the C:\tensorflow1\models\research\object_detection folder. (Henceforth, this folder will be referred to as the “\object_detection” folder.)  Unzip the .tar.gz file using a file archiver like WinZip or 7-Zip. After the file has been fully unzipped, you should have a folder called "ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03" within the \object_detection folder.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1b-configure-training" class="anchor" aria-hidden="true" href="#step-1b-configure-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1b. Configure training&lt;/h4&gt;
&lt;p&gt;If you're training your own TensorFlow Lite model, make sure the following items from my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous guide&lt;/a&gt; have been completed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Train and test images and their XML label files are placed in the \object_detection\images\train and \object_detection\images\test folders&lt;/li&gt;
&lt;li&gt;train_labels.csv and test_labels.csv have been generated and are located in the \object_detection\images folder&lt;/li&gt;
&lt;li&gt;train.record and test.record have been generated and are located in the \object_detection folder&lt;/li&gt;
&lt;li&gt;labelmap.pbtxt file has been created and is located in the \object_detection\training folder&lt;/li&gt;
&lt;li&gt;proto files in \object_detection\protos have been generated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you have any questions about these files or don’t know how to generate them, &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;Steps 2, 3, 4, and 5 of my previous tutorial&lt;/a&gt; show how they are all created.&lt;/p&gt;
&lt;p&gt;Copy the ssd_mobilenet_v2_quantized_300x300_coco.config file from the \object_detection\samples\configs folder to the \object_detection\training folder. Then, open the file using a text editor.&lt;/p&gt;
&lt;p&gt;Make the following changes to the ssd_mobilenet_v2_quantized_300x300_coco.config file. Note: The paths must be entered with single forward slashes (NOT backslashes), or TensorFlow will give a file path error when trying to train the model! Also, the paths must be in double quotation marks ( " ), not single quotation marks ( ' ).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Line 9. Change num_classes to the number of different objects you want the classifier to detect. For my bird/squirrel/raccoon detector example, there are three classes, so I set num_classes: 3&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 141. Change batch_size: 24 to batch_size: 6 . The smaller batch size will prevent OOM (Out of Memory) errors during training.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 156. Change fine_tune_checkpoint to: "C:/tensorflow1/models/research/object_detection/ ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 175. Change input_path to: "C:/tensorflow1/models/research/object_detection/train.record"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 177. Change label_map_path to: "C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 181. Change num_examples to the number of images you have in the \images\test directory. For my bird/squirrel/raccoon detector example, there are 582 test images, so I set num_examples: 582.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 189. Change input_path to: "C:/tensorflow1/models/research/object_detection/test.record"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Line 191. Change label_map_path to: "C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt"&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Save and exit the training file after the changes have been made.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1c-run-training-in-anaconda-virtual-environment" class="anchor" aria-hidden="true" href="#step-1c-run-training-in-anaconda-virtual-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1c. Run training in Anaconda virtual environment&lt;/h4&gt;
&lt;p&gt;All that's left to do is train the model! First, move the “train.py” file from the \object_detection\legacy folder into the main \object_detection folder. (See the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ&lt;/a&gt; for why I am using the legacy train.py script rather than model_main.py for training.)&lt;/p&gt;
&lt;p&gt;Then, open a new Anaconda Prompt window by searching for “Anaconda Prompt” in the Start menu and clicking on it. Activate the “tensorflow1” virtual environment (which was set up in my &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"&gt;previous tutorial&lt;/a&gt;) by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;activate tensorflow1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, set the PYTHONPATH environment variable by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set PYTHONPATH=C:\tensorflow1\models;C:\tensorflow1\models\research;C:\tensorflow1\models\research\slim
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, change directories to the \object_detection folder:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd C:\tensorflow1\models\research\object_detection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, train the model by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python train.py --logtostderr –train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_quantized_300x300_coco.config
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything was set up correctly, the model will begin training after a couple minutes of initialization.&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/training_in_progress.png"&gt;&lt;img src="doc/training_in_progress.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Allow the model to train until the loss consistently drops below 2. For my bird/squirrel/raccoon detector model, this took about 9000 steps, or 8 hours of training. (Time will vary depending on how powerful your CPU and GPU are. Please see &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/blob/master/README.md#6-run-the-training"&gt;Step 6 of my previous tutorial&lt;/a&gt; for more information on training and an explanation of how to view the progress of the training job using TensorBoard.)&lt;/p&gt;
&lt;p&gt;Once training is complete (i.e. the loss has consistently dropped below 2), press Ctrl+C to stop training. The latest checkpoint will be saved in the \object_detection\training folder, and we will use that checkpoint to export the frozen TensorFlow Lite graph. Take note of the checkpoint number of the model.ckpt file in the training folder (i.e. model.ckpt-XXXX), as it will be used later.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-1d-export-frozen-inference-graph-for-tensorflow-lite" class="anchor" aria-hidden="true" href="#step-1d-export-frozen-inference-graph-for-tensorflow-lite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1d. Export frozen inference graph for TensorFlow Lite&lt;/h4&gt;
&lt;p&gt;Now that training has finished, the model can be exported for conversion to TensorFlow Lite using the export_tflite_ssd_graph.py script. First, create a folder in \object_detection called “TFLite_model” by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, let’s set up some environment variables so the commands are easier to type out. Issue the following commands in Anaconda Prompt. (Note, the XXXX in the second command should be replaced with the highest-numbered model.ckpt file in the \object_detection\training folder.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set CONFIG_FILE=C:\\tensorflow1\models\research\object_detection\training\ssd_mobilenet_v2_quantized_300x300_coco.config
set CHECKPOINT_PATH=C:\\tensorflow1\models\research\object_detection\training\model.ckpt-XXXX
set OUTPUT_DIR=C:\\tensorflow1\models\research\object_detection\TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that those are set up, issue this command to export the model for TensorFlow Lite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python export_tflite_ssd_graph.py --pipeline_config_path=%CONFIG_FILE% --trained_checkpoint_prefix=%CHECKPOINT_PATH% --output_directory=%OUTPUT_DIR% --add_postprocessing_op=true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the command has executed, there should be two new files in the \object_detection\TFLite_model folder: tflite_graph.pb and tflite_graph.pbtxt.&lt;/p&gt;
&lt;p&gt;That’s it! The new inference graph has been trained and exported. This inference graph's architecture and network operations are compatible with TensorFlow Lite's framework. However, the graph still needs to be converted to an actual TensorFlow Lite model. We'll do that in Step 3. First, we have to build TensorFlow from source. On to Step 2!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-build-tensorflow-from-source" class="anchor" aria-hidden="true" href="#step-2-build-tensorflow-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2. Build TensorFlow From Source&lt;/h3&gt;
&lt;p&gt;To convert the frozen graph we just exported into a model that can be used by TensorFlow Lite, it has to be run through the TensorFlow Lite Optimizing Converter (TOCO). Unfortunately, to use TOCO, we have to build TensorFlow from source on our computer. To do this, we’ll create a separate Anaconda virtual environment for building TensorFlow.&lt;/p&gt;
&lt;p&gt;This part of the tutorial breaks down step-by-step how to build TensorFlow from source on your Windows PC. It follows the &lt;a href="https://www.tensorflow.org/install/source_windows" rel="nofollow"&gt;Build TensorFlow From Source on Windows&lt;/a&gt; instructions given on the official TensorFlow website, with some slight modifications.&lt;/p&gt;
&lt;p&gt;This guide will show how to build either the CPU-only version of TensorFlow or the GPU-enabled version of TensorFlow v1.13. If you would like to build a version other than TF v1.13, you can still use this guide, but check the &lt;a href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="nofollow"&gt;build configuration list&lt;/a&gt; and make sure you use the correct package versions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you are only building TensorFlow to convert a TensorFlow Lite object detection model, I recommend building the CPU-only version!&lt;/strong&gt; It takes very little computational effort to export the model, so your CPU can do it just fine without help from your GPU. If you’d like to build the GPU-enabled version anyway, then you need to have the appropriate version of CUDA and cuDNN installed. &lt;a href="https://www.tensorflow.org/install/gpu#windows_setup" rel="nofollow"&gt;The TensorFlow installation guide&lt;/a&gt; explains how to install CUDA and cuDNN. Check the &lt;a href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="nofollow"&gt;build configuration list&lt;/a&gt; to see which versions of CUDA and cuDNN are compatible with which versions of TensorFlow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you get any errors during this process, please look at the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ section&lt;/a&gt; at the bottom of this guide! It gives solutions to common errors that occur.&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2a-install-msys2" class="anchor" aria-hidden="true" href="#step-2a-install-msys2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2a. Install MSYS2&lt;/h4&gt;
&lt;p&gt;MSYS2 has some binary tools needed for building TensorFlow. It also automatically converts Windows-style directory paths to Linux-style paths when using Bazel. The Bazel build won’t work without MSYS2 installed!&lt;/p&gt;
&lt;p&gt;First, install MSYS2 by following the instructions on the &lt;a href="https://www.msys2.org/" rel="nofollow"&gt;MSYS2 website&lt;/a&gt;. Download the msys2-x86_64 executable file and run it. Use the default options for installation. After installing, open MSYS2 and issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pacman -Syu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After it's completed, close the window, re-open it, and then issue the following two commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pacman -Su
pacman -S patch unzip
&lt;/code&gt;&lt;/pre&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/MSYS_window.png"&gt;&lt;img src="doc/MSYS_window.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;This updates MSYS2’s package manager and downloads the patch and unzip packages. Now, close the MSYS2 window. We'll add the MSYS2 binary to the PATH environment variable in Step 2c.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2b-install-visual-c-build-tools-2015" class="anchor" aria-hidden="true" href="#step-2b-install-visual-c-build-tools-2015"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2b. Install Visual C++ Build Tools 2015&lt;/h4&gt;
&lt;p&gt;Install Microsoft Build Tools 2015 and Microsoft Visual C++ 2015 Redistributable by visiting the &lt;a href="https://visualstudio.microsoft.com/vs/older-downloads/" rel="nofollow"&gt;Visual Studio older downloads&lt;/a&gt; page. Click the “Redistributables and Build Tools” dropdown at the bottom of the list.  Download and install the following two packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Build Tools 2015 Update 3&lt;/strong&gt; - Use the default installation options in the install wizard. Once you begin installing, it goes through a fairly large download, so it will take a while if you have a slow internet connection. It may give you some warnings saying build tools or redistributables have already been installed. If so, that's fine; just click through them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Visual C++ 2015 Redistributable Update 3&lt;/strong&gt; – This may give you an error saying the redistributable has already been installed. If so, that’s fine.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Restart your PC after installation has finished.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2c-update-anaconda-and-create-tensorflow-build-environment" class="anchor" aria-hidden="true" href="#step-2c-update-anaconda-and-create-tensorflow-build-environment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2c. Update Anaconda and create tensorflow-build environment&lt;/h4&gt;
&lt;p&gt;Now that the Visual Studio tools are installed and your PC is freshly restarted, open a new Anaconda Prompt window. First, update Anaconda to make sure its package list is up to date. In the Anaconda Prompt window, issue these two commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda update -n base -c defaults conda
conda update --all
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The update process may take up to an hour, depending on how it's been since you installed or updated Anaconda. Next, create a new Anaconda virtual environment called “tensorflow-build”. We’ll work in this environment for the rest of the build process. Create and activate the environment by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda create -n tensorflow-build pip python=3.6
conda activate tensorflow-build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the environment is activated, you should see (tensorflow-build) before the active path in the command window.&lt;/p&gt;
&lt;p&gt;&amp;lt;Maybe I should add a picture of the Anaconda window here?&amp;gt;&lt;/p&gt;
&lt;p&gt;Update pip by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m pip install --upgrade pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We'll use Anaconda's git package to download the TensorFlow repository, so install git using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c anaconda git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, add the MSYS2 binaries to this environment's PATH variable by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set PATH=%PATH%;C:\msys64\usr\bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(If MSYS2 is installed in a different location than C:\msys64, use that location instead.) You’ll have to re-issue this PATH command if you ever close and re-open the Anaconda Prompt window.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2d-download-bazel-and-python-package-dependencies" class="anchor" aria-hidden="true" href="#step-2d-download-bazel-and-python-package-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2d. Download Bazel and Python package dependencies&lt;/h4&gt;
&lt;p&gt;Next, we’ll install Bazel and some other Python packages that are used for building TensorFlow. Install the necessary Python packages by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install six numpy wheel
pip install keras_applications==1.0.6 --no-deps
pip install keras_preprocessing==1.0.5 --no-deps
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then install Bazel v0.21.0 by issuing the following command. (If you are building a version of TensorFlow other than v1.13, you may need to use a different version of Bazel.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge bazel=0.21.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-step-2d-download-tensorflow-source-and-configure-build" class="anchor" aria-hidden="true" href="#step-2d-download-tensorflow-source-and-configure-build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2d. Download TensorFlow source and configure build&lt;/h4&gt;
&lt;p&gt;Time to download TensorFlow’s source code from GitHub! Issue the following commands to create a new folder directly in C:\ called “tensorflow-build” and cd into it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir C:\tensorflow-build
cd C:\tensorflow-build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, clone the TensorFlow repository and cd into it by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/tensorflow/tensorflow.git 
cd tensorflow 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, check out the branch for TensorFlow v1.13:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout r1.13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The version you check out should match the TensorFlow version you used to train your model in &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#step-1-train-quantized-ssd-mobilenet-model-and-export-frozen-tensorflow-lite-graph"&gt;Step 1&lt;/a&gt;. If you used a different version than TF v1.13, then replace "1.13" with the version you used. See the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#how-do-i-check-which-tensorflow-version-i-used-to-train-my-detection-model"&gt;FAQs section&lt;/a&gt; for instructions on how to check the TensorFlow version you used for training.&lt;/p&gt;
&lt;p&gt;Next, we’ll configure the TensorFlow build using the configure.py script. From the C:\tensorflow-build\tensorflow directory, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python ./configure.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will initiate a Bazel session. As I mentioned before, you can build either the CPU-only version of TensorFlow or the GPU-enabled version of TensorFlow. If you're only using this TensorFlow build to convert your TensorFlow Lite model, &lt;strong&gt;I recommend building the CPU-only version&lt;/strong&gt;. If you’d still like to build the GPU-enabled version for some other reason, then you need to have the appropriate version of CUDA and cuDNN installed.&lt;/p&gt;
&lt;p&gt;Here’s what the configuration session will look like if you are building for CPU only. Basically, press Enter to select the default option for each question. You can see the configuration session for building the GPU-enabled version in the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#bazel-configuration-session-for-building-gpu-enabled-tensorflow"&gt;FAQ section&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;You have bazel 0.21.0- (@non-git) installed. 

Please specify the location of python. [Default is C:\ProgramData\Anaconda3\envs\tensorflow-build\python.exe]: 
  
Found possible Python library paths: 

  C:\ProgramData\Anaconda3\envs\tensorflow-build\lib\site-packages 

Please input the desired Python library path to use.  Default is [C:\ProgramData\Anaconda3\envs\tensorflow-build\lib\site-packages] 

Do you wish to build TensorFlow with XLA JIT support? [y/N]: N 
No XLA JIT support will be enabled for TensorFlow. 

Do you wish to build TensorFlow with ROCm support? [y/N]: N 
No ROCm support will be enabled for TensorFlow. 
  
Do you wish to build TensorFlow with CUDA support? [y/N]: N 
No CUDA support will be enabled for TensorFlow. 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the configuration is finished, TensorFlow is ready to be bulit!&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2e-build-tensorflow-package" class="anchor" aria-hidden="true" href="#step-2e-build-tensorflow-package"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2e. Build TensorFlow package&lt;/h4&gt;
&lt;p&gt;Next, use Bazel to create the package builder for TensorFlow. To create the CPU-only version, issue the following command. The build process took about 70 minutes on my computer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re building the GPU-enabled version of TensorFlow, issue the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that the package builder has been created, let’s use it to build the actual TensorFlow wheel file. Issue the following command (it took about 5 minutes to complete on my computer):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel-bin\tensorflow\tools\pip_package\build_pip_package C:/tmp/tensorflow_pkg 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates the wheel file and places it in C:\tmp\tensorflow_pkg.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-2f-install-tensorflow-and-test-it-out" class="anchor" aria-hidden="true" href="#step-2f-install-tensorflow-and-test-it-out"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2f. Install TensorFlow and test it out!&lt;/h4&gt;
&lt;p&gt;TensorFlow is finally ready to be installed! Open File Explorer and browse to the C:\tmp\tensorflow_pkg folder. Copy the full filename of the .whl file, and paste it in the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip3 install C:/tmp/tensorflow_pkg/&amp;lt;Paste full .whl filename here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That's it! TensorFlow is installed! Let's make sure it installed correctly by opening a Python shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the shell is opened, issue these commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import tensorflow as tf
&amp;gt;&amp;gt;&amp;gt; tf.__version__
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If everything was installed properly, it will respond with the installed version of TensorFlow. Note: You may get some deprecation warnings after the "import tensorflow as tf" command. As long as they are warnings and not actual errors, you can ignore them! Exit the shell by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;exit()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With TensorFlow installed, we can finally convert our trained model into a TensorFlow Lite model. On to the last step: Step 3!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-3-use-toco-to-create-optimzed-tensorflow-lite-model-create-label-map-run-model" class="anchor" aria-hidden="true" href="#step-3-use-toco-to-create-optimzed-tensorflow-lite-model-create-label-map-run-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3. Use TOCO to Create Optimzed TensorFlow Lite Model, Create Label Map, Run Model&lt;/h3&gt;
&lt;p&gt;Although we've already exported a frozen graph of our detection model for TensorFlow Lite, we still need run it through the TensorFlow Lite Optimizing Converter (TOCO) before it will work with the TensorFlow Lite interpreter. TOCO converts models into an optimized FlatBuffer format that allows them to run efficiently on TensorFlow Lite. We also need to create a new label map before running the model.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-3a-create-optimized-tensorflow-lite-model" class="anchor" aria-hidden="true" href="#step-3a-create-optimized-tensorflow-lite-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3a. Create optimized TensorFlow Lite model&lt;/h4&gt;
&lt;p&gt;First, we’ll run the model through TOCO to create an optimzed TensorFLow Lite model. The TOCO tool lives deep in the C:\tensorflow-build directory, and it will be run from the “tensorflow-build” Anaconda virtual environment that we created and used during Step 2. Meanwhile, the model we trained in Step 1 lives inside the C:\tensorflow1\models\research\object_detection\TFLite_model directory. We’ll create an environment variable called OUTPUT_DIR that points at the correct model directory to make it easier to enter the TOCO command.&lt;/p&gt;
&lt;p&gt;If you don't already have an Anaconda Prompt window open with the "tensorflow-build" environment active and working in C:\tensorflow-build, open a new Anaconda Prompt window and issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;activate tensorflow-build
cd C:\tensorflow-build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create the OUTPUT_DIR environment variable by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set OUTPUT_DIR=C:\\tensorflow1\models\research\object_detection\TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, use Bazel to run the model through the TOCO tool by issuing this command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel run --config=opt tensorflow/lite/toco:toco -- --input_file=%OUTPUT_DIR%/tflite_graph.pb --output_file=%OUTPUT_DIR%/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: If you are using a floating, non-quantized SSD model (e.g. the ssdlite_mobilenet_v2_coco model rather than the ssd_mobilenet_v2_quantized_coco model), the Bazel TOCO command must be modified slightly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bazel run --config=opt tensorflow/lite/toco:toco -- --input_file=$OUTPUT_DIR/tflite_graph.pb --output_file=$OUTPUT_DIR/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=FLOAT --allow_custom_ops 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you are using Linux, make sure to use the commands given in the &lt;a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md"&gt;official TensorFlow instructions here&lt;/a&gt;. I removed the ' characters from the command, because for some reason they cause errors on Windows!&lt;/p&gt;
&lt;p&gt;After the command finishes running, you should see a file called detect.tflite in the \object_detection\TFLite_model directory. This is the model that can be used with TensorFlow Lite!&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-3b-create-new-label-map" class="anchor" aria-hidden="true" href="#step-3b-create-new-label-map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3b. Create new label map&lt;/h4&gt;
&lt;p&gt;For some reason, TensorFlow Lite uses a different label map format than classic TensorFlow. The classic TensorFlow label map format looks like this (you can see an example in the \object_detection\data\mscoco_label_map.pbtxt file):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;item { 
  name: "/m/01g317" 
  id: 1 
  display_name: "person" 
} 
item { 
  name: "/m/0199g" 
  id: 2 
  display_name: "bicycle" 
} 
item { 
  name: "/m/0k4j" 
  id: 3 
  display_name: "car" 
} 
item { 
  name: "/m/04_sv" 
  id: 4 
  display_name: "motorcycle" 
} 
And so on...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the label map provided with the &lt;a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip" rel="nofollow"&gt;example TensorFlow Lite object detection model&lt;/a&gt; looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;person 
bicycle 
car 
motorcycle 
And so on...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Basically, rather than explicitly stating the name and ID number for each class like the classic TensorFlow label map format does, the TensorFlow Lite format just lists each class. To stay consistent with the example provided by Google, I’m going to stick with the TensorFlow Lite label map format for this guide.&lt;/p&gt;
&lt;p&gt;Thus, we need to create a new label map that matches the TensorFlow Lite style. Open a text editor and list each class in order of their class number. Then, save the file as “labelmap.txt” in the TFLite_model folder. As an example, here's what the labelmap.txt file for my bird/squirrel/raccoon detector looks like:&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/labelmap_example.png"&gt;&lt;img src="doc/labelmap_example.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Now we’re ready to run the model!&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-step-3c-run-the-tensorflow-lite-model" class="anchor" aria-hidden="true" href="#step-3c-run-the-tensorflow-lite-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3c. Run the TensorFlow Lite model!&lt;/h4&gt;
&lt;p&gt;I wrote three Python scripts to run the TensorFlow Lite object detection model on an image, video, or webcam feed: TFLite_detection_image.py, TFLite_detection_video.py, and &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_webcam.py"&gt;TFLite_detection_wecam.py&lt;/a&gt;. The scripts are based off the label_image.py example given in the &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py"&gt;TensorFlow Lite examples GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We’ll download the Python scripts directly from this repository. First, install wget for Anaconda by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c menpo wget
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once it's installed, download the scripts by issuing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_image.py --no-check-certificate
wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_video.py --no-check-certificate
wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/TFLite_detection_webcam.py --no-check-certificate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following instructions show how to run the webcam, video, and image scripts. These instructions assume your .tflite model file and labelmap.txt file are in the “TFLite_model” folder in your \object_detection directory as per the instructions given in this guide.&lt;/p&gt;
&lt;p&gt;If you’d like try using the sample TFLite object detection model provided by Google, simply download it &lt;a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip" rel="nofollow"&gt;here&lt;/a&gt; and unzip it into the \object_detection folder. Then, use &lt;code&gt;--modeldir=coco_ssd_mobilenet_v1_1.0_quant_2018_06_29&lt;/code&gt; rather than &lt;code&gt;--modeldir=TFLite_model&lt;/code&gt; when running the script.&lt;/p&gt;
&lt;p&gt;For more information on options that can be used while running the scripts, use the &lt;code&gt;-h&lt;/code&gt; option when calling the script. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py -h
&lt;/code&gt;&lt;/pre&gt;
&lt;h5&gt;&lt;a id="user-content-webcam" class="anchor" aria-hidden="true" href="#webcam"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Webcam&lt;/h5&gt;
&lt;p&gt;Make sure you have a USB webcam plugged into your computer. If you’re on a laptop with a built-in camera, you don’t need to plug in a USB webcam.&lt;/p&gt;
&lt;p&gt;From the \object_detection directory, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_webcam.py --modeldir=TFLite_model 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a few moments of initializing, a window will appear showing the webcam feed. Detected objects will have bounding boxes and labels displayed on them in real time.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-video" class="anchor" aria-hidden="true" href="#video"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Video&lt;/h5&gt;
&lt;p&gt;To run the video detection script, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A window will appear showing consecutive frames from the video, with each object in the frame labeled. Press 'q' to close the window and end the script. By default, the video detection script will open a video named 'test.mp4'. To open a specific video file, use the &lt;code&gt;--video&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model --video='birdy.mp4'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: Video detection will run at a slower FPS than realtime webcam detection. This is mainly because loading a frame from a video file requires more processor I/O than receiving a frame from a webcam.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-image" class="anchor" aria-hidden="true" href="#image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image&lt;/h5&gt;
&lt;p&gt;To run the image detection script, issue:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The image will appear with all objects labeled. Press 'q' to close the image and end the script. By default, the image detection script will open an image named 'test1.jpg'. To open a specific image file, use the &lt;code&gt;--image&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model --image=squirrel.jpg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can also open an entire folder full of images and perform detection on each image. There can only be images files in the folder, or errors will occur. To specify which folder has images to perform detection on, use the &lt;code&gt;--imagedir&lt;/code&gt; option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python TFLite_detection_image.py --modeldir=TFLite_model --imagedir=squirrels
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press any key (other than 'q') to advance to the next image. Do not use both the --image option and the --imagedir option when running the script, or it will throw an error.&lt;/p&gt;
&lt;p align="center"&gt;
   &lt;a target="_blank" rel="noopener noreferrer" href="doc/squirrels!!.png"&gt;&lt;img src="doc/squirrels!!.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;If you encounter errors while running these scripts, please check the &lt;a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi#frequently-asked-questions-and-common-errors"&gt;FAQ section&lt;/a&gt; of this guide. It has a list of common errors and their solutions. If you can successfully run the script, but your object isn’t detected, it is most likely because your model isn’t accurate enough. The FAQ has further discussion on how to resolve this.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-next-steps" class="anchor" aria-hidden="true" href="#next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next Steps&lt;/h3&gt;
&lt;p&gt;This concludes Part 1 of my TensorFlow Lite guide! You now have a trained TensorFlow Lite model and the scripts needed to run it on a PC.&lt;/p&gt;
&lt;p&gt;But who cares about running it on a PC? The whole reason we’re using TensorFlow Lite is so we can run our models on lightweight devices that are more portable and less power-hungry than a PC!  The next two parts of my guide show how to run this TFLite model on a Raspberry Pi or an Android Device.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Links to be added when these are completed!&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Part 2. How to Run TensorFlow Lite Object Detection Models on the Raspberry Pi (with optional Coral USB Accelerator)&lt;/li&gt;
&lt;li&gt;Part 3. How to Run TensorFlow Lite Object Detection Models on Android Devices&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-frequently-asked-questions-and-common-errors" class="anchor" aria-hidden="true" href="#frequently-asked-questions-and-common-errors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Frequently Asked Questions and Common Errors&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-why-does-this-guide-use-trainpy-rather-than-model_mainpy-for-training" class="anchor" aria-hidden="true" href="#why-does-this-guide-use-trainpy-rather-than-model_mainpy-for-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why does this guide use train.py rather than model_main.py for training?&lt;/h4&gt;
&lt;p&gt;This guide uses "train.py" to run training on the TFLite detection model. The train.py script is deprecated, but the model_main.py script that replaced it doesn't log training progress by default, and it requires pycocotools to be installed. Using model_main.py requires a few extra setup steps, and I want to keep this guide as simple as possible. Since there are no major differences between train.py and model_main.py that will affect training (&lt;a href="https://github.com/tensorflow/models/issues/6100"&gt;see TensorFlow Issue #6100&lt;/a&gt;), I use train.py for this guide.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-how-do-i-check-which-tensorflow-version-i-used-to-train-my-detection-model" class="anchor" aria-hidden="true" href="#how-do-i-check-which-tensorflow-version-i-used-to-train-my-detection-model"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How do I check which TensorFlow version I used to train my detection model?&lt;/h4&gt;
&lt;p&gt;Here’s how you can check the version of TensorFlow you used for training.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open a new Anaconda Prompt window and issue &lt;code&gt;activate tensorflow1&lt;/code&gt; (or whichever environment name you used)&lt;/li&gt;
&lt;li&gt;Open a python shell by issuing &lt;code&gt;python&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Within the Python shell, import TensorFlow by issuing &lt;code&gt;import tensorflow as tf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Check the TensorFlow version by issuing &lt;code&gt;tf.__version__&lt;/code&gt; . It will respond with the version of TensorFlow. This is the version that you used for training.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-bazel-configuration-session-for-building-gpu-enabled-tensorflow" class="anchor" aria-hidden="true" href="#bazel-configuration-session-for-building-gpu-enabled-tensorflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bazel configuration session for building GPU-enabled TensorFlow&lt;/h4&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>EdjeElectronics</author><guid isPermaLink="false">https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi</guid><pubDate>Wed, 20 Nov 2019 00:22:00 GMT</pubDate></item><item><title>ddbourgin/numpy-ml #23 in Python, Today</title><link>https://github.com/ddbourgin/numpy-ml</link><description>&lt;p&gt;&lt;i&gt;Machine learning, in numpy&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-numpy-ml" class="anchor" aria-hidden="true" href="#numpy-ml"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;numpy-ml&lt;/h1&gt;
&lt;p&gt;Ever wish you had an inefficient but somewhat legible collection of machine
learning algorithms implemented exclusively in numpy? No?&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;To see all of the available models, take a look at the &lt;a href="https://numpy-ml.readthedocs.io/" rel="nofollow"&gt;project documentation&lt;/a&gt; or see &lt;a href="https://github.com/ddbourgin/numpy-ml/blob/master/numpy_ml/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Am I missing your favorite model? Is there something that could be cleaner /
less confusing? Did I mess something up? Submit a PR! The only requirement is
that your models are written with just the &lt;a href="https://docs.python.org/3/library/" rel="nofollow"&gt;Python standard
library&lt;/a&gt; and &lt;a href="https://www.numpy.org/" rel="nofollow"&gt;NumPy&lt;/a&gt;. The
&lt;a href="https://scipy.github.io/devdocs/" rel="nofollow"&gt;SciPy library&lt;/a&gt; is also permitted under special
circumstances ;)&lt;/p&gt;
&lt;p&gt;See full contributing guidelines &lt;a href="./CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ddbourgin</author><guid isPermaLink="false">https://github.com/ddbourgin/numpy-ml</guid><pubDate>Wed, 20 Nov 2019 00:23:00 GMT</pubDate></item><item><title>NVlabs/stylegan #24 in Python, Today</title><link>https://github.com/NVlabs/stylegan</link><description>&lt;p&gt;&lt;i&gt;StyleGAN - Official TensorFlow Implementation&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-stylegan--official-tensorflow-implementation" class="anchor" aria-hidden="true" href="#stylegan--official-tensorflow-implementation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;StyleGAN — Official TensorFlow Implementation&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/d4c11ac2b538cba463dfd1e43d05fe4f30f2d33d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d677265656e2e7376673f7374796c653d706c6173746963" alt="Python 3.6" data-canonical-src="https://img.shields.io/badge/python-3.6-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/11658cad8470d233bb733d0b72dc9f85738b0c60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f74656e736f72666c6f772d312e31302d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/11658cad8470d233bb733d0b72dc9f85738b0c60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f74656e736f72666c6f772d312e31302d677265656e2e7376673f7374796c653d706c6173746963" alt="TensorFlow 1.10" data-canonical-src="https://img.shields.io/badge/tensorflow-1.10-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a5dab5f383e89d8397bd6a26b35ecafbca94277c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6375646e6e2d372e332e312d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/a5dab5f383e89d8397bd6a26b35ecafbca94277c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6375646e6e2d372e332e312d677265656e2e7376673f7374796c653d706c6173746963" alt="cuDNN 7.3.1" data-canonical-src="https://img.shields.io/badge/cudnn-7.3.1-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a94f8355ec38c4cee39dec1e250552a499c37ac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43435f42592d2d4e432d677265656e2e7376673f7374796c653d706c6173746963"&gt;&lt;img src="https://camo.githubusercontent.com/1a94f8355ec38c4cee39dec1e250552a499c37ac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d43435f42592d2d4e432d677265656e2e7376673f7374796c653d706c6173746963" alt="License CC BY-NC" data-canonical-src="https://img.shields.io/badge/license-CC_BY--NC-green.svg?style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./stylegan-teaser.png"&gt;&lt;img src="./stylegan-teaser.png" alt="Teaser image" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;strong&gt;Picture:&lt;/strong&gt; &lt;em&gt;These people are not real – they were produced by our generator that allows control over different aspects of the image.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the official TensorFlow implementation of the following paper:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A Style-Based Generator Architecture for Generative Adversarial Networks&lt;/strong&gt;&lt;br&gt;
Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)&lt;br&gt;
&lt;a href="http://stylegan.xyz/paper" rel="nofollow"&gt;http://stylegan.xyz/paper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;em&gt;We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For business inquiries, please contact &lt;a href="mailto:researchinquiries@nvidia.com"&gt;researchinquiries@nvidia.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For press and other inquiries, please contact Hector Marinez at &lt;a href="mailto:hmarinez@nvidia.com"&gt;hmarinez@nvidia.com&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h2&gt;
&lt;p&gt;All material related to our paper is available via the following links:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Link&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/paper" rel="nofollow"&gt;http://stylegan.xyz/paper&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Paper PDF.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/video" rel="nofollow"&gt;http://stylegan.xyz/video&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Result video.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/code" rel="nofollow"&gt;http://stylegan.xyz/code&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Source code.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;http://stylegan.xyz/ffhq&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Flickr-Faces-HQ dataset.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/drive" rel="nofollow"&gt;http://stylegan.xyz/drive&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Google Drive folder.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Additional material can be found in Google Drive folder:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Path&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="http://stylegan.xyz/drive" rel="nofollow"&gt;StyleGAN&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Main folder.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1v-HkF3Ehrpon7wVIx4r5DLcko_U_V6Lt" rel="nofollow"&gt;stylegan-paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality version of the paper PDF.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1uzwkZHQX_9pYg1i0d1Nbe3D9xPO8-qBf" rel="nofollow"&gt;stylegan-video.mp4&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality version of the result video.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1-l46akONUWF6LCpDoeq63H53rD7MeiTd" rel="nofollow"&gt;images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Example images produced using our generator.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│  ├  &lt;a href="https://drive.google.com/open?id=1ToY5P4Vvf5_c3TyUizQ8fckFFoFtBvD8" rel="nofollow"&gt;representative-images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;High-quality images to be used in articles, blog posts, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│  └  &lt;a href="https://drive.google.com/open?id=100DJ0QXyG89HZzB4w2Cbyf4xjNK54cQ1" rel="nofollow"&gt;100k-generated-images&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;100,000 generated images for different amounts of truncation.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     ├  &lt;a href="https://drive.google.com/open?id=14lm8VRN1pr4g_KVe6_LvyDX1PObst6d4" rel="nofollow"&gt;ffhq-1024x1024&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using Flickr-Faces-HQ dataset at 1024×1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     ├  &lt;a href="https://drive.google.com/open?id=1Vxz9fksw4kgjiHrvHkX4Hze4dyThFW6t" rel="nofollow"&gt;bedrooms-256x256&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Bedroom dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     ├  &lt;a href="https://drive.google.com/open?id=1MFCvOMdLE2_mpeLPTiDw5dxc2CRuKkzS" rel="nofollow"&gt;cars-512x384&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Car dataset at 512×384.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│     └  &lt;a href="https://drive.google.com/open?id=1gq-Gj3GRFiyghTPKhp8uDMA9HV_0ZFWQ" rel="nofollow"&gt;cats-256x256&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Generated using LSUN Cat dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1N8pOd_Bf8v89NGUaROdbD8-ayLPgyRRo" rel="nofollow"&gt;videos&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Example videos produced using our generator.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;│  └  &lt;a href="https://drive.google.com/open?id=1NFO7_vH0t98J13ckJYFd7kuaTkyeRJ86" rel="nofollow"&gt;high-quality-video-clips&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Individual segments of the result video as high-quality MP4.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;├  &lt;a href="https://drive.google.com/open?id=1u2xu7bSrWxrbUxk-dT-UvEJq8IjdmNTP" rel="nofollow"&gt;ffhq-dataset&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Raw data for the &lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;Flickr-Faces-HQ dataset&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;└  &lt;a href="https://drive.google.com/open?id=1MASQyN5m0voPcx7-9K0r5gObhvvPups7" rel="nofollow"&gt;networks&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Pre-trained networks as pickled instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ" rel="nofollow"&gt;stylegan-ffhq-1024x1024.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with Flickr-Faces-HQ dataset at 1024×1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MGqJl28pN4t7SAtSrPdSRJSQJqahkzUf" rel="nofollow"&gt;stylegan-celebahq-1024x1024.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with CelebA-HQ dataset at 1024×1024.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MOSKeGF0FJcivpBI7s63V9YHloUTORiF" rel="nofollow"&gt;stylegan-bedrooms-256x256.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Bedroom dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MJ6iCfNtMIRicihwRorsM3b7mmtmK9c3" rel="nofollow"&gt;stylegan-cars-512x384.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Car dataset at 512×384.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   ├  &lt;a href="https://drive.google.com/uc?id=1MQywl0FNt6lHu8E_EUqnRbviagS7fbiJ" rel="nofollow"&gt;stylegan-cats-256x256.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;StyleGAN trained with LSUN Cat dataset at 256×256.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;   └  &lt;a href="https://drive.google.com/open?id=1MvYdWCBuMfnoYGptRH-AgKLbPTsIQLhl" rel="nofollow"&gt;metrics&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Auxiliary networks for the quality and disentanglement metrics.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      ├  &lt;a href="https://drive.google.com/uc?id=1MzTY44rLToO5APn8TZmfR7_ENSe5aZUn" rel="nofollow"&gt;inception_v3_features.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Standard &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; classifier that outputs a raw feature vector.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      ├  &lt;a href="https://drive.google.com/uc?id=1N2-m9qszOeVC9Tq77WxsLnuWwOedQiD2" rel="nofollow"&gt;vgg16_zhang_perceptual.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Standard &lt;a href="https://arxiv.org/abs/1801.03924" rel="nofollow"&gt;LPIPS&lt;/a&gt; metric to estimate perceptual similarity.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      ├  &lt;a href="https://drive.google.com/uc?id=1Q5-AI6TwWhCVM7Muu4tBM7rp5nG_gmCX" rel="nofollow"&gt;celebahq-classifier-00-male.pkl&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Binary classifier trained to detect a single attribute of CelebA-HQ.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;      └ ⋯&lt;/td&gt;
&lt;td align="left"&gt;Please see the file listing for remaining networks.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-licenses" class="anchor" aria-hidden="true" href="#licenses"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Licenses&lt;/h2&gt;
&lt;p&gt;All material, excluding the Flickr-Faces-HQ dataset, is made available under &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" rel="nofollow"&gt;Creative Commons BY-NC 4.0&lt;/a&gt; license by NVIDIA Corporation. You can &lt;strong&gt;use, redistribute, and adapt&lt;/strong&gt; the material for &lt;strong&gt;non-commercial purposes&lt;/strong&gt;, as long as you give appropriate credit by &lt;strong&gt;citing our paper&lt;/strong&gt; and &lt;strong&gt;indicating any changes&lt;/strong&gt; that you've made.&lt;/p&gt;
&lt;p&gt;For license information regarding the FFHQ dataset, please refer to the &lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;Flickr-Faces-HQ repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;inception_v3_features.pkl&lt;/code&gt; and &lt;code&gt;inception_v3_softmax.pkl&lt;/code&gt; are derived from the pre-trained &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; network by Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. The network was originally shared under &lt;a href="https://github.com/tensorflow/models/blob/master/LICENSE"&gt;Apache 2.0&lt;/a&gt; license on the &lt;a href="https://github.com/tensorflow/models"&gt;TensorFlow Models&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vgg16.pkl&lt;/code&gt; and &lt;code&gt;vgg16_zhang_perceptual.pkl&lt;/code&gt; are derived from the pre-trained &lt;a href="https://arxiv.org/abs/1409.1556" rel="nofollow"&gt;VGG-16&lt;/a&gt; network by Karen Simonyan and Andrew Zisserman. The network was originally shared under &lt;a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow"&gt;Creative Commons BY 4.0&lt;/a&gt; license on the &lt;a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" rel="nofollow"&gt;Very Deep Convolutional Networks for Large-Scale Visual Recognition&lt;/a&gt; project page.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vgg16_zhang_perceptual.pkl&lt;/code&gt; is further derived from the pre-trained &lt;a href="https://arxiv.org/abs/1801.03924" rel="nofollow"&gt;LPIPS&lt;/a&gt; weights by Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, and Oliver Wang. The weights were originally shared under &lt;a href="https://github.com/richzhang/PerceptualSimilarity/blob/master/LICENSE"&gt;BSD 2-Clause "Simplified" License&lt;/a&gt; on the &lt;a href="https://github.com/richzhang/PerceptualSimilarity"&gt;PerceptualSimilarity&lt;/a&gt; repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-system-requirements" class="anchor" aria-hidden="true" href="#system-requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Both Linux and Windows are supported, but we strongly recommend Linux for performance and compatibility reasons.&lt;/li&gt;
&lt;li&gt;64-bit Python 3.6 installation. We recommend Anaconda3 with numpy 1.14.3 or newer.&lt;/li&gt;
&lt;li&gt;TensorFlow 1.10.0 or newer with GPU support.&lt;/li&gt;
&lt;li&gt;One or more high-end NVIDIA GPUs with at least 11GB of DRAM. We recommend NVIDIA DGX-1 with 8 Tesla V100 GPUs.&lt;/li&gt;
&lt;li&gt;NVIDIA driver 391.35 or newer, CUDA toolkit 9.0 or newer, cuDNN 7.3.1 or newer.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-using-pre-trained-networks" class="anchor" aria-hidden="true" href="#using-pre-trained-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using pre-trained networks&lt;/h2&gt;
&lt;p&gt;A minimal example of using a pre-trained StyleGAN generator is given in &lt;a href="./pretrained_example.py"&gt;pretrained_example.py&lt;/a&gt;. When executed, the script downloads a pre-trained StyleGAN generator from Google Drive and uses it to generate an image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python pretrained_example.py
Downloading https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ .... done

Gs                              Params    OutputShape          WeightShape
---                             ---       ---                  ---
latents_in                      -         (?, 512)             -
...
images_out                      -         (?, 3, 1024, 1024)   -
---                             ---       ---                  ---
Total                           26219627

&amp;gt; ls results
example.png # https://drive.google.com/uc?id=1UDLT_zb-rof9kKH0GwiJW_bS9MoZi8oP
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A more advanced example is given in &lt;a href="./generate_figures.py"&gt;generate_figures.py&lt;/a&gt;. The script reproduces the figures from our paper in order to illustrate style mixing, noise inputs, and truncation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python generate_figures.py
results/figure02-uncurated-ffhq.png     # https://drive.google.com/uc?id=1U3r1xgcD7o-Fd0SBRpq8PXYajm7_30cu
results/figure03-style-mixing.png       # https://drive.google.com/uc?id=1U-nlMDtpnf1RcYkaFQtbh5oxnhA97hy6
results/figure04-noise-detail.png       # https://drive.google.com/uc?id=1UX3m39u_DTU6eLnEW6MqGzbwPFt2R9cG
results/figure05-noise-components.png   # https://drive.google.com/uc?id=1UQKPcvYVeWMRccGMbs2pPD9PVv1QDyp_
results/figure08-truncation-trick.png   # https://drive.google.com/uc?id=1ULea0C12zGlxdDQFNLXOWZCHi3QNfk_v
results/figure10-uncurated-bedrooms.png # https://drive.google.com/uc?id=1UEBnms1XMfj78OHj3_cx80mUf_m9DUJr
results/figure11-uncurated-cars.png     # https://drive.google.com/uc?id=1UO-4JtAs64Kun5vIj10UXqAJ1d5Ir1Ke
results/figure12-uncurated-cats.png     # https://drive.google.com/uc?id=1USnJc14prlu3QAYxstrtlfXC9sDWPA-W
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pre-trained networks are stored as standard pickle files on Google Drive:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Load pre-trained network.
url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl
with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:
    _G, _D, Gs = pickle.load(f)
    # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.
    # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.
    # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code downloads the file and unpickles it to yield 3 instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;. To generate images, you will typically want to use &lt;code&gt;Gs&lt;/code&gt; – the other two networks are provided for completeness. In order for &lt;code&gt;pickle.load()&lt;/code&gt; to work, you will need to have the &lt;code&gt;dnnlib&lt;/code&gt; source directory in your PYTHONPATH and a &lt;code&gt;tf.Session&lt;/code&gt; set as default. The session can initialized by calling &lt;code&gt;dnnlib.tflib.init_tf()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There are three ways to use the pre-trained generator:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;Gs.run()&lt;/code&gt; for immediate-mode operation where the inputs and outputs are numpy arrays:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Pick latent vector.
rnd = np.random.RandomState(5)
latents = rnd.randn(1, Gs.input_shape[1])

# Generate image.
fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)
images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first argument is a batch of latent vectors of shape &lt;code&gt;[num, 512]&lt;/code&gt;. The second argument is reserved for class labels (not used by StyleGAN). The remaining keyword arguments are optional and can be used to further modify the operation (see below). The output is a batch of images, whose format is dictated by the &lt;code&gt;output_transform&lt;/code&gt; argument.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;Gs.get_output_for()&lt;/code&gt; to incorporate the generator as a part of a larger TensorFlow expression:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;latents = tf.random_normal([self.minibatch_per_gpu] + Gs_clone.input_shape[1:])
images = Gs_clone.get_output_for(latents, None, is_validation=True, randomize_noise=True)
images = tflib.convert_images_to_uint8(images)
result_expr.append(inception_clone.get_output_for(images))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code is from &lt;a href="./metrics/frechet_inception_distance.py"&gt;metrics/frechet_inception_distance.py&lt;/a&gt;. It generates a batch of random images and feeds them directly to the &lt;a href="https://arxiv.org/abs/1512.00567" rel="nofollow"&gt;Inception-v3&lt;/a&gt; network without having to convert the data to numpy arrays in between.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Look up &lt;code&gt;Gs.components.mapping&lt;/code&gt; and &lt;code&gt;Gs.components.synthesis&lt;/code&gt; to access individual sub-networks of the generator. Similar to &lt;code&gt;Gs&lt;/code&gt;, the sub-networks are represented as independent instances of &lt;a href="./dnnlib/tflib/network.py"&gt;dnnlib.tflib.Network&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)
src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]
src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code is from &lt;a href="./generate_figures.py"&gt;generate_figures.py&lt;/a&gt;. It first transforms a batch of latent vectors into the intermediate &lt;em&gt;W&lt;/em&gt; space using the mapping network and then turns these vectors into a batch of images using the synthesis network. The &lt;code&gt;dlatents&lt;/code&gt; array stores a separate copy of the same &lt;em&gt;w&lt;/em&gt; vector for each layer of the synthesis network to facilitate style mixing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The exact details of the generator are defined in &lt;a href="./training/networks_stylegan.py"&gt;training/networks_stylegan.py&lt;/a&gt; (see &lt;code&gt;G_style&lt;/code&gt;, &lt;code&gt;G_mapping&lt;/code&gt;, and &lt;code&gt;G_synthesis&lt;/code&gt;). The following keyword arguments can be specified to modify the behavior when calling &lt;code&gt;run()&lt;/code&gt; and &lt;code&gt;get_output_for()&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;truncation_psi&lt;/code&gt; and &lt;code&gt;truncation_cutoff&lt;/code&gt; control the truncation trick that that is performed by default when using &lt;code&gt;Gs&lt;/code&gt; (ψ=0.7, cutoff=8). It can be disabled by setting &lt;code&gt;truncation_psi=1&lt;/code&gt; or &lt;code&gt;is_validation=True&lt;/code&gt;, and the image quality can be further improved at the cost of variation by setting e.g. &lt;code&gt;truncation_psi=0.5&lt;/code&gt;. Note that truncation is always disabled when using the sub-networks directly. The average &lt;em&gt;w&lt;/em&gt; needed to manually perform the truncation trick can be looked up using &lt;code&gt;Gs.get_var('dlatent_avg')&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;randomize_noise&lt;/code&gt; determines whether to use re-randomize the noise inputs for each generated image (&lt;code&gt;True&lt;/code&gt;, default) or whether to use specific noise values for the entire minibatch (&lt;code&gt;False&lt;/code&gt;). The specific values can be accessed via the &lt;code&gt;tf.Variable&lt;/code&gt; instances that are found using &lt;code&gt;[var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When using the mapping network directly, you can specify &lt;code&gt;dlatent_broadcast=None&lt;/code&gt; to disable the automatic duplication of &lt;code&gt;dlatents&lt;/code&gt; over the layers of the synthesis network.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Runtime performance can be fine-tuned via &lt;code&gt;structure='fixed'&lt;/code&gt; and &lt;code&gt;dtype='float16'&lt;/code&gt;. The former disables support for progressive growing, which is not needed for a fully-trained generator, and the latter performs all computation using half-precision floating point arithmetic.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-preparing-datasets-for-training" class="anchor" aria-hidden="true" href="#preparing-datasets-for-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preparing datasets for training&lt;/h2&gt;
&lt;p&gt;The training and evaluation scripts operate on datasets stored as multi-resolution TFRecords. Each dataset is represented by a directory containing the same image data in several resolutions to enable efficient streaming. There is a separate *.tfrecords file for each resolution, and if the dataset contains labels, they are stored in a separate file as well. By default, the scripts expect to find the datasets at &lt;code&gt;datasets/&amp;lt;NAME&amp;gt;/&amp;lt;NAME&amp;gt;-&amp;lt;RESOLUTION&amp;gt;.tfrecords&lt;/code&gt;. The directory can be changed by editing &lt;a href="./config.py"&gt;config.py&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;result_dir = 'results'
data_dir = 'datasets'
cache_dir = 'cache'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To obtain the FFHQ dataset (&lt;code&gt;datasets/ffhq&lt;/code&gt;), please refer to the &lt;a href="http://stylegan.xyz/ffhq" rel="nofollow"&gt;Flickr-Faces-HQ repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To obtain the CelebA-HQ dataset (&lt;code&gt;datasets/celebahq&lt;/code&gt;), please refer to the &lt;a href="https://github.com/tkarras/progressive_growing_of_gans"&gt;Progressive GAN repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To obtain other datasets, including LSUN, please consult their corresponding project pages. The datasets can be converted to multi-resolution TFRecords using the provided &lt;a href="./dataset_tool.py"&gt;dataset_tool.py&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; python dataset_tool.py create_lsun datasets/lsun-bedroom-full ~/lsun/bedroom_lmdb --resolution 256
&amp;gt; python dataset_tool.py create_lsun_wide datasets/lsun-car-512x384 ~/lsun/car_lmdb --width 512 --height 384
&amp;gt; python dataset_tool.py create_lsun datasets/lsun-cat-full ~/lsun/cat_lmdb --resolution 256
&amp;gt; python dataset_tool.py create_cifar10 datasets/cifar10 ~/cifar10
&amp;gt; python dataset_tool.py create_from_images datasets/custom-dataset ~/custom-images
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-training-networks" class="anchor" aria-hidden="true" href="#training-networks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training networks&lt;/h2&gt;
&lt;p&gt;Once the datasets are set up, you can train your own StyleGAN networks as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Edit &lt;a href="./train.py"&gt;train.py&lt;/a&gt; to specify the dataset and training configuration by uncommenting or editing specific lines.&lt;/li&gt;
&lt;li&gt;Run the training script with &lt;code&gt;python train.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The results are written to a newly created directory &lt;code&gt;results/&amp;lt;ID&amp;gt;-&amp;lt;DESCRIPTION&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The training may take several days (or weeks) to complete, depending on the configuration.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By default, &lt;code&gt;train.py&lt;/code&gt; is configured to train the highest-quality StyleGAN (configuration F in Table 1) for the FFHQ dataset at 1024×1024 resolution using 8 GPUs. Please note that we have used 8 GPUs in all of our experiments. Training with fewer GPUs may not produce identical results – if you wish to compare against our technique, we strongly recommend using the same number of GPUs.&lt;/p&gt;
&lt;p&gt;Expected training times for the default configuration using Tesla V100 GPUs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;GPUs&lt;/th&gt;
&lt;th align="left"&gt;1024×1024&lt;/th&gt;
&lt;th align="left"&gt;512×512&lt;/th&gt;
&lt;th align="left"&gt;256×256&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;41 days 4 hours&lt;/td&gt;
&lt;td align="left"&gt;24 days 21 hours&lt;/td&gt;
&lt;td align="left"&gt;14 days 22 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;21 days 22 hours&lt;/td&gt;
&lt;td align="left"&gt;13 days 7 hours&lt;/td&gt;
&lt;td align="left"&gt;9 days 5 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;4&lt;/td&gt;
&lt;td align="left"&gt;11 days 8 hours&lt;/td&gt;
&lt;td align="left"&gt;7 days 0 hours&lt;/td&gt;
&lt;td align="left"&gt;4 days 21 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;8&lt;/td&gt;
&lt;td align="left"&gt;6 days 14 hours&lt;/td&gt;
&lt;td align="left"&gt;4 days 10 hours&lt;/td&gt;
&lt;td align="left"&gt;3 days 8 hours&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-evaluating-quality-and-disentanglement" class="anchor" aria-hidden="true" href="#evaluating-quality-and-disentanglement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Evaluating quality and disentanglement&lt;/h2&gt;
&lt;p&gt;The quality and disentanglement metrics used in our paper can be evaluated using &lt;a href="./run_metrics.py"&gt;run_metrics.py&lt;/a&gt;. By default, the script will evaluate the Fréchet Inception Distance (&lt;code&gt;fid50k&lt;/code&gt;) for the pre-trained FFHQ generator and write the results into a newly created directory under &lt;code&gt;results&lt;/code&gt;. The exact behavior can be changed by uncommenting or editing specific lines in &lt;a href="./run_metrics.py"&gt;run_metrics.py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Expected evaluation time and results for the pre-trained FFHQ generator using one Tesla V100 GPU:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Metric&lt;/th&gt;
&lt;th align="left"&gt;Time&lt;/th&gt;
&lt;th align="left"&gt;Result&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;fid50k&lt;/td&gt;
&lt;td align="left"&gt;16 min&lt;/td&gt;
&lt;td align="left"&gt;4.4159&lt;/td&gt;
&lt;td align="left"&gt;Fréchet Inception Distance using 50,000 images.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_zfull&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;664.8854&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for full paths in &lt;em&gt;Z&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_wfull&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;233.3059&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for full paths in &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_zend&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;666.1057&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for path endpoints in &lt;em&gt;Z&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ppl_wend&lt;/td&gt;
&lt;td align="left"&gt;55 min&lt;/td&gt;
&lt;td align="left"&gt;197.2266&lt;/td&gt;
&lt;td align="left"&gt;Perceptual Path Length for path endpoints in &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ls&lt;/td&gt;
&lt;td align="left"&gt;10 hours&lt;/td&gt;
&lt;td align="left"&gt;z: 165.0106&lt;br&gt;w: 3.7447&lt;/td&gt;
&lt;td align="left"&gt;Linear Separability in &lt;em&gt;Z&lt;/em&gt; and &lt;em&gt;W&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Please note that the exact results may vary from run to run due to the non-deterministic nature of TensorFlow.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;We thank Jaakko Lehtinen, David Luebke, and Tuomas Kynkäänniemi for in-depth discussions and helpful comments; Janne Hellsten, Tero Kuosmanen, and Pekka Jänis for compute infrastructure and help with the code release.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVlabs</author><guid isPermaLink="false">https://github.com/NVlabs/stylegan</guid><pubDate>Wed, 20 Nov 2019 00:24:00 GMT</pubDate></item><item><title>catalyst-team/catalyst #25 in Python, Today</title><link>https://github.com/catalyst-team/catalyst</link><description>&lt;p&gt;&lt;i&gt;Reproducible and fast DL &amp; RL&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
&lt;p&gt;&lt;a href="https://github.com/catalyst-team/catalyst"&gt;&lt;img src="https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/pics/catalyst_logo.png" alt="Catalyst logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reproducible and fast DL &amp;amp; RL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pypi.org/project/catalyst/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c4f41e1d6a05c335a76f37cc05b25f31217bc809/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f636174616c7973742e737667" alt="Pipi version" data-canonical-src="https://img.shields.io/pypi/v/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://catalyst-team.github.io/catalyst/index.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5a2afef7a5a4afd31a003c058e51451cd67a0007/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e2e7376673f6c6162656c3d646f63732675726c3d6874747073253341253246253246707970692e6f726725324670797069253246636174616c7973742532466a736f6e2671756572793d2532342e696e666f2e76657273696f6e26636f6c6f72423d627269676874677265656e267072656669783d76" alt="Docs" data-canonical-src="https://img.shields.io/badge/dynamic/json.svg?label=docs&amp;amp;url=https%3A%2F%2Fpypi.org%2Fpypi%2Fcatalyst%2Fjson&amp;amp;query=%24.info.version&amp;amp;colorB=brightgreen&amp;amp;prefix=v" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pepy.tech/project/catalyst" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/69489501d90b81553e734386061c46aebc849507/68747470733a2f2f706570792e746563682f62616467652f636174616c797374" alt="PyPI Status" data-canonical-src="https://pepy.tech/badge/catalyst" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/catalyst-team/catalyst/graphs/contributors"&gt;&lt;img src="https://camo.githubusercontent.com/f8425658eab8a24a0033afbad274cc4750edc61f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f636174616c7973742d7465616d2f636174616c7973742e7376673f6c6f676f3d676974687562266c6f676f436f6c6f723d7768697465" alt="Github contributors" data-canonical-src="https://img.shields.io/github/contributors/catalyst-team/catalyst.svg?logo=github&amp;amp;logoColor=white" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/4dd98dd86a5776f8d32031475d75fd9bca4ce5c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f636174616c7973742d7465616d2f636174616c7973742e737667" alt="License" data-canonical-src="https://img.shields.io/github/license/catalyst-team/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.com/catalyst-team/catalyst" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5235785ad73d976a0d7cc80c54a4c09b6b979aa7/68747470733a2f2f7472617669732d63692e636f6d2f636174616c7973742d7465616d2f636174616c7973742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/catalyst-team/catalyst.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://t.me/catalyst_team" rel="nofollow"&gt;&lt;img src="./pics/telegram.svg" alt="Telegram" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/catalyst-team/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1c7fa92782c1c4bbe3ddf337253b405382bc0cd3/68747470733a2f2f6261646765732e6769747465722e696d2f636174616c7973742d7465616d2f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/catalyst-team/community.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://opendatascience.slack.com/messages/CGK4KQBHD" rel="nofollow"&gt;&lt;img src="./pics/slack.svg" alt="Slack" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.patreon.com/catalyst_team" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/third_party_pics/patreon.png" alt="Donate" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;High-level utils for PyTorch DL &amp;amp; RL research.
It was developed with a focus on reproducibility,
fast experimentation and code/ideas reusing.
Being able to research/develop something new,
rather than write another regular train loop.&lt;/p&gt;
&lt;p&gt;Break the cycle - use the Catalyst!&lt;/p&gt;
&lt;hr&gt;
&lt;h4&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h4&gt;
&lt;p&gt;Common installation:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -U catalyst&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;More specific with additional requirements:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install catalyst[rl] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; installs DL+RL based catalyst&lt;/span&gt;
pip install catalyst[contrib] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; installs DL+contrib based catalyst&lt;/span&gt;
pip install catalyst[all] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; installs everything. Very convenient to deploy on a new server&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Catalyst is compatible with: Python 3.6+. PyTorch 1.0.0+.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-docs-and-examples" class="anchor" aria-hidden="true" href="#docs-and-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docs and examples&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Detailed &lt;a href="./examples/notebooks/classification-tutorial.ipynb"&gt;classification tutorial&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/catalyst-team/catalyst/blob/master/examples/notebooks/classification-tutorial.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Advanced &lt;a href="./examples/notebooks/segmentation-tutorial.ipynb"&gt;segmentation tutorial&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/catalyst-team/catalyst/blob/master/examples/notebooks/segmentation-tutorial.ipynb" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Comprehensive &lt;a href="https://github.com/catalyst-team/classification"&gt;classification pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Binary and semantic &lt;a href="https://github.com/catalyst-team/segmentation"&gt;segmentation pipeline&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API documentation and an overview of the library can be found here
&lt;a href="https://catalyst-team.github.io/catalyst/index.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5a2afef7a5a4afd31a003c058e51451cd67a0007/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e2e7376673f6c6162656c3d646f63732675726c3d6874747073253341253246253246707970692e6f726725324670797069253246636174616c7973742532466a736f6e2671756572793d2532342e696e666f2e76657273696f6e26636f6c6f72423d627269676874677265656e267072656669783d76" alt="Docs" data-canonical-src="https://img.shields.io/badge/dynamic/json.svg?label=docs&amp;amp;url=https%3A%2F%2Fpypi.org%2Fpypi%2Fcatalyst%2Fjson&amp;amp;query=%24.info.version&amp;amp;colorB=brightgreen&amp;amp;prefix=v" style="max-width:100%;"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;strong&gt;&lt;a href="examples"&gt;examples folder&lt;/a&gt;&lt;/strong&gt;
of the repository, you can find advanced tutorials and Catalyst best practices.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-blog" class="anchor" aria-hidden="true" href="#blog"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Blog&lt;/h5&gt;
&lt;p&gt;To learn more about Catalyst internals and to be aware of the most important features, you can read &lt;strong&gt;&lt;a href="https://github.com/catalyst-team/catalyst-info"&gt;Catalyst-info&lt;/a&gt;&lt;/strong&gt;, our blog where we regularly write facts about the framework.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-awesome-list-of-catalyst-powered-repositories" class="anchor" aria-hidden="true" href="#awesome-list-of-catalyst-powered-repositories"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Awesome list of Catalyst-powered repositories&lt;/h5&gt;
&lt;p&gt;We supervise the &lt;strong&gt;&lt;a href="https://github.com/catalyst-team/awesome-catalyst-list"&gt;Awesome Catalyst list&lt;/a&gt;&lt;/strong&gt;. You can make a PR with your project to the list.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-releases" class="anchor" aria-hidden="true" href="#releases"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Releases&lt;/h5&gt;
&lt;p&gt;We release a major release once a month with a name like &lt;code&gt;YY.MM&lt;/code&gt;.
And micro-releases with hotfixes and framework improvements in the format &lt;code&gt;YY.MM.#&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can view the changelog on the &lt;strong&gt;&lt;a href="https://github.com/catalyst-team/catalyst/releases"&gt;GitHub Releases&lt;/a&gt;&lt;/strong&gt; page.&lt;/p&gt;
&lt;p&gt;Current version: &lt;a href="https://pypi.org/project/catalyst/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c4f41e1d6a05c335a76f37cc05b25f31217bc809/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f636174616c7973742e737667" alt="Pipi version" data-canonical-src="https://img.shields.io/pypi/v/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h2&gt;
&lt;p&gt;Catalyst helps you write compact
but full-featured DL &amp;amp; RL pipelines in a few lines of code.
You get a training loop with metrics, early-stopping, model checkpointing
and other features without the boilerplate.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Universal train/inference loop.&lt;/li&gt;
&lt;li&gt;Configuration files for model/data hyperparameters.&lt;/li&gt;
&lt;li&gt;Reproducibility – all source code and environment variables will be saved.&lt;/li&gt;
&lt;li&gt;Callbacks – reusable train/inference pipeline parts.&lt;/li&gt;
&lt;li&gt;Training stages support.&lt;/li&gt;
&lt;li&gt;Easy customization.&lt;/li&gt;
&lt;li&gt;PyTorch best practices (SWA, AdamW, Ranger optimizer, OneCycleLRWithWarmup, FP16 and more).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-structure" class="anchor" aria-hidden="true" href="#structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structure&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DL&lt;/strong&gt; – runner for training and inference,
all of the classic machine learning and computer vision metrics
and a variety of callbacks for training, validation
and inference of neural networks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RL&lt;/strong&gt; – scalable Reinforcement Learning,
on-policy &amp;amp; off-policy algorithms and their improvements
with distributed training support.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;contrib&lt;/strong&gt; - additional modules contributed by Catalyst users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;data&lt;/strong&gt; - useful tools and scripts for data processing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-30-seconds-with-catalyst" class="anchor" aria-hidden="true" href="#getting-started-30-seconds-with-catalyst"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started: 30 seconds with Catalyst&lt;/h2&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; torch
&lt;span class="pl-k"&gt;from&lt;/span&gt; catalyst.dl &lt;span class="pl-k"&gt;import&lt;/span&gt; SupervisedRunner

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; experiment setup&lt;/span&gt;
logdir &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;./logdir&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
num_epochs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;42&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; data&lt;/span&gt;
loaders &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;train&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;...&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;valid&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-c1"&gt;...&lt;/span&gt;}

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; model, criterion, optimizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; Net()
criterion &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.nn.CrossEntropyLoss()
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.optim.Adam(model.parameters())
scheduler &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; model runner&lt;/span&gt;
runner &lt;span class="pl-k"&gt;=&lt;/span&gt; SupervisedRunner()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; model training&lt;/span&gt;
runner.train(
    &lt;span class="pl-v"&gt;model&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;model,
    &lt;span class="pl-v"&gt;criterion&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;criterion,
    &lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;optimizer,
    &lt;span class="pl-v"&gt;scheduler&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;scheduler,
    &lt;span class="pl-v"&gt;loaders&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;loaders,
    &lt;span class="pl-v"&gt;logdir&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;logdir,
    &lt;span class="pl-v"&gt;num_epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_epochs,
    &lt;span class="pl-v"&gt;verbose&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For Catalyst.RL introduction, please follow &lt;a href="https://github.com/catalyst-team/catalyst/tree/master/examples/rl_gym"&gt;OpenAI Gym example&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h2&gt;
&lt;p&gt;Catalyst has its own &lt;a href="https://hub.docker.com/r/catalystteam/catalyst/tags" rel="nofollow"&gt;DockerHub page&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}&lt;/code&gt; – simple image with Catalyst&lt;/li&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}-fp16&lt;/code&gt; – Catalyst with FP16&lt;/li&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}-dev&lt;/code&gt; – Catalyst for development with all the requirements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;catalystteam/catalyst:{CATALYST_VERSION}-dev-fp16&lt;/code&gt; – Catalyst for development with FP16&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://hub.docker.com/r/catalystteam/catalyst/tags" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2bd63deb2f7eaab1293d2da52ff8e4a5d026cbee/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f636174616c7973747465616d2f636174616c797374" alt="Docker Pulls" data-canonical-src="https://img.shields.io/docker/pulls/catalystteam/catalyst" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To build a docker from the sources and get more information and examples,
please visit &lt;a href="docker"&gt;docker folder&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guide" class="anchor" aria-hidden="true" href="#contribution-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guide&lt;/h2&gt;
&lt;p&gt;We appreciate all contributions.
If you are planning to contribute back bug-fixes,
please do so without any further discussion.
If you plan to contribute new features, utility functions or extensions,
please first open an issue and discuss the feature with us.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Please see the &lt;a href="CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; for more information.&lt;/li&gt;
&lt;li&gt;By participating in this project, you agree to abide by its &lt;a href="CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.patreon.com/catalyst_team" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3d9b27bdf72d7e5407fbad6f9240f6cadc98a7a5/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e2e706e67" alt="Donate" data-canonical-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is licensed under the Apache License, Version 2.0 see the &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file for details
&lt;a href="LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/4dd98dd86a5776f8d32031475d75fd9bca4ce5c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f636174616c7973742d7465616d2f636174616c7973742e737667" alt="License" data-canonical-src="https://img.shields.io/github/license/catalyst-team/catalyst.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;Please use this bibtex if you want to cite this repository in your publications:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{catalyst,
    author = {Kolesnikov, Sergey},
    title = {Reproducible and fast DL &amp;amp; RL.},
    year = {2018},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/catalyst-team/catalyst}},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>catalyst-team</author><guid isPermaLink="false">https://github.com/catalyst-team/catalyst</guid><pubDate>Wed, 20 Nov 2019 00:25:00 GMT</pubDate></item></channel></rss>