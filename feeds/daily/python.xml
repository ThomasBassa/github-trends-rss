<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Python, Today</title><link>https://github.com/trending/python?since=daily</link><description>The top repositories on GitHub for python, measured daily</description><pubDate>Sat, 02 Nov 2019 00:07:58 GMT</pubDate><lastBuildDate>Sat, 02 Nov 2019 00:07:58 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>1400</ttl><item><title>streamlit/streamlit #1 in Python, Today</title><link>https://github.com/streamlit/streamlit</link><description>&lt;p&gt;&lt;i&gt;Streamlit ‚Äî The fastest way to build custom ML tools&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-welcome-to-streamlit-wave" class="anchor" aria-hidden="true" href="#welcome-to-streamlit-wave"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to Streamlit &lt;g-emoji class="g-emoji" alias="wave" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44b.png"&gt;üëã&lt;/g-emoji&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The fastest way to build custom ML tools.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Streamlit lets you create apps for your machine learning projects with deceptively simple Python scripts. It supports hot-reloading, so your app updates live as you edit and save your file. No need to mess with HTTP requests, HTML, JavaScript, etc. All you need is your favorite editor and a browser. Take a look at Streamlit in action:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5ae1dcfd188be26bbb0648fb62e9d6d593dbb6f5/68747470733a2f2f617773312e646973636f757273652d63646e2e636f6d2f7374616e6461726431302f75706c6f6164732f73747265616d6c69742f6f726967696e616c2f31582f323932653938356637663735656637626566386332376235383939663731663736636435373765302e676966"&gt;&lt;img src="https://camo.githubusercontent.com/5ae1dcfd188be26bbb0648fb62e9d6d593dbb6f5/68747470733a2f2f617773312e646973636f757273652d63646e2e636f6d2f7374616e6461726431302f75706c6f6164732f73747265616d6c69742f6f726967696e616c2f31582f323932653938356637663735656637626566386332376235383939663731663736636435373765302e676966" alt="Example of live coding a dashboard in Streamlit|635x380" data-canonical-src="https://aws1.discourse-cdn.com/standard10/uploads/streamlit/original/1X/292e985f7f75ef7bef8c27b5899f71f76cd577e0.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check out our &lt;a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace" rel="nofollow"&gt;launch blog post&lt;/a&gt;!!&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install streamlit
streamlit hello&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;p&gt;Streamlit lets you build interactive apps ridiculously easily:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; streamlit &lt;span class="pl-k"&gt;as&lt;/span&gt; st

x &lt;span class="pl-k"&gt;=&lt;/span&gt; st.slider(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Select a value&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
st.write(x, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;squared is&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, x &lt;span class="pl-k"&gt;*&lt;/span&gt; x)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1e18efff3f06946e9d1559712cea0cb76364f004/68747470733a2f2f73747265616d6c69742d64656d6f2d646174612e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f737175617265642d696d6167652d666f722d6769746875622d726561646d652d322e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1e18efff3f06946e9d1559712cea0cb76364f004/68747470733a2f2f73747265616d6c69742d64656d6f2d646174612e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f737175617265642d696d6167652d666f722d6769746875622d726561646d652d322e706e67" width="490/" data-canonical-src="https://streamlit-demo-data.s3-us-west-2.amazonaws.com/squared-image-for-github-readme-2.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-a-bigger-example" class="anchor" aria-hidden="true" href="#a-bigger-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Bigger Example&lt;/h2&gt;
&lt;p&gt;Despite its simplicity Streamlit lets you build incredibly rich and powerful tools. &lt;a href="https://github.com/streamlit/demo-self-driving"&gt;This demo project&lt;/a&gt; lets you browse the entire &lt;a href="https://github.com/udacity/self-driving-car"&gt;Udacity self-driving-car dataset&lt;/a&gt; and run inference in real time using the &lt;a href="https://pjreddie.com/darknet/yolo" rel="nofollow"&gt;YOLO object detection net&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/streamlit/demo-self-driving/master/av_final_optimized.gif"&gt;&lt;img src="https://raw.githubusercontent.com/streamlit/demo-self-driving/master/av_final_optimized.gif" alt="Making-of Animation" title="Making-of Animation" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The complete demo is implemented in less than 300 lines of Python. In fact, the app contains &lt;a href="https://github.com/streamlit/demo-self-driving/blob/master/app.py"&gt;only 23 Streamlit calls&lt;/a&gt; which illustrates all the major building blocks of Streamlit. You can try it right now with:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install --upgrade streamlit opencv-python
streamlit run https://raw.githubusercontent.com/streamlit/demo-self-driving/master/app.py&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-more-information" class="anchor" aria-hidden="true" href="#more-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Our &lt;a href="https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace" rel="nofollow"&gt;launch post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Our lovely &lt;a href="https://discuss.streamlit.io/" rel="nofollow"&gt;community&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Streamlit &lt;a href="https://streamlit.io/docs" rel="nofollow"&gt;documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More &lt;a href="https://github.com/streamlit/"&gt;demo projects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If you would like to contribute, see &lt;a href="https://github.com/streamlit/streamlit/wiki/Contributing"&gt;instructions here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-streamlit-for-teams" class="anchor" aria-hidden="true" href="#streamlit-for-teams"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Streamlit for Teams&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://streamlit.io/forteams/" rel="nofollow"&gt;Streamlit for Teams&lt;/a&gt; is our enterprise edition, with single-click deploy, authentication, web editing, versioning, and more. Please contact us if you would like to learn more.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Streamlit is completely free and open source and licensed under the &lt;a href="https://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;Apache 2.0&lt;/a&gt; license.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>streamlit</author><guid isPermaLink="false">https://github.com/streamlit/streamlit</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>iGhibli/iOS-DeviceSupport #2 in Python, Today</title><link>https://github.com/iGhibli/iOS-DeviceSupport</link><description>&lt;p&gt;&lt;i&gt;This repository holds the device support files for the iOS, and I will update it regularly.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ios-devicesupport" class="anchor" aria-hidden="true" href="#ios-devicesupport"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;iOS-DeviceSupport&lt;/h1&gt;
&lt;p&gt;This repository holds the device support files for the iOS, and I will update it regularly.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;See docs: &lt;a href="https://ighibli.github.io/2017/03/28/Could-not-locate-device-support-files/" rel="nofollow"&gt;https://ighibli.github.io/2017/03/28/Could-not-locate-device-support-files/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Below command will try to unzip all new device support files to &lt;code&gt;/Applications/Xcode.app&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo ./deploy.py&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can use &lt;code&gt;-t&lt;/code&gt; if your Xcode is not in &lt;code&gt;/Applications/&lt;/code&gt; or has different name.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;sudo ./deploy.py -t /Applications/Xcode&lt;span class="pl-cce"&gt;\ &lt;/span&gt;9.app&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;./deploy.py -h
usage: deploy.py [-h] [-t TARGET]

optional arguments:
  -h, --help  show this &lt;span class="pl-c1"&gt;help&lt;/span&gt; message and &lt;span class="pl-c1"&gt;exit&lt;/span&gt;
  -t TARGET   The path &lt;span class="pl-k"&gt;for&lt;/span&gt; Xcode&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-supported-versions" class="anchor" aria-hidden="true" href="#supported-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported versions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;iOS8
&lt;ul&gt;
&lt;li&gt;8.0 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;8.1 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;8.2 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;8.3 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;8.4 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;iOS9
&lt;ul&gt;
&lt;li&gt;9.0 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;9.1 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;9.2 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;9.3 &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;iOS10
&lt;ul&gt;
&lt;li&gt;10.0 (14A345) &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;10.0 &lt;code&gt;2017/12/05&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;10.1 (14B72) &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;10.1 &lt;code&gt;2017/12/05&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;10.2 (14C92) &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;10.2 &lt;code&gt;2017/12/05&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;10.3 (14E269) &lt;code&gt;2017/04/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;10.3 &lt;code&gt;2017/12/05&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;iOS11
&lt;ul&gt;
&lt;li&gt;11.0 &lt;code&gt;2017/12/05&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.1 (15B87) &lt;code&gt;2017/12/05&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.1 &lt;code&gt;2017/12/11&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.2 (15C107) &lt;code&gt;2017/12/11&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.2 &lt;code&gt;2018/03/06&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.3 (15E5167d) &lt;code&gt;2018/01/30&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.3 (15E5201e) &lt;code&gt;2018/03/06&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.3 &lt;code&gt;2018/04/09&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.4 (15F5037c) &lt;code&gt;2018/04/09&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.4 (15F5061c) &lt;code&gt;2018/07/29&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.4 (15F79) &lt;code&gt;2018/07/29&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;11.4 &lt;code&gt;2018/06/07&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;iOS12
&lt;ul&gt;
&lt;li&gt;12.0 (16A5288q) &lt;code&gt;2018/06/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.0 (16A5308d) &lt;code&gt;2018/06/19&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.0 (16A5318d) &lt;code&gt;2018/06/29&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.0 (16A5327d) &lt;code&gt;2018/07/20&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.0 (16A5339e) &lt;code&gt;2018/07/31&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.0 (16A5354b) &lt;code&gt;2018/08/15&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.0 (16A366) &lt;code&gt;2018/09/18&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.0 &lt;code&gt;2019/01/29&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.1 (16B5059d) &lt;code&gt;2018/09/21&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.1 (16B5068g) &lt;code&gt;2018/10/08&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.1 (16B5084a) &lt;code&gt;2018/10/16&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.1 (16B91) &lt;code&gt;2018/10/31&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.1 (16B5084a) &lt;code&gt;2018/10/16&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.1 &lt;code&gt;2019/01/29&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.2 (16E5181e) &lt;code&gt;2019/01/29&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.2 (16E5212e) &lt;code&gt;2019/03/07&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.2 (16E226) &lt;code&gt;2019/03/27&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.3 &lt;code&gt;2019/06/04&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.4 (16G73) &lt;code&gt;2019/07/22&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;12.4 (FromXcode_11_Beta_7_xip) &lt;code&gt;2019/09/03&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;iOS13
&lt;ul&gt;
&lt;li&gt;13.0 &lt;code&gt;2019/06/04&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;13.0 (FromXcode_11_Beta_7_xip) &lt;code&gt;2019/09/03&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;13.1 &lt;code&gt;2019/08/28&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;13.2 &lt;code&gt;2019/10/02&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>iGhibli</author><guid isPermaLink="false">https://github.com/iGhibli/iOS-DeviceSupport</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>tamarott/SinGAN #3 in Python, Today</title><link>https://github.com/tamarott/SinGAN</link><description>&lt;p&gt;&lt;i&gt;Official pytorch implementation of the paper: "SinGAN: Learning a Generative Model from a Single Natural Image"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-singan" class="anchor" aria-hidden="true" href="#singan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SinGAN&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://webee.technion.ac.il/people/tomermic/SinGAN/SinGAN.htm" rel="nofollow"&gt;Project&lt;/a&gt; | &lt;a href="https://arxiv.org/pdf/1905.01164.pdf" rel="nofollow"&gt;Arxiv&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-official-pytorch-implementation-of-the-paper-singan-learning-a-generative-model-from-a-single-natural-image" class="anchor" aria-hidden="true" href="#official-pytorch-implementation-of-the-paper-singan-learning-a-generative-model-from-a-single-natural-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Official pytorch implementation of the paper: "SinGAN: Learning a Generative Model from a Single Natural Image"&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-iccv-2019" class="anchor" aria-hidden="true" href="#iccv-2019"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ICCV 2019&lt;/h4&gt;
&lt;h2&gt;&lt;a id="user-content-random-samples-from-a-single-image" class="anchor" aria-hidden="true" href="#random-samples-from-a-single-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Random samples from a &lt;em&gt;single&lt;/em&gt; image&lt;/h2&gt;
&lt;p&gt;With SinGAN, you can train a generative model from a single natural image, and then generate random samples form the given image, for example:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="imgs/teaser.PNG"&gt;&lt;img src="imgs/teaser.PNG" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-singans-applications" class="anchor" aria-hidden="true" href="#singans-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SinGAN's applications&lt;/h2&gt;
&lt;p&gt;SinGAN can be also use to a line of image manipulation task, for example:
&lt;a target="_blank" rel="noopener noreferrer" href="imgs/manipulation.PNG"&gt;&lt;img src="imgs/manipulation.PNG" alt="" style="max-width:100%;"&gt;&lt;/a&gt;
This is done by injecting an image to the already trained model. See section 4 in our &lt;a href="https://arxiv.org/pdf/1905.01164.pdf" rel="nofollow"&gt;paper&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-code" class="anchor" aria-hidden="true" href="#code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h3&gt;
&lt;p&gt;To train SinGAN model on your own image, put the desire training image under Input/Images, and run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python main_train.py --input_name &amp;lt;input_file_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will also use the resulting trained model to generate random samples starting from the coarsest scale (n=0).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-random-samples" class="anchor" aria-hidden="true" href="#random-samples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Random samples&lt;/h3&gt;
&lt;p&gt;To generate random samples from any starting generation scale, please first train SinGAN model for the desire image (as described above), then run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python random_samples.py --input_name &amp;lt;training_image_file_name&amp;gt; --mode random_samples --gen_start_scale &amp;lt;generation start scale number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;pay attention: for using the full model, specify the generation start scale to be 0, to start the generation from the second scale, specify it to be 1, and so on.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-random-samples-of-arbitrery-sizes" class="anchor" aria-hidden="true" href="#random-samples-of-arbitrery-sizes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Random samples of arbitrery sizes&lt;/h3&gt;
&lt;p&gt;To generate random samples of arbitrery sizes, please first train SinGAN model for the desire image (as described above), then run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python random_samples.py --input_name &amp;lt;training_image_file_name&amp;gt; --mode random_samples_arbitrary_sizes --scale_h &amp;lt;horizontal scaling factor&amp;gt; --scale_v &amp;lt;vertical scaling factor&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-animation-from-a-single-image" class="anchor" aria-hidden="true" href="#animation-from-a-single-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Animation from a single image&lt;/h3&gt;
&lt;p&gt;To generate short animation from a single image, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python animation.py --input_name &amp;lt;input_file_name&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will automatically start a new training phase with noise padding mode.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-harmonization" class="anchor" aria-hidden="true" href="#harmonization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Harmonization&lt;/h3&gt;
&lt;p&gt;To harmonize a pasted object into an image (See example in Fig. 13 in &lt;a href="https://arxiv.org/pdf/1905.01164.pdf" rel="nofollow"&gt;our paper&lt;/a&gt;), please first train SinGAN model for the desire background image (as described above), then save the naively pasted reference image and it's binary mask under "Input/Harmonization" (see saved images for an example). Run the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python harmonization.py --input_name &amp;lt;training_image_file_name&amp;gt; --ref_name &amp;lt;naively_pasted_reference_image_file_name&amp;gt; --harmonization_start_scale &amp;lt;scale to inject&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please note that different injection scale will produce different harmonization effects. The coarsest injection scale equals 1.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-editing" class="anchor" aria-hidden="true" href="#editing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Editing&lt;/h3&gt;
&lt;p&gt;To edit an image, (See example in Fig. 12 in &lt;a href="https://arxiv.org/pdf/1905.01164.pdf" rel="nofollow"&gt;our paper&lt;/a&gt;), please first train SinGAN model on the desire non-edited image (as described above), then save the naive edit as a reference image under "Input/Editing" with a corresponding binary map (see saved images for an example). Run the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python editing.py --input_name &amp;lt;training_image_file_name&amp;gt; --ref_name &amp;lt;edited_image_file_name&amp;gt; --editing_start_scale &amp;lt;scale to inject&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;both the masked and unmasked output will be saved.
Here as well, different injection scale will produce different editing effects. The coarsest injection scale equals 1.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-paint-to-image" class="anchor" aria-hidden="true" href="#paint-to-image"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Paint to Image&lt;/h3&gt;
&lt;p&gt;To transfer a paint into a realistic image (See example in Fig. 11 in &lt;a href="https://arxiv.org/pdf/1905.01164.pdf" rel="nofollow"&gt;our paper&lt;/a&gt;), please first train SinGAN model on the desire image (as described above), then save your paint under "Input/Paint", and run the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python paint2image.py --input_name &amp;lt;training_image_file_name&amp;gt; --ref_name &amp;lt;paint_image_file_name&amp;gt; --paint_start_scale &amp;lt;scale to inject&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here as well, different injection scale will produce different editing effects. The coarsest injection scale equals 1.&lt;/p&gt;
&lt;p&gt;Advanced option: Specify quantization_flag to be True, to re-train &lt;em&gt;only&lt;/em&gt; the injection level of the model, to get a on a color-quantized version of upsamled generated images from previous scale. For some images, this might lead to more realistic results.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-super-resolution" class="anchor" aria-hidden="true" href="#super-resolution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Super Resolution&lt;/h3&gt;
&lt;p&gt;To super resolve an image, Please run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python3 SR.py --input_name &amp;lt;LR_image_file_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will aoutomatically train a SinGAN model correspond to 4x upsampling factor (if not exist already).
For different SR factors, please specify it using the parametr 'sr_factor' when calling the function.
SinGAN's results on BSD100 dataset can be download from the 'Downloads' folder.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h3&gt;
&lt;p&gt;If you use this code for your research, please cite our paper:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{shaham2019singan,
  title={SinGAN: Learning a Generative Model from a Single Natural Image},
  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},
  booktitle={Computer Vision (ICCV), IEEE International Conference on},
  year={2019}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tamarott</author><guid isPermaLink="false">https://github.com/tamarott/SinGAN</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>plotly/dash #4 in Python, Today</title><link>https://github.com/plotly/dash</link><description>&lt;p&gt;&lt;i&gt;Analytical Web Apps for Python &amp; R. No JavaScript Required.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dash" class="anchor" aria-hidden="true" href="#dash"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dash&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/plotly/dash" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2488249996549b3d8197eb061e51975ede759cb6/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f70726f6a6563742f6769746875622f706c6f746c792f646173682f6d61737465722e737667" alt="CircleCI" data-canonical-src="https://img.shields.io/circleci/project/github/plotly/dash/master.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/plotly/dash/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/3cd42a5b87f7de7a0fe06c16c0de8403cce5ec1e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f706c6f746c792f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="GitHub" data-canonical-src="https://img.shields.io/github/license/plotly/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/dash/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/591a9710a9507f246482d0d57d33e473aef1bba7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/dash/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/09415013d09c9e287dcb0f00c5287fc57825efcd/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/plotly/dash/graphs/contributors"&gt;&lt;img src="https://camo.githubusercontent.com/2c0f084bce301be8501650815385bda2802e580e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f792f706c6f746c792f646173682e7376673f636f6c6f723d6461726b2d677265656e" alt="GitHub commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/y/plotly/dash.svg?color=dark-green" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/plotly/dash/alerts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1c0f2f026b76562ac6828803af41b652a1c1c113/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f706c6f746c792f646173682e737667" alt="LGTM Alerts" data-canonical-src="https://img.shields.io/lgtm/alerts/g/plotly/dash.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://lgtm.com/projects/g/plotly/dash/context:python" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ab2cb9245f5eed317879ce495d4e708c93cab8b7/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f706c6f746c792f646173682e737667" alt="LGTM Grade" data-canonical-src="https://img.shields.io/lgtm/grade/python/g/plotly/dash.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-dash-is-a-python-framework-for-building-analytical-web-applications-no-javascript-required" class="anchor" aria-hidden="true" href="#dash-is-a-python-framework-for-building-analytical-web-applications-no-javascript-required"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;em&gt;Dash is a Python framework for building analytical web applications. No JavaScript required&lt;/em&gt;.&lt;/h4&gt;
&lt;p&gt;Built on top of Plotly.js, React and Flask, Dash ties modern UI elements like dropdowns, sliders, and graphs directly to your analytical Python code. Read our tutorial proudly crafted &lt;g-emoji class="g-emoji" alias="heart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2764.png"&gt;‚ù§Ô∏è&lt;/g-emoji&gt; by Dash itself.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://dash.plot.ly/getting-started" rel="nofollow"&gt;User Guide&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/plotly/dash-docs/blob/master/pdf-docs/Dash_User_Guide_and_Documentation.pdf"&gt;Offline (PDF) Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://dash-docs.herokuapp.com/" rel="nofollow"&gt;Dash Docs on Heroku&lt;/a&gt; (for corporate network that cannot access plot.ly)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-app-samples" class="anchor" aria-hidden="true" href="#app-samples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;App Samples&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;App&lt;/th&gt;
&lt;th align="center"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif" alt="Sample Dash App" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Here‚Äôs a simple example of a Dash App that ties a Dropdown to a D3.js Plotly Graph. As the user selects a value in the Dropdown, the application code dynamically exports data from Google Finance into a Pandas DataFrame. This app was written in just &lt;strong&gt;43&lt;/strong&gt; lines of code (&lt;a href="https://gist.github.com/chriddyp/3d2454905d8f01886d651f207e2419f0"&gt;view the source&lt;/a&gt;).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif" alt="Crossfiltering Dash App" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash app code is declarative and reactive, which makes it easy to build complex apps that contain many interactive elements. Here‚Äôs an example with 5 inputs, 3 outputs, and cross filtering. This app was composed in just 160 lines of code, all of which were Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif" alt="Dash App with Mapbox map showing walmart store openings" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash uses &lt;a href="https://github.com/plotly/plotly.js"&gt;Plotly.js&lt;/a&gt; for charting. Over 35 chart types are supported, including maps.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/plotly/dash-docs/blob/516f80c417051406210b94ea23a6d3b6cd84d146/assets/images/gallery/dash-financial-report.gif"&gt;&lt;img src="https://github.com/plotly/dash-docs/raw/516f80c417051406210b94ea23a6d3b6cd84d146/assets/images/gallery/dash-financial-report.gif" alt="Financial report" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;Dash isn't just for dashboards. You have full control over the look and feel of your applications. Here's a Dash App that's styled to look like a PDF report.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To learn more about Dash, read the &lt;a href="https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503" rel="nofollow"&gt;extensive announcement letter&lt;/a&gt; or &lt;a href="https://plot.ly/dash" rel="nofollow"&gt;jump in with the user guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contact-and-support" class="anchor" aria-hidden="true" href="#contact-and-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact and Support&lt;/h3&gt;
&lt;p&gt;For companies with software budgets, Plotly offers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Dash Deployment Server&lt;/strong&gt;&lt;/a&gt; speeds your time-to-delivery while providing the right resources, security, and scalability you need to deliver production-quality apps&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Dash Design Kit&lt;/strong&gt;&lt;/a&gt; makes your internal dashboard awesome without expertise in JavaScript &amp;amp; CSS.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plot.ly/products/dash/" rel="nofollow"&gt;&lt;strong&gt;Snapshot Engine&lt;/strong&gt;&lt;/a&gt; seamlessly links your analytics and reporting workflows together, giving you a fast way to generate interactive reports of just the data you need&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href="https://plot.ly/dash/support" rel="nofollow"&gt;https://plot.ly/dash/support&lt;/a&gt; for ways to get in touch.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1280389/30084008-9fbc68fc-925e-11e7-891c-18a9b8f6ac6b.png"&gt;&lt;img src="https://user-images.githubusercontent.com/1280389/30084008-9fbc68fc-925e-11e7-891c-18a9b8f6ac6b.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>plotly</author><guid isPermaLink="false">https://github.com/plotly/dash</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>NVIDIA/DeepLearningExamples #5 in Python, Today</title><link>https://github.com/NVIDIA/DeepLearningExamples</link><description>&lt;p&gt;&lt;i&gt;Deep Learning Examples&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-nvidia-deep-learning-examples-for-tensor-cores" class="anchor" aria-hidden="true" href="#nvidia-deep-learning-examples-for-tensor-cores"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NVIDIA Deep Learning Examples for Tensor Cores&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This repository provides the latest deep learning example networks for training.  These examples focus on achieving the best performance and convergence from NVIDIA Volta Tensor Cores.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-nvidia-gpu-cloud-ngc-container-registry" class="anchor" aria-hidden="true" href="#nvidia-gpu-cloud-ngc-container-registry"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NVIDIA GPU Cloud (NGC) Container Registry&lt;/h2&gt;
&lt;p&gt;These examples, along with our NVIDIA deep learning software stack, are provided in a monthly updated Docker container on the NGC container registry (&lt;a href="https://ngc.nvidia.com" rel="nofollow"&gt;https://ngc.nvidia.com&lt;/a&gt;). These containers include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The latest NVIDIA examples from this repository&lt;/li&gt;
&lt;li&gt;The latest NVIDIA contributions shared upstream to the respective framework&lt;/li&gt;
&lt;li&gt;The latest NVIDIA Deep Learning software libraries, such as cuDNN, NCCL, cuBLAS, etc. which have all been through a rigorous monthly quality assurance process to ensure that they provide the best possible performance&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.nvidia.com/deeplearning/dgx/index.html#nvidia-optimized-frameworks-release-notes" rel="nofollow"&gt;Monthly release notes&lt;/a&gt; for each of the NVIDIA optimized containers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-directory-structure" class="anchor" aria-hidden="true" href="#directory-structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Directory structure&lt;/h2&gt;
&lt;p&gt;The examples are organized first by framework, such as TensorFlow, PyTorch, etc. and second by use case, such as computer vision, natural language processing, etc. We hope this structure enables you to quickly locate the example networks that best suit your needs. Here are the currently supported models:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-computer-vision" class="anchor" aria-hidden="true" href="#computer-vision"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Computer Vision&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ResNet-50&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/MxNet/Classification/RN50v1.5"&gt;MXNet&lt;/a&gt;] [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/RN50v1.5"&gt;PyTorch&lt;/a&gt;] [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Classification/RN50v1.5"&gt;TensorFlow&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSD&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD"&gt;PyTorch&lt;/a&gt;] [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Detection/SSD"&gt;TensorFlow&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mask R-CNN&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Segmentation/MaskRCNN"&gt;PyTorch&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;U-Net(industrial)&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Segmentation/UNet_Industrial"&gt;TensorFlow&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;U-Net(medical)&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Segmentation/UNet_Medical"&gt;TensorFlow&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-natural-language-processing" class="anchor" aria-hidden="true" href="#natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Natural Language Processing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GNMT&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Translation/GNMT"&gt;PyTorch&lt;/a&gt;] [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Translation/GNMT"&gt;TensorFlow&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Translation/Transformer"&gt;PyTorch&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BERT&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT"&gt;PyTorch&lt;/a&gt;][&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/LanguageModeling/BERT"&gt;TensorFlow&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-recommender-systems" class="anchor" aria-hidden="true" href="#recommender-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recommender Systems&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NCF&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Recommendation/NCF"&gt;PyTorch&lt;/a&gt;] [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Recommendation/NCF"&gt;TensorFlow&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-text-to-speech" class="anchor" aria-hidden="true" href="#text-to-speech"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Text to Speech&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tacotron &amp;amp; WaveGlow&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2"&gt;PyTorch&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-speech-recognition" class="anchor" aria-hidden="true" href="#speech-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speech Recognition&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Jasper&lt;/strong&gt; [&lt;a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechRecognition/Jasper"&gt;PyTorch&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-nvidia-support" class="anchor" aria-hidden="true" href="#nvidia-support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NVIDIA support&lt;/h2&gt;
&lt;p&gt;In each of the network READMEs, we indicate the level of support that will be provided. The range is from ongoing updates and improvements to a point-in-time release for thought leadership.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-feedback--contributions" class="anchor" aria-hidden="true" href="#feedback--contributions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feedback / Contributions&lt;/h2&gt;
&lt;p&gt;We're posting these examples on GitHub to better support the community, facilitate feedback, as well as collect and implement contributions using GitHub Issues and pull requests. We welcome all contributions!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-known-issues" class="anchor" aria-hidden="true" href="#known-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Known issues&lt;/h2&gt;
&lt;p&gt;In each of the network READMEs, we indicate any known issues and encourage the community to provide feedback.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>NVIDIA</author><guid isPermaLink="false">https://github.com/NVIDIA/DeepLearningExamples</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>521xueweihan/HelloGitHub #6 in Python, Today</title><link>https://github.com/521xueweihan/HelloGitHub</link><description>&lt;p&gt;&lt;i&gt;:octocat: Find pearls on open-source seashore ÂàÜ‰∫´ GitHub ‰∏äÊúâË∂£„ÄÅÂÖ•Èó®Á∫ßÁöÑÂºÄÊ∫êÈ°πÁõÆ&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/521xueweihan/img/master/hellogithub/logo/readme.gif"&gt;&lt;img src="https://raw.githubusercontent.com/521xueweihan/img/master/hellogithub/logo/readme.gif" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;‰∏≠Êñá | &lt;a href="README_en.md"&gt;English&lt;/a&gt;
  &lt;br&gt;&lt;strong&gt;HelloGitHub&lt;/strong&gt; ‰∏Ä‰∏™ÂàÜ‰∫´ GitHub ‰∏äÊúâË∂£„ÄÅÂÖ•Èó®Á∫ßÁöÑÂºÄÊ∫êÈ°πÁõÆ„ÄÇ&lt;br&gt;ÂÖ¥Ë∂£ÊòØÊúÄÂ•ΩÁöÑËÄÅÂ∏àÔºåËøôÈáåËÉΩÂ§üÂ∏Æ‰Ω†ÊâæÂà∞ÁºñÁ®ãÁöÑÂÖ¥Ë∂£ÔºÅ
&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a href="https://hellogithub.com/weixin.png" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/61343b85520a4714ddb37eb300f8268cc881ae7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f54616c6b2d2545352542452541452545342542462541312545372542452541342d627269676874677265656e2e7376673f7374796c653d706f706f75742d737175617265" alt="WeiXin" data-canonical-src="https://img.shields.io/badge/Talk-%E5%BE%AE%E4%BF%A1%E7%BE%A4-brightgreen.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="https://github.com/521xueweihan/HelloGitHub/stargazers"&gt;&lt;img src="https://camo.githubusercontent.com/0aec7fa1a5647255bbe8af37a82a007be69d8739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f35323178756577656968616e2f48656c6c6f4769744875622e7376673f7374796c653d706f706f75742d737175617265" alt="GitHub stars" data-canonical-src="https://img.shields.io/github/stars/521xueweihan/HelloGitHub.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;a href="https://github.com/521xueweihan/HelloGitHub/issues"&gt;&lt;img src="https://camo.githubusercontent.com/a8367e38e94eccf7e469023edfec05db15132454/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f35323178756577656968616e2f48656c6c6f4769744875622e7376673f7374796c653d706f706f75742d737175617265" alt="GitHub issues" data-canonical-src="https://img.shields.io/github/issues/521xueweihan/HelloGitHub.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;a href="https://weibo.com/hellogithub" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4627590b5d81a690c6c83abaf47f678d70d26e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2545362539362542302545362542352541412d576569626f2d7265642e7376673f7374796c653d706f706f75742d737175617265" alt="Sina Weibo" data-canonical-src="https://img.shields.io/badge/%E6%96%B0%E6%B5%AA-Weibo-red.svg?style=popout-square" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ÁÆÄ‰ªã" class="anchor" aria-hidden="true" href="#ÁÆÄ‰ªã"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ÁÆÄ‰ªã&lt;/h2&gt;
&lt;p&gt;ËøôÊòØ‰∏Ä‰∏™Èù¢ÂêëÁºñÁ®ãÊñ∞Êâã„ÄÅÁÉ≠Áà±ÁºñÁ®ã„ÄÅÂØπÂºÄÊ∫êÁ§æÂå∫ÊÑüÂÖ¥Ë∂£‰∫∫Áæ§ÁöÑÈ°πÁõÆÔºåÂÜÖÂÆπ&lt;strong&gt;ÊØèÊúà 28 Âè∑&lt;/strong&gt;‰ª•ÊúàÂàäÁöÑÂΩ¢ÂºèÊõ¥Êñ∞ÂèëÂ∏É„ÄÇÂÜÖÂÆπÂåÖÊã¨Ôºö&lt;strong&gt;ÊµÅË°åÈ°πÁõÆ&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÂÖ•Èó®Á∫ßÈ°πÁõÆ&lt;/strong&gt;„ÄÅ&lt;strong&gt;ËÆ©ÁîüÊ¥ªÂèòÂæóÊõ¥ÁæéÂ•ΩÁöÑÂ∑•ÂÖ∑&lt;/strong&gt;„ÄÅ&lt;strong&gt;‰π¶Á±ç&lt;/strong&gt;„ÄÅ&lt;strong&gt;Â≠¶‰π†ÂøÉÂæóÁ¨îËÆ∞&lt;/strong&gt;„ÄÅ&lt;strong&gt;‰ºÅ‰∏öÁ∫ßÈ°πÁõÆ&lt;/strong&gt;Á≠âÔºåËøô‰∫õÂºÄÊ∫êÈ°πÁõÆÂ§ßÂ§öÈÉΩÊòØÈùûÂ∏∏ÂÆπÊòì‰∏äÊâã„ÄÅÂæà CoolÔºåËÉΩÂ§üËÆ©‰Ω†Áî®ÂæàÁü≠Êó∂Èó¥ÊÑüÂèóÂà∞ÁºñÁ®ãÁöÑÈ≠ÖÂäõÂíå‰æøÊç∑„ÄÇ‰ªéËÄåËÆ©Â§ßÂÆ∂ÊÑüÂèóÂà∞ÁºñÁ®ãÁöÑ‰πêË∂£ÔºåÂä®ÊâãÂºÄÂßãÁºñÁ®ã„ÄÇ&lt;/p&gt;
&lt;p&gt;Â∏åÊúõÈÄöËøáÊú¨È°πÁõÆËÉΩÂ§üÊúâÊõ¥Â§ö‰∫∫Âä†ÂÖ•Âà∞ÂºÄÊ∫êÁ§æÂå∫„ÄÅÂõûÈ¶àÁ§æÂå∫„ÄÇ&lt;strong&gt;ËÆ©ÊúâË∂£„ÄÅÊúâ‰ª∑ÂÄºÁöÑÈ°πÁõÆË¢´Êõ¥Â§ö‰∫∫ÂèëÁé∞ÂíåÂä†ÂÖ•&lt;/strong&gt;„ÄÇÂú®ÂèÇ‰∏éËøô‰∫õÈ°πÁõÆÁöÑËøáÁ®ã‰∏≠Ôºå‰Ω†Â∞ÜÂæóÂà∞Ôºö&lt;strong&gt;ÁÉ≠Áà±ÁºñÁ®ãÁöÑÂ∞è‰ºô‰º¥&lt;/strong&gt;&lt;g-emoji class="g-emoji" alias="man_dancing" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f57a.png"&gt;üï∫&lt;/g-emoji&gt; „ÄÅ&lt;strong&gt;Êõ¥Â§öÁºñÁ®ãÁü•ËØÜ&lt;/strong&gt;&lt;g-emoji class="g-emoji" alias="books" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png"&gt;üìö&lt;/g-emoji&gt; „ÄÅ&lt;strong&gt;‰ºòÁßÄÁöÑÁºñÁ®ãÊäÄÂ∑ß&lt;/strong&gt;&lt;g-emoji class="g-emoji" alias="computer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png"&gt;üíª&lt;/g-emoji&gt; „ÄÅ&lt;strong&gt;ÊâæÂà∞ÁºñÁ®ãÁöÑ‰πêË∂£&lt;/strong&gt;&lt;g-emoji class="g-emoji" alias="video_game" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3ae.png"&gt;üéÆ&lt;/g-emoji&gt; „ÄÇ&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;„ÄéÊØèÊó•Á≤æÈÄâ„Äè&lt;/strong&gt; ÂÖ≥Ê≥®Êàë‰ª¨ÁöÑ&lt;a href="https://weibo.com/hellogithub" rel="nofollow"&gt;ÊúÄÊÉ®ÂÆòÂæÆ&lt;/a&gt;Ëé∑ÂèñÊúÄÊñ∞È°πÁõÆÊé®Ëçê„ÄÇ&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;„ÄéËÆ≤Ëß£ÂºÄÊ∫êÈ°πÁõÆ„Äè&lt;/strong&gt; Ê¨¢ËøéÂºÄÊ∫êÁà±Â•ΩËÄÖÁªôÊàë‰ª¨ÊäïÁ®ø&lt;a href="https://github.com/HelloGitHub-Team/Article/blob/master/%E5%88%9B%E4%BD%9C%E9%A1%BB%E7%9F%A5.md"&gt;Êü•ÁúãÂàõ‰ΩúÈ°ªÁü•&lt;/a&gt;„ÄÇ&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-ÂÜÖÂÆπ" class="anchor" aria-hidden="true" href="#ÂÜÖÂÆπ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ÂÜÖÂÆπ&lt;/h2&gt;
&lt;p&gt;ÊØèÊúà 28 Âè∑ÂèëÂ∏É&lt;a href="/content/last.md"&gt;ÊúÄÊñ∞‰∏ÄÊúü&lt;/a&gt; | &lt;a href="https://hellogithub.com" rel="nofollow"&gt;ÂÆòÁΩë&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;img class="emoji" title=":shipit:" alt=":shipit:" src="https://github.githubassets.com/images/icons/emoji/shipit.png" height="20" width="20" align="absmiddle"&gt;&lt;/th&gt;
&lt;th&gt;&lt;g-emoji class="g-emoji" alias="jack_o_lantern" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f383.png"&gt;üéÉ&lt;/g-emoji&gt;&lt;/th&gt;
&lt;th&gt;&lt;g-emoji class="g-emoji" alias="beer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f37a.png"&gt;üç∫&lt;/g-emoji&gt;&lt;/th&gt;
&lt;th&gt;&lt;g-emoji class="g-emoji" alias="fish_cake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f365.png"&gt;üç•&lt;/g-emoji&gt;&lt;/th&gt;
&lt;th&gt;&lt;img class="emoji" title=":octocat:" alt=":octocat:" src="https://github.githubassets.com/images/icons/emoji/octocat.png" height="20" width="20" align="absmiddle"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/43/HelloGitHub43.md"&gt;Á¨¨ 43 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/42/HelloGitHub42.md"&gt;Á¨¨ 42 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/41/HelloGitHub41.md"&gt;Á¨¨ 41 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/40/HelloGitHub40.md"&gt;Á¨¨ 40 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/39/HelloGitHub39.md"&gt;Á¨¨ 39 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/38/HelloGitHub38.md"&gt;Á¨¨ 38 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/37/HelloGitHub37.md"&gt;Á¨¨ 37 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/36/HelloGitHub36.md"&gt;Á¨¨ 36 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/35/HelloGitHub35.md"&gt;Á¨¨ 35 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/34/HelloGitHub34.md"&gt;Á¨¨ 34 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/33/HelloGitHub33.md"&gt;Á¨¨ 33 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/32/HelloGitHub32.md"&gt;Á¨¨ 32 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/31/HelloGitHub31.md"&gt;Á¨¨ 31 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/30/HelloGitHub30.md"&gt;Á¨¨ 30 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/29/HelloGitHub29.md"&gt;Á¨¨ 29 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/28/HelloGitHub28.md"&gt;Á¨¨ 28 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/27/HelloGitHub27.md"&gt;Á¨¨ 27 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/26/HelloGitHub26.md"&gt;Á¨¨ 26 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/25/HelloGitHub25.md"&gt;Á¨¨ 25 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/24/HelloGitHub24.md"&gt;Á¨¨ 24 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/23/HelloGitHub23.md"&gt;Á¨¨ 23 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/22/HelloGitHub22.md"&gt;Á¨¨ 22 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/21/HelloGitHub21.md"&gt;Á¨¨ 21 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/20/HelloGitHub20.md"&gt;Á¨¨ 20 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/19/HelloGitHub19.md"&gt;Á¨¨ 19 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/18/HelloGitHub18.md"&gt;Á¨¨ 18 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/17/HelloGitHub17.md"&gt;Á¨¨ 17 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/16/HelloGitHub16.md"&gt;Á¨¨ 16 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/15/HelloGitHub15.md"&gt;Á¨¨ 15 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/14/HelloGitHub14.md"&gt;Á¨¨ 14 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/13/HelloGitHub13.md"&gt;Á¨¨ 13 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/12/HelloGitHub12.md"&gt;Á¨¨ 12 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/11/HelloGitHub11.md"&gt;Á¨¨ 11 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/10/HelloGitHub10.md"&gt;Á¨¨ 10 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/09/HelloGitHub09.md"&gt;Á¨¨ 09 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/08/HelloGitHub08.md"&gt;Á¨¨ 08 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/07/HelloGitHub07.md"&gt;Á¨¨ 07 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/06/HelloGitHub06.md"&gt;Á¨¨ 06 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/content/05/HelloGitHub05.md"&gt;Á¨¨ 05 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/04/HelloGitHub04.md"&gt;Á¨¨ 04 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/03/HelloGitHub03.md"&gt;Á¨¨ 03 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/02/HelloGitHub02.md"&gt;Á¨¨ 02 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="/content/01/HelloGitHub01.md"&gt;Á¨¨ 01 Êúü&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Ê¨¢Ëøé&lt;a href="https://github.com/521xueweihan/HelloGitHub/issues/new"&gt;Êé®ËçêÊàñËá™ËçêÈ°πÁõÆ&lt;/a&gt;Êàê‰∏∫ &lt;strong&gt;HelloGitHub&lt;/strong&gt; ÁöÑ&lt;a href="https://github.com/521xueweihan/HelloGitHub/blob/master/content/contributors.md"&gt;Ë¥°ÁåÆËÄÖ&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-Ë¥°ÁåÆËÄÖ" class="anchor" aria-hidden="true" href="#Ë¥°ÁåÆËÄÖ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ë¥°ÁåÆËÄÖ&lt;/h2&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/521xueweihan"&gt;
          &lt;img src="https://avatars2.githubusercontent.com/u/8255800?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;ÂâäÂæÆÂØí&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/ming995"&gt;
          &lt;img src="https://avatars0.githubusercontent.com/u/46031112?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;Á≥ñÈÜãÈáåËÑä&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/FrontMage"&gt;
          &lt;img src="https://avatars0.githubusercontent.com/u/17007026?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;FrontMage&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/xibinyue"&gt;
          &lt;img src="https://avatars0.githubusercontent.com/u/14122146?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;xibinyue&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/Eurus-Holmes"&gt;
          &lt;img src="https://avatars3.githubusercontent.com/u/34226570?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;Feiyang Chen&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/ChungZH"&gt;
          &lt;img src="https://avatars1.githubusercontent.com/u/42088872?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;ChungZH&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/daixiang0"&gt;
          &lt;img src="https://avatars3.githubusercontent.com/u/26538619?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;daixiang0&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/nivance"&gt;
          &lt;img src="https://avatars3.githubusercontent.com/u/3291404?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;nivance&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/hellowHuaairen"&gt;
          &lt;img src="https://avatars2.githubusercontent.com/u/19610305?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;hellowHuaairen&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/521xueweihan/HelloGitHub/blob/master/content/contributors.md"&gt;
          &lt;img src="https://avatars1.githubusercontent.com/u/17665302?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;Êõ¥Â§öË¥°ÁåÆËÄÖ&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-Âêà‰ΩúÁªÑÁªá" class="anchor" aria-hidden="true" href="#Âêà‰ΩúÁªÑÁªá"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Âêà‰ΩúÁªÑÁªá&lt;/h2&gt;
&lt;p&gt;Ê¨¢ËøéÂêÑÁßç&lt;img class="emoji" title=":octocat:" alt=":octocat:" src="https://github.githubassets.com/images/icons/emoji/octocat.png" height="20" width="20" align="absmiddle"&gt;ÂºÄÊ∫êÁªÑÁªáÂêà‰Ωú&lt;a href="Mailto:595666367@qq.com"&gt;ÁÇπÂáªËÅîÁ≥ªÊàë&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/FGDBTKD"&gt;
          &lt;img src="https://avatars3.githubusercontent.com/u/40509403?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;FGDBTKD&lt;/sub&gt;&lt;br&gt;
          &lt;sub&gt;AI/ML/DL/NLP&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/d2-projects"&gt;
          &lt;img src="https://avatars3.githubusercontent.com/u/40857578?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;D2 Projects&lt;/sub&gt;&lt;br&gt;
          &lt;sub&gt;Vue/JavaScript&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
      &lt;th align="center"&gt;
        &lt;a href="https://github.com/doocs"&gt;
          &lt;img src="https://avatars1.githubusercontent.com/u/43716716?s=50&amp;amp;v=4" style="max-width:100%;"&gt;&lt;br&gt;
          &lt;sub&gt;Doocs&lt;/sub&gt;&lt;br&gt;
          &lt;sub&gt;Technical Knowledge&lt;/sub&gt;
        &lt;/a&gt;&lt;br&gt;
      &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-Â£∞Êòé" class="anchor" aria-hidden="true" href="#Â£∞Êòé"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Â£∞Êòé&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="nofollow"&gt;&lt;img alt="Áü•ËØÜÂÖ±‰∫´ËÆ∏ÂèØÂçèËÆÆ" src="https://camo.githubusercontent.com/1ae74a56e22c4897b6fbfb9f301bd829c77429a7/68747470733a2f2f6c6963656e7365627574746f6e732e6e65742f6c2f62792d6e632d6e642f342e302f38387833312e706e67" data-canonical-src="https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;Êú¨‰ΩúÂìÅÈááÁî® &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="nofollow"&gt;ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Á¶ÅÊ≠¢ÊºîÁªé 4.0 ÂõΩÈôÖ&lt;/a&gt; ËøõË°åËÆ∏ÂèØ„ÄÇ&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>521xueweihan</author><guid isPermaLink="false">https://github.com/521xueweihan/HelloGitHub</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>facebookresearch/SlowFast #7 in Python, Today</title><link>https://github.com/facebookresearch/SlowFast</link><description>&lt;p&gt;&lt;i&gt;Present SlowFast networks for video recognition.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pyslowfast" class="anchor" aria-hidden="true" href="#pyslowfast"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PySlowFast&lt;/h1&gt;
&lt;p&gt;PySlowFast is an open source video understanding codebase from FAIR that provides state-of-the-art video classification models, including papers "&lt;a href="https://arxiv.org/abs/1812.03982" rel="nofollow"&gt;SlowFast Networks for Video Recognition&lt;/a&gt;", and "&lt;a href="https://arxiv.org/abs/1711.07971" rel="nofollow"&gt;Non-local Neural Networks&lt;/a&gt;".&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="demo/ava_demo.gif"&gt;&lt;img src="demo/ava_demo.gif" width="600px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The goal of PySlowFast is to provide a high-performance, light-weight pytorch codebase provides state-of-the-art video backbones for video understanding research. It is designed in order to support rapid implementation and evaluation of novel video research ideas. PySlowFast includes implementations of the following backbone network architectures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SlowFast&lt;/li&gt;
&lt;li&gt;SlowOnly&lt;/li&gt;
&lt;li&gt;C2D&lt;/li&gt;
&lt;li&gt;I3D&lt;/li&gt;
&lt;li&gt;Non-local Network&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h2&gt;
&lt;p&gt;PySlowFast is released in conjunction with our &lt;a href="https://alexander-kirillov.github.io/tutorials/visual-recognition-iccv19/" rel="nofollow"&gt;ICCV 2019 Tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;PySlowFast is released under the &lt;a href="LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-zoo-and-baselines" class="anchor" aria-hidden="true" href="#model-zoo-and-baselines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model Zoo and Baselines&lt;/h2&gt;
&lt;p&gt;We provide a large set of baseline results and trained models available for download in the PySlowFast &lt;a href="MODEL_ZOO.md"&gt;Model Zoo&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;Please find installation instructions for PyTorch and PySlowFast in &lt;a href="INSTALL.md"&gt;INSTALL.md&lt;/a&gt;. You may follow the instructions in &lt;a href="slowfast/datasets/DATASET.md"&gt;DATASET.md&lt;/a&gt; to prepare the datasets.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;Follow the example in &lt;a href="GETTING_STARTED.md"&gt;GETTING_STARTED.md&lt;/a&gt; to start playing video models with PySlowFast.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>facebookresearch</author><guid isPermaLink="false">https://github.com/facebookresearch/SlowFast</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>deezer/spleeter #8 in Python, Today</title><link>https://github.com/deezer/spleeter</link><description>&lt;p&gt;&lt;i&gt;Deezer source separation library including pretrained models.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/deezer/spleeter/raw/master/images/spleeter_logo.png"&gt;&lt;img src="https://github.com/deezer/spleeter/raw/master/images/spleeter_logo.png" height="80" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://badge.fury.io/py/spleeter" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/384c6765b84c81f0c37f7f1504ef7d512a97ee9f/68747470733a2f2f62616467652e667572792e696f2f70792f73706c65657465722e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/spleeter.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/220130f46de51248362c8b4643e71243fe88dc3e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f73706c6565746572"&gt;&lt;img src="https://camo.githubusercontent.com/220130f46de51248362c8b4643e71243fe88dc3e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f73706c6565746572" alt="Conda" data-canonical-src="https://img.shields.io/conda/dn/conda-forge/spleeter" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b20de8e30b90fda67073582722d7cf1b26ffa3e2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f73706c6565746572"&gt;&lt;img src="https://camo.githubusercontent.com/b20de8e30b90fda67073582722d7cf1b26ffa3e2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f73706c6565746572" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/spleeter" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-about" class="anchor" aria-hidden="true" href="#about"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Spleeter&lt;/strong&gt; is the &lt;a href="https://www.deezer.com/" rel="nofollow"&gt;Deezer&lt;/a&gt; source separation library with pretrained models
written in &lt;a href="https://www.python.org/" rel="nofollow"&gt;Python&lt;/a&gt; and uses &lt;a href="tensorflow.org/"&gt;Tensorflow&lt;/a&gt;. It makes it easy
to train source separation model (assuming you have a dataset of isolated sources), and provides
already trained state of the art model for performing various flavour of separation :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vocals (singing voice) / accompaniment separation (&lt;a href="https://github.com/deezer/spleeter/wiki/2.-Getting-started#using-2stems-model"&gt;2 stems&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Vocals / drums / bass / other separation (&lt;a href="https://github.com/deezer/spleeter/wiki/2.-Getting-started#using-4stems-model"&gt;4 stems&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Vocals / drums / bass / piano / other separation (&lt;a href="https://github.com/deezer/spleeter/wiki/2.-Getting-started#using-5stems-model"&gt;5 stems&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2 stems and 4 stems models have state of the art performances on the &lt;a href="https://sigsep.github.io/datasets/musdb.html" rel="nofollow"&gt;musdb&lt;/a&gt; dataset. &lt;strong&gt;Spleeter&lt;/strong&gt; is also very fast as it can perform separation of audio files to 4 stems 100x faster than real-time when run on a GPU.&lt;/p&gt;
&lt;p&gt;We designed &lt;strong&gt;Spleeter&lt;/strong&gt; so you can use it straight from &lt;a href="https://github.com/deezer/spleeter/wiki/2.-Getting-started#usage"&gt;command line&lt;/a&gt;
as well as directly in your own development pipeline as a &lt;a href="https://github.com/deezer/spleeter/wiki/4.-API-Reference#separator"&gt;Python library&lt;/a&gt;. It can be installed with &lt;a href="https://github.com/deezer/spleeter/wiki/1.-Installation#using-conda"&gt;Conda&lt;/a&gt;,
with &lt;a href="https://github.com/deezer/spleeter/wiki/1.-Installation#using-pip"&gt;pip&lt;/a&gt; or be used with
&lt;a href="https://github.com/deezer/spleeter/wiki/2.-Getting-started#using-docker-image"&gt;Docker&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick start&lt;/h2&gt;
&lt;p&gt;Want to try it out ? Just clone the repository and install a
&lt;a href="https://github.com/deezer/spleeter/wiki/1.-Installation#using-conda"&gt;Conda&lt;/a&gt;
environment to start separating audio file as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/Deezer/spleeter
conda env create -f spleeter/conda/spleeter-cpu.yaml
conda activate spleeter-cpu
spleeter separate -i spleeter/audio_example.mp3 -p spleeter:2stems -o output&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should get two separated audio files (&lt;code&gt;vocals.wav&lt;/code&gt; and &lt;code&gt;accompaniment.wav&lt;/code&gt;)
in the &lt;code&gt;output/audio_example&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;For a more detailed documentation, please check the &lt;a href="https://github.com/deezer/spleeter/wiki"&gt;repository wiki&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-reference" class="anchor" aria-hidden="true" href="#reference"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reference&lt;/h2&gt;
&lt;p&gt;If you use &lt;strong&gt;Spleeter&lt;/strong&gt; in your work, please cite:&lt;/p&gt;
&lt;div class="highlight highlight-text-bibtex"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;@misc&lt;/span&gt;{&lt;span class="pl-en"&gt;spleeter2019&lt;/span&gt;,
  &lt;span class="pl-s"&gt;title&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;Spleeter: A Fast And State-of-the Art Music Source Separation Tool With Pre-trained Models&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;author&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;Romain Hennequin and Anis Khlif and Felix Voituret and Manuel Moussallam&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;howpublished&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;Late-Breaking/Demo ISMIR 2019&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;month&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;November&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;year&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;2019&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;The code of &lt;strong&gt;Spleeter&lt;/strong&gt; is MIT-licensed.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-note" class="anchor" aria-hidden="true" href="#note"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Note&lt;/h2&gt;
&lt;p&gt;This repository include a demo audio file &lt;code&gt;audio_example.mp3&lt;/code&gt; which is an excerpt
from Slow Motion Dream by Steven M Bryant (c) copyright 2011 Licensed under a Creative
Commons Attribution (3.0) license. &lt;a href="http://dig.ccmixter.org/files/stevieb357/34740" rel="nofollow"&gt;http://dig.ccmixter.org/files/stevieb357/34740&lt;/a&gt;
Ft: CSoul,Alex Beroza &amp;amp; Robert Siekawitch&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>deezer</author><guid isPermaLink="false">https://github.com/deezer/spleeter</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>evildmp/BrachioGraph #9 in Python, Today</title><link>https://github.com/evildmp/BrachioGraph</link><description>&lt;p&gt;&lt;i&gt;BrachioGraph is an ultra-cheap (total cost of materials: ‚Ç¨14) plotter that can be built with minimal skills.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-brachiograph---the-cheapest-simplest-possible-pen-plotter" class="anchor" aria-hidden="true" href="#brachiograph---the-cheapest-simplest-possible-pen-plotter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BrachioGraph - the cheapest, simplest possible pen-plotter&lt;/h1&gt;
&lt;p&gt;BrachioGraph is an ultra-cheap (total cost of materials: ~‚Ç¨14) plotter that can be built with minimal skills.&lt;/p&gt;
&lt;p&gt;At its heart is a Raspberry Pi Zero and some relatively simple custom software, driving three servo motors.&lt;/p&gt;
&lt;p&gt;The mechanical hardware can be built from nothing but stiff card, a pen or pencil and some glue. The only tools required are a ruler and a sharp knife.&lt;/p&gt;
&lt;p&gt;Almost everything required can be found in a desk or kitchen drawer. The entire device can be built with no special skills in about an hour.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/images/readme_combined_image.png"&gt;&lt;img alt="docs/images/readme_combined_image.png" src="docs/images/readme_combined_image.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a name="user-content-documentation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;The full documentation of the project, with detailed instructions on how to use it,
&lt;a href="https://brachiograph.readthedocs.io/en/latest/" rel="nofollow"&gt;can be found here&lt;/a&gt;&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>evildmp</author><guid isPermaLink="false">https://github.com/evildmp/BrachioGraph</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>huggingface/transformers #10 in Python, Today</title><link>https://github.com/huggingface/transformers</link><description>&lt;p&gt;&lt;i&gt;ü§ó Transformers: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
    &lt;br&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png"&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png" width="400" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;br&gt;
&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;&lt;p align="center"&gt;
    &lt;a href="https://circleci.com/gh/huggingface/transformers" rel="nofollow"&gt;
        &lt;img alt="Build" src="https://camo.githubusercontent.com/045b8639882280ff5cd38c403499977386c25134/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f6275696c642f6769746875622f68756767696e67666163652f7472616e73666f726d6572732f6d6173746572" data-canonical-src="https://img.shields.io/circleci/build/github/huggingface/transformers/master" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://github.com/huggingface/transformers/blob/master/LICENSE"&gt;
        &lt;img alt="GitHub" src="https://camo.githubusercontent.com/440e73b137335cc0088bb06e6c90cc7b503b14a2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f68756767696e67666163652f7472616e73666f726d6572732e7376673f636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://huggingface.co/transformers/index.html" rel="nofollow"&gt;
        &lt;img alt="Documentation" src="https://camo.githubusercontent.com/b104c21f478c4d4a37f63292ab2898047f19ee24/68747470733a2f2f696d672e736869656c64732e696f2f776562736974652f687474702f68756767696e67666163652e636f2f7472616e73666f726d6572732f696e6465782e68746d6c2e7376673f646f776e5f636f6c6f723d72656426646f776e5f6d6573736167653d6f66666c696e652675705f6d6573736167653d6f6e6c696e65" data-canonical-src="https://img.shields.io/website/http/huggingface.co/transformers/index.html.svg?down_color=red&amp;amp;down_message=offline&amp;amp;up_message=online" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://github.com/huggingface/transformers/releases"&gt;
        &lt;img alt="GitHub release" src="https://camo.githubusercontent.com/8409fd8716dd1a11afa7ab38e1218b34918164eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f68756767696e67666163652f7472616e73666f726d6572732e737667" data-canonical-src="https://img.shields.io/github/release/huggingface/transformers.svg" style="max-width:100%;"&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;h3 align="center"&gt;&lt;a id="user-content-state-of-the-art-natural-language-processing-for-tensorflow-20-and-pytorch" class="anchor" aria-hidden="true" href="#state-of-the-art-natural-language-processing-for-tensorflow-20-and-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;p&gt;State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch
&lt;/p&gt;&lt;/h3&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ü§ó&lt;/g-emoji&gt; Transformers (formerly known as &lt;code&gt;pytorch-transformers&lt;/code&gt; and &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt;) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;As easy to use as pytorch-transformers&lt;/li&gt;
&lt;li&gt;As powerful and concise as Keras&lt;/li&gt;
&lt;li&gt;High performance on NLU and NLG tasks&lt;/li&gt;
&lt;li&gt;Low barrier to entry for educators and practitioners&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;State-of-the-art NLP for everyone&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deep learning researchers&lt;/li&gt;
&lt;li&gt;Hands-on practitioners&lt;/li&gt;
&lt;li&gt;AI/ML/NLP teachers and educators&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lower compute costs, smaller carbon footprint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Researchers can share trained models instead of always retraining&lt;/li&gt;
&lt;li&gt;Practitioners can reduce compute time and production costs&lt;/li&gt;
&lt;li&gt;10 architectures with over 30 pretrained models, some in more than 100 languages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Choose the right framework for every part of a model's lifetime&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Train state-of-the-art models in 3 lines of code&lt;/li&gt;
&lt;li&gt;Deep interoperability between TensorFlow 2.0 and PyTorch models&lt;/li&gt;
&lt;li&gt;Move a single model between TF2.0/PyTorch frameworks at will&lt;/li&gt;
&lt;li&gt;Seamlessly pick the right framework for training, evaluation, production&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Section&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;How to install the package&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#model-architectures"&gt;Model architectures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Architectures (with pretrained weights)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#online-demo"&gt;Online demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Experimenting with this repo‚Äôs text generation capabilities&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#quick-tour"&gt;Quick tour: Usage&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Tokenizers &amp;amp; models usage: Bert and GPT-2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Quick-tour-TF-20-training-and-PyTorch-interoperability"&gt;Quick tour: TF 2.0 and PyTorch &lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Train a TF 2.0 model in 10 lines of code, load it in PyTorch&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#quick-tour-of-the-fine-tuningusage-scripts"&gt;Quick tour: Fine-tuning/usage scripts&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Using provided scripts: GLUE, SQuAD and Text generation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Migrating-from-pytorch-transformers-to-transformers"&gt;Migrating from pytorch-transformers to transformers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Migrating your code from pytorch-transformers to transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="#Migrating-from-pytorch-pretrained-bert-to-transformers"&gt;Migrating from pytorch-pretrained-bert to pytorch-transformers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Migrating your code from pytorch-pretrained-bert to transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;Documentation&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v2.1.1" rel="nofollow"&gt;(v2.1.1)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v2.0.0" rel="nofollow"&gt;(v2.0.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.2.0" rel="nofollow"&gt;(v1.2.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.1.0" rel="nofollow"&gt;(v1.1.0)&lt;/a&gt; &lt;a href="https://huggingface.co/transformers/v1.0.0" rel="nofollow"&gt;(v1.0.0)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Full API documentation and more&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;This repo is tested on Python 2.7 and 3.5+ (examples are tested only on python 3.5+), PyTorch 1.0.0+ and TensorFlow 2.0.0-rc1&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-with-pip" class="anchor" aria-hidden="true" href="#with-pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;With pip&lt;/h3&gt;
&lt;p&gt;First you need to install one of, or both, TensorFlow 2.0 and PyTorch.
Please refer to &lt;a href="https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available" rel="nofollow"&gt;TensorFlow installation page&lt;/a&gt; and/or &lt;a href="https://pytorch.org/get-started/locally/#start-locally" rel="nofollow"&gt;PyTorch installation page&lt;/a&gt; regarding the specific install command for your platform.&lt;/p&gt;
&lt;p&gt;When TensorFlow 2.0 and/or PyTorch has been installed, &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ü§ó&lt;/g-emoji&gt; Transformers can be installed using pip as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install transformers&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-from-source" class="anchor" aria-hidden="true" href="#from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;From source&lt;/h3&gt;
&lt;p&gt;Here also, you first need to install one of, or both, TensorFlow 2.0 and PyTorch.
Please refer to &lt;a href="https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-available" rel="nofollow"&gt;TensorFlow installation page&lt;/a&gt; and/or &lt;a href="https://pytorch.org/get-started/locally/#start-locally" rel="nofollow"&gt;PyTorch installation page&lt;/a&gt; regarding the specific install command for your platform.&lt;/p&gt;
&lt;p&gt;When TensorFlow 2.0 and/or PyTorch has been installed, you can install from source by cloning the repository and running:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install [--editable] &lt;span class="pl-c1"&gt;.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-tests" class="anchor" aria-hidden="true" href="#tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tests&lt;/h3&gt;
&lt;p&gt;A series of tests are included for the library and the example scripts. Library tests can be found in the &lt;a href="https://github.com/huggingface/transformers/tree/master/transformers/tests"&gt;tests folder&lt;/a&gt; and examples tests in the &lt;a href="https://github.com/huggingface/transformers/tree/master/examples"&gt;examples folder&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These tests can be run using &lt;code&gt;pytest&lt;/code&gt; (install pytest if needed with &lt;code&gt;pip install pytest&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Depending on which framework is installed (TensorFlow 2.0 and/or PyTorch), the irrelevant tests will be skipped. Ensure that both frameworks are installed if you want to execute all tests.&lt;/p&gt;
&lt;p&gt;You can run the tests from the root of the cloned repository with the commands:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m pytest -sv ./transformers/tests/
python -m pytest -sv ./examples/&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-do-you-want-to-run-a-transformer-model-on-a-mobile-device" class="anchor" aria-hidden="true" href="#do-you-want-to-run-a-transformer-model-on-a-mobile-device"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Do you want to run a Transformer model on a mobile device?&lt;/h3&gt;
&lt;p&gt;You should check out our &lt;a href="https://github.com/huggingface/swift-coreml-transformers"&gt;&lt;code&gt;swift-coreml-transformers&lt;/code&gt;&lt;/a&gt; repo.&lt;/p&gt;
&lt;p&gt;It contains a set of tools to convert PyTorch or TensorFlow 2.0 trained Transformer models (currently contains &lt;code&gt;GPT-2&lt;/code&gt;, &lt;code&gt;DistilGPT-2&lt;/code&gt;, &lt;code&gt;BERT&lt;/code&gt;, and &lt;code&gt;DistilBERT&lt;/code&gt;) to CoreML models that run on iOS devices.&lt;/p&gt;
&lt;p&gt;At some point in the future, you'll be able to seamlessly move from pre-training or fine-tuning models to productizing them in CoreML, or prototype a model or an app in CoreML then research its hyperparameters or architecture from TensorFlow 2.0 and/or PyTorch. Super exciting!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-model-architectures" class="anchor" aria-hidden="true" href="#model-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model architectures&lt;/h2&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ü§ó&lt;/g-emoji&gt; Transformers currently provides 10 NLU/NLG architectures:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/google-research/bert"&gt;BERT&lt;/a&gt;&lt;/strong&gt; (from Google) released with the paper &lt;a href="https://arxiv.org/abs/1810.04805" rel="nofollow"&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt; by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/openai/finetune-transformer-lm"&gt;GPT&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href="https://blog.openai.com/language-unsupervised/" rel="nofollow"&gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt; by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://blog.openai.com/better-language-models/" rel="nofollow"&gt;GPT-2&lt;/a&gt;&lt;/strong&gt; (from OpenAI) released with the paper &lt;a href="https://blog.openai.com/better-language-models/" rel="nofollow"&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt; by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/kimiyoung/transformer-xl"&gt;Transformer-XL&lt;/a&gt;&lt;/strong&gt; (from Google/CMU) released with the paper &lt;a href="https://arxiv.org/abs/1901.02860" rel="nofollow"&gt;Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context&lt;/a&gt; by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/zihangdai/xlnet/"&gt;XLNet&lt;/a&gt;&lt;/strong&gt; (from Google/CMU) released with the paper &lt;a href="https://arxiv.org/abs/1906.08237" rel="nofollow"&gt;‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding&lt;/a&gt; by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/facebookresearch/XLM/"&gt;XLM&lt;/a&gt;&lt;/strong&gt; (from Facebook) released together with the paper &lt;a href="https://arxiv.org/abs/1901.07291" rel="nofollow"&gt;Cross-lingual Language Model Pretraining&lt;/a&gt; by Guillaume Lample and Alexis Conneau.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/pytorch/fairseq/tree/master/examples/roberta"&gt;RoBERTa&lt;/a&gt;&lt;/strong&gt; (from Facebook), released together with the paper a &lt;a href="https://arxiv.org/abs/1907.11692" rel="nofollow"&gt;Robustly Optimized BERT Pretraining Approach&lt;/a&gt; by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/huggingface/transformers/tree/master/examples/distillation"&gt;DistilBERT&lt;/a&gt;&lt;/strong&gt; (from HuggingFace), released together with the paper &lt;a href="https://arxiv.org/abs/1910.01108" rel="nofollow"&gt;DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter&lt;/a&gt; by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into &lt;a href="https://github.com/huggingface/transformers/tree/master/examples/distillation"&gt;DistilGPT2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/salesforce/ctrl/"&gt;CTRL&lt;/a&gt;&lt;/strong&gt; (from Salesforce) released with the paper &lt;a href="https://arxiv.org/abs/1909.05858" rel="nofollow"&gt;CTRL: A Conditional Transformer Language Model for Controllable Generation&lt;/a&gt; by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.&lt;/li&gt;
&lt;li&gt;Want to contribute a new model? We have added a &lt;strong&gt;detailed guide and templates&lt;/strong&gt; to guide you in the process of adding a new model. You can find them in the &lt;a href="./templates"&gt;&lt;code&gt;templates&lt;/code&gt;&lt;/a&gt; folder of the repository. Be sure to check the &lt;a href="./CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; and contact the maintainers or open an issue to collect feedbacks before starting your PR.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These implementations have been tested on several datasets (see the example scripts) and should match the performances of the original implementations (e.g. ~93 F1 on SQuAD for BERT Whole-Word-Masking, ~88 F1 on RocStories for OpenAI GPT, ~18.3 perplexity on WikiText 103 for Transformer-XL, ~0.916 Peason R coefficient on STS-B for XLNet). You can find more details on the performances in the Examples section of the &lt;a href="https://huggingface.co/transformers/examples.html" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-online-demo" class="anchor" aria-hidden="true" href="#online-demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online demo&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://transformer.huggingface.co" rel="nofollow"&gt;Write With Transformer&lt;/a&gt;&lt;/strong&gt;, built by the Hugging Face team at transformer.huggingface.co, is the official demo of this repo‚Äôs text generation capabilities.
You can use it to experiment with completions generated by &lt;code&gt;GPT2Model&lt;/code&gt;, &lt;code&gt;TransfoXLModel&lt;/code&gt;, and &lt;code&gt;XLNetModel&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚Äú&lt;g-emoji class="g-emoji" alias="unicorn" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f984.png"&gt;ü¶Ñ&lt;/g-emoji&gt; Write with transformer is to writing what calculators are to calculus.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba91bf4a35939363eca4ca83f3ad3f83248bbc60/68747470733a2f2f7472616e73666f726d65722e68756767696e67666163652e636f2f66726f6e742f6173736574732f7468756d626e61696c2d6c617267652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba91bf4a35939363eca4ca83f3ad3f83248bbc60/68747470733a2f2f7472616e73666f726d65722e68756767696e67666163652e636f2f66726f6e742f6173736574732f7468756d626e61696c2d6c617267652e706e67" alt="write_with_transformer" data-canonical-src="https://transformer.huggingface.co/front/assets/thumbnail-large.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour" class="anchor" aria-hidden="true" href="#quick-tour"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour&lt;/h2&gt;
&lt;p&gt;Let's do a very quick overview of the model architectures in &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ü§ó&lt;/g-emoji&gt; Transformers. Detailed examples for each model architecture (Bert, GPT, GPT-2, Transformer-XL, XLNet and XLM) can be found in the &lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;full documentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; torch
&lt;span class="pl-k"&gt;from&lt;/span&gt; transformers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Transformers has a unified API&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; for 8 transformer architectures and 30 pretrained weights.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;          Model          | Tokenizer          | Pretrained weights shortcut&lt;/span&gt;
&lt;span class="pl-c1"&gt;MODELS&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [(BertModel,       BertTokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (OpenAIGPTModel,  OpenAIGPTTokenizer,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;openai-gpt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (GPT2Model,       GPT2Tokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;gpt2&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (CTRLModel,       CTRLTokenizer,       &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ctrl&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (TransfoXLModel,  TransfoXLTokenizer,  &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;transfo-xl-wt103&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (XLNetModel,      XLNetTokenizer,      &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;xlnet-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (XLMModel,        XLMTokenizer,        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;xlm-mlm-enfr-1024&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (DistilBertModel, DistilBertTokenizer, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;distilbert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;),
          (RobertaModel,    RobertaTokenizer,    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;roberta-base&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Let's encode some text in a sequence of hidden-states using each model:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; model_class, tokenizer_class, pretrained_weights &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;MODELS&lt;/span&gt;:
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load pretrained model/tokenizer&lt;/span&gt;
    tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer_class.from_pretrained(pretrained_weights)
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Encode text&lt;/span&gt;
    input_ids &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.tensor([tokenizer.encode(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Here is some text to encode&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)])  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Add special tokens takes care of adding [CLS], [SEP], &amp;lt;s&amp;gt;... tokens in the right way for each model.&lt;/span&gt;
    &lt;span class="pl-k"&gt;with&lt;/span&gt; torch.no_grad():
        last_hidden_states &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids)[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models outputs are now tuples&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.&lt;/span&gt;
&lt;span class="pl-c1"&gt;BERT_MODEL_CLASSES&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,
                      BertForSequenceClassification, BertForMultipleChoice, BertForTokenClassification,
                      BertForQuestionAnswering]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; All the classes for an architecture can be initiated from pretrained weights for this architecture&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Note that additional weights added for fine-tuning are only initialized&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; and need to be trained on the down-stream task&lt;/span&gt;
pretrained_weights &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(pretrained_weights)
&lt;span class="pl-k"&gt;for&lt;/span&gt; model_class &lt;span class="pl-k"&gt;in&lt;/span&gt; &lt;span class="pl-c1"&gt;BERT_MODEL_CLASSES&lt;/span&gt;:
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load pretrained model/tokenizer&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights)

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models can return full list of hidden-states &amp;amp; attentions weights at each layer&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights,
                                        &lt;span class="pl-v"&gt;output_hidden_states&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;,
                                        &lt;span class="pl-v"&gt;output_attentions&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
    input_ids &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.tensor([tokenizer.encode(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Let's see all hidden-states and attentions on this text&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)])
    all_hidden_states, all_attentions &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids)[&lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;:]

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Models are compatible with Torchscript&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(pretrained_weights, &lt;span class="pl-v"&gt;torchscript&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
    traced_model &lt;span class="pl-k"&gt;=&lt;/span&gt; torch.jit.trace(model, (input_ids,))

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Simple serialization for models and tokenizers&lt;/span&gt;
    model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; save&lt;/span&gt;
    model &lt;span class="pl-k"&gt;=&lt;/span&gt; model_class.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; re-load&lt;/span&gt;
    tokenizer.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; save&lt;/span&gt;
    tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./directory/to/save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; re-load&lt;/span&gt;

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; SOTA examples for GLUE, SQUAD, text generation...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour-tf-20-training-and-pytorch-interoperability" class="anchor" aria-hidden="true" href="#quick-tour-tf-20-training-and-pytorch-interoperability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour TF 2.0 training and PyTorch interoperability&lt;/h2&gt;
&lt;p&gt;Let's do a quick example of how a TensorFlow 2.0 model can be trained in 12 lines of code with &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ü§ó&lt;/g-emoji&gt; Transformers and then loaded in PyTorch for fast inspection/tests.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow &lt;span class="pl-k"&gt;as&lt;/span&gt; tf
&lt;span class="pl-k"&gt;import&lt;/span&gt; tensorflow_datasets
&lt;span class="pl-k"&gt;from&lt;/span&gt; transformers &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-k"&gt;*&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load dataset, tokenizer, model from pretrained model/vocabulary&lt;/span&gt;
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
model &lt;span class="pl-k"&gt;=&lt;/span&gt; TFBertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-cased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
data &lt;span class="pl-k"&gt;=&lt;/span&gt; tensorflow_datasets.load(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;glue/mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Prepare dataset for GLUE as a tf.data.Dataset instance&lt;/span&gt;
train_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; glue_convert_examples_to_features(data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;train&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], tokenizer, &lt;span class="pl-v"&gt;max_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;task&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
valid_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; glue_convert_examples_to_features(data[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;validation&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], tokenizer, &lt;span class="pl-v"&gt;max_length&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;128&lt;/span&gt;, &lt;span class="pl-v"&gt;task&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;mrpc&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
train_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; train_dataset.shuffle(&lt;span class="pl-c1"&gt;100&lt;/span&gt;).batch(&lt;span class="pl-c1"&gt;32&lt;/span&gt;).repeat(&lt;span class="pl-c1"&gt;2&lt;/span&gt;)
valid_dataset &lt;span class="pl-k"&gt;=&lt;/span&gt; valid_dataset.batch(&lt;span class="pl-c1"&gt;64&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule &lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.optimizers.Adam(&lt;span class="pl-v"&gt;learning_rate&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;3e-5&lt;/span&gt;, &lt;span class="pl-v"&gt;epsilon&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1e-08&lt;/span&gt;, &lt;span class="pl-v"&gt;clipnorm&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;1.0&lt;/span&gt;)
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.losses.SparseCategoricalCrossentropy(&lt;span class="pl-v"&gt;from_logits&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
metric &lt;span class="pl-k"&gt;=&lt;/span&gt; tf.keras.metrics.SparseCategoricalAccuracy(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;accuracy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
model.compile(&lt;span class="pl-v"&gt;optimizer&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;optimizer, &lt;span class="pl-v"&gt;loss&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;loss, &lt;span class="pl-v"&gt;metrics&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;[metric])

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train and evaluate using tf.keras.Model.fit()&lt;/span&gt;
history &lt;span class="pl-k"&gt;=&lt;/span&gt; model.fit(train_dataset, &lt;span class="pl-v"&gt;epochs&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-v"&gt;steps_per_epoch&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;115&lt;/span&gt;,
                    &lt;span class="pl-v"&gt;validation_data&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;valid_dataset, &lt;span class="pl-v"&gt;validation_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;7&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Load the TensorFlow model in PyTorch for inspection&lt;/span&gt;
model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
pytorch_model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./save/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;from_tf&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Quickly test a few predictions - MRPC is a paraphrasing task, let's see if our model learned the task&lt;/span&gt;
sentence_0 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;This research was consistent with his findings.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
sentence_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;His findings were compatible with this research.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
sentence_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;His findings were not compatible with this research.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
inputs_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer.encode_plus(sentence_0, sentence_1, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-v"&gt;return_tensors&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
inputs_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; tokenizer.encode_plus(sentence_0, sentence_2, &lt;span class="pl-v"&gt;add_special_tokens&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;, &lt;span class="pl-v"&gt;return_tensors&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;pt&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

pred_1 &lt;span class="pl-k"&gt;=&lt;/span&gt; pytorch_model(inputs_1[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], &lt;span class="pl-v"&gt;token_type_ids&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;inputs_1[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;token_type_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].argmax().item()
pred_2 &lt;span class="pl-k"&gt;=&lt;/span&gt; pytorch_model(inputs_2[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;input_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;], &lt;span class="pl-v"&gt;token_type_ids&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;inputs_2[&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;token_type_ids&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])[&lt;span class="pl-c1"&gt;0&lt;/span&gt;].argmax().item()

&lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sentence_1 is&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; pred_1 &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;not a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;of sentence_0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-c1"&gt;print&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;sentence_2 is&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;if&lt;/span&gt; pred_2 &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;not a paraphrase&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;of sentence_0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-quick-tour-of-the-fine-tuningusage-scripts" class="anchor" aria-hidden="true" href="#quick-tour-of-the-fine-tuningusage-scripts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick tour of the fine-tuning/usage scripts&lt;/h2&gt;
&lt;p&gt;The library comprises several example scripts with SOTA performances for NLU and NLG tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;run_glue.py&lt;/code&gt;: an example fine-tuning Bert, XLNet and XLM on nine different GLUE tasks (&lt;em&gt;sequence-level classification&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_squad.py&lt;/code&gt;: an example fine-tuning Bert, XLNet and XLM on the question answering dataset SQuAD 2.0 (&lt;em&gt;token-level classification&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_generation.py&lt;/code&gt;: an example using GPT, GPT-2, CTRL, Transformer-XL and XLNet for conditional language generation&lt;/li&gt;
&lt;li&gt;other model-specific examples (see the documentation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are three quick usage examples for these scripts:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run_gluepy-fine-tuning-on-glue-tasks-for-sequence-classification" class="anchor" aria-hidden="true" href="#run_gluepy-fine-tuning-on-glue-tasks-for-sequence-classification"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_glue.py&lt;/code&gt;: Fine-tuning on GLUE tasks for sequence classification&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://gluebenchmark.com/" rel="nofollow"&gt;General Language Understanding Evaluation (GLUE) benchmark&lt;/a&gt; is a collection of nine sentence- or sentence-pair language understanding tasks for evaluating and analyzing natural language understanding systems.&lt;/p&gt;
&lt;p&gt;Before running anyone of these GLUE tasks you should download the
&lt;a href="https://gluebenchmark.com/tasks" rel="nofollow"&gt;GLUE data&lt;/a&gt; by running
&lt;a href="https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e"&gt;this script&lt;/a&gt;
and unpack it to some directory &lt;code&gt;$GLUE_DIR&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You should also install the additional packages required by the examples:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install -r ./examples/requirements.txt&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue
&lt;span class="pl-k"&gt;export&lt;/span&gt; TASK_NAME=MRPC

python ./examples/run_glue.py \
    --model_type bert \
    --model_name_or_path bert-base-uncased \
    --task_name &lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt; \
    --do_train \
    --do_eval \
    --do_lower_case \
    --data_dir &lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/&lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt; \
    --max_seq_length 128 \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --learning_rate 2e-5 \
    --num_train_epochs 3.0 \
    --output_dir /tmp/&lt;span class="pl-smi"&gt;$TASK_NAME&lt;/span&gt;/&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where task name can be one of CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, RTE, WNLI.&lt;/p&gt;
&lt;p&gt;The dev set results will be present within the text file 'eval_results.txt' in the specified output_dir. In case of MNLI, since there are two separate dev sets, matched and mismatched, there will be a separate output folder called '/tmp/MNLI-MM/' in addition to '/tmp/MNLI/'.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-fine-tuning-xlnet-model-on-the-sts-b-regression-task" class="anchor" aria-hidden="true" href="#fine-tuning-xlnet-model-on-the-sts-b-regression-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning XLNet model on the STS-B regression task&lt;/h4&gt;
&lt;p&gt;This example code fine-tunes XLNet on the STS-B corpus using parallel training on a server with 4 V100 GPUs.
Parallel training is a simple way to use several GPUs (but is slower and less flexible than distributed training, see below).&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; GLUE_DIR=/path/to/glue

python ./examples/run_glue.py \
    --model_type xlnet \
    --model_name_or_path xlnet-large-cased \
    --do_train  \
    --do_eval   \
    --task_name=sts-b     \
    --data_dir=&lt;span class="pl-smi"&gt;${GLUE_DIR}&lt;/span&gt;/STS-B  \
    --output_dir=./proc_data/sts-b-110   \
    --max_seq_length=128   \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --gradient_accumulation_steps=1 \
    --max_steps=1200  \
    --model_name=xlnet-large-cased   \
    --overwrite_output_dir   \
    --overwrite_cache \
    --warmup_steps=120&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On this machine we thus have a batch size of 32, please increase &lt;code&gt;gradient_accumulation_steps&lt;/code&gt; to reach the same batch size if you have a smaller machine. These hyper-parameters should result in a Pearson correlation coefficient of &lt;code&gt;+0.917&lt;/code&gt; on the development set.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-fine-tuning-bert-model-on-the-mrpc-classification-task" class="anchor" aria-hidden="true" href="#fine-tuning-bert-model-on-the-mrpc-classification-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fine-tuning Bert model on the MRPC classification task&lt;/h4&gt;
&lt;p&gt;This example code fine-tunes the Bert Whole Word Masking model on the Microsoft Research Paraphrase Corpus (MRPC) corpus using distributed training on 8 V100 GPUs to reach a F1 &amp;gt; 92.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m torch.distributed.launch --nproc_per_node 8 ./examples/run_glue.py   \
    --model_type bert \
    --model_name_or_path bert-large-uncased-whole-word-masking \
    --task_name MRPC \
    --do_train   \
    --do_eval   \
    --do_lower_case   \
    --data_dir &lt;span class="pl-smi"&gt;$GLUE_DIR&lt;/span&gt;/MRPC/   \
    --max_seq_length 128   \
    --per_gpu_eval_batch_size=8   \
    --per_gpu_train_batch_size=8   \
    --learning_rate 2e-5   \
    --num_train_epochs 3.0  \
    --output_dir /tmp/mrpc_output/ \
    --overwrite_output_dir   \
    --overwrite_cache \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Training with these hyper-parameters gave us the following results:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;  acc = 0.8823529411764706
  acc_and_f1 = 0.901702786377709
  eval_loss = 0.3418912578906332
  f1 = 0.9210526315789473
  global_step = 174
  loss = 0.07231863956341798&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-run_squadpy-fine-tuning-on-squad-for-question-answering" class="anchor" aria-hidden="true" href="#run_squadpy-fine-tuning-on-squad-for-question-answering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_squad.py&lt;/code&gt;: Fine-tuning on SQuAD for question-answering&lt;/h3&gt;
&lt;p&gt;This example code fine-tunes BERT on the SQuAD dataset using distributed training on 8 V100 GPUs and Bert Whole Word Masking uncased model to reach a F1 &amp;gt; 93 on SQuAD:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m torch.distributed.launch --nproc_per_node=8 ./examples/run_squad.py \
    --model_type bert \
    --model_name_or_path bert-large-uncased-whole-word-masking \
    --do_train \
    --do_eval \
    --do_lower_case \
    --train_file &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/train-v1.1.json \
    --predict_file &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json \
    --learning_rate 3e-5 \
    --num_train_epochs 2 \
    --max_seq_length 384 \
    --doc_stride 128 \
    --output_dir ../models/wwm_uncased_finetuned_squad/ \
    --per_gpu_eval_batch_size=3   \
    --per_gpu_train_batch_size=3   \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Training with these hyper-parameters gave us the following results:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/evaluate-v1.1.py &lt;span class="pl-smi"&gt;$SQUAD_DIR&lt;/span&gt;/dev-v1.1.json ../models/wwm_uncased_finetuned_squad/predictions.json
{&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;exact_match&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 86.91579943235573, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;f1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;: 93.1532499015869}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the model provided as &lt;code&gt;bert-large-uncased-whole-word-masking-finetuned-squad&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-run_generationpy-text-generation-with-gpt-gpt-2-ctrl-transformer-xl-and-xlnet" class="anchor" aria-hidden="true" href="#run_generationpy-text-generation-with-gpt-gpt-2-ctrl-transformer-xl-and-xlnet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;run_generation.py&lt;/code&gt;: Text generation with GPT, GPT-2, CTRL, Transformer-XL and XLNet&lt;/h3&gt;
&lt;p&gt;A conditional generation script is also included to generate text from a prompt.
The generation script includes the &lt;a href="https://github.com/rusiaaman/XLNet-gen#methodology"&gt;tricks&lt;/a&gt; proposed by Aman Rusia to get high-quality generation with memory models like Transformer-XL and XLNet (include a predefined text to make short inputs longer).&lt;/p&gt;
&lt;p&gt;Here is how to run the script with the small version of OpenAI GPT-2 model:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./examples/run_generation.py \
    --model_type=gpt2 \
    --length=20 \
    --model_name_or_path=gpt2 \&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and from the Salesforce CTRL model:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python ./examples/run_generation.py \
    --model_type=ctrl \
    --length=20 \
    --model_name_or_path=ctrl \
    --temperature=0 \
    --repetition_penalty=1.2 \&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-migrating-from-pytorch-transformers-to-transformers" class="anchor" aria-hidden="true" href="#migrating-from-pytorch-transformers-to-transformers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Migrating from pytorch-transformers to transformers&lt;/h2&gt;
&lt;p&gt;Here is a quick summary of what you should take care of when migrating from &lt;code&gt;pytorch-transformers&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-positional-order-of-some-models-keywords-inputs-attention_mask-token_type_ids-changed" class="anchor" aria-hidden="true" href="#positional-order-of-some-models-keywords-inputs-attention_mask-token_type_ids-changed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Positional order of some models' keywords inputs (&lt;code&gt;attention_mask&lt;/code&gt;, &lt;code&gt;token_type_ids&lt;/code&gt;...) changed&lt;/h3&gt;
&lt;p&gt;To be able to use Torchscript (see #1010, #1204 and #1195) the specific order of some models &lt;strong&gt;keywords inputs&lt;/strong&gt; (&lt;code&gt;attention_mask&lt;/code&gt;, &lt;code&gt;token_type_ids&lt;/code&gt;...) has been changed.&lt;/p&gt;
&lt;p&gt;If you used to call the models with keyword names for keyword arguments, e.g. &lt;code&gt;model(inputs_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)&lt;/code&gt;, this should not cause any change.&lt;/p&gt;
&lt;p&gt;If you used to call the models with positional inputs for keyword arguments, e.g. &lt;code&gt;model(inputs_ids, attention_mask, token_type_ids)&lt;/code&gt;, you may have to double check the exact order of input arguments.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-migrating-from-pytorch-pretrained-bert-to-transformers" class="anchor" aria-hidden="true" href="#migrating-from-pytorch-pretrained-bert-to-transformers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Migrating from pytorch-pretrained-bert to transformers&lt;/h2&gt;
&lt;p&gt;Here is a quick summary of what you should take care of when migrating from &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-models-always-output-tuples" class="anchor" aria-hidden="true" href="#models-always-output-tuples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models always output &lt;code&gt;tuples&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The main breaking change when migrating from &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt; is that every model's forward method always outputs a &lt;code&gt;tuple&lt;/code&gt; with various elements depending on the model and the configuration parameters.&lt;/p&gt;
&lt;p&gt;The exact content of the tuples for each model is detailed in the models' docstrings and the &lt;a href="https://huggingface.co/transformers/" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In pretty much every case, you will be fine by taking the first element of the output as the output you previously used in &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is a &lt;code&gt;pytorch-pretrained-bert&lt;/code&gt; to &lt;code&gt;transformers&lt;/code&gt; conversion example for a &lt;code&gt;BertForSequenceClassification&lt;/code&gt; classification model:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Let's load our model&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; If you used to have this line in pytorch-pretrained-bert:&lt;/span&gt;
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Now just use this line in transformers to extract the loss from the output tuple:&lt;/span&gt;
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)
loss &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs[&lt;span class="pl-c1"&gt;0&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; In transformers you can also have access to the logits:&lt;/span&gt;
loss, logits &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs[:&lt;span class="pl-c1"&gt;2&lt;/span&gt;]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; And even the attention weights if you configure the model to output them (and other outputs too, see the docstrings and documentation)&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;output_attentions&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)
outputs &lt;span class="pl-k"&gt;=&lt;/span&gt; model(input_ids, &lt;span class="pl-v"&gt;labels&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;labels)
loss, logits, attentions &lt;span class="pl-k"&gt;=&lt;/span&gt; outputs&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-using-hidden-states" class="anchor" aria-hidden="true" href="#using-hidden-states"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using hidden states&lt;/h3&gt;
&lt;p&gt;By enabling the configuration option &lt;code&gt;output_hidden_states&lt;/code&gt;, it was possible to retrieve the last hidden states of the encoder. In &lt;code&gt;pytorch-transformers&lt;/code&gt; as well as &lt;code&gt;transformers&lt;/code&gt; the return value has changed slightly: &lt;code&gt;all_hidden_states&lt;/code&gt; now also includes the hidden state of the embeddings in addition to those of the encoding layers. This allows users to easily access the embeddings final state.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-serialization" class="anchor" aria-hidden="true" href="#serialization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Serialization&lt;/h3&gt;
&lt;p&gt;Breaking change in the &lt;code&gt;from_pretrained()&lt;/code&gt; method:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Models are now set in evaluation mode by default when instantiated with the &lt;code&gt;from_pretrained()&lt;/code&gt; method. To train them, don't forget to set them back in training mode (&lt;code&gt;model.train()&lt;/code&gt;) to activate the dropout modules.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The additional &lt;code&gt;*input&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; arguments supplied to the &lt;code&gt;from_pretrained()&lt;/code&gt; method used to be directly passed to the underlying model's class &lt;code&gt;__init__()&lt;/code&gt; method. They are now used to update the model configuration attribute instead, which can break derived model classes built based on the previous &lt;code&gt;BertForSequenceClassification&lt;/code&gt; examples. We are working on a way to mitigate this breaking change in &lt;a href="https://github.com/huggingface/transformers/pull/866"&gt;#866&lt;/a&gt; by forwarding the the model's &lt;code&gt;__init__()&lt;/code&gt; method (i) the provided positional arguments and (ii) the keyword arguments which do not match any configuration class attributes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Also, while not a breaking change, the serialization methods have been standardized and you probably should switch to the new method &lt;code&gt;save_pretrained(save_directory)&lt;/code&gt; if you were using any other serialization method before.&lt;/p&gt;
&lt;p&gt;Here is an example:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Let's load a model and tokenizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;bert-base-uncased&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Do some stuff to our model and tokenizer&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Ex: add new tokens to the vocabulary and embeddings of our model&lt;/span&gt;
tokenizer.add_tokens([&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;[SPECIAL_TOKEN_1]&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;[SPECIAL_TOKEN_2]&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;])
model.resize_token_embeddings(&lt;span class="pl-c1"&gt;len&lt;/span&gt;(tokenizer))
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train our model&lt;/span&gt;
train(model)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Now let's save our model and tokenizer to a directory&lt;/span&gt;
model.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer.save_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Reload the model and the tokenizer&lt;/span&gt;
model &lt;span class="pl-k"&gt;=&lt;/span&gt; BertForSequenceClassification.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)
tokenizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertTokenizer.from_pretrained(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./my_saved_model_directory/&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-optimizers-bertadam--openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules" class="anchor" aria-hidden="true" href="#optimizers-bertadam--openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Optimizers: BertAdam &amp;amp; OpenAIAdam are now AdamW, schedules are standard PyTorch schedules&lt;/h3&gt;
&lt;p&gt;The two optimizers previously included, &lt;code&gt;BertAdam&lt;/code&gt; and &lt;code&gt;OpenAIAdam&lt;/code&gt;, have been replaced by a single &lt;code&gt;AdamW&lt;/code&gt; optimizer which has a few differences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it only implements weights decay correction,&lt;/li&gt;
&lt;li&gt;schedules are now externals (see below),&lt;/li&gt;
&lt;li&gt;gradient clipping is now also external (see below).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The new optimizer &lt;code&gt;AdamW&lt;/code&gt; matches PyTorch &lt;code&gt;Adam&lt;/code&gt; optimizer API and let you use standard PyTorch or apex methods for the schedule and clipping.&lt;/p&gt;
&lt;p&gt;The schedules are now standard &lt;a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" rel="nofollow"&gt;PyTorch learning rate schedulers&lt;/a&gt; and not part of the optimizer anymore.&lt;/p&gt;
&lt;p&gt;Here is a conversion examples from &lt;code&gt;BertAdam&lt;/code&gt; with a linear warmup and decay schedule to &lt;code&gt;AdamW&lt;/code&gt; and the same schedule:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Parameters:&lt;/span&gt;
lr &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1e-3&lt;/span&gt;
max_grad_norm &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1.0&lt;/span&gt;
num_total_steps &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;1000&lt;/span&gt;
num_warmup_steps &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;100&lt;/span&gt;
warmup_proportion &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;float&lt;/span&gt;(num_warmup_steps) &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-c1"&gt;float&lt;/span&gt;(num_total_steps)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 0.1&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## Previously BertAdam optimizer was instantiated like this:&lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; BertAdam(model.parameters(), &lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;lr, &lt;span class="pl-v"&gt;schedule&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;warmup_linear&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-v"&gt;warmup&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;warmup_proportion, &lt;span class="pl-v"&gt;t_total&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_total_steps)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## and used like this:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; batch &lt;span class="pl-k"&gt;in&lt;/span&gt; train_data:
    loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(batch)
    loss.backward()
    optimizer.step()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## In Transformers, optimizer and schedules are splitted and instantiated like this:&lt;/span&gt;
optimizer &lt;span class="pl-k"&gt;=&lt;/span&gt; AdamW(model.parameters(), &lt;span class="pl-v"&gt;lr&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;lr, &lt;span class="pl-v"&gt;correct_bias&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;False&lt;/span&gt;)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; To reproduce BertAdam specific behavior set correct_bias=False&lt;/span&gt;
scheduler &lt;span class="pl-k"&gt;=&lt;/span&gt; WarmupLinearSchedule(optimizer, &lt;span class="pl-v"&gt;warmup_steps&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_warmup_steps, &lt;span class="pl-v"&gt;t_total&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;num_total_steps)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; PyTorch scheduler&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt;## and used like this:&lt;/span&gt;
&lt;span class="pl-k"&gt;for&lt;/span&gt; batch &lt;span class="pl-k"&gt;in&lt;/span&gt; train_data:
    loss &lt;span class="pl-k"&gt;=&lt;/span&gt; model(batch)
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Gradient clipping is not in AdamW anymore (so you can use amp without issue)&lt;/span&gt;
    optimizer.step()
    scheduler.step()
    optimizer.zero_grad()&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;We now have a paper you can cite for the &lt;g-emoji class="g-emoji" alias="hugs" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f917.png"&gt;ü§ó&lt;/g-emoji&gt; Transformers library:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>huggingface</author><guid isPermaLink="false">https://github.com/huggingface/transformers</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>JiahuiYu/generative_inpainting #11 in Python, Today</title><link>https://github.com/JiahuiYu/generative_inpainting</link><description>&lt;p&gt;&lt;i&gt;DeepFill v1/v2, Contextual Attention and Gated Convolution, CVPR 2018, and ICCV 2019 Oral&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-generative-image-inpainting" class="anchor" aria-hidden="true" href="#generative-image-inpainting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generative Image Inpainting&lt;/h1&gt;
&lt;p&gt;An open source framework for generative image inpainting task, with the support of &lt;a href="https://arxiv.org/abs/1801.07892" rel="nofollow"&gt;Contextual Attention&lt;/a&gt; (CVPR 2018) and &lt;a href="https://arxiv.org/abs/1806.03589" rel="nofollow"&gt;Gated Convolution&lt;/a&gt; (ICCV 2019 Oral).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For the code of previous version (DeepFill v1), please checkout branch &lt;a href="https://github.com/JiahuiYu/generative_inpainting/tree/v1.0.0"&gt;v1.0.0&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1801.07892" rel="nofollow"&gt;CVPR 2018 Paper&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/1806.03589" rel="nofollow"&gt;ICCV 2019 Oral Paper&lt;/a&gt;| &lt;a href="http://jiahuiyu.com/deepfill" rel="nofollow"&gt;Project&lt;/a&gt; | &lt;a href="http://jiahuiyu.com/deepfill" rel="nofollow"&gt;Demo&lt;/a&gt; | &lt;a href="https://youtu.be/xz1ZvcdhgQ0" rel="nofollow"&gt;YouTube v1&lt;/a&gt; | &lt;a href="https://youtu.be/uZkEi9Y2dj4" rel="nofollow"&gt;YouTube v2&lt;/a&gt; | &lt;a href="#citing"&gt;BibTex&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case1_raw.png"&gt;&lt;img src="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case1_raw.png" width="280" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case1_input.png"&gt;&lt;img src="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case1_input.png" width="280" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case1_output.png"&gt;&lt;img src="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case1_output.png" width="280" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case4_raw.png"&gt;&lt;img src="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case4_raw.png" width="280" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case4_input.png"&gt;&lt;img src="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case4_input.png" width="280" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case4_output.png"&gt;&lt;img src="https://raw.githubusercontent.com/JiahuiYu/generative_inpainting/v2.0.0/examples/places2/case4_output.png" width="280" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Free-form image inpainting results by our system built on gated convolution. Each triad shows original image, free-form input and our result from left to right. The system supports free-form mask and guidance like user sketch. It helps user remove distracting objects, modify image layouts and edit faces in images.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-run" class="anchor" aria-hidden="true" href="#run"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Run&lt;/h2&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Requirements:
&lt;ul&gt;
&lt;li&gt;Install python3.&lt;/li&gt;
&lt;li&gt;Install &lt;a href="https://www.tensorflow.org/install/" rel="nofollow"&gt;tensorflow&lt;/a&gt; (tested on Release 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0).&lt;/li&gt;
&lt;li&gt;Install tensorflow toolkit &lt;a href="https://github.com/JiahuiYu/neuralgym"&gt;neuralgym&lt;/a&gt; (run &lt;code&gt;pip install git+https://github.com/JiahuiYu/neuralgym&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Training:
&lt;ul&gt;
&lt;li&gt;Prepare training images filelist and shuffle it (&lt;a href="https://github.com/JiahuiYu/generative_inpainting/issues/15"&gt;example&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Modify &lt;a href="/inpaint.yml"&gt;inpaint.yml&lt;/a&gt; to set DATA_FLIST, LOG_DIR, IMG_SHAPES and other parameters.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;python train.py&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Resume training:
&lt;ul&gt;
&lt;li&gt;Modify MODEL_RESTORE flag in &lt;a href="/inpaint.yml"&gt;inpaint.yml&lt;/a&gt;. E.g., MODEL_RESTORE: 20180115220926508503_places2_model.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;python train.py&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Testing:
&lt;ul&gt;
&lt;li&gt;Run &lt;code&gt;python test.py --image examples/input.png --mask examples/mask.png --output examples/output.png --checkpoint model_logs/your_model_dir&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Still have questions?
&lt;ul&gt;
&lt;li&gt;If you still have questions (e.g.: How filelist looks like? How to use multi-gpus? How to do batch testing?), please first search over closed issues. If the problem is not solved, please open a new issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-pretrained-models" class="anchor" aria-hidden="true" href="#pretrained-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrained models&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://drive.google.com/drive/folders/1y7Irxm3HSHGvp546hZdAZwuNmhLUVcjO?usp=sharing" rel="nofollow"&gt;Places2&lt;/a&gt; | &lt;a href="https://drive.google.com/drive/folders/1uvcDgMer-4hgWlm6_G9xjvEQGP8neW15?usp=sharing" rel="nofollow"&gt;CelebA-HQ&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Download the model dirs and put it under &lt;code&gt;model_logs/&lt;/code&gt; (rename &lt;code&gt;checkpoint.txt&lt;/code&gt; to &lt;code&gt;checkpoint&lt;/code&gt; because google drive automatically add ext after download). Run testing or resume training as described above. All models are trained with images of resolution 256x256 and largest hole size 128x128, above which the results may be deteriorated. We provide several example test cases. Please run:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Places2 512x680 input&lt;/span&gt;
python test.py --image examples/places2/case1_input.png --mask examples/places2/case1_mask.png --output examples/places2/case1_output.png --checkpoint_dir model_logs/release_places2_256
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; CelebA-HQ 256x256 input&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Please visit CelebA-HQ demo at: jhyu.me/deepfill&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Please make sure the mask file completely cover the masks in input file. You may check it with saving a new image to visualize &lt;code&gt;cv2.imwrite('new.png', img - mask)&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tensorboard" class="anchor" aria-hidden="true" href="#tensorboard"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorBoard&lt;/h2&gt;
&lt;p&gt;Visualization on &lt;a href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard" rel="nofollow"&gt;TensorBoard&lt;/a&gt; for training and validation is supported. Run &lt;code&gt;tensorboard --logdir model_logs --port 6006&lt;/code&gt; to view training progress.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;CC 4.0 Attribution-NonCommercial International&lt;/p&gt;
&lt;p&gt;The software is for educaitonal and academic research purpose only.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citing" class="anchor" aria-hidden="true" href="#citing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citing&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;@article{yu2018generative,
  title={Generative Image Inpainting with Contextual Attention},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  journal={arXiv preprint arXiv:1801.07892},
  year={2018}
}

@article{yu2018free,
  title={Free-Form Image Inpainting with Gated Convolution},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  journal={arXiv preprint arXiv:1806.03589},
  year={2018}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>JiahuiYu</author><guid isPermaLink="false">https://github.com/JiahuiYu/generative_inpainting</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>donnemartin/system-design-primer #12 in Python, Today</title><link>https://github.com/donnemartin/system-design-primer</link><description>&lt;p&gt;&lt;i&gt;Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;em&gt;&lt;a href="README.md"&gt;English&lt;/a&gt; ‚àô &lt;a href="README-ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; ‚àô &lt;a href="README-zh-Hans.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; ‚àô &lt;a href="README-zh-TW.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/170"&gt;ÿßŸÑÿπŸéÿ±Ÿéÿ®ŸêŸäŸéŸëÿ©‚Äé&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/220"&gt;‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/40"&gt;Portugu√™s do Brasil&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/186"&gt;Deutsch&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/130"&gt;ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/272"&gt;◊¢◊ë◊®◊ô◊™&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/104"&gt;Italiano&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/102"&gt;ÈüìÂúãË™û&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/110"&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/68"&gt;Polski&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/87"&gt;—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/136"&gt;Espa√±ol&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/187"&gt;‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/39"&gt;T√ºrk√ße&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/127"&gt;ti·∫øng Vi·ªát&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/250"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-the-system-design-primer" class="anchor" aria-hidden="true" href="#the-system-design-primer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The System Design Primer&lt;/h1&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67" data-canonical-src="http://i.imgur.com/jj3A5N8.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt;
&lt;p&gt;Prep for the system design interview.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-learn-how-to-design-large-scale-systems" class="anchor" aria-hidden="true" href="#learn-how-to-design-large-scale-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn how to design large-scale systems&lt;/h3&gt;
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt;
&lt;p&gt;System design is a broad topic.  There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt;
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-learn-from-the-open-source-community" class="anchor" aria-hidden="true" href="#learn-from-the-open-source-community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn from the open source community&lt;/h3&gt;
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt;
&lt;p&gt;&lt;a href="#contributing"&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-prep-for-the-system-design-interview" class="anchor" aria-hidden="true" href="#prep-for-the-system-design-interview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prep for the system design interview&lt;/h3&gt;
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#study-guide"&gt;Study guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-anki-flashcards" class="anchor" aria-hidden="true" href="#anki-flashcards"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Anki flashcards&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/75b5cf737556050871218226ea211256f19f3a40/687474703a2f2f692e696d6775722e636f6d2f7a6443416b42332e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/75b5cf737556050871218226ea211256f19f3a40/687474703a2f2f692e696d6775722e636f6d2f7a6443416b42332e706e67" data-canonical-src="http://i.imgur.com/zdCAkB3.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;The provided &lt;a href="https://apps.ankiweb.net/" rel="nofollow"&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg"&gt;System design deck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg"&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg"&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-coding-resource-interactive-coding-challenges" class="anchor" aria-hidden="true" href="#coding-resource-interactive-coding-challenges"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt;
&lt;p&gt;Looking for resources to help you prep for the &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/473700c20356af5875155f24d3a26b57ae940bdc/687474703a2f2f692e696d6775722e636f6d2f6234597441454e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/473700c20356af5875155f24d3a26b57ae940bdc/687474703a2f2f692e696d6775722e636f6d2f6234597441454e2e706e67" data-canonical-src="http://i.imgur.com/b4YtAEN.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;Check out the sister repo &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg"&gt;Coding deck&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn from the community.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fix errors&lt;/li&gt;
&lt;li&gt;Improve sections&lt;/li&gt;
&lt;li&gt;Add new sections&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Translate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Content that needs some polishing is placed &lt;a href="#under-development"&gt;under development&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Review the &lt;a href="CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-index-of-system-design-topics" class="anchor" aria-hidden="true" href="#index-of-system-design-topics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Index of system design topics&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Summaries of various system design topics, including pros and cons.  &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67" data-canonical-src="http://i.imgur.com/jrUBAF7.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#system-design-topics-start-here"&gt;System design topics: start here&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#step-1-review-the-scalability-video-lecture"&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#step-2-review-the-scalability-article"&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#next-steps"&gt;Next steps&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#performance-vs-scalability"&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-vs-throughput"&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-vs-consistency"&gt;Availability vs consistency&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cap-theorem"&gt;CAP theorem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cp---consistency-and-partition-tolerance"&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ap---availability-and-partition-tolerance"&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#consistency-patterns"&gt;Consistency patterns&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#weak-consistency"&gt;Weak consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eventual-consistency"&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#strong-consistency"&gt;Strong consistency&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-patterns"&gt;Availability patterns&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#fail-over"&gt;Fail-over&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#replication"&gt;Replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#availability-in-numbers"&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#domain-name-system"&gt;Domain name system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#content-delivery-network"&gt;Content delivery network&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#push-cdns"&gt;Push CDNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pull-cdns"&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#load-balancer"&gt;Load balancer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#active-passive"&gt;Active-passive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#active-active"&gt;Active-active&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-4-load-balancing"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-7-load-balancing"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#horizontal-scaling"&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#reverse-proxy-web-server"&gt;Reverse proxy (web server)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#load-balancer-vs-reverse-proxy"&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#application-layer"&gt;Application layer&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#microservices"&gt;Microservices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#service-discovery"&gt;Service discovery&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#database"&gt;Database&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#relational-database-management-system-rdbms"&gt;Relational database management system (RDBMS)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sharding"&gt;Sharding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sql-tuning"&gt;SQL tuning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#nosql"&gt;NoSQL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#key-value-store"&gt;Key-value store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#document-store"&gt;Document store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wide-column-store"&gt;Wide column store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#graph-database"&gt;Graph Database&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#cache"&gt;Cache&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#client-caching"&gt;Client caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cdn-caching"&gt;CDN caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#web-server-caching"&gt;Web server caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database-caching"&gt;Database caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#application-caching"&gt;Application caching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching-at-the-database-query-level"&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#caching-at-the-object-level"&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#when-to-update-the-cache"&gt;When to update the cache&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#cache-aside"&gt;Cache-aside&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#write-through"&gt;Write-through&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#write-behind-write-back"&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#refresh-ahead"&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#asynchronism"&gt;Asynchronism&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#message-queues"&gt;Message queues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#task-queues"&gt;Task queues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#back-pressure"&gt;Back pressure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#communication"&gt;Communication&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#transmission-control-protocol-tcp"&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#user-datagram-protocol-udp"&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#remote-procedure-call-rpc"&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#representational-state-transfer-rest"&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#security"&gt;Security&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#appendix"&gt;Appendix&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#company-architectures"&gt;Company architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#under-development"&gt;Under development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#credits"&gt;Credits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact-info"&gt;Contact info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-study-guide" class="anchor" aria-hidden="true" href="#study-guide"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Study guide&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/eb92600aa3bb1314b33edd0204da8428d4d3a493/687474703a2f2f692e696d6775722e636f6d2f4f66566c6c65782e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/eb92600aa3bb1314b33edd0204da8428d4d3a493/687474703a2f2f692e696d6775722e636f6d2f4f66566c6c65782e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/OfVllex.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A: No, you don't need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How much experience you have&lt;/li&gt;
&lt;li&gt;What your technical background is&lt;/li&gt;
&lt;li&gt;What positions you are interviewing for&lt;/li&gt;
&lt;li&gt;Which companies you are interviewing with&lt;/li&gt;
&lt;li&gt;Luck&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More experienced candidates are generally expected to know more about system design.  Architects or team leads might be expected to know more than individual contributors.  Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt;
&lt;p&gt;Start broad and go deeper in a few areas.  It helps to know a little about various key system design topics.  Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics.  Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Short&lt;/th&gt;
&lt;th&gt;Medium&lt;/th&gt;
&lt;th&gt;Long&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Read through the &lt;a href="#index-of-system-design-topics"&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read through a few articles in the &lt;a href="#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read through a few &lt;a href="#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Review &lt;a href="#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;td&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;üëç&lt;/g-emoji&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Work through &lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Work through &lt;a href="#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Review &lt;a href="#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Some&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Most&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-approach-a-system-design-interview-question" class="anchor" aria-hidden="true" href="#how-to-approach-a-system-design-interview-question"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to approach a system design interview question&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;How to tackle a system design interview question.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;.  You are expected to lead it.&lt;/p&gt;
&lt;p&gt;You can use the following steps to guide the discussion.  To help solidify this process, work through the &lt;a href="#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-outline-use-cases-constraints-and-assumptions" class="anchor" aria-hidden="true" href="#step-1-outline-use-cases-constraints-and-assumptions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt;
&lt;p&gt;Gather requirements and scope the problem.  Ask questions to clarify use cases and constraints.  Discuss assumptions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who is going to use it?&lt;/li&gt;
&lt;li&gt;How are they going to use it?&lt;/li&gt;
&lt;li&gt;How many users are there?&lt;/li&gt;
&lt;li&gt;What does the system do?&lt;/li&gt;
&lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt;
&lt;li&gt;How much data do we expect to handle?&lt;/li&gt;
&lt;li&gt;How many requests per second do we expect?&lt;/li&gt;
&lt;li&gt;What is the expected read to write ratio?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-create-a-high-level-design" class="anchor" aria-hidden="true" href="#step-2-create-a-high-level-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2: Create a high level design&lt;/h3&gt;
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sketch the main components and connections&lt;/li&gt;
&lt;li&gt;Justify your ideas&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-3-design-core-components" class="anchor" aria-hidden="true" href="#step-3-design-core-components"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 3: Design core components&lt;/h3&gt;
&lt;p&gt;Dive into details for each core component.  For example, if you were asked to &lt;a href="solutions/system_design/pastebin/README.md"&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generating and storing a hash of the full url
&lt;ul&gt;
&lt;li&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;MD5&lt;/a&gt; and &lt;a href="solutions/system_design/pastebin/README.md"&gt;Base62&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hash collisions&lt;/li&gt;
&lt;li&gt;SQL or NoSQL&lt;/li&gt;
&lt;li&gt;Database schema&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Translating a hashed url to the full url
&lt;ul&gt;
&lt;li&gt;Database lookup&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API and object-oriented design&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-4-scale-the-design" class="anchor" aria-hidden="true" href="#step-4-scale-the-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 4: Scale the design&lt;/h3&gt;
&lt;p&gt;Identify and address bottlenecks, given the constraints.  For example, do you need the following to address scalability issues?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Load balancer&lt;/li&gt;
&lt;li&gt;Horizontal scaling&lt;/li&gt;
&lt;li&gt;Caching&lt;/li&gt;
&lt;li&gt;Database sharding&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Discuss potential solutions and trade-offs.  Everything is a trade-off.  Address bottlenecks using &lt;a href="#index-of-system-design-topics"&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-back-of-the-envelope-calculations" class="anchor" aria-hidden="true" href="#back-of-the-envelope-calculations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Back-of-the-envelope calculations&lt;/h3&gt;
&lt;p&gt;You might be asked to do some estimates by hand.  Refer to the &lt;a href="#appendix"&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html" rel="nofollow"&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading" class="anchor" aria-hidden="true" href="#sources-and-further-reading"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/" rel="nofollow"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design" rel="nofollow"&gt;The system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZgdS0EUmn70" rel="nofollow"&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-system-design-interview-questions-with-solutions" class="anchor" aria-hidden="true" href="#system-design-interview-questions-with-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System design interview questions with solutions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/twitter/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a web crawler&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/web_crawler/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Mint.com&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/mint/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the data structures for a social network&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/social_graph/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a key-value store for a search engine&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/query_cache/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Amazon's sales ranking by category feature&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/sales_rank/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/system_design/scaling_aws/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add a system design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-design-pastebincom-or-bitly" class="anchor" aria-hidden="true" href="#design-pastebincom-or-bitly"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/pastebin/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4aee2d26ebedc20e7fa07a2c30780e332fa29f2c/687474703a2f2f692e696d6775722e636f6d2f346564584730542e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/4aee2d26ebedc20e7fa07a2c30780e332fa29f2c/687474703a2f2f692e696d6775722e636f6d2f346564584730542e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/4edXG0T.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-the-twitter-timeline-and-search-or-facebook-feed-and-search" class="anchor" aria-hidden="true" href="#design-the-twitter-timeline-and-search-or-facebook-feed-and-search"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/twitter/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/14f76dab28dfbfa12ea6b02c6bd0ec726fc17306/687474703a2f2f692e696d6775722e636f6d2f6a7255424146372e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/jrUBAF7.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-web-crawler" class="anchor" aria-hidden="true" href="#design-a-web-crawler"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a web crawler&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/web_crawler/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ba21a95852d1cf7bb64c8c4622a79d1d5a20d344/687474703a2f2f692e696d6775722e636f6d2f625778507451412e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/ba21a95852d1cf7bb64c8c4622a79d1d5a20d344/687474703a2f2f692e696d6775722e636f6d2f625778507451412e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/bWxPtQA.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-mintcom" class="anchor" aria-hidden="true" href="#design-mintcom"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Mint.com&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/mint/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/12fea5f9324f74189a9cd983b02239c68615b67e/687474703a2f2f692e696d6775722e636f6d2f563571353776552e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/12fea5f9324f74189a9cd983b02239c68615b67e/687474703a2f2f692e696d6775722e636f6d2f563571353776552e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/V5q57vU.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-the-data-structures-for-a-social-network" class="anchor" aria-hidden="true" href="#design-the-data-structures-for-a-social-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design the data structures for a social network&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/social_graph/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/16d78e51c2e2949e23122f4c26afe5886f82a96f/687474703a2f2f692e696d6775722e636f6d2f636443763567372e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/16d78e51c2e2949e23122f4c26afe5886f82a96f/687474703a2f2f692e696d6775722e636f6d2f636443763567372e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/cdCv5g7.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-key-value-store-for-a-search-engine" class="anchor" aria-hidden="true" href="#design-a-key-value-store-for-a-search-engine"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a key-value store for a search engine&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/query_cache/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b6439861687b9a0fc62d0149a364082643ebaf86/687474703a2f2f692e696d6775722e636f6d2f346a39396d68652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b6439861687b9a0fc62d0149a364082643ebaf86/687474703a2f2f692e696d6775722e636f6d2f346a39396d68652e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/4j99mhe.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-amazons-sales-ranking-by-category-feature" class="anchor" aria-hidden="true" href="#design-amazons-sales-ranking-by-category-feature"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Amazon's sales ranking by category feature&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/sales_rank/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a56f5600f7ae29dc0c2e436b8e4e4b55c44d6894/687474703a2f2f692e696d6775722e636f6d2f4d7a45785030362e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a56f5600f7ae29dc0c2e436b8e4e4b55c44d6894/687474703a2f2f692e696d6775722e636f6d2f4d7a45785030362e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/MzExP06.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-design-a-system-that-scales-to-millions-of-users-on-aws" class="anchor" aria-hidden="true" href="#design-a-system-that-scales-to-millions-of-users-on-aws"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt;
&lt;p&gt;&lt;a href="solutions/system_design/scaling_aws/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e45e39c36eebcc4c66e1aecd4e4145112d8e88e3/687474703a2f2f692e696d6775722e636f6d2f6a6a3341354e382e706e67" alt="Imgur" data-canonical-src="http://i.imgur.com/jj3A5N8.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-object-oriented-design-interview-questions-with-solutions" class="anchor" aria-hidden="true" href="#object-oriented-design-interview-questions-with-solutions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Object-oriented design interview questions with solutions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt;
&lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design a hash map&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/hash_table/hash_map.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a least recently used cache&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/lru_cache/lru_cache.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a call center&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/call_center/call_center.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a deck of cards&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a parking lot&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/parking_lot/parking_lot.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a chat server&lt;/td&gt;
&lt;td&gt;&lt;a href="solutions/object_oriented_design/online_chat/online_chat.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a circular array&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add an object-oriented design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-system-design-topics-start-here" class="anchor" aria-hidden="true" href="#system-design-topics-start-here"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System design topics: start here&lt;/h2&gt;
&lt;p&gt;New to system design?&lt;/p&gt;
&lt;p&gt;First, you'll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-step-1-review-the-scalability-video-lecture" class="anchor" aria-hidden="true" href="#step-1-review-the-scalability-video-lecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 1: Review the scalability video lecture&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4" rel="nofollow"&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topics covered:
&lt;ul&gt;
&lt;li&gt;Vertical scaling&lt;/li&gt;
&lt;li&gt;Horizontal scaling&lt;/li&gt;
&lt;li&gt;Caching&lt;/li&gt;
&lt;li&gt;Load balancing&lt;/li&gt;
&lt;li&gt;Database replication&lt;/li&gt;
&lt;li&gt;Database partitioning&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-step-2-review-the-scalability-article" class="anchor" aria-hidden="true" href="#step-2-review-the-scalability-article"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step 2: Review the scalability article&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.lecloud.net/tagged/scalability/chrono" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topics covered:
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones" rel="nofollow"&gt;Clones&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database" rel="nofollow"&gt;Databases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache" rel="nofollow"&gt;Caches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism" rel="nofollow"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-next-steps" class="anchor" aria-hidden="true" href="#next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next steps&lt;/h3&gt;
&lt;p&gt;Next, we'll look at high-level trade-offs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Then we'll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-performance-vs-scalability" class="anchor" aria-hidden="true" href="#performance-vs-scalability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance vs scalability&lt;/h2&gt;
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html" rel="nofollow"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt;
&lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-1" class="anchor" aria-hidden="true" href="#sources-and-further-reading-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html" rel="nofollow"&gt;A word on scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-latency-vs-throughput" class="anchor" aria-hidden="true" href="#latency-vs-throughput"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency vs throughput&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt;
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-2" class="anchor" aria-hidden="true" href="#sources-and-further-reading-2"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://community.cadence.com/cadence_blogs_8/b/sd/archive/2010/09/13/understanding-latency-vs-throughput" rel="nofollow"&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-availability-vs-consistency" class="anchor" aria-hidden="true" href="#availability-vs-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability vs consistency&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-cap-theorem" class="anchor" aria-hidden="true" href="#cap-theorem"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CAP theorem&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/13719354da7dcd34cd79ff5f8b6306a67bc18261/687474703a2f2f692e696d6775722e636f6d2f62674c4d4932752e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/13719354da7dcd34cd79ff5f8b6306a67bc18261/687474703a2f2f692e696d6775722e636f6d2f62674c4d4932752e706e67" data-canonical-src="http://i.imgur.com/bgLMI2u.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited" rel="nofollow"&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Networks aren't reliable, so you'll need to support partition tolerance.  You'll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-cp---consistency-and-partition-tolerance" class="anchor" aria-hidden="true" href="#cp---consistency-and-partition-tolerance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CP - consistency and partition tolerance&lt;/h4&gt;
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error.  CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-ap---availability-and-partition-tolerance" class="anchor" aria-hidden="true" href="#ap---availability-and-partition-tolerance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AP - availability and partition tolerance&lt;/h4&gt;
&lt;p&gt;Responses return the most recent version of the data available on a node, which might not be the latest.  Writes might take some time to propagate when the partition is resolved.&lt;/p&gt;
&lt;p&gt;AP is a good choice if the business needs allow for &lt;a href="#eventual-consistency"&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-3" class="anchor" aria-hidden="true" href="#sources-and-further-reading-3"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/" rel="nofollow"&gt;CAP theorem revisited&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem/" rel="nofollow"&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/henryr/cap-faq"&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-consistency-patterns" class="anchor" aria-hidden="true" href="#consistency-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Consistency patterns&lt;/h2&gt;
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data.  Recall the definition of consistency from the &lt;a href="#cap-theorem"&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-weak-consistency" class="anchor" aria-hidden="true" href="#weak-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Weak consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads may or may not see it.  A best effort approach is taken.&lt;/p&gt;
&lt;p&gt;This approach is seen in systems such as memcached.  Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games.  For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-eventual-consistency" class="anchor" aria-hidden="true" href="#eventual-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eventual consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds).  Data is replicated asynchronously.&lt;/p&gt;
&lt;p&gt;This approach is seen in systems such as DNS and email.  Eventual consistency works well in highly available systems.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-strong-consistency" class="anchor" aria-hidden="true" href="#strong-consistency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Strong consistency&lt;/h3&gt;
&lt;p&gt;After a write, reads will see it.  Data is replicated synchronously.&lt;/p&gt;
&lt;p&gt;This approach is seen in file systems and RDBMSes.  Strong consistency works well in systems that need transactions.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-4" class="anchor" aria-hidden="true" href="#sources-and-further-reading-4"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://snarfed.org/transactions_across_datacenters_io.html" rel="nofollow"&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-availability-patterns" class="anchor" aria-hidden="true" href="#availability-patterns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability patterns&lt;/h2&gt;
&lt;p&gt;There are two main patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-fail-over" class="anchor" aria-hidden="true" href="#fail-over"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fail-over&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-active-passive" class="anchor" aria-hidden="true" href="#active-passive"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Active-passive&lt;/h4&gt;
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby.  If the heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.&lt;/p&gt;
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in 'hot' standby or whether it needs to start up from 'cold' standby.  Only the active server handles traffic.&lt;/p&gt;
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-active-active" class="anchor" aria-hidden="true" href="#active-active"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Active-active&lt;/h4&gt;
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt;
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers.  If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt;
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-failover" class="anchor" aria-hidden="true" href="#disadvantages-failover"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): failover&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt;
&lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-replication" class="anchor" aria-hidden="true" href="#replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Replication&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-master-slave-and-master-master" class="anchor" aria-hidden="true" href="#master-slave-and-master-master"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-slave and master-master&lt;/h4&gt;
&lt;p&gt;This topic is further discussed in the &lt;a href="#database"&gt;Database&lt;/a&gt; section:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-availability-in-numbers" class="anchor" aria-hidden="true" href="#availability-in-numbers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability in numbers&lt;/h3&gt;
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available.  Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-999-availability---three-9s" class="anchor" aria-hidden="true" href="#999-availability---three-9s"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;99.9% availability - three 9s&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Acceptable downtime&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per year&lt;/td&gt;
&lt;td&gt;8h 45min 57s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per month&lt;/td&gt;
&lt;td&gt;43m 49.7s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per week&lt;/td&gt;
&lt;td&gt;10m 4.8s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per day&lt;/td&gt;
&lt;td&gt;1m 26.4s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-9999-availability---four-9s" class="anchor" aria-hidden="true" href="#9999-availability---four-9s"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;99.99% availability - four 9s&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Duration&lt;/th&gt;
&lt;th&gt;Acceptable downtime&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per year&lt;/td&gt;
&lt;td&gt;52min 35.7s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per month&lt;/td&gt;
&lt;td&gt;4m 23s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per week&lt;/td&gt;
&lt;td&gt;1m 5s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Downtime per day&lt;/td&gt;
&lt;td&gt;8.6s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-availability-in-parallel-vs-in-sequence" class="anchor" aria-hidden="true" href="#availability-in-parallel-vs-in-sequence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability in parallel vs in sequence&lt;/h4&gt;
&lt;p&gt;If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt;
&lt;h6&gt;&lt;a id="user-content-in-sequence" class="anchor" aria-hidden="true" href="#in-sequence"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In sequence&lt;/h6&gt;
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt;
&lt;h6&gt;&lt;a id="user-content-in-parallel" class="anchor" aria-hidden="true" href="#in-parallel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In parallel&lt;/h6&gt;
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-domain-name-system" class="anchor" aria-hidden="true" href="#domain-name-system"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Domain name system&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fae27d1291ed38dd120595d692eacd2505cd3a9c/687474703a2f2f692e696d6775722e636f6d2f494f794c6a34692e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/fae27d1291ed38dd120595d692eacd2505cd3a9c/687474703a2f2f692e696d6775722e636f6d2f494f794c6a34692e6a7067" data-canonical-src="http://i.imgur.com/IOyLj4i.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/srikrupa5/dns-security-presentation-issa" rel="nofollow"&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href="http://www.example.com" rel="nofollow"&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt;
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level.  Your router or ISP provides information about which DNS server(s) to contact when doing a lookup.  Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays.  DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href="https://en.wikipedia.org/wiki/Time_to_live" rel="nofollow"&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href="http://www.example.com" rel="nofollow"&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Services such as &lt;a href="https://www.cloudflare.com/dns/" rel="nofollow"&gt;CloudFlare&lt;/a&gt; and &lt;a href="https://aws.amazon.com/route53/" rel="nofollow"&gt;Route 53&lt;/a&gt; provide managed DNS services.  Some DNS services can route traffic through various methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://g33kinfo.com/info/archives/2657" rel="nofollow"&gt;Weighted round robin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt;
&lt;li&gt;Balance between varying cluster sizes&lt;/li&gt;
&lt;li&gt;A/B testing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Latency-based&lt;/li&gt;
&lt;li&gt;Geolocation-based&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-dns" class="anchor" aria-hidden="true" href="#disadvantages-dns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): DNS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt;
&lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href="http://superuser.com/questions/472695/who-controls-the-dns-servers/472729" rel="nofollow"&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;DNS services have recently come under &lt;a href="http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/" rel="nofollow"&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter's IP address(es).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-5" class="anchor" aria-hidden="true" href="#sources-and-further-reading-5"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx" rel="nofollow"&gt;DNS architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Domain_Name_System" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://support.dnsimple.com/categories/dns/" rel="nofollow"&gt;DNS articles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-content-delivery-network" class="anchor" aria-hidden="true" href="#content-delivery-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content delivery network&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/853a8603651149c686bf3c504769fc594ff08849/687474703a2f2f692e696d6775722e636f6d2f683954417547492e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/853a8603651149c686bf3c504769fc594ff08849/687474703a2f2f692e696d6775722e636f6d2f683954417547492e6a7067" data-canonical-src="http://i.imgur.com/h9TAuGI.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/" rel="nofollow"&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user.  Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content.  The site's DNS resolution will tell clients which server to contact.&lt;/p&gt;
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users receive content at data centers close to them&lt;/li&gt;
&lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-push-cdns" class="anchor" aria-hidden="true" href="#push-cdns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Push CDNs&lt;/h3&gt;
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server.  You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN.  You can configure when content expires and when it is updated.  Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt;
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs.  Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-pull-cdns" class="anchor" aria-hidden="true" href="#pull-cdns"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pull CDNs&lt;/h3&gt;
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content.  You leave the content on your server and rewrite URLs to point to the CDN.  This results in a slower request until the content is cached on the CDN.&lt;/p&gt;
&lt;p&gt;A &lt;a href="https://en.wikipedia.org/wiki/Time_to_live" rel="nofollow"&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached.  Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt;
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-cdn" class="anchor" aria-hidden="true" href="#disadvantages-cdn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): CDN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt;
&lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt;
&lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-6" class="anchor" aria-hidden="true" href="#sources-and-further-reading-6"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972" rel="nofollow"&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/" rel="nofollow"&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-load-balancer" class="anchor" aria-hidden="true" href="#load-balancer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load balancer&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/21caea3d7f67f451630012f657ae59a56709365c/687474703a2f2f692e696d6775722e636f6d2f6838316e39694b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/21caea3d7f67f451630012f657ae59a56709365c/687474703a2f2f692e696d6775722e636f6d2f6838316e39694b2e706e67" data-canonical-src="http://i.imgur.com/h81n9iK.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases.  In each case, the load balancer returns the response from the computing resource to the appropriate client.  Load balancers are effective at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt;
&lt;li&gt;Preventing overloading resources&lt;/li&gt;
&lt;li&gt;Helping eliminate single points of failure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt;
&lt;p&gt;Additional benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
&lt;ul&gt;
&lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509" rel="nofollow"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To protect against failures, it's common to set up multiple load balancers, either in &lt;a href="#active-passive"&gt;active-passive&lt;/a&gt; or &lt;a href="#active-active"&gt;active-active&lt;/a&gt; mode.&lt;/p&gt;
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Random&lt;/li&gt;
&lt;li&gt;Least loaded&lt;/li&gt;
&lt;li&gt;Session/cookies&lt;/li&gt;
&lt;li&gt;&lt;a href="http://g33kinfo.com/info/archives/2657" rel="nofollow"&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-4-load-balancing"&gt;Layer 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#layer-7-load-balancing"&gt;Layer 7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-layer-4-load-balancing" class="anchor" aria-hidden="true" href="#layer-4-load-balancing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Layer 4 load balancing&lt;/h3&gt;
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href="#communication"&gt;transport layer&lt;/a&gt; to decide how to distribute requests.  Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet.  Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/" rel="nofollow"&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-layer-7-load-balancing" class="anchor" aria-hidden="true" href="#layer-7-load-balancing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Layer 7 load balancing&lt;/h3&gt;
&lt;p&gt;Layer 7 load balancers look at the &lt;a href="#communication"&gt;application layer&lt;/a&gt; to decide how to distribute requests.  This can involve contents of the header, message, and cookies.  Layer 7 load balancers terminates network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server.  For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt;
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-horizontal-scaling" class="anchor" aria-hidden="true" href="#horizontal-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Horizontal scaling&lt;/h3&gt;
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability.  Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;.  It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-horizontal-scaling" class="anchor" aria-hidden="true" href="#disadvantages-horizontal-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers
&lt;ul&gt;
&lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt;
&lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href="#database"&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href="#cache"&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-load-balancer" class="anchor" aria-hidden="true" href="#disadvantages-load-balancer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): load balancer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt;
&lt;li&gt;Introducing a load balancer to help eliminate single points of failure results in increased complexity.&lt;/li&gt;
&lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-7" class="anchor" aria-hidden="true" href="#sources-and-further-reading-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" rel="nofollow"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt" rel="nofollow"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Load_balancing_(computing)" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/" rel="nofollow"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/" rel="nofollow"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html" rel="nofollow"&gt;ELB listener config&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-reverse-proxy-web-server" class="anchor" aria-hidden="true" href="#reverse-proxy-web-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reverse proxy (web server)&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e88216d0999853426f72b28e41223f43977d22b7/687474703a2f2f692e696d6775722e636f6d2f6e3431417a66662e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/e88216d0999853426f72b28e41223f43977d22b7/687474703a2f2f692e696d6775722e636f6d2f6e3431417a66662e706e67" data-canonical-src="http://i.imgur.com/n41Azff.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg" rel="nofollow"&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt;
  &lt;br&gt;
&lt;/p&gt;
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public.  Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.&lt;/p&gt;
&lt;p&gt;Additional benefits include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy's IP, allowing you to scale servers or change their configuration&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
&lt;ul&gt;
&lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509" rel="nofollow"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly
&lt;ul&gt;
&lt;li&gt;HTML/CSS/JS&lt;/li&gt;
&lt;li&gt;Photos&lt;/li&gt;
&lt;li&gt;Videos&lt;/li&gt;
&lt;li&gt;Etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-load-balancer-vs-reverse-proxy" class="anchor" aria-hidden="true" href="#load-balancer-vs-reverse-proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Load balancer vs reverse proxy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deploying a load balancer is useful when you have multiple servers.  Often, load balancers  route traffic to a set of servers serving the same function.&lt;/li&gt;
&lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt;
&lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-reverse-proxy" class="anchor" aria-hidden="true" href="#disadvantages-reverse-proxy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): reverse proxy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt;
&lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href="https://en.wikipedia.org/wiki/Failover" rel="nofollow"&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-8" class="anchor" aria-hidden="true" href="#sources-and-further-reading-8"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/" rel="nofollow"&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" rel="nofollow"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt" rel="nofollow"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Reverse_proxy" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-application-layer" class="anchor" aria-hidden="true" href="#application-layer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Application layer&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/feeb549c5b6e94f65c613635f7166dc26e0c7de7/687474703a2f2f692e696d6775722e636f6d2f7942355359776d2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/feeb549c5b6e94f65c613635f7166dc26e0c7de7/687474703a2f2f692e696d6775722e636f6d2f7942355359776d2e706e67" data-canonical-src="http://i.imgur.com/yB5SYwm.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer" rel="nofollow"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently.  Adding a new API results in adding application servers without necessarily adding additional web servers.  The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together.  Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt;
&lt;p&gt;Workers in the application layer also help enable &lt;a href="#asynchronism"&gt;asynchronism&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-microservices" class="anchor" aria-hidden="true" href="#microservices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Microservices&lt;/h3&gt;
&lt;p&gt;Related to this discussion are &lt;a href="https://en.wikipedia.org/wiki/Microservices" rel="nofollow"&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services.  Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href="https://smartbear.com/learn/api-design/what-are-microservices" rel="nofollow"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-service-discovery" class="anchor" aria-hidden="true" href="#service-discovery"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Service Discovery&lt;/h3&gt;
&lt;p&gt;Systems such as &lt;a href="https://www.consul.io/docs/index.html" rel="nofollow"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/docs/latest" rel="nofollow"&gt;Etcd&lt;/a&gt;, and &lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports.  &lt;a href="https://www.consul.io/intro/getting-started/checks.html" rel="nofollow"&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href="#hypertext-transfer-protocol-http"&gt;HTTP&lt;/a&gt; endpoint.  Both Consul and Etcd have a built in &lt;a href="#key-value-store"&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-application-layer" class="anchor" aria-hidden="true" href="#disadvantages-application-layer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): application layer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt;
&lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-9" class="anchor" aria-hidden="true" href="#sources-and-further-reading-9"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale" rel="nofollow"&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Service-oriented_architecture" rel="nofollow"&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/" rel="nofollow"&gt;Here's what you need to know about building microservices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-database" class="anchor" aria-hidden="true" href="#database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/15a7553727e6da98d0de5e9ca3792f6d2b5e92d4/687474703a2f2f692e696d6775722e636f6d2f586b6d3543587a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/15a7553727e6da98d0de5e9ca3792f6d2b5e92d4/687474703a2f2f692e696d6775722e636f6d2f586b6d3543587a2e706e67" data-canonical-src="http://i.imgur.com/Xkm5CXz.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-relational-database-management-system-rdbms" class="anchor" aria-hidden="true" href="#relational-database-management-system-rdbms"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Relational database management system (RDBMS)&lt;/h3&gt;
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href="https://en.wikipedia.org/wiki/Database_transaction" rel="nofollow"&gt;transactions&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-master-slave-replication" class="anchor" aria-hidden="true" href="#master-slave-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-slave replication&lt;/h4&gt;
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads.  Slaves can also replicate to additional slaves in a tree-like fashion.  If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6a097809b9690236258747d969b1d3e0d93bb8ca/687474703a2f2f692e696d6775722e636f6d2f4339696f47746e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6a097809b9690236258747d969b1d3e0d93bb8ca/687474703a2f2f692e696d6775722e636f6d2f4339696f47746e2e706e67" data-canonical-src="http://i.imgur.com/C9ioGtn.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-master-slave-replication" class="anchor" aria-hidden="true" href="#disadvantages-master-slave-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): master-slave replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt;
&lt;li&gt;See &lt;a href="#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-master-master-replication" class="anchor" aria-hidden="true" href="#master-master-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Master-master replication&lt;/h4&gt;
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes.  If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/5862604b102ee97d85f86f89edda44bde85a5b7f/687474703a2f2f692e696d6775722e636f6d2f6b7241484c47672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/5862604b102ee97d85f86f89edda44bde85a5b7f/687474703a2f2f692e696d6775722e636f6d2f6b7241484c47672e706e67" data-canonical-src="http://i.imgur.com/krAHLGg.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-master-master-replication" class="anchor" aria-hidden="true" href="#disadvantages-master-master-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): master-master replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;You'll need a load balancer or you'll need to make changes to your application logic to determine where to write.&lt;/li&gt;
&lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt;
&lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt;
&lt;li&gt;See &lt;a href="#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-replication" class="anchor" aria-hidden="true" href="#disadvantages-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt;
&lt;li&gt;Writes are replayed to the read replicas.  If there are a lot of writes, the read replicas can get bogged down with replaying writes and can't do as many reads.&lt;/li&gt;
&lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt;
&lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt;
&lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-replication" class="anchor" aria-hidden="true" href="#sources-and-further-reading-replication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: replication&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication" rel="nofollow"&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-federation" class="anchor" aria-hidden="true" href="#federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Federation&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/6eb6570a8b6b4e1d52e3d7cc07e7959ea5dac75f/687474703a2f2f692e696d6775722e636f6d2f553371563333652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/6eb6570a8b6b4e1d52e3d7cc07e7959ea5dac75f/687474703a2f2f692e696d6775722e636f6d2f553371563333652e706e67" data-canonical-src="http://i.imgur.com/U3qV33e.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Federation (or functional partitioning) splits up databases by function.  For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag.  Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality.  With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-federation" class="anchor" aria-hidden="true" href="#disadvantages-federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): federation&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt;
&lt;li&gt;You'll need to update your application logic to determine which database to read and write.&lt;/li&gt;
&lt;li&gt;Joining data from two databases is more complex with a &lt;a href="http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers" rel="nofollow"&gt;server link&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-federation" class="anchor" aria-hidden="true" href="#sources-and-further-reading-federation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: federation&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sharding" class="anchor" aria-hidden="true" href="#sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sharding&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1df78be67b749171569a0e11a51aa76b3b678d4f/687474703a2f2f692e696d6775722e636f6d2f775538783549642e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1df78be67b749171569a0e11a51aa76b3b678d4f/687474703a2f2f692e696d6775722e636f6d2f775538783549642e706e67" data-canonical-src="http://i.imgur.com/wU8x5Id.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data.  Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt;
&lt;p&gt;Similar to the advantages of &lt;a href="#federation"&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits.  Index size is also reduced, which generally improves performance with faster queries.  If one shard goes down, the other shards are still operational, although you'll want to add some form of replication to avoid data loss.  Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt;
&lt;p&gt;Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-sharding" class="anchor" aria-hidden="true" href="#disadvantages-sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): sharding&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;You'll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt;
&lt;li&gt;Data distribution can become lopsided in a shard.  For example, a set of power users on a shard could result in increased load to that shard compared to others.
&lt;ul&gt;
&lt;li&gt;Rebalancing adds additional complexity.  A sharding function based on &lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" rel="nofollow"&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt;
&lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sharding" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sharding"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: sharding&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html" rel="nofollow"&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)" rel="nofollow"&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" rel="nofollow"&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-denormalization" class="anchor" aria-hidden="true" href="#denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Denormalization&lt;/h4&gt;
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance.  Redundant copies of the data are written in multiple tables to avoid expensive joins.  Some RDBMS such as &lt;a href="https://en.wikipedia.org/wiki/PostgreSQL" rel="nofollow"&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href="https://en.wikipedia.org/wiki/Materialized_view" rel="nofollow"&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt;
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href="#federation"&gt;federation&lt;/a&gt; and &lt;a href="#sharding"&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity.  Denormalization might circumvent the need for such complex joins.&lt;/p&gt;
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1.  A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-denormalization" class="anchor" aria-hidden="true" href="#disadvantages-denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): denormalization&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Data is duplicated.&lt;/li&gt;
&lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt;
&lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt;
&lt;/ul&gt;
&lt;h6&gt;&lt;a id="user-content-sources-and-further-reading-denormalization" class="anchor" aria-hidden="true" href="#sources-and-further-reading-denormalization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: denormalization&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Denormalization" rel="nofollow"&gt;Denormalization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sql-tuning" class="anchor" aria-hidden="true" href="#sql-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQL tuning&lt;/h4&gt;
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href="https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning" rel="nofollow"&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt;
&lt;p&gt;It's important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href="http://httpd.apache.org/docs/2.2/programs/ab.html" rel="nofollow"&gt;ab&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html" rel="nofollow"&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-tighten-up-the-schema" class="anchor" aria-hidden="true" href="#tighten-up-the-schema"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tighten up the schema&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts.  &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches.  Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt;
&lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search" rel="nofollow"&gt;improve search performance&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-use-good-indices" class="anchor" aria-hidden="true" href="#use-good-indices"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use good indices&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt;
&lt;li&gt;Indices are usually represented as self-balancing &lt;a href="https://en.wikipedia.org/wiki/B-tree" rel="nofollow"&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt;
&lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt;
&lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt;
&lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-avoid-expensive-joins" class="anchor" aria-hidden="true" href="#avoid-expensive-joins"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Avoid expensive joins&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#denormalization"&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-partition-tables" class="anchor" aria-hidden="true" href="#partition-tables"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Partition tables&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-tune-the-query-cache" class="anchor" aria-hidden="true" href="#tune-the-query-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tune the query cache&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;In some cases, the &lt;a href="https://dev.mysql.com/doc/refman/5.7/en/query-cache.html" rel="nofollow"&gt;query cache&lt;/a&gt; could lead to &lt;a href="https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/" rel="nofollow"&gt;performance issues&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sql-tuning" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sql-tuning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/" rel="nofollow"&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l" rel="nofollow"&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search" rel="nofollow"&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html" rel="nofollow"&gt;Slow query log&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-nosql" class="anchor" aria-hidden="true" href="#nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NoSQL&lt;/h3&gt;
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;.  Data is denormalized, and joins are generally done in the application code.  Most NoSQL stores lack true ACID transactions and favor &lt;a href="#eventual-consistency"&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases.  In comparison with the &lt;a href="#cap-theorem"&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn't receive input during that period.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to choosing between &lt;a href="#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s).  We'll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-key-value-store" class="anchor" aria-hidden="true" href="#key-value-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Key-value store&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: hash table&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD.  Data stores can maintain keys in &lt;a href="https://en.wikipedia.org/wiki/Lexicographical_order" rel="nofollow"&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges.  Key-value stores can allow for storing of metadata with a value.&lt;/p&gt;
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer.  Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt;
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-key-value-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-key-value-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: key-value store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Key-value_database" rel="nofollow"&gt;Key-value database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or" rel="nofollow"&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qnimate.com/overview-of-redis-architecture/" rel="nofollow"&gt;Redis architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.adayinthelifeof.nl/2011/02/06/memcache-internals/" rel="nofollow"&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-document-store" class="anchor" aria-hidden="true" href="#document-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Document store&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object.  Document stores provide APIs or a query language to query based on the internal structure of the document itself.  &lt;em&gt;Note, many key-value stores include features for working with a value's metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories.  Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt;
&lt;p&gt;Some document stores like &lt;a href="https://www.mongodb.com/mongodb-architecture" rel="nofollow"&gt;MongoDB&lt;/a&gt; and &lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/" rel="nofollow"&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries.  &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf" rel="nofollow"&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt;
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-document-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-document-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: document store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Document-oriented_database" rel="nofollow"&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mongodb.com/mongodb-architecture" rel="nofollow"&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/" rel="nofollow"&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up" rel="nofollow"&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-wide-column-store" class="anchor" aria-hidden="true" href="#wide-column-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Wide column store&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/823668b07b4bff50574e934273c9244e4e5017d6/687474703a2f2f692e696d6775722e636f6d2f6e3136694f476b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/823668b07b4bff50574e934273c9244e4e5017d6/687474703a2f2f692e696d6775722e636f6d2f6e3136694f476b2e706e67" data-canonical-src="http://i.imgur.com/n16iOGk.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html" rel="nofollow"&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A wide column store's basic unit of data is a column (name/value pair).  A column can be grouped in column families (analogous to a SQL table).  Super column families further group column families.  You can access each column independently with a row key, and columns with the same row key form a row.  Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt;
&lt;p&gt;Google introduced &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" rel="nofollow"&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html" rel="nofollow"&gt;Cassandra&lt;/a&gt; from Facebook.  Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt;
&lt;p&gt;Wide column stores offer high availability and high scalability.  They are often used for very large data sets.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-wide-column-store" class="anchor" aria-hidden="true" href="#sources-and-further-reading-wide-column-store"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: wide column store&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html" rel="nofollow"&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture" rel="nofollow"&gt;HBase architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html" rel="nofollow"&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-graph-database" class="anchor" aria-hidden="true" href="#graph-database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Graph database&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bf6508b65e98a7210d9861515833afa0d9434436/687474703a2f2f692e696d6775722e636f6d2f664e636c3635672e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/bf6508b65e98a7210d9861515833afa0d9434436/687474703a2f2f692e696d6775722e636f6d2f664e636c3635672e706e67" data-canonical-src="http://i.imgur.com/fNcl65g.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png" rel="nofollow"&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Abstraction: graph&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes.  Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt;
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network.  They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources.  Many graphs can only be accessed with &lt;a href="#representational-state-transfer-rest"&gt;REST APIs&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-graph" class="anchor" aria-hidden="true" href="#sources-and-further-reading-graph"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: graph&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database" rel="nofollow"&gt;Graph database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://neo4j.com/" rel="nofollow"&gt;Neo4j&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.twitter.com/2010/introducing-flockdb" rel="nofollow"&gt;FlockDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-nosql" class="anchor" aria-hidden="true" href="#sources-and-further-reading-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: NoSQL&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/3342497/explanation-of-base-terminology" rel="nofollow"&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq" rel="nofollow"&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qI_g07C_Q5I" rel="nofollow"&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html" rel="nofollow"&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sql-or-nosql" class="anchor" aria-hidden="true" href="#sql-or-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SQL or NoSQL&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a6e2e844765c9d5382d9c9b64ef7693977981646/687474703a2f2f692e696d6775722e636f6d2f775847714735662e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/a6e2e844765c9d5382d9c9b64ef7693977981646/687474703a2f2f692e696d6775722e636f6d2f775847714735662e706e67" data-canonical-src="http://i.imgur.com/wXGqG5f.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.infoq.com/articles/Transition-RDBMS-NoSQL/" rel="nofollow"&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Structured data&lt;/li&gt;
&lt;li&gt;Strict schema&lt;/li&gt;
&lt;li&gt;Relational data&lt;/li&gt;
&lt;li&gt;Need for complex joins&lt;/li&gt;
&lt;li&gt;Transactions&lt;/li&gt;
&lt;li&gt;Clear patterns for scaling&lt;/li&gt;
&lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt;
&lt;li&gt;Lookups by index are very fast&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semi-structured data&lt;/li&gt;
&lt;li&gt;Dynamic or flexible schema&lt;/li&gt;
&lt;li&gt;Non-relational data&lt;/li&gt;
&lt;li&gt;No need for complex joins&lt;/li&gt;
&lt;li&gt;Store many TB (or PB) of data&lt;/li&gt;
&lt;li&gt;Very data intensive workload&lt;/li&gt;
&lt;li&gt;Very high throughput for IOPS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt;
&lt;li&gt;Leaderboard or scoring data&lt;/li&gt;
&lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt;
&lt;li&gt;Frequently accessed ('hot') tables&lt;/li&gt;
&lt;li&gt;Metadata/lookup tables&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-sources-and-further-reading-sql-or-nosql" class="anchor" aria-hidden="true" href="#sources-and-further-reading-sql-or-nosql"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=w95murBkYmU" rel="nofollow"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sitepoint.com/sql-vs-nosql-differences/" rel="nofollow"&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-cache" class="anchor" aria-hidden="true" href="#cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cache&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7acedde6aa7853baf2eb4a53f88e2595ebe43756/687474703a2f2f692e696d6775722e636f6d2f51367a32344c612e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/7acedde6aa7853baf2eb4a53f88e2595ebe43756/687474703a2f2f692e696d6775722e636f6d2f51367a32344c612e706e67" data-canonical-src="http://i.imgur.com/Q6z24La.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases.  In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt;
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions.  Popular items can skew the distribution, causing bottlenecks.  Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-client-caching" class="anchor" aria-hidden="true" href="#client-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Client caching&lt;/h3&gt;
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href="#reverse-proxy-web-server"&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-cdn-caching" class="anchor" aria-hidden="true" href="#cdn-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CDN caching&lt;/h3&gt;
&lt;p&gt;&lt;a href="#content-delivery-network"&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-web-server-caching" class="anchor" aria-hidden="true" href="#web-server-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Web server caching&lt;/h3&gt;
&lt;p&gt;&lt;a href="#reverse-proxy-web-server"&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href="https://www.varnish-cache.org/" rel="nofollow"&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly.  Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-database-caching" class="anchor" aria-hidden="true" href="#database-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database caching&lt;/h3&gt;
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case.  Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-application-caching" class="anchor" aria-hidden="true" href="#application-caching"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Application caching&lt;/h3&gt;
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage.  Since the data is held in RAM, it is much faster than typical databases where data is stored on disk.  RAM is more limited than disk, so &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms" rel="nofollow"&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used" rel="nofollow"&gt;least recently used (LRU)&lt;/a&gt; can help invalidate 'cold' entries and keep 'hot' data in RAM.&lt;/p&gt;
&lt;p&gt;Redis has the following additional features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Persistence option&lt;/li&gt;
&lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Row level&lt;/li&gt;
&lt;li&gt;Query-level&lt;/li&gt;
&lt;li&gt;Fully-formed serializable objects&lt;/li&gt;
&lt;li&gt;Fully-rendered HTML&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-caching-at-the-database-query-level" class="anchor" aria-hidden="true" href="#caching-at-the-database-query-level"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching at the database query level&lt;/h3&gt;
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache.  This approach suffers from expiration issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt;
&lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-caching-at-the-object-level" class="anchor" aria-hidden="true" href="#caching-at-the-object-level"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caching at the object level&lt;/h3&gt;
&lt;p&gt;See your data as an object, similar to what you do with your application code.  Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt;
&lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User sessions&lt;/li&gt;
&lt;li&gt;Fully rendered web pages&lt;/li&gt;
&lt;li&gt;Activity streams&lt;/li&gt;
&lt;li&gt;User graph data&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-when-to-update-the-cache" class="anchor" aria-hidden="true" href="#when-to-update-the-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;When to update the cache&lt;/h3&gt;
&lt;p&gt;Since you can only store a limited amount of data in cache, you'll need to determine which cache update strategy works best for your use case.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-cache-aside" class="anchor" aria-hidden="true" href="#cache-aside"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cache-aside&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/7f5934e49a678b67f65e5ed53134bc258b007ebb/687474703a2f2f692e696d6775722e636f6d2f4f4e6a4f52716b2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/7f5934e49a678b67f65e5ed53134bc258b007ebb/687474703a2f2f692e696d6775722e636f6d2f4f4e6a4f52716b2e706e67" data-canonical-src="http://i.imgur.com/ONjORqk.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;The application is responsible for reading and writing from storage.  The cache does not interact with storage directly.  The application does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt;
&lt;li&gt;Load entry from the database&lt;/li&gt;
&lt;li&gt;Add entry to cache&lt;/li&gt;
&lt;li&gt;Return entry&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;get_user&lt;/span&gt;(&lt;span class="pl-smi"&gt;&lt;span class="pl-smi"&gt;self&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-smi"&gt;user_id&lt;/span&gt;):
    user &lt;span class="pl-k"&gt;=&lt;/span&gt; cache.get(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;user.&lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id)
    &lt;span class="pl-k"&gt;if&lt;/span&gt; user &lt;span class="pl-k"&gt;is&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;:
        user &lt;span class="pl-k"&gt;=&lt;/span&gt; db.query(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;SELECT * FROM users WHERE user_id = &lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id)
        &lt;span class="pl-k"&gt;if&lt;/span&gt; user &lt;span class="pl-k"&gt;is&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; &lt;span class="pl-c1"&gt;None&lt;/span&gt;:
            key &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;user.&lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;.format(user_id)
            cache.set(key, json.dumps(user))
    &lt;span class="pl-k"&gt;return&lt;/span&gt; user&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="https://memcached.org/" rel="nofollow"&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt;
&lt;p&gt;Subsequent reads of data added to cache are fast.  Cache-aside is also referred to as lazy loading.  Only requested data is cached, which avoids filling up the cache with data that isn't requested.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-cache-aside" class="anchor" aria-hidden="true" href="#disadvantages-cache-aside"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): cache-aside&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt;
&lt;li&gt;Data can become stale if it is updated in the database.  This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt;
&lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-write-through" class="anchor" aria-hidden="true" href="#write-through"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Write-through&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/56b870f4d199335ccdbc98b989ef6511ed14f0e2/687474703a2f2f692e696d6775722e636f6d2f3076426330684e2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/56b870f4d199335ccdbc98b989ef6511ed14f0e2/687474703a2f2f692e696d6775722e636f6d2f3076426330684e2e706e67" data-canonical-src="http://i.imgur.com/0vBc0hN.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Application adds/updates entry in cache&lt;/li&gt;
&lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt;
&lt;li&gt;Return&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Application code:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;set_user(&lt;span class="pl-c1"&gt;12345&lt;/span&gt;, {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;foo&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;:&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;bar&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;})&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Cache code:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;set_user&lt;/span&gt;(&lt;span class="pl-smi"&gt;user_id&lt;/span&gt;, &lt;span class="pl-smi"&gt;values&lt;/span&gt;):
    user &lt;span class="pl-k"&gt;=&lt;/span&gt; db.query(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;UPDATE Users WHERE id = &lt;span class="pl-c1"&gt;{0}&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, user_id, values)
    cache.set(user_id, user)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast.  Users are generally more tolerant of latency when updating data than reading data.  Data in the cache is not stale.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-write-through" class="anchor" aria-hidden="true" href="#disadvantages-write-through"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): write through&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database.  Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt;
&lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-write-behind-write-back" class="anchor" aria-hidden="true" href="#write-behind-write-back"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Write-behind (write-back)&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/8aa9f1a2f050c1422898bb5e82f1f01773334e22/687474703a2f2f692e696d6775722e636f6d2f72675372766a472e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/8aa9f1a2f050c1422898bb5e82f1f01773334e22/687474703a2f2f692e696d6775722e636f6d2f72675372766a472e706e67" data-canonical-src="http://i.imgur.com/rgSrvjG.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add/update entry in cache&lt;/li&gt;
&lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-write-behind" class="anchor" aria-hidden="true" href="#disadvantages-write-behind"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): write-behind&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt;
&lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-refresh-ahead" class="anchor" aria-hidden="true" href="#refresh-ahead"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Refresh-ahead&lt;/h4&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/49dcb54307763b4f56d61a4a1369826e2e7d52e4/687474703a2f2f692e696d6775722e636f6d2f6b78746a7167452e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/49dcb54307763b4f56d61a4a1369826e2e7d52e4/687474703a2f2f692e696d6775722e636f6d2f6b78746a7167452e706e67" data-canonical-src="http://i.imgur.com/kxtjqgE.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt;
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt;
&lt;h5&gt;&lt;a id="user-content-disadvantages-refresh-ahead" class="anchor" aria-hidden="true" href="#disadvantages-refresh-ahead"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-cache" class="anchor" aria-hidden="true" href="#disadvantages-cache"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): cache&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms" rel="nofollow"&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt;
&lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-10" class="anchor" aria-hidden="true" href="#sources-and-further-reading-10"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast" rel="nofollow"&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html" rel="nofollow"&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/" rel="nofollow"&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/" rel="nofollow"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache" rel="nofollow"&gt;Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html" rel="nofollow"&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cache_(computing)" rel="nofollow"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-asynchronism" class="anchor" aria-hidden="true" href="#asynchronism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Asynchronism&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/c01ec137453216bbc188e3a8f16da39ec9131234/687474703a2f2f692e696d6775722e636f6d2f353447597353782e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/c01ec137453216bbc188e3a8f16da39ec9131234/687474703a2f2f692e696d6775722e636f6d2f353447597353782e706e67" data-canonical-src="http://i.imgur.com/54GYsSx.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer" rel="nofollow"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line.  They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-message-queues" class="anchor" aria-hidden="true" href="#message-queues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Message queues&lt;/h3&gt;
&lt;p&gt;Message queues receive, hold, and deliver messages.  If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt;
&lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The user is not blocked and the job is processed in the background.  During this time, the client might optionally do a small amount of processing to make it seem like the task has completed.  For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://redis.io/" rel="nofollow"&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.rabbitmq.com/" rel="nofollow"&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the 'AMQP' protocol and manage your own nodes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/sqs/" rel="nofollow"&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-task-queues" class="anchor" aria-hidden="true" href="#task-queues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Task queues&lt;/h3&gt;
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results.  They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Celery&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-back-pressure" class="anchor" aria-hidden="true" href="#back-pressure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Back pressure&lt;/h3&gt;
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance.  &lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html" rel="nofollow"&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue.  Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later.  Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff" rel="nofollow"&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-disadvantages-asynchronism" class="anchor" aria-hidden="true" href="#disadvantages-asynchronism"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): asynchronism&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-11" class="anchor" aria-hidden="true" href="#sources-and-further-reading-11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1KRYH75wgy4" rel="nofollow"&gt;It's all a numbers game&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html" rel="nofollow"&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Little%27s_law" rel="nofollow"&gt;Little's law&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function" rel="nofollow"&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-communication" class="anchor" aria-hidden="true" href="#communication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Communication&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1d761d5688d28ce1fb12a0f1c8191bca96eece4c/687474703a2f2f692e696d6775722e636f6d2f354b656f6351732e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/1d761d5688d28ce1fb12a0f1c8191bca96eece4c/687474703a2f2f692e696d6775722e636f6d2f354b656f6351732e6a7067" data-canonical-src="http://i.imgur.com/5KeocQs.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.escotal.com/osilayer.html" rel="nofollow"&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-hypertext-transfer-protocol-http" class="anchor" aria-hidden="true" href="#hypertext-transfer-protocol-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt;
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server.  It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request.  HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt;
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint).  Below are common HTTP verbs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Verb&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Idempotent*&lt;/th&gt;
&lt;th&gt;Safe&lt;/th&gt;
&lt;th&gt;Cacheable&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;GET&lt;/td&gt;
&lt;td&gt;Reads a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;POST&lt;/td&gt;
&lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Yes if response contains freshness info&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUT&lt;/td&gt;
&lt;td&gt;Creates or replace a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PATCH&lt;/td&gt;
&lt;td&gt;Partially updates a resource&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Yes if response contains freshness info&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DELETE&lt;/td&gt;
&lt;td&gt;Deletes a resource&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt;
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-http" class="anchor" aria-hidden="true" href="#sources-and-further-reading-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: HTTP&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/http/" rel="nofollow"&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol" rel="nofollow"&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1" rel="nofollow"&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-transmission-control-protocol-tcp" class="anchor" aria-hidden="true" href="#transmission-control-protocol-tcp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transmission control protocol (TCP)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/821620cf6aa83566f4def561e754e5991480ca8d/687474703a2f2f692e696d6775722e636f6d2f4a6441736476472e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/821620cf6aa83566f4def561e754e5991480ca8d/687474703a2f2f692e696d6775722e636f6d2f4a6441736476472e6a7067" data-canonical-src="http://i.imgur.com/JdAsdvG.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/" rel="nofollow"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href="https://en.wikipedia.org/wiki/Internet_Protocol" rel="nofollow"&gt;IP network&lt;/a&gt;.  Connection is established and terminated using a &lt;a href="https://en.wikipedia.org/wiki/Handshaking" rel="nofollow"&gt;handshake&lt;/a&gt;.  All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequence numbers and &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation" rel="nofollow"&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)" rel="nofollow"&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets.  If there are multiple timeouts, the connection is dropped.  TCP also implements &lt;a href="https://en.wikipedia.org/wiki/Flow_control_(data)" rel="nofollow"&gt;flow control&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Network_congestion#Congestion_control" rel="nofollow"&gt;congestion control&lt;/a&gt;.  These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt;
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage.  It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href="https://memcached.org/" rel="nofollow"&gt;memcached&lt;/a&gt; server.  &lt;a href="https://en.wikipedia.org/wiki/Connection_pool" rel="nofollow"&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt;
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical.  Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt;
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need all of the data to arrive intact&lt;/li&gt;
&lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-user-datagram-protocol-udp" class="anchor" aria-hidden="true" href="#user-datagram-protocol-udp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;User datagram protocol (UDP)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/47eb14c0a2dff2166f8781a6ce8c7f33d4c33da8/687474703a2f2f692e696d6775722e636f6d2f797a44724a74412e6a7067"&gt;&lt;img src="https://camo.githubusercontent.com/47eb14c0a2dff2166f8781a6ce8c7f33d4c33da8/687474703a2f2f692e696d6775722e636f6d2f797a44724a74412e6a7067" data-canonical-src="http://i.imgur.com/yzDrJtA.jpg" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/" rel="nofollow"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;UDP is connectionless.  Datagrams (analogous to packets) are guaranteed only at the datagram level.  Datagrams might reach their destination out of order or not at all.  UDP does not support congestion control.  Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt;
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet.  This is useful with &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol" rel="nofollow"&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt;
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt;
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need the lowest latency&lt;/li&gt;
&lt;li&gt;Late data is worse than loss of data&lt;/li&gt;
&lt;li&gt;You want to implement your own error correction&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-tcp-and-udp" class="anchor" aria-hidden="true" href="#sources-and-further-reading-tcp-and-udp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/" rel="nofollow"&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/" rel="nofollow"&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp" rel="nofollow"&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol" rel="nofollow"&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol" rel="nofollow"&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf" rel="nofollow"&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-remote-procedure-call-rpc" class="anchor" aria-hidden="true" href="#remote-procedure-call-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Remote procedure call (RPC)&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1a3d7771c0b0a7816d0533fffeb6eeeb442d9945/687474703a2f2f692e696d6775722e636f6d2f6946344d6b62352e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/1a3d7771c0b0a7816d0533fffeb6eeeb442d9945/687474703a2f2f692e696d6775722e636f6d2f6946344d6b62352e706e67" data-canonical-src="http://i.imgur.com/iF4Mkb5.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server.  The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program.  Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls.  Popular RPC frameworks include &lt;a href="https://developers.google.com/protocol-buffers/" rel="nofollow"&gt;Protobuf&lt;/a&gt;, &lt;a href="https://thrift.apache.org/" rel="nofollow"&gt;Thrift&lt;/a&gt;, and &lt;a href="https://avro.apache.org/docs/current/" rel="nofollow"&gt;Avro&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure.  The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; -  Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt;
&lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample RPC calls:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  "data":"anId";
  "anotherdata": "another value"
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RPC is focused on exposing behaviors.  RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt;
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You know your target platform.&lt;/li&gt;
&lt;li&gt;You want to control how your "logic" is accessed.&lt;/li&gt;
&lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt;
&lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-rpc" class="anchor" aria-hidden="true" href="#disadvantages-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): RPC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt;
&lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt;
&lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt;
&lt;li&gt;You might not be able to leverage existing technologies out of the box.  For example, it might require additional effort to ensure &lt;a href="http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/" rel="nofollow"&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href="http://www.squid-cache.org/" rel="nofollow"&gt;Squid&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-representational-state-transfer-rest" class="anchor" aria-hidden="true" href="#representational-state-transfer-rest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Representational state transfer (REST)&lt;/h3&gt;
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server.  The server provides a representation of resources and actions that can either manipulate or get a new representation of resources.  All communication must be stateless and cacheable.&lt;/p&gt;
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don't reinvent the wheel.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="http://restcookbook.com/Basics/hateoas/" rel="nofollow"&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sample REST calls:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{"anotherdata": "another value"}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;REST is focused on exposing data.  It minimizes the coupling between client/server and is often used for public HTTP APIs.  REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href="https://github.com/for-GET/know-your-http-well/blob/master/headers.md"&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH.  Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-disadvantages-rest" class="anchor" aria-hidden="true" href="#disadvantages-rest"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disadvantage(s): REST&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy.  For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path.  With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt;
&lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn't fit your use case.  For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt;
&lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt;
&lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-rpc-and-rest-calls-comparison" class="anchor" aria-hidden="true" href="#rpc-and-rest-calls-comparison"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RPC and REST calls comparison&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operation&lt;/th&gt;
&lt;th&gt;RPC&lt;/th&gt;
&lt;th&gt;REST&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Signup&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resign&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br&gt;{&lt;br&gt;"personid": "1234"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read a person&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read a person‚Äôs items list&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add an item to a person‚Äôs items&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br&gt;{&lt;br&gt;"personid": "1234";&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Update an item&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br&gt;{&lt;br&gt;"itemid": "456";&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br&gt;{&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Delete an item&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align="center"&gt;
  &lt;i&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/" rel="nofollow"&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-rest-and-rpc" class="anchor" aria-hidden="true" href="#sources-and-further-reading-rest-and-rpc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/" rel="nofollow"&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://programmers.stackexchange.com/a/181186" rel="nofollow"&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15056878/rest-vs-json-rpc" rel="nofollow"&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/" rel="nofollow"&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs" rel="nofollow"&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.facebook.com/posts/1468950976659943/" rel="nofollow"&gt;Thrift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arstechnica.com/civis/viewtopic.php?t=1190508" rel="nofollow"&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-security" class="anchor" aria-hidden="true" href="#security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Security&lt;/h2&gt;
&lt;p&gt;This section could use some updates.  Consider &lt;a href="#contributing"&gt;contributing&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Security is a broad topic.  Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won't need to know more than the basics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt;
&lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting" rel="nofollow"&gt;XSS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/SQL_injection" rel="nofollow"&gt;SQL injection&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt;
&lt;li&gt;Use the principle of &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege" rel="nofollow"&gt;least privilege&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sources-and-further-reading-12" class="anchor" aria-hidden="true" href="#sources-and-further-reading-12"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/FallibleInc/security-guide-for-developers"&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet" rel="nofollow"&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-appendix" class="anchor" aria-hidden="true" href="#appendix"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Appendix&lt;/h2&gt;
&lt;p&gt;You'll sometimes be asked to do 'back-of-the-envelope' estimates.  For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take.  The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-powers-of-two-table" class="anchor" aria-hidden="true" href="#powers-of-two-table"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Powers of two table&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-13" class="anchor" aria-hidden="true" href="#sources-and-further-reading-13"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Power_of_two" rel="nofollow"&gt;Powers of two&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-latency-numbers-every-programmer-should-know" class="anchor" aria-hidden="true" href="#latency-numbers-every-programmer-should-know"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency numbers every programmer should know&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read sequentially from disk at 30 MB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt;
&lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt;
&lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt;
&lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-latency-numbers-visualized" class="anchor" aria-hidden="true" href="#latency-numbers-visualized"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency numbers visualized&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-14" class="anchor" aria-hidden="true" href="#sources-and-further-reading-14"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf" rel="nofollow"&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf" rel="nofollow"&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-additional-system-design-interview-questions" class="anchor" aria-hidden="true" href="#additional-system-design-interview-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional system design interview questions&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Question&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc" rel="nofollow"&gt;youtube.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a search engine like Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://queue.acm.org/detail.cfm?id=988407" rel="nofollow"&gt;queue.acm.org&lt;/a&gt;&lt;br&gt;&lt;a href="http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search" rel="nofollow"&gt;stackexchange.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.ardendertat.com/2012/01/11/implementing-search-engines/" rel="nofollow"&gt;ardendertat.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://infolab.stanford.edu/~backrub/google.html" rel="nofollow"&gt;stanford.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design Google docs&lt;/td&gt;
&lt;td&gt;&lt;a href="https://code.google.com/p/google-mobwrite/" rel="nofollow"&gt;code.google.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://neil.fraser.name/writing/sync/" rel="nofollow"&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a key-value store like Redis&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a cache system like Memcached&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a recommendation system like Amazon's&lt;/td&gt;
&lt;td&gt;&lt;a href="https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html" rel="nofollow"&gt;hulu.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf" rel="nofollow"&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt;
&lt;td&gt;&lt;a href="http://n00tc0d3r.blogspot.com/" rel="nofollow"&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook news feed function&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed" rel="nofollow"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook timeline function&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.facebook.com/note.php?note_id=10150468255628920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design the Facebook chat function&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf" rel="nofollow"&gt;erlang-factory.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a graph search function like Facebook's&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920" rel="nofollow"&gt;facebook.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt;
&lt;td&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972" rel="nofollow"&gt;figshare.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a trending topic system like Twitter's&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/" rel="nofollow"&gt;michael-noll.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/" rel="nofollow"&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a random ID generation system&lt;/td&gt;
&lt;td&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake" rel="nofollow"&gt;blog.twitter.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/twitter/snowflake/"&gt;github.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Return the top k requests during a time interval&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cs.ucsb.edu/sites/cs.ucsb.edu/files/docs/reports/2005-23.pdf" rel="nofollow"&gt;cs.ucsb.edu&lt;/a&gt;&lt;br&gt;&lt;a href="http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf" rel="nofollow"&gt;wpi.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html" rel="nofollow"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design an online multiplayer card game&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html" rel="nofollow"&gt;indieflashblog.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://buildnewgames.com/real-time-multiplayer/" rel="nofollow"&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design a garbage collection system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/" rel="nofollow"&gt;stuffwithstuff.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf" rel="nofollow"&gt;washington.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Design an API rate limiter&lt;/td&gt;
&lt;td&gt;&lt;a href="https://stripe.com/blog/rate-limiters" rel="nofollow"&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Add a system design question&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-real-world-architectures" class="anchor" aria-hidden="true" href="#real-world-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Real world architectures&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b7c71be73fb466344c2d773178ae74e3fbb1dcc6/687474703a2f2f692e696d6775722e636f6d2f5463556f3266772e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/b7c71be73fb466344c2d773178ae74e3fbb1dcc6/687474703a2f2f692e696d6775722e636f6d2f5463556f3266772e706e67" data-canonical-src="http://i.imgur.com/TcUo2fw.png" style="max-width:100%;"&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;i&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability" rel="nofollow"&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Don't focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt;
&lt;li&gt;Study what problems are solved by each component, where it works, where it doesn't&lt;/li&gt;
&lt;li&gt;Review the lessons learned&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/AGrishchenko/apache-spark-architecture" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data processing&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/previa/storm-16094009" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf" rel="nofollow"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/alexbaranau/intro-to-hbase" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf" rel="nofollow"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/mdirolf/introduction-to-mongodb" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://research.google.com/archive/spanner-osdi2012.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data store&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File system&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File system&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt;
&lt;td&gt;&lt;a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" rel="nofollow"&gt;apache.org&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt;
&lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf" rel="nofollow"&gt;research.google.com&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/mumrah/kafka-talk-tri-hug" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Misc&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" rel="nofollow"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Add an architecture&lt;/td&gt;
&lt;td&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-company-architectures" class="anchor" aria-hidden="true" href="#company-architectures"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Company architectures&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Company&lt;/th&gt;
&lt;th&gt;Reference(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Amazon&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/amazon-architecture" rel="nofollow"&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cinchcast&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html" rel="nofollow"&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DataSift&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html" rel="nofollow"&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DropBox&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc" rel="nofollow"&gt;How we've scaled Dropbox&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ESPN&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html" rel="nofollow"&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/google-architecture" rel="nofollow"&gt;Google architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Instagram&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html" rel="nofollow"&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br&gt;&lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances" rel="nofollow"&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Justin.tv&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html" rel="nofollow"&gt;Justin.Tv's live video broadcasting architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Facebook&lt;/td&gt;
&lt;td&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf" rel="nofollow"&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf" rel="nofollow"&gt;TAO: Facebook‚Äôs distributed data store for the social graph&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf" rel="nofollow"&gt;Facebook‚Äôs photo storage&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html" rel="nofollow"&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Flickr&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture" rel="nofollow"&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mailbox&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html" rel="nofollow"&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Netflix&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html" rel="nofollow"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html" rel="nofollow"&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pinterest&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html" rel="nofollow"&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html" rel="nofollow"&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Playfish&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html" rel="nofollow"&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PlentyOfFish&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/plentyoffish-architecture" rel="nofollow"&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Salesforce&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html" rel="nofollow"&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stack Overflow&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html" rel="nofollow"&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TripAdvisor&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html" rel="nofollow"&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tumblr&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html" rel="nofollow"&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Twitter&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster" rel="nofollow"&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html" rel="nofollow"&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html" rel="nofollow"&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability" rel="nofollow"&gt;Timelines at scale&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI" rel="nofollow"&gt;Big and small data at Twitter&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=z8LU0Cj6BOU" rel="nofollow"&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html" rel="nofollow"&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Uber&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html" rel="nofollow"&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html" rel="nofollow"&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WhatsApp&lt;/td&gt;
&lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html" rel="nofollow"&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;YouTube&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=w5WVu624fY8" rel="nofollow"&gt;YouTube scalability&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/youtube-architecture" rel="nofollow"&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-company-engineering-blogs" class="anchor" aria-hidden="true" href="#company-engineering-blogs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Company engineering blogs&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt;
&lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://nerds.airbnb.com/" rel="nofollow"&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.atlassian.com/blog/" rel="nofollow"&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/aws/" rel="nofollow"&gt;AWS Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://word.bitly.com/" rel="nofollow"&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.box.com/blog/category/engineering" rel="nofollow"&gt;Box Blogs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.cloudera.com/" rel="nofollow"&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tech.dropbox.com/" rel="nofollow"&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.quora.com/" rel="nofollow"&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ebaytechblog.com/" rel="nofollow"&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.evernote.com/tech/" rel="nofollow"&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://codeascraft.com/" rel="nofollow"&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.facebook.com/Engineering" rel="nofollow"&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://code.flickr.net/" rel="nofollow"&gt;Flickr Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.foursquare.com/" rel="nofollow"&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://githubengineering.com/" rel="nofollow"&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://googleresearch.blogspot.com/" rel="nofollow"&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.groupon.com/" rel="nofollow"&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.heroku.com/" rel="nofollow"&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://product.hubspot.com/blog/topic/engineering" rel="nofollow"&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/" rel="nofollow"&gt;High Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://instagram-engineering.tumblr.com/" rel="nofollow"&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://software.intel.com/en-us/blogs/" rel="nofollow"&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.janestreet.com/category/ocaml/" rel="nofollow"&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineering.linkedin.com/blog" rel="nofollow"&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.microsoft.com/" rel="nofollow"&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.msdn.microsoft.com/pythonengineering/" rel="nofollow"&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://techblog.netflix.com/" rel="nofollow"&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://devblog.paypal.com/category/engineering/" rel="nofollow"&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@Pinterest_Engineering" rel="nofollow"&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://engineering.quora.com/" rel="nofollow"&gt;Quora Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.redditblog.com/" rel="nofollow"&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.salesforce.com/blogs/engineering/" rel="nofollow"&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://slack.engineering/" rel="nofollow"&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labs.spotify.com/" rel="nofollow"&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.twilio.com/engineering" rel="nofollow"&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.twitter.com/engineering/" rel="nofollow"&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eng.uber.com/" rel="nofollow"&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yahooeng.tumblr.com/" rel="nofollow"&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://engineeringblog.yelp.com/" rel="nofollow"&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.zynga.com/blogs/engineering" rel="nofollow"&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-sources-and-further-reading-15" class="anchor" aria-hidden="true" href="#sources-and-further-reading-15"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Source(s) and further reading&lt;/h4&gt;
&lt;p&gt;Looking to add a blog?  To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kilimchoi/engineering-blogs"&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-under-development" class="anchor" aria-hidden="true" href="#under-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Under development&lt;/h2&gt;
&lt;p&gt;Interested in adding a section or helping complete one in-progress?  &lt;a href="#contributing"&gt;Contribute&lt;/a&gt;!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distributed computing with MapReduce&lt;/li&gt;
&lt;li&gt;Consistent hashing&lt;/li&gt;
&lt;li&gt;Scatter gather&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contribute&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt;
&lt;p&gt;Special thanks to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/" rel="nofollow"&gt;Hired in tech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/dp/0984782850/" rel="nofollow"&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/" rel="nofollow"&gt;High scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shashank88/system_design"&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mmcgrana/services-engineering"&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f"&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dancres.github.io/Pages/" rel="nofollow"&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview" rel="nofollow"&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contact-info" class="anchor" aria-hidden="true" href="#contact-info"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact info&lt;/h2&gt;
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt;
&lt;p&gt;My contact info can be found on my &lt;a href="https://github.com/donnemartin"&gt;GitHub page&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>donnemartin</author><guid isPermaLink="false">https://github.com/donnemartin/system-design-primer</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>tensorflow/models #13 in Python, Today</title><link>https://github.com/tensorflow/models</link><description>&lt;p&gt;&lt;i&gt;Models and examples built with TensorFlow&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-models" class="anchor" aria-hidden="true" href="#tensorflow-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow Models&lt;/h1&gt;
&lt;p&gt;This repository contains a number of different models implemented in &lt;a href="https://www.tensorflow.org" rel="nofollow"&gt;TensorFlow&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;The &lt;a href="official"&gt;official models&lt;/a&gt; are a collection of example models that use TensorFlow's high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest stable TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read. We especially recommend newer TensorFlow users to start here.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/tensorflow/models/tree/master/research"&gt;research models&lt;/a&gt; are a large collection of models implemented in TensorFlow by researchers. They are not officially supported or available in release branches; it is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.&lt;/p&gt;
&lt;p&gt;The &lt;a href="samples"&gt;samples folder&lt;/a&gt; contains code snippets and smaller models that demonstrate features of TensorFlow, including code presented in various blog posts.&lt;/p&gt;
&lt;p&gt;The &lt;a href="tutorials"&gt;tutorials folder&lt;/a&gt; is a collection of models described in the &lt;a href="https://www.tensorflow.org/tutorials/" rel="nofollow"&gt;TensorFlow tutorials&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-guidelines" class="anchor" aria-hidden="true" href="#contribution-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution guidelines&lt;/h2&gt;
&lt;p&gt;If you want to contribute to models, be sure to review the &lt;a href="CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tensorflow</author><guid isPermaLink="false">https://github.com/tensorflow/models</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>michuanhaohao/reid-strong-baseline #14 in Python, Today</title><link>https://github.com/michuanhaohao/reid-strong-baseline</link><description>&lt;p&gt;&lt;i&gt;Bag of Tricks and A Strong Baseline for Deep Person Re-identification&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bag-of-tricks-and-a-strong-reid-baseline" class="anchor" aria-hidden="true" href="#bag-of-tricks-and-a-strong-reid-baseline"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bag of Tricks and A Strong ReID Baseline&lt;/h1&gt;
&lt;p&gt;Bag of Tricks and A Strong Baseline for Deep Person Re-identification. CVPRW2019, Oral.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/TRMTMCT/Luo_Bag_of_Tricks_and_a_Strong_Baseline_for_Deep_Person_CVPRW_2019_paper.pdf" rel="nofollow"&gt;[PDF]&lt;/a&gt;
&lt;a href="https://drive.google.com/open?id=1h9SgdJenvfoNp9PTUxPiz5_K5HFCho-V" rel="nofollow"&gt;[Slides]&lt;/a&gt;
&lt;a href="https://drive.google.com/open?id=1izZYAwylBsrldxSMqHCH432P6hnyh1vR" rel="nofollow"&gt;[Poster]&lt;/a&gt;
&lt;a href="https://arxiv.org/pdf/1906.08332" rel="nofollow"&gt;[Journal Version]&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-we-are-very-grateful-for-your-contribution-to-our-project-and-hope-that-this-project-can-help-your-research-or-work" class="anchor" aria-hidden="true" href="#we-are-very-grateful-for-your-contribution-to-our-project-and-hope-that-this-project-can-help-your-research-or-work"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;We are very grateful for your contribution to our project and hope that this project can help your research or work.&lt;/h3&gt;
&lt;p&gt;The codes are expanded on a &lt;a href="https://github.com/L1aoXingyu/reid_baseline"&gt;ReID-baseline&lt;/a&gt; , which is open sourced by our co-first author &lt;a href="https://github.com/L1aoXingyu"&gt;Xingyu Liao&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another re-implement is developed by python2.7 and pytorch0.4. &lt;a href="https://github.com/wangguanan/Pytorch-Person-REID-Baseline-Bag-of-Tricks"&gt;[link]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A tiny repo with simple re-implement. &lt;a href="https://github.com/lulujianjie/person-reid-tiny-baseline"&gt;[link]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Our baseline also achieves great performance on &lt;strong&gt;Vehicle ReID&lt;/strong&gt; task! &lt;a href="https://github.com/DTennant/reid_baseline_with_syncbn"&gt;[link]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With Ranked List loss(CVPR2019)&lt;a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Ranked_List_Loss_for_Deep_Metric_Learning_CVPR_2019_paper.pdf" rel="nofollow"&gt;[link]&lt;/a&gt;, our baseline can achieve better performance. &lt;a href="https://github.com/Qidian213/Ranked_Person_ReID"&gt;[link]&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@InProceedings{Luo_2019_CVPR_Workshops,
author = {Luo, Hao and Gu, Youzhi and Liao, Xingyu and Lai, Shenqi and Jiang, Wei},
title = {Bag of Tricks and a Strong Baseline for Deep Person Re-Identification},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2019}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/michuanhaohao"&gt;Hao Luo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/shaoniangu"&gt;Youzhi Gu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/L1aoXingyu"&gt;Xingyu Liao&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/xiaolai-sqlai"&gt;Shenqi Lai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We support&lt;/p&gt;
&lt;ul class="contains-task-list"&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; easy dataset preparation&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; end-to-end training and evaluation&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; high modular management&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; speed up inference &lt;a href="https://github.com/DTennant/reid_baseline_with_syncbn"&gt;[link]&lt;/a&gt;&lt;/li&gt;
&lt;li class="task-list-item"&gt;&lt;input type="checkbox" id="" disabled="" class="task-list-item-checkbox" checked=""&gt; support multi-gpus training &lt;a href="https://github.com/DTennant/reid_baseline_with_syncbn"&gt;[link]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bag of tricks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Warm up learning rate&lt;/li&gt;
&lt;li&gt;Random erasing augmentation&lt;/li&gt;
&lt;li&gt;Label smoothing&lt;/li&gt;
&lt;li&gt;Last stride&lt;/li&gt;
&lt;li&gt;BNNeck&lt;/li&gt;
&lt;li&gt;Center loss&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-todo-list" class="anchor" aria-hidden="true" href="#todo-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODO list&lt;/h2&gt;
&lt;p&gt;In the future, we will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[] support more datasets&lt;/li&gt;
&lt;li&gt;[] support more models&lt;/li&gt;
&lt;li&gt;[] explore more tricks&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-pipeline" class="anchor" aria-hidden="true" href="#pipeline"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pipeline&lt;/h2&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="imgs/pipeline.jpg"&gt;&lt;img src="imgs/pipeline.jpg" width="800" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-results-rank1map" class="anchor" aria-hidden="true" href="#results-rank1map"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Results (rank1/mAP)&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Market1501&lt;/th&gt;
&lt;th&gt;DukeMTMC-reID&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Standard baseline&lt;/td&gt;
&lt;td&gt;87.7 (74.0)&lt;/td&gt;
&lt;td&gt;79.7 (63.8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+Warmup&lt;/td&gt;
&lt;td&gt;88.7 (75.2)&lt;/td&gt;
&lt;td&gt;80.6(65.1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+Random erasing augmentation&lt;/td&gt;
&lt;td&gt;91.3 (79.3)&lt;/td&gt;
&lt;td&gt;81.5 (68.3)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+Label smoothing&lt;/td&gt;
&lt;td&gt;91.4 (80.3)&lt;/td&gt;
&lt;td&gt;82.4 (69.3)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+Last stride=1&lt;/td&gt;
&lt;td&gt;92.0 (81.7)&lt;/td&gt;
&lt;td&gt;82.6 (70.6)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+BNNeck&lt;/td&gt;
&lt;td&gt;94.1 (85.7)&lt;/td&gt;
&lt;td&gt;86.2 (75.9)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+Center loss&lt;/td&gt;
&lt;td&gt;94.5 (85.9)&lt;/td&gt;
&lt;td&gt;86.4 (76.4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;+Reranking&lt;/td&gt;
&lt;td&gt;95.4 (94.2)&lt;/td&gt;
&lt;td&gt;90.3 (89.1)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Backbone&lt;/th&gt;
&lt;th&gt;Market1501&lt;/th&gt;
&lt;th&gt;DukeMTMC-reID&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ResNet18&lt;/td&gt;
&lt;td&gt;91.7 (77.8)&lt;/td&gt;
&lt;td&gt;82.5 (68.8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ResNet34&lt;/td&gt;
&lt;td&gt;92.7 (82.7)&lt;/td&gt;
&lt;td&gt;86.4(73.6)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ResNet50&lt;/td&gt;
&lt;td&gt;94.5 (85.9)&lt;/td&gt;
&lt;td&gt;86.4 (76.4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ResNet101&lt;/td&gt;
&lt;td&gt;94.5 (87.1)&lt;/td&gt;
&lt;td&gt;87.6 (77.6)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ResNet152&lt;/td&gt;
&lt;td&gt;80.9 (59.0)&lt;/td&gt;
&lt;td&gt;87.5 (78.0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SeResNet50&lt;/td&gt;
&lt;td&gt;94.4 (86.3)&lt;/td&gt;
&lt;td&gt;86.4 (76.5)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SeResNet101&lt;/td&gt;
&lt;td&gt;94.6 (87.3)&lt;/td&gt;
&lt;td&gt;87.5 (78.0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SeResNeXt50&lt;/td&gt;
&lt;td&gt;94.9 (87.6)&lt;/td&gt;
&lt;td&gt;88.0 (78.3)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SeResNeXt101&lt;/td&gt;
&lt;td&gt;95.0 (88.0)&lt;/td&gt;
&lt;td&gt;88.4 (79.0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IBN-Net50-a&lt;/td&gt;
&lt;td&gt;95.0 (88.2)&lt;/td&gt;
&lt;td&gt;90.1 (79.1)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a href="https://drive.google.com/open?id=1hn0sXLZ5yJcxtmuY-ItQfYD7hBtHwt7A" rel="nofollow"&gt;model(Market1501)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://drive.google.com/open?id=1LARvQe-gUbflbanidUM0keKmHoKTpLUj" rel="nofollow"&gt;model(DukeMTMC-reID)&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-get-started" class="anchor" aria-hidden="true" href="#get-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get Started&lt;/h2&gt;
&lt;p&gt;The designed architecture follows this guide &lt;a href="https://github.com/L1aoXingyu/PyTorch-Project-Template"&gt;PyTorch-Project-Template&lt;/a&gt;, you can check each folder's purpose by yourself.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;cd&lt;/code&gt; to folder where you want to download this repo&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;git clone https://github.com/michuanhaohao/reid-strong-baseline.git&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pytorch.org/" rel="nofollow"&gt;pytorch&amp;gt;=0.4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;torchvision&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pytorch/ignite"&gt;ignite=0.1.2&lt;/a&gt; (Note: V0.2.0 may result in an error)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rbgirshick/yacs"&gt;yacs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prepare dataset&lt;/p&gt;
&lt;p&gt;Create a directory to store reid datasets under this repo or outside this repo. Remember to set your path to the root of the dataset in &lt;code&gt;config/defaults.py&lt;/code&gt; for all training and testing or set in every single config file in &lt;code&gt;configs/&lt;/code&gt; or set in every single command.&lt;/p&gt;
&lt;p&gt;You can create a directory to store reid datasets under this repo via&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd&lt;/span&gt; reid-strong-baseline
mkdir data&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ôºà1ÔºâMarket1501&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download dataset to &lt;code&gt;data/&lt;/code&gt; from &lt;a href="http://www.liangzheng.org/Project/project_reid.html" rel="nofollow"&gt;http://www.liangzheng.org/Project/project_reid.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Extract dataset and rename to &lt;code&gt;market1501&lt;/code&gt;. The data structure would like:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;data
    market1501 &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; this folder contains 6 files.&lt;/span&gt;
        bounding_box_test/
        bounding_box_train/
        ......&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ôºà2ÔºâDukeMTMC-reID&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download dataset to &lt;code&gt;data/&lt;/code&gt; from &lt;a href="https://github.com/layumi/DukeMTMC-reID_evaluation#download-dataset"&gt;https://github.com/layumi/DukeMTMC-reID_evaluation#download-dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Extract dataset and rename to &lt;code&gt;dukemtmc-reid&lt;/code&gt;. The data structure would like:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;data
    dukemtmc-reid
    	DukeMTMC-reID &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; this folder contains 8 files.&lt;/span&gt;
        	bounding_box_test/
        	bounding_box_train/
        	......&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prepare pretrained model if you don't have&lt;/p&gt;
&lt;p&gt;Ôºà1ÔºâResNet&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; torchvision &lt;span class="pl-k"&gt;import&lt;/span&gt; models
models.resnet50(&lt;span class="pl-v"&gt;pretrained&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-c1"&gt;True&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ôºà2ÔºâSenet&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; torch.utils.model_zoo &lt;span class="pl-k"&gt;as&lt;/span&gt; model_zoo
model_zoo.load_url(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;the pth you want to download (specific urls are listed in  ./modeling/backbones/senet.py)&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then it will automatically download model in &lt;code&gt;~/.torch/models/&lt;/code&gt;, you should set this path in &lt;code&gt;config/defaults.py&lt;/code&gt; for all training or set in every single training config file in &lt;code&gt;configs/&lt;/code&gt; or set in every single command.&lt;/p&gt;
&lt;p&gt;Ôºà3ÔºâResNet_IBN_a&lt;/p&gt;
&lt;p&gt;You can download the ImageNet pre-trained weights from here &lt;a href="https://drive.google.com/open?id=1_r4wp14hEMkABVow58Xr4mPg7gvgOMto" rel="nofollow"&gt;[link]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ôºà4ÔºâLoad your self-trained model
If you want to continue your train process based on your self-trained model, you can change the configuration &lt;code&gt;PRETRAIN_CHOICE&lt;/code&gt; from 'imagenet' to 'self' and set the &lt;code&gt;PRETRAIN_PATH&lt;/code&gt; to your self-trained model. We offer &lt;code&gt;Experiment-pretrain_choice-all_tricks-tri_center-market.sh&lt;/code&gt; as an example.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you want to know the detailed configurations and their meaning, please refer to &lt;code&gt;config/defaults.py&lt;/code&gt;. If you want to set your own parameters, you can follow our method: create a new yml file, then set your own parameters.  Add &lt;code&gt;--config_file='configs/your yml file'&lt;/code&gt; int the commands described below, then our code will merge your configuration. automatically.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-train" class="anchor" aria-hidden="true" href="#train"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Train&lt;/h2&gt;
&lt;p&gt;You can run these commands in  &lt;code&gt;.sh &lt;/code&gt; files for training different datasets of differernt loss.  You can also directly run code &lt;code&gt;sh *.sh&lt;/code&gt; to run our demo after your custom modification.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Market1501, cross entropy loss + triplet loss&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 tools/train.py --config_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;configs/softmax_triplet.yml&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; MODEL.DEVICE_ID &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your device id')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; DATASETS.NAMES &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('market1501')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; OUTPUT_DIR &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your path to save checkpoints and logs')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="2"&gt;
&lt;li&gt;DukeMTMC-reID, cross entropy loss + triplet loss + center loss&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 tools/train.py --config_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;configs/softmax_triplet_with_center.yml&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; MODEL.DEVICE_ID &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your device id')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; DATASETS.NAMES &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('dukemtmc')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; OUTPUT_DIR &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your path to save checkpoints and logs')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-test" class="anchor" aria-hidden="true" href="#test"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Test&lt;/h2&gt;
&lt;p&gt;You can test your model's performance directly by running these commands in &lt;code&gt;.sh &lt;/code&gt; files after your custom modification. You can also change the configuration to determine which feature of BNNeck is used and whether the feature is normalized (equivalent to use Cosine distance or Euclidean distance) for testing.&lt;/p&gt;
&lt;p&gt;Please replace the data path of the model and set the &lt;code&gt;PRETRAIN_CHOICE&lt;/code&gt; as 'self' to avoid time consuming on loading ImageNet pretrained model.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Test with Euclidean distance using feature before BN without re-ranking,.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 tools/test.py --config_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;configs/softmax_triplet_with_center.yml&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; MODEL.DEVICE_ID &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your device id')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; DATASETS.NAMES &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('market1501')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.NECK_FEAT &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('before')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.FEAT_NORM &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('no')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; MODEL.PRETRAIN_CHOICE &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('self')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.WEIGHT &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your path to trained checkpoints')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Test with Cosine distance using feature after BN without re-ranking,.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 tools/test.py --config_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;configs/softmax_triplet_with_center.yml&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; MODEL.DEVICE_ID &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your device id')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; DATASETS.NAMES &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('market1501')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.NECK_FEAT &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('after')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.FEAT_NORM &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('yes')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; MODEL.PRETRAIN_CHOICE &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('self')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.WEIGHT &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your path to trained checkpoints')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Test with Cosine distance using feature after BN with re-ranking&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 tools/test.py --config_file=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;configs/softmax_triplet_with_center.yml&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; MODEL.DEVICE_ID &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your device id')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; DATASETS.NAMES &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('dukemtmc')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.NECK_FEAT &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('after')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.FEAT_NORM &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('yes')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; MODEL.PRETRAIN_CHOICE &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('self')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.RE_RANKING &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('yes')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; TEST.WEIGHT &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;('your path to trained checkpoints')&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>michuanhaohao</author><guid isPermaLink="false">https://github.com/michuanhaohao/reid-strong-baseline</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>rwightman/gen-efficientnet-pytorch #15 in Python, Today</title><link>https://github.com/rwightman/gen-efficientnet-pytorch</link><description>&lt;p&gt;&lt;i&gt;Pretrained EfficientNet, MixNet, MobileNetV3, MNASNet A1 and B1, FBNet, Single-Path NAS&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-generic-efficientnets-for-pytorch" class="anchor" aria-hidden="true" href="#generic-efficientnets-for-pytorch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;(Generic) EfficientNets for PyTorch&lt;/h1&gt;
&lt;p&gt;A 'generic' implementation of EfficientNet, MixNet, MobileNetV3, etc. that covers most of the compute/parameter efficient architectures derived from the MobileNet V1/V2 block sequence, including those found via automated neural architecture search.&lt;/p&gt;
&lt;p&gt;All models are implemented by GenEfficientNet or MobileNetV3 classes, with string based architecture definitions to configure the block layouts (idea from &lt;a href="https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_models.py"&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-whats-new" class="anchor" aria-hidden="true" href="#whats-new"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's New&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-oct-30-2019" class="anchor" aria-hidden="true" href="#oct-30-2019"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Oct 30, 2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Many of the models will now work with torch.jit.script, MixNet being the biggest exception&lt;/li&gt;
&lt;li&gt;Improved interface for enabling torchscript or ONNX export compatible modes (via config)&lt;/li&gt;
&lt;li&gt;Add JIT optimized mem-efficient Swish/Mish autograd.fn in addition to memory-efficient autgrad.fn&lt;/li&gt;
&lt;li&gt;Activation factory to select best version of activation by name or override one globally&lt;/li&gt;
&lt;li&gt;Add pretrained checkpoint load helper that handles input conv and classifier changes&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-oct-27-2019" class="anchor" aria-hidden="true" href="#oct-27-2019"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Oct 27, 2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Add CondConv EfficientNet variants ported from &lt;a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/condconv"&gt;https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/condconv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Add RandAug weights for TF EfficientNet B5 and B7 from &lt;a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet"&gt;https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bring over MixNet-XL model and depth scaling algo from my pytorch-image-models code base&lt;/li&gt;
&lt;li&gt;Switch activations and global pooling to modules&lt;/li&gt;
&lt;li&gt;Add memory-efficient Swish/Mish impl&lt;/li&gt;
&lt;li&gt;Add as_sequential() method to all models and allow as an argument in entrypoint fns&lt;/li&gt;
&lt;li&gt;Move MobileNetV3 into own file since it has a different head&lt;/li&gt;
&lt;li&gt;Remove ChamNet, MobileNet V2/V1 since they will likely never be used here&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models&lt;/h2&gt;
&lt;p&gt;Implemented models include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;EfficientNet (B0-B7) (&lt;a href="https://arxiv.org/abs/1905.11946" rel="nofollow"&gt;https://arxiv.org/abs/1905.11946&lt;/a&gt;) -- validated, compat with TF weights&lt;/li&gt;
&lt;li&gt;EfficientNet-EdgeTPU (S, M, L) (&lt;a href="https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html" rel="nofollow"&gt;https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html&lt;/a&gt;) --validated w/ TF weights&lt;/li&gt;
&lt;li&gt;EfficientNet-CondConv (&lt;a href="https://arxiv.org/abs/1904.04971" rel="nofollow"&gt;https://arxiv.org/abs/1904.04971&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;MixNet (&lt;a href="https://arxiv.org/abs/1907.09595" rel="nofollow"&gt;https://arxiv.org/abs/1907.09595&lt;/a&gt;) -- validated, compat with TF weights&lt;/li&gt;
&lt;li&gt;MNASNet B1, A1 (Squeeze-Excite), and Small (&lt;a href="https://arxiv.org/abs/1807.11626" rel="nofollow"&gt;https://arxiv.org/abs/1807.11626&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;MobileNet-V3 (&lt;a href="https://arxiv.org/abs/1905.02244" rel="nofollow"&gt;https://arxiv.org/abs/1905.02244&lt;/a&gt;) -- native PyTorch model trained better than paper spec&lt;/li&gt;
&lt;li&gt;FBNet-C (&lt;a href="https://arxiv.org/abs/1812.03443" rel="nofollow"&gt;https://arxiv.org/abs/1812.03443&lt;/a&gt;) -- TODO A/B variants&lt;/li&gt;
&lt;li&gt;Single-Path NAS (&lt;a href="https://arxiv.org/abs/1904.02877" rel="nofollow"&gt;https://arxiv.org/abs/1904.02877&lt;/a&gt;) -- pixel1 variant&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I originally implemented and trained some these models with code &lt;a href="https://github.com/rwightman/pytorch-image-models"&gt;here&lt;/a&gt;, this repository contains just the GenEfficientNet models, validation, and associated ONNX/Caffe2 export code.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-pretrained" class="anchor" aria-hidden="true" href="#pretrained"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pretrained&lt;/h2&gt;
&lt;p&gt;I've managed to train several of the models to accuracies close to or above the originating papers and official impl. My training code is here: &lt;a href="https://github.com/rwightman/pytorch-image-models"&gt;https://github.com/rwightman/pytorch-image-models&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Prec@1 (Err)&lt;/th&gt;
&lt;th&gt;Prec@5 (Err)&lt;/th&gt;
&lt;th&gt;Param#(M)&lt;/th&gt;
&lt;th&gt;MAdds(M)&lt;/th&gt;
&lt;th&gt;Image Scaling&lt;/th&gt;
&lt;th&gt;Resolution&lt;/th&gt;
&lt;th&gt;Crop&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;mixnet_xl&lt;/td&gt;
&lt;td&gt;80.120 (19.880)&lt;/td&gt;
&lt;td&gt;95.022 (4.978)&lt;/td&gt;
&lt;td&gt;11.90&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mixnet_l&lt;/td&gt;
&lt;td&gt;78.976 (21.024&lt;/td&gt;
&lt;td&gt;94.184 (5.816)&lt;/td&gt;
&lt;td&gt;7.33&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;efficientnet_b2&lt;/td&gt;
&lt;td&gt;79.668 (20.332)&lt;/td&gt;
&lt;td&gt;94.634 (5.366)&lt;/td&gt;
&lt;td&gt;9.1&lt;/td&gt;
&lt;td&gt;1003&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;260&lt;/td&gt;
&lt;td&gt;0.890&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;efficientnet_b1&lt;/td&gt;
&lt;td&gt;78.692 (21.308)&lt;/td&gt;
&lt;td&gt;94.086 (5.914)&lt;/td&gt;
&lt;td&gt;7.8&lt;/td&gt;
&lt;td&gt;694&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;240&lt;/td&gt;
&lt;td&gt;0.882&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mixnet_m&lt;/td&gt;
&lt;td&gt;77.256 (22.744)&lt;/td&gt;
&lt;td&gt;93.418 (6.582)&lt;/td&gt;
&lt;td&gt;5.01&lt;/td&gt;
&lt;td&gt;353&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;efficientnet_b0&lt;/td&gt;
&lt;td&gt;76.912 (23.088)&lt;/td&gt;
&lt;td&gt;93.210 (6.790)&lt;/td&gt;
&lt;td&gt;5.3&lt;/td&gt;
&lt;td&gt;390&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mixnet_s&lt;/td&gt;
&lt;td&gt;75.988 (24.012)&lt;/td&gt;
&lt;td&gt;92.794 (7.206)&lt;/td&gt;
&lt;td&gt;4.13&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mobilenetv3_100&lt;/td&gt;
&lt;td&gt;75.634 (24.366)&lt;/td&gt;
&lt;td&gt;92.708 (7.292)&lt;/td&gt;
&lt;td&gt;5.5&lt;/td&gt;
&lt;td&gt;219&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mnasnet_a1&lt;/td&gt;
&lt;td&gt;75.448 (24.552)&lt;/td&gt;
&lt;td&gt;92.604 (7.396)&lt;/td&gt;
&lt;td&gt;3.9&lt;/td&gt;
&lt;td&gt;312&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fbnetc_100&lt;/td&gt;
&lt;td&gt;75.124 (24.876)&lt;/td&gt;
&lt;td&gt;92.386 (7.614)&lt;/td&gt;
&lt;td&gt;5.6&lt;/td&gt;
&lt;td&gt;385&lt;/td&gt;
&lt;td&gt;bilinear&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mnasnet_b1&lt;/td&gt;
&lt;td&gt;74.658 (25.342)&lt;/td&gt;
&lt;td&gt;92.114 (7.886)&lt;/td&gt;
&lt;td&gt;4.4&lt;/td&gt;
&lt;td&gt;315&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spnasnet_100&lt;/td&gt;
&lt;td&gt;74.084 (25.916)&lt;/td&gt;
&lt;td&gt;91.818 (8.182)&lt;/td&gt;
&lt;td&gt;4.4&lt;/td&gt;
&lt;td&gt;TBV&lt;/td&gt;
&lt;td&gt;bilinear&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;More pretrained models to come...&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ported-weights" class="anchor" aria-hidden="true" href="#ported-weights"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ported Weights&lt;/h2&gt;
&lt;p&gt;The weights ported from Tensorflow checkpoints for the EfficientNet models do pretty much match accuracy in Tensorflow once a SAME convolution padding equivalent is added, and the same crop factors, image scaling, etc (see table) are used via cmd line args.&lt;/p&gt;
&lt;p&gt;Ex, to run validation for tf_efficientnet_b5:
&lt;code&gt;python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b5 -b 64 --img-size 456 --crop-pct 0.934 --interpolation bicubic&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Enabling the Tensorflow preprocessing pipeline with &lt;code&gt;--tf-preprocessing&lt;/code&gt; at validation time will improve these scores by 0.1-0.5% as it's closer to what these models were trained with.&lt;/p&gt;
&lt;p&gt;Ex, to run validation w/ TF preprocessing for tf_efficientnet_b5:
&lt;code&gt;python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b5 -b 64 --img-size 456 --tf-preprocessing&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;EdgeTPU and EfficientNet-CondConv models use different normalization consts. Use Inception style 0.5, 0.5, 0.5 for mean and std.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Prec@1 (Err)&lt;/th&gt;
&lt;th&gt;Prec@5 (Err)&lt;/th&gt;
&lt;th&gt;Param #&lt;/th&gt;
&lt;th&gt;Image Scaling&lt;/th&gt;
&lt;th&gt;Image Size&lt;/th&gt;
&lt;th&gt;Crop&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b7 *tfp&lt;/td&gt;
&lt;td&gt;84.940 (15.060)&lt;/td&gt;
&lt;td&gt;97.214 (2.786)&lt;/td&gt;
&lt;td&gt;66.35&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;600&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b7&lt;/td&gt;
&lt;td&gt;84.932 (15.068)&lt;/td&gt;
&lt;td&gt;97.208 (2.792)&lt;/td&gt;
&lt;td&gt;66.35&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;600&lt;/td&gt;
&lt;td&gt;0.949&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b6 *tfp&lt;/td&gt;
&lt;td&gt;84.140 (15.860)&lt;/td&gt;
&lt;td&gt;96.852 (3.148)&lt;/td&gt;
&lt;td&gt;43.04&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;528&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b6&lt;/td&gt;
&lt;td&gt;84.110 (15.890)&lt;/td&gt;
&lt;td&gt;96.886 (3.114)&lt;/td&gt;
&lt;td&gt;43.04&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;528&lt;/td&gt;
&lt;td&gt;0.942&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b5 *tfp&lt;/td&gt;
&lt;td&gt;83.822 (16.178)&lt;/td&gt;
&lt;td&gt;96.756 (3.244)&lt;/td&gt;
&lt;td&gt;30.39&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;456&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b5&lt;/td&gt;
&lt;td&gt;83.812 (16.188)&lt;/td&gt;
&lt;td&gt;96.748 (3.252)&lt;/td&gt;
&lt;td&gt;30.39&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;456&lt;/td&gt;
&lt;td&gt;0.934&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b4&lt;/td&gt;
&lt;td&gt;83.022 (16.978)&lt;/td&gt;
&lt;td&gt;96.300 (3.700)&lt;/td&gt;
&lt;td&gt;19.34&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;380&lt;/td&gt;
&lt;td&gt;0.922&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b4 *tfp&lt;/td&gt;
&lt;td&gt;82.948 (17.052)&lt;/td&gt;
&lt;td&gt;96.308 (3.692)&lt;/td&gt;
&lt;td&gt;19.34&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;380&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b3 *tfp&lt;/td&gt;
&lt;td&gt;81.576 (18.424)&lt;/td&gt;
&lt;td&gt;95.662 (4.338)&lt;/td&gt;
&lt;td&gt;12.23&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;300&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b3&lt;/td&gt;
&lt;td&gt;81.636 (18.364)&lt;/td&gt;
&lt;td&gt;95.718 (4.282)&lt;/td&gt;
&lt;td&gt;12.23&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;300&lt;/td&gt;
&lt;td&gt;0.903&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_el&lt;/td&gt;
&lt;td&gt;80.534 (19.466)&lt;/td&gt;
&lt;td&gt;95.190 (4.810)&lt;/td&gt;
&lt;td&gt;10.59&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;300&lt;/td&gt;
&lt;td&gt;0.903&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_el *tfp&lt;/td&gt;
&lt;td&gt;80.476 (19.524)&lt;/td&gt;
&lt;td&gt;95.200 (4.800)&lt;/td&gt;
&lt;td&gt;10.59&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;300&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b2 *tfp&lt;/td&gt;
&lt;td&gt;80.188 (19.812)&lt;/td&gt;
&lt;td&gt;94.974 (5.026)&lt;/td&gt;
&lt;td&gt;9.11&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;260&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b2&lt;/td&gt;
&lt;td&gt;80.086 (19.914)&lt;/td&gt;
&lt;td&gt;94.908 (5.092)&lt;/td&gt;
&lt;td&gt;9.11&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;260&lt;/td&gt;
&lt;td&gt;0.890&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_cc_b1_8e *tfp&lt;/td&gt;
&lt;td&gt;79.464 (20.536)&lt;/td&gt;
&lt;td&gt;94.492 (5.508)&lt;/td&gt;
&lt;td&gt;39.7&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;240&lt;/td&gt;
&lt;td&gt;0.88&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_cc_b1_8e&lt;/td&gt;
&lt;td&gt;79.298 (20.702)&lt;/td&gt;
&lt;td&gt;94.364 (5.636)&lt;/td&gt;
&lt;td&gt;39.7&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;240&lt;/td&gt;
&lt;td&gt;0.888&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b1 *tfp&lt;/td&gt;
&lt;td&gt;79.172 (20.828)&lt;/td&gt;
&lt;td&gt;94.450 (5.550)&lt;/td&gt;
&lt;td&gt;7.79&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;240  N/A&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_em *tfp&lt;/td&gt;
&lt;td&gt;78.958 (21.042)&lt;/td&gt;
&lt;td&gt;94.458 (5.542)&lt;/td&gt;
&lt;td&gt;6.90&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;240&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_mixnet_l *tfp&lt;/td&gt;
&lt;td&gt;78.846 (21.154)&lt;/td&gt;
&lt;td&gt;94.212 (5.788)&lt;/td&gt;
&lt;td&gt;7.33&lt;/td&gt;
&lt;td&gt;bilinear&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b1&lt;/td&gt;
&lt;td&gt;78.826 (21.174)&lt;/td&gt;
&lt;td&gt;94.198 (5.802)&lt;/td&gt;
&lt;td&gt;7.79&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;240&lt;/td&gt;
&lt;td&gt;0.88&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_mixnet_l&lt;/td&gt;
&lt;td&gt;78.770 (21.230)&lt;/td&gt;
&lt;td&gt;94.004 (5.996)&lt;/td&gt;
&lt;td&gt;7.33&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_em&lt;/td&gt;
&lt;td&gt;78.742 (21.258)&lt;/td&gt;
&lt;td&gt;94.332 (5.668)&lt;/td&gt;
&lt;td&gt;6.90&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;240&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_cc_b0_8e *tfp&lt;/td&gt;
&lt;td&gt;78.314 (21.686)&lt;/td&gt;
&lt;td&gt;93.790 (6.210)&lt;/td&gt;
&lt;td&gt;24.0&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_cc_b0_8e&lt;/td&gt;
&lt;td&gt;77.908 (22.092)&lt;/td&gt;
&lt;td&gt;93.656 (6.344)&lt;/td&gt;
&lt;td&gt;24.0&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_cc_b0_4e *tfp&lt;/td&gt;
&lt;td&gt;77.746 (22.254)&lt;/td&gt;
&lt;td&gt;93.552 (6.448)&lt;/td&gt;
&lt;td&gt;13.3&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_cc_b0_4e&lt;/td&gt;
&lt;td&gt;77.304 (22.696)&lt;/td&gt;
&lt;td&gt;93.332 (6.668)&lt;/td&gt;
&lt;td&gt;13.3&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_es *tfp&lt;/td&gt;
&lt;td&gt;77.616 (22.384)&lt;/td&gt;
&lt;td&gt;93.750 (6.250)&lt;/td&gt;
&lt;td&gt;5.44&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_es&lt;/td&gt;
&lt;td&gt;77.264 (22.736)&lt;/td&gt;
&lt;td&gt;93.600 (6.400)&lt;/td&gt;
&lt;td&gt;5.44&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b0 *tfp&lt;/td&gt;
&lt;td&gt;77.258 (22.742)&lt;/td&gt;
&lt;td&gt;93.478 (6.522)&lt;/td&gt;
&lt;td&gt;5.29&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_mixnet_m *tfp&lt;/td&gt;
&lt;td&gt;77.072 (22.928)&lt;/td&gt;
&lt;td&gt;93.368 (6.632)&lt;/td&gt;
&lt;td&gt;5.01&lt;/td&gt;
&lt;td&gt;bilinear&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_mixnet_m&lt;/td&gt;
&lt;td&gt;76.950 (23.050)&lt;/td&gt;
&lt;td&gt;93.156 (6.844)&lt;/td&gt;
&lt;td&gt;5.01&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_efficientnet_b0&lt;/td&gt;
&lt;td&gt;76.848 (23.152)&lt;/td&gt;
&lt;td&gt;93.228 (6.772)&lt;/td&gt;
&lt;td&gt;5.29&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_mixnet_s *tfp&lt;/td&gt;
&lt;td&gt;75.800 (24.200)&lt;/td&gt;
&lt;td&gt;92.788 (7.212)&lt;/td&gt;
&lt;td&gt;4.13&lt;/td&gt;
&lt;td&gt;bilinear&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tf_mixnet_s&lt;/td&gt;
&lt;td&gt;75.648 (24.352)&lt;/td&gt;
&lt;td&gt;92.636 (7.364)&lt;/td&gt;
&lt;td&gt;4.13&lt;/td&gt;
&lt;td&gt;bicubic&lt;/td&gt;
&lt;td&gt;224&lt;/td&gt;
&lt;td&gt;0.875&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;*tfp models validated with &lt;code&gt;tf-preprocessing&lt;/code&gt; pipeline&lt;/p&gt;
&lt;p&gt;Google tf and tflite weights ported from official Tensorflow repositories&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet"&gt;https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet"&gt;https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-pytorch-hub" class="anchor" aria-hidden="true" href="#pytorch-hub"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PyTorch Hub&lt;/h2&gt;
&lt;p&gt;Models can be accessed via the PyTorch Hub API&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; torch.hub.list('rwightman/gen-efficientnet-pytorch')
['efficientnet_b0', ...]
&amp;gt;&amp;gt;&amp;gt; model = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)
&amp;gt;&amp;gt;&amp;gt; model.eval()
&amp;gt;&amp;gt;&amp;gt; output = model(torch.randn(1,3,224,224))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-pip" class="anchor" aria-hidden="true" href="#pip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pip&lt;/h3&gt;
&lt;p&gt;This package can be installed via pip.&lt;/p&gt;
&lt;p&gt;Install (after conda env/install):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install geffnet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Eval use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import geffnet
&amp;gt;&amp;gt;&amp;gt; m = geffnet.create_model('mobilenetv3_100', pretrained=True)
&amp;gt;&amp;gt;&amp;gt; m.eval()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Train use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import geffnet
&amp;gt;&amp;gt;&amp;gt; # models can also be created by using the entrypoint directly
&amp;gt;&amp;gt;&amp;gt; m = geffnet.efficientnet_b2(pretrained=True, drop_rate=0.25, drop_connect_rate=0.2)
&amp;gt;&amp;gt;&amp;gt; m.train()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create in a nn.Sequential container, for fast.ai, etc:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import geffnet
&amp;gt;&amp;gt;&amp;gt; m = geffnet.mixnet_l(pretrained=True, drop_rate=0.25, drop_connect_rate=0.2, as_sequential=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-exporting" class="anchor" aria-hidden="true" href="#exporting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Exporting&lt;/h2&gt;
&lt;p&gt;Scripts to export models to ONNX and then to Caffe2 are included, along with a Caffe2 script to verify.&lt;/p&gt;
&lt;p&gt;As an example, to export the MobileNet-V3 pretrained model and then run an Imagenet validation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python onnx_export.py --model mobilenetv3_100 ./mobilenetv3_100.onnx
python onnx_to_caffe.py ./mobilenetv3_100.onnx --c2-prefix mobilenetv3
python caffe2_validate.py /imagenet/validation/ --c2-init ./mobilenetv3.init.pb --c2-predict ./mobilenetv3.predict.pb --interpolation bicubic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; the TF ported weights with the 'SAME' conv padding activated cannot be exported to ONNX unless &lt;code&gt;_EXPORTABLE&lt;/code&gt; flag in &lt;code&gt;config.py&lt;/code&gt; is set to True. Use &lt;code&gt;config.set_exportable(True)&lt;/code&gt; as in the updated &lt;code&gt;onnx_export.py&lt;/code&gt; example script.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rwightman</author><guid isPermaLink="false">https://github.com/rwightman/gen-efficientnet-pytorch</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>sebastianruder/NLP-progress #16 in Python, Today</title><link>https://github.com/sebastianruder/NLP-progress</link><description>&lt;p&gt;&lt;i&gt;Repository to track the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tracking-progress-in-natural-language-processing" class="anchor" aria-hidden="true" href="#tracking-progress-in-natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tracking Progress in Natural Language Processing&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of contents&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-english" class="anchor" aria-hidden="true" href="#english"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;English&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="english/automatic_speech_recognition.md"&gt;Automatic speech recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/ccg.md"&gt;CCG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/common_sense.md"&gt;Common sense&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/constituency_parsing.md"&gt;Constituency parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/coreference_resolution.md"&gt;Coreference resolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/dependency_parsing.md"&gt;Dependency parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/dialogue.md"&gt;Dialogue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/domain_adaptation.md"&gt;Domain adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/entity_linking.md"&gt;Entity linking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/grammatical_error_correction.md"&gt;Grammatical error correction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/information_extraction.md"&gt;Information extraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/language_modeling.md"&gt;Language modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/lexical_normalization.md"&gt;Lexical normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/machine_translation.md"&gt;Machine translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/missing_elements.md"&gt;Missing elements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/multi-task_learning.md"&gt;Multi-task learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/multimodal.md"&gt;Multi-modal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/named_entity_recognition.md"&gt;Named entity recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/natural_language_inference.md"&gt;Natural language inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/part-of-speech_tagging.md"&gt;Part-of-speech tagging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/question_answering.md"&gt;Question answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/relation_prediction.md"&gt;Relation prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/relationship_extraction.md"&gt;Relationship extraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/semantic_textual_similarity.md"&gt;Semantic textual similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/semantic_parsing.md"&gt;Semantic parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/semantic_role_labeling.md"&gt;Semantic role labeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/sentiment_analysis.md"&gt;Sentiment analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/shallow_syntax.md"&gt;Shallow syntax&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/simplification.md"&gt;Simplification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/stance_detection.md"&gt;Stance detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/summarization.md"&gt;Summarization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/taxonomy_learning.md"&gt;Taxonomy learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/temporal_processing.md"&gt;Temporal processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/text_classification.md"&gt;Text classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="english/word_sense_disambiguation.md"&gt;Word sense disambiguation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-chinese" class="anchor" aria-hidden="true" href="#chinese"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Chinese&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="chinese/chinese.md#entity-linking"&gt;Entity linking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="chinese/chinese_word_segmentation.md"&gt;Chinese word segmentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-hindi" class="anchor" aria-hidden="true" href="#hindi"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hindi&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="hindi/hindi.md#chunking"&gt;Chunking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="hindi/hindi.md#part-of-speech-tagging"&gt;Part-of-speech tagging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="hindi/hindi.md#machine-translation"&gt;Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-vietnamese" class="anchor" aria-hidden="true" href="#vietnamese"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vietnamese&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="vietnamese/vietnamese.md#dependency-parsing"&gt;Dependency parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="vietnamese/vietnamese.md#machine-translation"&gt;Machine translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="vietnamese/vietnamese.md#named-entity-recognition"&gt;Named entity recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="vietnamese/vietnamese.md#part-of-speech-tagging"&gt;Part-of-speech tagging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="vietnamese/vietnamese.md#word-segmentation"&gt;Word segmentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-spanish" class="anchor" aria-hidden="true" href="#spanish"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spanish&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="spanish/entity_linking.md#entity-linking"&gt;Entity linking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-portuguese" class="anchor" aria-hidden="true" href="#portuguese"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Portuguese&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="portuguese/question_answering.md"&gt;Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This document aims to track the progress in Natural Language Processing (NLP) and give an overview
of the state-of-the-art (SOTA) across the most common NLP tasks and their corresponding datasets.&lt;/p&gt;
&lt;p&gt;It aims to cover both traditional and core NLP tasks such as dependency parsing and part-of-speech tagging
as well as more recent ones such as reading comprehension and natural language inference. The main objective
is to provide the reader with a quick overview of benchmark datasets and the state-of-the-art for their
task of interest, which serves as a stepping stone for further research. To this end, if there is a
place where results for a task are already published and regularly maintained, such as a public leaderboard,
the reader will be pointed there.&lt;/p&gt;
&lt;p&gt;If you want to find this document again in the future, just go to &lt;a href="https://nlpprogress.com/" rel="nofollow"&gt;&lt;code&gt;nlpprogress.com&lt;/code&gt;&lt;/a&gt;
or &lt;a href="http://nlpsota.com/" rel="nofollow"&gt;&lt;code&gt;nlpsota.com&lt;/code&gt;&lt;/a&gt; in your browser.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-guidelines" class="anchor" aria-hidden="true" href="#guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Guidelines&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt; ¬† Results reported in published papers are preferred; an exception may be made for influential preprints.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Datasets&lt;/strong&gt; ¬† Datasets should have been used for evaluation in at least one published paper besides
the one that introduced the dataset.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt; ¬† We recommend to add a link to an implementation
if available. You can add a &lt;code&gt;Code&lt;/code&gt; column (see below) to the table if it does not exist.
In the &lt;code&gt;Code&lt;/code&gt; column, indicate an official implementation with &lt;a href="http://link_to_implementation" rel="nofollow"&gt;Official&lt;/a&gt;.
If an unofficial implementation is available, use &lt;a href="http://link_to_implementation" rel="nofollow"&gt;Link&lt;/a&gt; (see below).
If no implementation is available, you can leave the cell empty.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-adding-a-new-result" class="anchor" aria-hidden="true" href="#adding-a-new-result"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Adding a new result&lt;/h4&gt;
&lt;p&gt;If you would like to add a new result, you can just click on the small edit button in the top-right
corner of the file for the respective task (see below).&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/edit_file.png"&gt;&lt;img src="img/edit_file.png" alt="Click on the edit button to add a file" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This allows you to edit the file in Markdown. Simply add a row to the corresponding table in the
same format. Make sure that the table stays sorted (with the best result on top).
After you've made your change, make sure that the table still looks ok by clicking on the
"Preview changes" tab at the top of the page. If everything looks good, go to the bottom of the page,
where you see the below form.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/propose_file_change.png"&gt;&lt;img src="img/propose_file_change.png" alt="Fill out the file change information" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Add a name for your proposed change, an optional description, indicate that you would like to
"Create a new branch for this commit and start a pull request", and click on "Propose file change".&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-adding-a-new-dataset-or-task" class="anchor" aria-hidden="true" href="#adding-a-new-dataset-or-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Adding a new dataset or task&lt;/h4&gt;
&lt;p&gt;For adding a new dataset or task, you can also follow the steps above. Alternatively, you can fork the repository.
In both cases, follow the steps below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If your task is completely new, create a new file and link to it in the table of contents above.&lt;/li&gt;
&lt;li&gt;If not, add your task or dataset to the respective section of the corresponding file (in alphabetical order).&lt;/li&gt;
&lt;li&gt;Briefly describe the dataset/task and include relevant references.&lt;/li&gt;
&lt;li&gt;Describe the evaluation setting and evaluation metric.&lt;/li&gt;
&lt;li&gt;Show how an annotated example of the dataset/task looks like.&lt;/li&gt;
&lt;li&gt;Add a download link if available.&lt;/li&gt;
&lt;li&gt;Copy the below table and fill in at least two results (including the state-of-the-art)
for your dataset/task (change Score to the metric of your dataset). If your dataset/task
has multiple metrics, add them to the right of &lt;code&gt;Score&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Submit your change as a pull request.&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th align="center"&gt;Score&lt;/th&gt;
&lt;th&gt;Paper / Source&lt;/th&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-wish-list" class="anchor" aria-hidden="true" href="#wish-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Wish list&lt;/h3&gt;
&lt;p&gt;These are tasks and datasets that are still missing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bilingual dictionary induction&lt;/li&gt;
&lt;li&gt;Discourse parsing&lt;/li&gt;
&lt;li&gt;Keyphrase extraction&lt;/li&gt;
&lt;li&gt;Knowledge base population (KBP)&lt;/li&gt;
&lt;li&gt;More dialogue tasks&lt;/li&gt;
&lt;li&gt;Semi-supervised learning&lt;/li&gt;
&lt;li&gt;Frame-semantic parsing (FrameNet full-sentence analysis)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-exporting-into-a-structured-format" class="anchor" aria-hidden="true" href="#exporting-into-a-structured-format"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Exporting into a structured format&lt;/h3&gt;
&lt;p&gt;You can extract all the data into a structured, machine-readable JSON format with parsed tasks, descriptions and SOTA tables.&lt;/p&gt;
&lt;p&gt;The instructions are in &lt;a href="structured/README.md"&gt;structured/README.md&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-instructions-for-building-the-site-locally" class="anchor" aria-hidden="true" href="#instructions-for-building-the-site-locally"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Instructions for building the site locally&lt;/h3&gt;
&lt;p&gt;Instructions for building the website locally using Jekyll can be found &lt;a href="jekyll_instructions.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>sebastianruder</author><guid isPermaLink="false">https://github.com/sebastianruder/NLP-progress</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>idealo/imagededup #17 in Python, Today</title><link>https://github.com/idealo/imagededup</link><description>&lt;p&gt;&lt;i&gt;üòé Finding duplicate images made easy!&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-image-deduplicator-imagededup" class="anchor" aria-hidden="true" href="#image-deduplicator-imagededup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Image Deduplicator (imagededup)&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://dev.azure.com/axelspringerai/Public/_build/latest?definitionId=1&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0ace10d6cee886f09052342f079da84f26af0c69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c737072696e67657261692f5075626c69632f5f617069732f6275696c642f7374617475732f696465616c6f2e696d61676564656475703f6272616e63684e616d653d6d6173746572" alt="Build Status" data-canonical-src="https://dev.azure.com/axelspringerai/Public/_apis/build/status/idealo.imagededup?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/idealo/imagededup" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a755b323568a2de1547b6ab400f1a844ff7cc02d/68747470733a2f2f7472617669732d63692e6f72672f696465616c6f2f696d61676564656475702e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/idealo/imagededup.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://idealo.github.io/imagededup/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d899216b558e71ce5e752afda08b23044fd1da27/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6f6e6c696e652d627269676874677265656e" alt="Docs" data-canonical-src="https://img.shields.io/badge/docs-online-brightgreen" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/idealo/imagededup" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/95183d7d5e4f9d46423ddaadd2887403643ed6a4/68747470733a2f2f636f6465636f762e696f2f67682f696465616c6f2f696d61676564656475702f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/idealo/imagededup/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://pypi.org/project/imagededup/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f22600aa79ff6c1614b2d8bc4ca835846e4c3eb7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f696d6167656465647570" alt="PyPI Version" data-canonical-src="https://img.shields.io/pypi/v/imagededup" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/idealo/imagededup/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/8051e9938a1ab39cf002818dfceb6b6092f34d68/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;imagededup is a python package that simplifies the task of finding &lt;strong&gt;exact&lt;/strong&gt; and &lt;strong&gt;near duplicates&lt;/strong&gt; in an image collection.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="readme_figures/mona_lisa.png"&gt;&lt;img src="readme_figures/mona_lisa.png" width="600" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;This package provides functionality to make use of hashing algorithms that are particularly good at finding exact
duplicates as well as convolutional neural networks which are also adept at finding near duplicates. An evaluation
framework is also provided to judge the quality of deduplication for a given dataset.&lt;/p&gt;
&lt;p&gt;Following details the functionality provided by the package:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Finding duplicates in a directory using one of the following algorithms:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1704.04861" rel="nofollow"&gt;Convolutional Neural Network&lt;/a&gt; (CNN)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html" rel="nofollow"&gt;Perceptual hashing&lt;/a&gt; (PHash)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html" rel="nofollow"&gt;Difference hashing&lt;/a&gt; (DHash)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://fullstackml.com/wavelet-image-hash-in-python-3504fdd282b5" rel="nofollow"&gt;Wavelet hashing&lt;/a&gt; (WHash)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html" rel="nofollow"&gt;Average hashing&lt;/a&gt; (AHash)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generation of encodings for images using one of the above stated algorithms.&lt;/li&gt;
&lt;li&gt;Framework to evaluate effectiveness of deduplication  given a ground truth mapping.&lt;/li&gt;
&lt;li&gt;Plotting duplicates found for a given image file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Detailed documentation for the package can be found at: &lt;a href="https://idealo.github.io/imagededup/" rel="nofollow"&gt;https://idealo.github.io/imagededup/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;imagededup is compatible with Python 3.6+ and runs on Linux, MacOS X and Windows.
It is distributed under the Apache 2.0 license.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--contents" class="anchor" aria-hidden="true" href="#-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png"&gt;üìñ&lt;/g-emoji&gt; Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#%EF%B8%8F-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#-contribute"&gt;Contribute&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#-citation"&gt;Citation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#-maintainers"&gt;Maintainers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#-copyright"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-Ô∏è-installation" class="anchor" aria-hidden="true" href="#Ô∏è-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="gear" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2699.png"&gt;‚öôÔ∏è&lt;/g-emoji&gt; Installation&lt;/h2&gt;
&lt;p&gt;There are two ways to install imagededup:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install imagededup from PyPI (recommended):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;pip install imagededup
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;g-emoji class="g-emoji" alias="warning" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png"&gt;‚ö†Ô∏è&lt;/g-emoji&gt; &lt;strong&gt;Note&lt;/strong&gt;: imagededup comes with TensorFlow CPU-only support by default. If you have GPUs, you should rather
install the TensorFlow version with GPU support especially when you use CNN to find duplicates. It's way faster. See the
&lt;a href="https://www.tensorflow.org/install/gpu" rel="nofollow"&gt;TensorFlow guide&lt;/a&gt; for more details on how to install it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Install imagededup from the GitHub source:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/idealo/imagededup.git
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; imagededup
pip install &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;cython&amp;gt;=0.29&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
python setup.py install&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content--quick-start" class="anchor" aria-hidden="true" href="#-quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="rocket" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png"&gt;üöÄ&lt;/g-emoji&gt; Quick Start&lt;/h2&gt;
&lt;p&gt;In order to find duplicates in an image directory using perceptual hashing, following workflow can be used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Import perceptual hashing method&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; imagededup.methods &lt;span class="pl-k"&gt;import&lt;/span&gt; PHash
phasher &lt;span class="pl-k"&gt;=&lt;/span&gt; PHash()&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Generate encodings for all images in an image directory&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;encodings &lt;span class="pl-k"&gt;=&lt;/span&gt; phasher.encode_images(&lt;span class="pl-v"&gt;image_dir&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path/to/image/directory&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Find duplicates using the generated encodings&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;duplicates &lt;span class="pl-k"&gt;=&lt;/span&gt; phasher.find_duplicates(&lt;span class="pl-v"&gt;encoding_map&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;encodings)&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Plot duplicates obtained for a given file (eg: 'ukbench00120.jpg') using the duplicates dictionary&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; imagededup.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; plot_duplicates
plot_duplicates(&lt;span class="pl-v"&gt;image_dir&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path/to/image/directory&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
                &lt;span class="pl-v"&gt;duplicate_map&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;duplicates,
                &lt;span class="pl-v"&gt;filename&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ukbench00120.jpg&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The output looks as below:&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="readme_figures/plot_dups.png"&gt;&lt;img src="readme_figures/plot_dups.png" width="600" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;The complete code for the workflow is:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; imagededup.methods &lt;span class="pl-k"&gt;import&lt;/span&gt; PHash
phasher &lt;span class="pl-k"&gt;=&lt;/span&gt; PHash()

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Generate encodings for all images in an image directory&lt;/span&gt;
encodings &lt;span class="pl-k"&gt;=&lt;/span&gt; phasher.encode_images(&lt;span class="pl-v"&gt;image_dir&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path/to/image/directory&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Find duplicates using the generated encodings&lt;/span&gt;
duplicates &lt;span class="pl-k"&gt;=&lt;/span&gt; phasher.find_duplicates(&lt;span class="pl-v"&gt;encoding_map&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;encodings)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; plot duplicates obtained for a given file using the duplicates dictionary&lt;/span&gt;
&lt;span class="pl-k"&gt;from&lt;/span&gt; imagededup.utils &lt;span class="pl-k"&gt;import&lt;/span&gt; plot_duplicates
plot_duplicates(&lt;span class="pl-v"&gt;image_dir&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;path/to/image/directory&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
                &lt;span class="pl-v"&gt;duplicate_map&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;duplicates,
                &lt;span class="pl-v"&gt;filename&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ukbench00120.jpg&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For more examples, refer &lt;a href="https://github.com/idealo/imagededup/tree/master/examples"&gt;this&lt;/a&gt; part of the
repository.&lt;/p&gt;
&lt;p&gt;For more detailed usage of the package functionality, refer: &lt;a href="https://idealo.github.io/imagededup/" rel="nofollow"&gt;https://idealo.github.io/imagededup/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--contribute" class="anchor" aria-hidden="true" href="#-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="handshake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f91d.png"&gt;ü§ù&lt;/g-emoji&gt; Contribute&lt;/h2&gt;
&lt;p&gt;We welcome all kinds of contributions.
See the &lt;a href="CONTRIBUTING.md"&gt;Contribution&lt;/a&gt; guide for more details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--citation" class="anchor" aria-hidden="true" href="#-citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="memo" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4dd.png"&gt;üìù&lt;/g-emoji&gt; Citation&lt;/h2&gt;
&lt;p&gt;Please cite Imagededup in your publications if this is useful for your research. Here is an example BibTeX entry:&lt;/p&gt;
&lt;div class="highlight highlight-text-bibtex"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;@misc&lt;/span&gt;{&lt;span class="pl-en"&gt;idealods2019imagededup&lt;/span&gt;,
  &lt;span class="pl-s"&gt;title&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;Imagededup&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;author&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;Tanuj Jain and Christopher Lennan and Zubin John and Dat Tran&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;year&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;2019&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
  &lt;span class="pl-s"&gt;howpublished&lt;/span&gt;=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;{&lt;/span&gt;\url{https://github.com/idealo/imagededup}&lt;span class="pl-pds"&gt;}&lt;/span&gt;&lt;/span&gt;,
}&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content--maintainers" class="anchor" aria-hidden="true" href="#-maintainers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;g-emoji class="g-emoji" alias="building_construction" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3d7.png"&gt;üèó&lt;/g-emoji&gt; Maintainers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tanuj Jain, github: &lt;a href="https://github.com/tanujjain"&gt;tanujjain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Christopher Lennan, github: &lt;a href="https://github.com/clennan"&gt;clennan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dat Tran, github: &lt;a href="https://github.com/datitran"&gt;datitran&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content--copyright" class="anchor" aria-hidden="true" href="#-copyright"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;¬© Copyright&lt;/h2&gt;
&lt;p&gt;See &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>idealo</author><guid isPermaLink="false">https://github.com/idealo/imagededup</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>frappe/frappe #18 in Python, Today</title><link>https://github.com/frappe/frappe</link><description>&lt;p&gt;&lt;i&gt;The most powerful web framework on the planet&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;div align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href=".github/frappe-framework-logo.png"&gt;&lt;img src=".github/frappe-framework-logo.png" height="150" style="max-width:100%;"&gt;&lt;/a&gt;
    &lt;h1&gt;&lt;a id="user-content---------------------frappe------------" class="anchor" aria-hidden="true" href="#--------------------frappe------------"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
        &lt;a href="https://frappe.io" rel="nofollow"&gt;
            frappe
        &lt;/a&gt;
    &lt;/h1&gt;
    &lt;h3&gt;&lt;a id="user-content---------a-web-framework-with-batteries-included----" class="anchor" aria-hidden="true" href="#--------a-web-framework-with-batteries-included----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
        a web framework with &lt;a href="https://www.youtube.com/watch?v=LOjk3m0wTwg" rel="nofollow"&gt;"batteries included"
    &lt;/a&gt;&lt;/h3&gt;&lt;a href="https://www.youtube.com/watch?v=LOjk3m0wTwg" rel="nofollow"&gt;
    &lt;h5&gt;&lt;a id="user-content---------its-pronounced---fra-pay----" class="anchor" aria-hidden="true" href="#--------its-pronounced---fra-pay----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
        it's pronounced - &lt;em&gt;fra-pay&lt;/em&gt;
    &lt;/h5&gt;
&lt;/a&gt;&lt;/div&gt;&lt;a href="https://www.youtube.com/watch?v=LOjk3m0wTwg" rel="nofollow"&gt;
&lt;/a&gt;&lt;div align="center"&gt;&lt;a href="https://www.youtube.com/watch?v=LOjk3m0wTwg" rel="nofollow"&gt;
    &lt;/a&gt;&lt;a href="https://travis-ci.org/frappe/frappe" rel="nofollow"&gt;
        &lt;img src="https://camo.githubusercontent.com/3a7a792980761e90d36c199a6688cd30232b17c6/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6672617070652f6672617070652e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/travis/frappe/frappe.svg?style=flat-square" style="max-width:100%;"&gt;
    &lt;/a&gt;
    &lt;a href="https://frappe.io/docs" rel="nofollow"&gt;
        &lt;img src="https://camo.githubusercontent.com/4660e43bad4e9a5bbb06dd5a88dba6e9b51c74d7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732df09f93962d3735373546462e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/badge/docs-üìñ-7575FF.svg?style=flat-square" style="max-width:100%;"&gt;
    &lt;/a&gt;
	&lt;a href="https://www.codetriage.com/frappe/frappe" rel="nofollow"&gt;
		&lt;img src="https://camo.githubusercontent.com/a1cbe3deaa0ef98b346ff70a64b14e3754a15ef1/68747470733a2f2f7777772e636f64657472696167652e636f6d2f6672617070652f6672617070652f6261646765732f75736572732e737667" data-canonical-src="https://www.codetriage.com/frappe/frappe/badges/users.svg" style="max-width:100%;"&gt;
	&lt;/a&gt;
    &lt;a href="https://coveralls.io/github/frappe/frappe?branch=develop" rel="nofollow"&gt;
        &lt;img src="https://camo.githubusercontent.com/5890b7d983e7818de7779f28bf5d94774e8411bb/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6672617070652f6672617070652f62616467652e7376673f6272616e63683d646576656c6f70" data-canonical-src="https://coveralls.io/repos/github/frappe/frappe/badge.svg?branch=develop" style="max-width:100%;"&gt;
    &lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Full-stack web application framework that uses Python and MariaDB on the server side and a tightly integrated client side library. Built for &lt;a href="https://erpnext.com" rel="nofollow"&gt;ERPNext&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/frappe/bench"&gt;Install via Frappe Bench&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Pull-Request-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://translate.erpnext.com" rel="nofollow"&gt;Translations&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-website" class="anchor" aria-hidden="true" href="#website"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Website&lt;/h3&gt;
&lt;p&gt;For details and documentation, see the website
&lt;a href="https://frappe.io" rel="nofollow"&gt;https://frappe.io&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;This repository has been released under the &lt;a href="LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>frappe</author><guid isPermaLink="false">https://github.com/frappe/frappe</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>ansible/ansible #19 in Python, Today</title><link>https://github.com/ansible/ansible</link><description>&lt;p&gt;&lt;i&gt;Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy. Avoid writing scripts or custom code to deploy and update your applications ‚Äî automate in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com/ansible/&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://pypi.org/project/ansible" rel="nofollow"&gt;&lt;img alt="PyPI version" src="https://camo.githubusercontent.com/1700ed8e65665052f4e72ba6ae9e1f1d7fddc6c6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f616e7369626c652e737667" data-canonical-src="https://img.shields.io/pypi/v/ansible.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/latest/" rel="nofollow"&gt;&lt;img alt="Docs badge" src="https://camo.githubusercontent.com/dc37b81ae5ef1245837ee1f1547892e8345ccd4b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/docs-latest-brightgreen.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/latest/community/communication.html" rel="nofollow"&gt;&lt;img alt="Chat badge" src="https://camo.githubusercontent.com/a36ab54aea33fa40f9d063c8804b9bbf1b6fbd47/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d4952432d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/chat-IRC-brightgreen.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://app.shippable.com/projects/573f79d02a8192902e20e34b" rel="nofollow"&gt;&lt;img alt="Build Status" src="https://camo.githubusercontent.com/c4dd185960fb101604717a4c8965ac9ba2725e69/68747470733a2f2f6170692e736869707061626c652e636f6d2f70726f6a656374732f3537336637396430326138313932393032653230653334622f62616467653f6272616e63683d646576656c" data-canonical-src="https://api.shippable.com/projects/573f79d02a8192902e20e34b/badge?branch=devel" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/latest/community/code_of_conduct.html" rel="nofollow"&gt;&lt;img alt="Ansible Code of Conduct" src="https://camo.githubusercontent.com/412f4c0b8d7289e25a69d8568bd02c1bf976f9fd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532306f66253230636f6e647563742d416e7369626c652d73696c7665722e737667" data-canonical-src="https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="https://docs.ansible.com/ansible/latest/community/communication.html#mailing-list-information" rel="nofollow"&gt;&lt;img alt="Ansible mailing lists" src="https://camo.githubusercontent.com/74dd4958c493abf9d3105cbcd020e55aa5df90c9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d61696c696e672532306c697374732d416e7369626c652d6f72616e67652e737667" data-canonical-src="https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg" style="max-width:100%;"&gt;
&lt;/a&gt; &lt;a href="COPYING"&gt;&lt;img alt="Repository License" src="https://camo.githubusercontent.com/0ac7552afd56fbe0c2ce6722d54f68857aa92b82/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c25323076332e302d627269676874677265656e2e737667" data-canonical-src="https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg" style="max-width:100%;"&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;a name="user-content-ansible"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-ansible" class="anchor" aria-hidden="true" href="#ansible"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ansible&lt;/h2&gt;
&lt;p&gt;Ansible is a radically simple IT automation system. It handles
configuration management, application deployment, cloud provisioning,
ad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex
changes like zero-downtime rolling updates with load balancers easy. More information on &lt;a href="https://ansible.com/" rel="nofollow"&gt;the Ansible website&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-design-principles"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-design-principles" class="anchor" aria-hidden="true" href="#design-principles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Design Principles&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Have a dead simple setup process and a minimal learning curve.&lt;/li&gt;
&lt;li&gt;Manage machines very quickly and in parallel.&lt;/li&gt;
&lt;li&gt;Avoid custom-agents and additional open ports, be agentless by
leveraging the existing SSH daemon.&lt;/li&gt;
&lt;li&gt;Describe infrastructure in a language that is both machine and human
friendly.&lt;/li&gt;
&lt;li&gt;Focus on security and easy auditability/review/rewriting of content.&lt;/li&gt;
&lt;li&gt;Manage new remote machines instantly, without bootstrapping any
software.&lt;/li&gt;
&lt;li&gt;Allow module development in any dynamic language, not just Python.&lt;/li&gt;
&lt;li&gt;Be usable as non-root.&lt;/li&gt;
&lt;li&gt;Be the easiest IT automation system to use, ever.&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-use-ansible"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-use-ansible" class="anchor" aria-hidden="true" href="#use-ansible"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Use Ansible&lt;/h3&gt;
&lt;p&gt;You can install a released version of Ansible via &lt;code&gt;pip&lt;/code&gt;, a package manager, or
our &lt;a href="https://releases.ansible.com/ansible/" rel="nofollow"&gt;release repository&lt;/a&gt;. See our
&lt;a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html" rel="nofollow"&gt;installation guide&lt;/a&gt; for details on installing Ansible
on a variety of platforms.&lt;/p&gt;
&lt;p&gt;Red Hat offers supported builds of &lt;a href="https://www.ansible.com/ansible-engine" rel="nofollow"&gt;Ansible Engine&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Power users and developers can run the &lt;code&gt;devel&lt;/code&gt; branch, which has the latest
features and fixes, directly. Although it is reasonably stable, you are more likely to encounter
breaking changes when running the &lt;code&gt;devel&lt;/code&gt; branch. We recommend getting involved
in the Ansible community if you want to run the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/p&gt;
&lt;a name="user-content-get-involved"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-get-involved" class="anchor" aria-hidden="true" href="#get-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get Involved&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Read &lt;a href="https://docs.ansible.com/ansible/latest/community" rel="nofollow"&gt;Community
Information&lt;/a&gt; for all
kinds of ways to contribute to and interact with the project,
including mailing list information and how to submit bug reports and
code to Ansible.&lt;/li&gt;
&lt;li&gt;Join a &lt;a href="https://github.com/ansible/community/wiki"&gt;Working Group&lt;/a&gt;, an organized community devoted to a specific technology domain or platform.&lt;/li&gt;
&lt;li&gt;Submit a proposed code update through a pull request to the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/li&gt;
&lt;li&gt;Talk to us before making larger changes
to avoid duplicate efforts. This not only helps everyone
know what is going on, it also helps save time and effort if we decide
some changes are needed.&lt;/li&gt;
&lt;li&gt;For a list of email lists, IRC channels and Working Groups, see the
&lt;a href="https://docs.ansible.com/ansible/latest/community/communication.html" rel="nofollow"&gt;Communication page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-branch-info"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-branch-info" class="anchor" aria-hidden="true" href="#branch-info"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Branch Info&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;devel&lt;/code&gt; branch corresponds to the release actively under development.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;stable-2.X&lt;/code&gt; branches correspond to stable releases.&lt;/li&gt;
&lt;li&gt;Create a branch based on &lt;code&gt;devel&lt;/code&gt; and set up a &lt;a href="https://docs.ansible.com/ansible/latest/dev_guide/developing_modules_general.html#common-environment-setup" rel="nofollow"&gt;dev environment&lt;/a&gt; if you want to open a PR.&lt;/li&gt;
&lt;li&gt;See the &lt;a href="https://docs.ansible.com/ansible/latest/reference_appendices/release_and_maintenance.html" rel="nofollow"&gt;Ansible release and maintenance&lt;/a&gt; page for information about active branches.&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-roadmap"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-roadmap" class="anchor" aria-hidden="true" href="#roadmap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Roadmap&lt;/h3&gt;
&lt;p&gt;Based on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8).
The &lt;a href="https://docs.ansible.com/ansible/devel/roadmap/" rel="nofollow"&gt;Ansible Roadmap page&lt;/a&gt; details what is planned and how to influence the roadmap.&lt;/p&gt;
&lt;a name="user-content-authors"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-authors" class="anchor" aria-hidden="true" href="#authors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authors&lt;/h3&gt;
&lt;p&gt;Ansible was created by &lt;a href="https://github.com/mpdehaan"&gt;Michael DeHaan&lt;/a&gt;
and has contributions from over 4600 users (and growing). Thanks everyone!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.ansible.com" rel="nofollow"&gt;Ansible&lt;/a&gt; is sponsored by &lt;a href="https://www.redhat.com" rel="nofollow"&gt;Red Hat, Inc.&lt;/a&gt;&lt;/p&gt;
&lt;a name="user-content-license"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;GNU General Public License v3.0&lt;/p&gt;
&lt;p&gt;See &lt;a href="COPYING"&gt;COPYING&lt;/a&gt; to see the full text.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>ansible</author><guid isPermaLink="false">https://github.com/ansible/ansible</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>healthchecks/healthchecks #20 in Python, Today</title><link>https://github.com/healthchecks/healthchecks</link><description>&lt;p&gt;&lt;i&gt;A Cron Monitoring Tool written in Python &amp; Django&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-healthchecks" class="anchor" aria-hidden="true" href="#healthchecks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Healthchecks&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/healthchecks/healthchecks" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2c77f36aa4981836828e3e92b104df90aa51e96c/68747470733a2f2f7472617669732d63692e6f72672f6865616c7468636865636b732f6865616c7468636865636b732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/healthchecks/healthchecks.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://coveralls.io/github/healthchecks/healthchecks?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/dd0efba1130e75501eb28f34434d1542ddfbab96/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6865616c7468636865636b732f6865616c7468636865636b732f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/healthchecks/healthchecks/badge.svg?branch=master&amp;amp;service=github" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/static/img/welcome.png?raw=true"&gt;&lt;img src="/static/img/welcome.png?raw=true" alt="Screenshot of Welcome page" title="Welcome Page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/static/img/my_checks.png?raw=true"&gt;&lt;img src="/static/img/my_checks.png?raw=true" alt="Screenshot of My Checks page" title="My Checks Page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/static/img/period_grace.png?raw=true"&gt;&lt;img src="/static/img/period_grace.png?raw=true" alt="Screenshot of Period/Grace dialog" title="Period/Grace Dialog" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/static/img/cron.png?raw=true"&gt;&lt;img src="/static/img/cron.png?raw=true" alt="Screenshot of Cron dialog" title="Cron Dialog" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/static/img/channels.png?raw=true"&gt;&lt;img src="/static/img/channels.png?raw=true" alt="Screenshot of Integrations page" title="Integrations Page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;healthchecks is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface.&lt;/p&gt;
&lt;p&gt;It is live here: &lt;a href="http://healthchecks.io/" rel="nofollow"&gt;http://healthchecks.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The building blocks are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 3&lt;/li&gt;
&lt;li&gt;Django 2&lt;/li&gt;
&lt;li&gt;PostgreSQL or MySQL&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-setting-up-for-development" class="anchor" aria-hidden="true" href="#setting-up-for-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setting Up for Development&lt;/h2&gt;
&lt;p&gt;These are instructions for setting up healthchecks Django app
in development environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;install dependencies (Debian/Ubuntu)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ sudo apt-get update
  $ sudo apt-get install -y gcc python3-dev python3-venv
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;prepare directory for project code and virtualenv:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ mkdir -p ~/webapps
  $ cd ~/webapps
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;prepare virtual environment
(with virtualenv you get pip, we'll use it soon to install requirements):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ python3 -m venv hc-venv
  $ source hc-venv/bin/activate
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;check out project code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ git clone https://github.com/healthchecks/healthchecks.git
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;install requirements (Django, ...) into virtualenv:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ pip install -r healthchecks/requirements.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;healthchecks is configured to use a SQLite database by default. To use
PostgreSQL or MySQL database, create and edit &lt;code&gt;hc/local_settings.py&lt;/code&gt; file.
There is a template you can copy and edit as needed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ cd ~/webapps/healthchecks
  $ cp hc/local_settings.py.example hc/local_settings.py
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;create database tables and the superuser account:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ cd ~/webapps/healthchecks
  $ ./manage.py migrate
  $ ./manage.py createsuperuser
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;run development server:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  $ ./manage.py runserver
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The site should now be running at &lt;code&gt;http://localhost:8080&lt;/code&gt;
To log into Django administration site as a super user,
visit &lt;code&gt;http://localhost:8080/admin&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Site configuration is loaded from environment variables. This is
done in &lt;code&gt;hc/settings.py&lt;/code&gt;. Additional configuration is loaded
from &lt;code&gt;hc/local_settings.py&lt;/code&gt; file, if it exists. You can create this file
(should be right next to &lt;code&gt;settings.py&lt;/code&gt; in the filesystem) and override
settings, or add extra settings as needed.&lt;/p&gt;
&lt;p&gt;Configurations settings loaded from environment variables:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Environment variable&lt;/th&gt;
&lt;th&gt;Default value&lt;/th&gt;
&lt;th&gt;Notes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#secret-key" rel="nofollow"&gt;SECRET_KEY&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"---"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#debug" rel="nofollow"&gt;DEBUG&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Set to &lt;code&gt;False&lt;/code&gt; for production&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#allowed-hosts" rel="nofollow"&gt;ALLOWED_HOSTS&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;*&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Separate multiple hosts with commas&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#default-from-email" rel="nofollow"&gt;DEFAULT_FROM_EMAIL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"healthchecks@example.org"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;USE_PAYMENTS&lt;/td&gt;
&lt;td&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;REGISTRATION_OPEN&lt;/td&gt;
&lt;td&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DB&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"sqlite"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Set to &lt;code&gt;"postgres"&lt;/code&gt; or &lt;code&gt;"mysql"&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#host" rel="nofollow"&gt;DB_HOST&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;""&lt;/code&gt; &lt;em&gt;(empty string)&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#port" rel="nofollow"&gt;DB_PORT&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;""&lt;/code&gt; &lt;em&gt;(empty string)&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#name" rel="nofollow"&gt;DB_NAME&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"hc"&lt;/code&gt; (PostgreSQL, MySQL) or &lt;code&gt;"/path/to/project/hc.sqlite"&lt;/code&gt; (SQLite)&lt;/td&gt;
&lt;td&gt;For SQLite, specify the full path to the database file.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#user" rel="nofollow"&gt;DB_USER&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"postgres"&lt;/code&gt; or &lt;code&gt;"root"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#password" rel="nofollow"&gt;DB_PASSWORD&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;""&lt;/code&gt; &lt;em&gt;(empty string)&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#conn-max-age" rel="nofollow"&gt;DB_CONN_MAX_AGE&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DB_SSLMODE&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"prefer"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;PostgreSQL-specific, &lt;a href="https://blog.github.com/2018-10-21-october21-incident-report/"&gt;details&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DB_TARGET_SESSION_ATTRS&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"read-write"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;PostgreSQL-specific, &lt;a href="https://www.postgresql.org/docs/10/static/libpq-connect.html#LIBPQ-CONNECT-TARGET-SESSION-ATTRS" rel="nofollow"&gt;details&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EMAIL_HOST&lt;/td&gt;
&lt;td&gt;&lt;code&gt;""&lt;/code&gt; &lt;em&gt;(empty string)&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EMAIL_PORT&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"587"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EMAIL_HOST_USER&lt;/td&gt;
&lt;td&gt;&lt;code&gt;""&lt;/code&gt; &lt;em&gt;(empty string)&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EMAIL_HOST_PASSWORD&lt;/td&gt;
&lt;td&gt;&lt;code&gt;""&lt;/code&gt; &lt;em&gt;(empty string)&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EMAIL_USE_TLS&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"True"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EMAIL_USE_VERIFICATION&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"True"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SITE_ROOT&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"http://localhost:8000"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SITE_NAME&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"Mychecks"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MASTER_BADGE_LABEL&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"Mychecks"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PING_ENDPOINT&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"http://localhost:8000/ping/"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PING_EMAIL_DOMAIN&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"localhost"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DISCORD_CLIENT_ID&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DISCORD_CLIENT_SECRET&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SLACK_CLIENT_ID&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SLACK_CLIENT_SECRET&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUSHOVER_API_TOKEN&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUSHOVER_SUBSCRIPTION_URL&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUSHOVER_EMERGENCY_RETRY_DELAY&lt;/td&gt;
&lt;td&gt;&lt;code&gt;300&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUSHOVER_EMERGENCY_EXPIRATION&lt;/td&gt;
&lt;td&gt;&lt;code&gt;86400&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUSHBULLET_CLIENT_ID&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUSHBULLET_CLIENT_SECRET&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TELEGRAM_BOT_NAME&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"ExampleBot"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TELEGRAM_TOKEN&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TWILIO_ACCOUNT&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TWILIO_AUTH&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TWILIO_FROM&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TWILIO_USE_WHATSAPP&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"False"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PD_VENDOR_KEY&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TRELLO_APP_KEY&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MATRIX_HOMESERVER&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MATRIX_USER_ID&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MATRIX_ACCESS_TOKEN&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;APPRISE_ENABLED&lt;/td&gt;
&lt;td&gt;&lt;code&gt;"False"&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Some useful settings keys to override are:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SITE_ROOT&lt;/code&gt; is used to build fully qualified URLs for pings, and for use in
emails and notifications. Example:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;SITE_ROOT&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://my-monitoring-project.com&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;SITE_NAME&lt;/code&gt; has the default value of "Mychecks" and is used throughout
the templates. Replace it with your own name to personalize your installation.
Example:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;SITE_NAME&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;My Monitoring Project&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;REGISTRATION_OPEN&lt;/code&gt; controls whether site visitors can create new accounts.
Set it to &lt;code&gt;False&lt;/code&gt; if you are setting up a private healthchecks instance, but
it needs to be publicly accessible (so, for example, your cloud services
can send pings).&lt;/p&gt;
&lt;p&gt;If you close new user registration, you can still selectively invite users
to your team account.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EMAIL_USE_VERIFICATION&lt;/code&gt; enables/disables the sending of a verification
link when an email address is added to the list of notification methods.
Set it to &lt;code&gt;False&lt;/code&gt; if you are setting up a private healthchecks instance where
you trust your users and want to avoid the extra verification step.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-database-configuration" class="anchor" aria-hidden="true" href="#database-configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database Configuration&lt;/h2&gt;
&lt;p&gt;Database configuration is loaded from environment variables. If you
need to use a non-standard configuration, you can override the
database configuration in &lt;code&gt;hc/local_settings.py&lt;/code&gt; like so:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;DATABASES&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
    &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;default&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: {
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;ENGINE&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:   &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;django.db.backends.postgresql&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;NAME&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:     &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;your-database-name-here&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;USER&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;:     &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;your-database-user-here&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;PASSWORD&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;your-database-password-here&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;TEST&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;CHARSET&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;UTF8&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;},
        &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;OPTIONS&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;: {
            &lt;span class="pl-c1"&gt;...&lt;/span&gt; your custom options here &lt;span class="pl-c1"&gt;...&lt;/span&gt;
        }
    }
}&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-sending-emails" class="anchor" aria-hidden="true" href="#sending-emails"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sending Emails&lt;/h2&gt;
&lt;p&gt;healthchecks must be able to send email messages, so it can send out login
links and alerts to users. Environment variables can be used to configure
SMTP settings, or your may put your SMTP server configuration in
&lt;code&gt;hc/local_settings.py&lt;/code&gt; like so:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;EMAIL_HOST&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;your-smtp-server-here.com&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;EMAIL_PORT&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;587&lt;/span&gt;
&lt;span class="pl-c1"&gt;EMAIL_HOST_USER&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;username&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;EMAIL_HOST_PASSWORD&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;password&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c1"&gt;EMAIL_USE_TLS&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;True&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For more information, have a look at Django documentation,
&lt;a href="https://docs.djangoproject.com/en/1.10/topics/email/" rel="nofollow"&gt;Sending Email&lt;/a&gt; section.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-receiving-emails" class="anchor" aria-hidden="true" href="#receiving-emails"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Receiving Emails&lt;/h2&gt;
&lt;p&gt;healthchecks comes with a &lt;code&gt;smtpd&lt;/code&gt; management command, which starts up a
SMTP listener service. With the command running, you can ping your
checks by sending email messages
to &lt;code&gt;your-uuid-here@my-monitoring-project.com&lt;/code&gt; email addresses.&lt;/p&gt;
&lt;p&gt;Start the SMTP listener on port 2525:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py smtpd --port 2525
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Send a test email:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl --url 'smtp://127.0.0.1:2525' \
    --mail-from 'foo@example.org' \
    --mail-rcpt '11111111-1111-1111-1111-111111111111@my-monitoring-project.com' \
    -F '='
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-sending-status-notifications" class="anchor" aria-hidden="true" href="#sending-status-notifications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sending Status Notifications&lt;/h2&gt;
&lt;p&gt;healtchecks comes with a &lt;code&gt;sendalerts&lt;/code&gt; management command, which continuously
polls database for any checks changing state, and sends out notifications as
needed. Within an activated virtualenv, you can manually run
the &lt;code&gt;sendalerts&lt;/code&gt; command like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py sendalerts
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a production setup, you will want to run this command from a process
manager like &lt;a href="http://supervisord.org/" rel="nofollow"&gt;supervisor&lt;/a&gt; or systemd.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-database-cleanup" class="anchor" aria-hidden="true" href="#database-cleanup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database Cleanup&lt;/h2&gt;
&lt;p&gt;With time and use the healthchecks database will grow in size. You may
decide to prune old data: inactive user accounts, old checks not assigned
to users, records of outgoing email messages and records of received pings.
There are separate Django management commands for each task:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Remove old records from &lt;code&gt;api_ping&lt;/code&gt; table. For each check, keep 100 most
recent pings:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py prunepings
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remove old records of sent notifications. For each check, remove
notifications that are older than the oldest stored ping for same check.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py prunenotifications
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remove user accounts that match either of these conditions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Account was created more than 6 months ago, and user has never logged in.
These can happen when user enters invalid email address when signing up.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Last login was more than 6 months ago, and the account has no checks.
Assume the user doesn't intend to use the account any more and would
probably &lt;em&gt;want&lt;/em&gt; it removed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py pruneusers
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remove old records from the &lt;code&gt;api_tokenbucket&lt;/code&gt; table. The TokenBucket
model is used for rate-limiting login attempts and similar operations.
Any records older than one day can be safely removed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py prunetokenbucket
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remove old records from the &lt;code&gt;api_flip&lt;/code&gt; table. The Flip
objects are used to track status changes of checks, and to calculate
downtime statistics month by month. Flip objects from more than 3 months
ago are not used and can be safely removed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py pruneflips
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When you first try these commands on your data, it is a good idea to
test them on a copy of your database, not on the live database right away.
In a production setup, you should also have regular, automated database
backups set up.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-integrations" class="anchor" aria-hidden="true" href="#integrations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Integrations&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-discord" class="anchor" aria-hidden="true" href="#discord"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Discord&lt;/h3&gt;
&lt;p&gt;To enable Discord integration, you will need to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;register a new application on &lt;a href="https://discordapp.com/developers/applications/me" rel="nofollow"&gt;https://discordapp.com/developers/applications/me&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;add a redirect URI to your Discord application. The URI format is
&lt;code&gt;SITE_ROOT/integrations/add_discord/&lt;/code&gt;. For example, if you are running a
development server on &lt;code&gt;localhost:8000&lt;/code&gt; then the redirect URI would be
&lt;code&gt;http://localhost:8000/integrations/add_discord/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Look up your Discord app's Client ID and Client Secret. Put them
in &lt;code&gt;DISCORD_CLIENT_ID&lt;/code&gt; and &lt;code&gt;DISCORD_CLIENT_SECRET&lt;/code&gt; environment
variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-pushover" class="anchor" aria-hidden="true" href="#pushover"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pushover&lt;/h3&gt;
&lt;p&gt;Pushover integration works by creating an application on Pushover.net which
is then subscribed to by Healthchecks users. The registration workflow is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On Healthchecks, the user adds a "Pushover" integration to a project&lt;/li&gt;
&lt;li&gt;Healthchecks redirects user's browser to a Pushover.net subscription page&lt;/li&gt;
&lt;li&gt;User approves adding the Healthchecks subscription to their Pushover account&lt;/li&gt;
&lt;li&gt;Pushover.net HTTP redirects back to Healthchecks with a subscription token&lt;/li&gt;
&lt;li&gt;Healthchecks saves the subscription token and uses it for sending Pushover
notifications&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To enable the Pushover integration, you will need to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Register a new application on Pushover via &lt;a href="https://pushover.net/apps/build" rel="nofollow"&gt;https://pushover.net/apps/build&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Within the Pushover 'application' configuration, enable subscriptions.
Make sure the subscription type is set to "URL". Also make sure the redirect
URL is configured to point back to the root of the Healthchecks instance
(e.g., &lt;code&gt;http://healthchecks.example.com/&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Put the Pushover application API Token and the Pushover subscription URL in
&lt;code&gt;PUSHOVER_API_TOKEN&lt;/code&gt; and &lt;code&gt;PUSHOVER_SUBSCRIPTION_URL&lt;/code&gt; environment
variables. The Pushover subscription URL should look similar to
&lt;code&gt;https://pushover.net/subscribe/yourAppName-randomAlphaNumericData&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-telegram" class="anchor" aria-hidden="true" href="#telegram"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Telegram&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Create a Telegram bot by talking to the
&lt;a href="https://core.telegram.org/bots#6-botfather" rel="nofollow"&gt;BotFather&lt;/a&gt;. Set the bot's name,
description, user picture, and add a "/start" command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After creating the bot you will have the bot's name and token. Put them
in &lt;code&gt;TELEGRAM_BOT_NAME&lt;/code&gt; and &lt;code&gt;TELEGRAM_TOKEN&lt;/code&gt; environment variables.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;settelegramwebhook&lt;/code&gt; management command. This command tells Telegram
where to forward channel messages by invoking Telegram's
&lt;a href="https://core.telegram.org/bots/api#setwebhook" rel="nofollow"&gt;setWebhook&lt;/a&gt; API call:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./manage.py settelegramwebhook
Done, Telegram's webhook set to: https://my-monitoring-project.com/integrations/telegram/bot/
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this to work, your &lt;code&gt;SITE_ROOT&lt;/code&gt; needs to be correct and use "https://"
scheme.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-apprise" class="anchor" aria-hidden="true" href="#apprise"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apprise&lt;/h3&gt;
&lt;p&gt;To enable Apprise integration, you will need to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ensure you have apprise installed in your local environment:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pip install apprise&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;enable the apprise functionality by setting the &lt;code&gt;APPRISE_ENABLED&lt;/code&gt; environment variable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-running-in-production" class="anchor" aria-hidden="true" href="#running-in-production"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running in Production&lt;/h2&gt;
&lt;p&gt;Here is a non-exhaustive list of pointers and things to check before launching a Healthchecks instance
in production.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Environment variables, settings.py and local_settings.py.
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#debug" rel="nofollow"&gt;DEBUG&lt;/a&gt;. Make sure it is set to &lt;code&gt;False&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#allowed-hosts" rel="nofollow"&gt;ALLOWED_HOSTS&lt;/a&gt;. Make sure it
contains the correct domain name you want to use.&lt;/li&gt;
&lt;li&gt;Server Errors. When DEBUG=False, Django will not show detailed error pages, and will not print exception
tracebacks to standard output. To receive exception tracebacks in email,
review and edit the &lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#admins" rel="nofollow"&gt;ADMINS&lt;/a&gt; and
&lt;a href="https://docs.djangoproject.com/en/2.2/ref/settings/#server-email" rel="nofollow"&gt;SERVER_EMAIL&lt;/a&gt; settings.
Another good option for receiving exception tracebacks is to use &lt;a href="https://sentry.io/for/django/" rel="nofollow"&gt;Sentry&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Management commands that need to be run during each deployment.
&lt;ul&gt;
&lt;li&gt;This project uses &lt;a href="https://django-compressor.readthedocs.io/en/stable/" rel="nofollow"&gt;Django Compressor&lt;/a&gt;
to combine the CSS and JS files. It is configured for offline compression ‚Äì run the
&lt;code&gt;manage.py compress&lt;/code&gt; command whenever files in the &lt;code&gt;/static/&lt;/code&gt; directory change.&lt;/li&gt;
&lt;li&gt;This project uses Django's &lt;a href="https://docs.djangoproject.com/en/2.2/ref/contrib/staticfiles/" rel="nofollow"&gt;staticfiles app&lt;/a&gt;.
Run the &lt;code&gt;manage.py collectstatic&lt;/code&gt; command whenever files in the &lt;code&gt;/static/&lt;/code&gt;
directory change. This command collects all the static files inside the &lt;code&gt;static-collected&lt;/code&gt; directory.
Configure your web server to serve files from this directory under the &lt;code&gt;/static/&lt;/code&gt; prefix.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Processes that need to be running constantly.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;manage.py runserver&lt;/code&gt; is intended for development only. Do not use it in production,
instead consider using &lt;a href="https://uwsgi-docs.readthedocs.io/en/latest/" rel="nofollow"&gt;uWSGI&lt;/a&gt; or
&lt;a href="https://gunicorn.org/" rel="nofollow"&gt;gunicorn&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Make sure the &lt;code&gt;manage.py sendalerts&lt;/code&gt; command is running and can survive server restarts.
On modern linux systems, a good option is to
&lt;a href="https://github.com/healthchecks/healthchecks/issues/273#issuecomment-520560304"&gt;define a systemd service&lt;/a&gt; for it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;General
&lt;ul&gt;
&lt;li&gt;Make sure the database is secured well and is getting backed up regularly&lt;/li&gt;
&lt;li&gt;Make sure the TLS certificates are secured well and are getting refreshed regularly&lt;/li&gt;
&lt;li&gt;Have monitoring in place to be sure the Healthchecks instance itself is operational
(is accepting pings, is sending out alerts, is not running out of resources).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>healthchecks</author><guid isPermaLink="false">https://github.com/healthchecks/healthchecks</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>FederatedAI/FATE #21 in Python, Today</title><link>https://github.com/FederatedAI/FATE</link><description>&lt;p&gt;&lt;i&gt;An Industrial Level Federated Learning Framework&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8051e9938a1ab39cf002818dfceb6b6092f34d68/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://checkstyle.sourceforge.io/google_style.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5293377fc6cab0f84eff7cb32a969ab03faa2d8f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436865636b2532305374796c652d476f6f676c652d627269676874677265656e" alt="CodeStyle" data-canonical-src="https://img.shields.io/badge/Check%20Style-Google-brightgreen" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://github.com/mmyjona/FATE-Serving/pulls"&gt;&lt;img src="https://camo.githubusercontent.com/2d342e6a87223e832e6b2a9301bcd99c2926853d/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e743f75726c3d68747470732533412532462532467363616e2e736272656c6c612e636f6d25324661646d696e253246617069253246763125324670696e706f696e74253246736869656c64253246466564657261746564414925324646415445" alt="Pinpoint Satellite" data-canonical-src="https://img.shields.io/endpoint?url=https%3A%2F%2Fscan.sbrella.com%2Fadmin%2Fapi%2Fv1%2Fpinpoint%2Fshield%2FFederatedAI%2FFATE" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://checkstyle.sourceforge.io/google_style.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ec23d1eb408174e4705f261fe996f57ead350831/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436865636b2532305374796c652d426c61636b2d626c61636b" alt="Style" data-canonical-src="https://img.shields.io/badge/Check%20Style-Black-black" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a target="_blank" rel="noopener noreferrer" href="./doc/images/FATE_logo.png"&gt;&lt;img src="./doc/images/FATE_logo.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;FATE (Federated AI Technology Enabler) is an open-source project initiated by Webank's AI Department to provide a secure computing framework to support the federated AI ecosystem. It implements secure computation protocols based on homomorphic encryption and multi-party computation (MPC). It supports federated learning architectures and secure computation of various machine learning algorithms, including logistic regression, tree-based algorithms, deep learning and transfer learning.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://fate.fedai.org" rel="nofollow"&gt;https://fate.fedai.org&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-involved" class="anchor" aria-hidden="true" href="#getting-involved"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Involved&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Join our maillist &lt;a href="https://groups.io/g/Fate-FedAI" rel="nofollow"&gt;Fate-FedAI Group IO&lt;/a&gt;. You can ask questions and participate in the development discussion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For any frequently asked questions, you can check in &lt;a href="https://github.com/WeBankFinTech/FATE/wiki"&gt;FAQ&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Please report bugs by submitting &lt;a href="https://github.com/WeBankFinTech/FATE/issues"&gt;issues&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Submit contributions using &lt;a href="https://github.com/WeBankFinTech/FATE/pulls"&gt;pull requests&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-federated-learning-algorithms-in-fate" class="anchor" aria-hidden="true" href="#federated-learning-algorithms-in-fate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Federated Learning Algorithms In FATE&lt;/h2&gt;
&lt;p&gt;FATE already supports a number of federated learning algorithms, including vertical federated learning, horizontal federated learning, and federated transfer learning. More details are available in &lt;a href="./federatedml"&gt;federatedml&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h2&gt;
&lt;p&gt;FATE can be installed on Linux or Mac. Now, FATE can support standalone and cluster deployments.&lt;/p&gt;
&lt;p&gt;Software environment :jdk1.8+„ÄÅPython3.6„ÄÅpython virtualenv„ÄÅmysql5.6+„ÄÅredis-5.0.2&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-standalone" class="anchor" aria-hidden="true" href="#standalone"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Standalone&lt;/h4&gt;
&lt;p&gt;FATE provides Standalone runtime architecture for developers. It can help developers quickly test FATE. Standalone support two types of deployment: Docker version and Manual version. Please refer to Standalone deployment guide: &lt;a href="./standalone-deploy/"&gt;standalone-deploy&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-cluster" class="anchor" aria-hidden="true" href="#cluster"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cluster&lt;/h4&gt;
&lt;p&gt;FATE also provides a distributed runtime architecture for Big Data scenario. Migration from standalone to cluster requires configuration change only. No algorithm change is needed.&lt;/p&gt;
&lt;p&gt;To deploy FATE on a cluster, please refer to cluster deployment guide: &lt;a href="./cluster-deploy"&gt;cluster-deploy&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-get-source" class="anchor" aria-hidden="true" href="#get-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get source&lt;/h4&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone --recursive git@github.com:FederatedAI/FATE.git&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-running-tests" class="anchor" aria-hidden="true" href="#running-tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running Tests&lt;/h2&gt;
&lt;p&gt;A script to run all the unittests has been provided in ./federatedml/test folder.&lt;/p&gt;
&lt;p&gt;Once FATE is installed, tests can be run using:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;sh ./federatedml/test/run_test.sh&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All the unittests shall pass if FATE is installed properly.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-programs" class="anchor" aria-hidden="true" href="#example-programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Programs&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h3&gt;
&lt;p&gt;We have provided a python script for quick starting modeling task. This scrip is located at &lt;a href="./examples/federatedml-1.x-examples"&gt;"examples/federatedml-1.x-examples"&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-standalone-version" class="anchor" aria-hidden="true" href="#standalone-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Standalone Version&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Start standalone version hetero-lr task (default)&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;python quick_run.py&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-cluster-version" class="anchor" aria-hidden="true" href="#cluster-version"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cluster Version&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Host party:&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;python quick_run.py -r host&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is just uploading data&lt;/p&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Guest party:&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;python quick_run.py -r guest&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The config files that generated is stored in a new created folder named &lt;strong&gt;user_config&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-start-a-predict-task" class="anchor" aria-hidden="true" href="#start-a-predict-task"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Start a Predict Task&lt;/h4&gt;
&lt;p&gt;Once you finish one training task, you can start a predict task. You need to modify "TASK" variable in quick_run.py script as "predict":&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Define what type of task it is
# TASK = 'train'
TASK = 'predict'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then all you need to do is running the following command:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python quick_run.py&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Please note this works only if you have finished the trainning task.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-obtain-model-and-check-out-results" class="anchor" aria-hidden="true" href="#obtain-model-and-check-out-results"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Obtain Model and Check Out Results&lt;/h3&gt;
&lt;p&gt;We provided functions such as tracking component output models or logs etc. through a tool called fate-flow. The deployment and usage of fate-flow can be found &lt;a href="./fate_flow/README.md"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-doc" class="anchor" aria-hidden="true" href="#doc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Doc&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-api-doc" class="anchor" aria-hidden="true" href="#api-doc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API doc&lt;/h3&gt;
&lt;p&gt;FATE provides some API documents in &lt;a href="./doc/api/"&gt;doc-api&lt;/a&gt;, including federatedml, eggroll, federation.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-develop-guide-doc" class="anchor" aria-hidden="true" href="#develop-guide-doc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Develop Guide doc&lt;/h3&gt;
&lt;p&gt;How to develop your federated learning algorithm using FATE? you can see FATE develop guide document in &lt;a href="./doc/develop_guide.md"&gt;develop-guide&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-other-doc" class="anchor" aria-hidden="true" href="#other-doc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other doc&lt;/h3&gt;
&lt;p&gt;FATE also provides many other documents in &lt;a href="./doc/"&gt;doc&lt;/a&gt;. These documents can help you understand FATE better.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>FederatedAI</author><guid isPermaLink="false">https://github.com/FederatedAI/FATE</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>robotframework/robotframework #22 in Python, Today</title><link>https://github.com/robotframework/robotframework</link><description>&lt;p&gt;&lt;i&gt;Generic automation framework for acceptance testing and RPA&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body rst" data-path="README.rst"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-robot-framework" class="anchor" aria-hidden="true" href="#robot-framework"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Robot Framework&lt;/h1&gt;
&lt;div id="user-content-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction" id="user-content-id7"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installation" id="user-content-id8"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example" id="user-content-id9"&gt;Example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#usage" id="user-content-id10"&gt;Usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation" id="user-content-id11"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#support-and-contact" id="user-content-id12"&gt;Support and contact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing" id="user-content-id13"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license" id="user-content-id14"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;a name="user-content-introduction"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id7"&gt;Introduction&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://robotframework.org" rel="nofollow"&gt;Robot Framework&lt;/a&gt; is a generic open source
automation framework for acceptance testing, acceptance test driven
development (ATDD), and robotic process automation (RPA). It has simple plain
text syntax and it can be extended easily with libraries implemented using
Python or Java.&lt;/p&gt;
&lt;p&gt;Robot Framework is operating system and application independent. The core
framework is implemented using &lt;a href="http://python.org" rel="nofollow"&gt;Python&lt;/a&gt;, supports both
Python 2 and Python 3, and runs also on &lt;a href="http://jython.org" rel="nofollow"&gt;Jython&lt;/a&gt; (JVM),
&lt;a href="http://ironpython.net" rel="nofollow"&gt;IronPython&lt;/a&gt; (.NET) and &lt;a href="http://pypy.org" rel="nofollow"&gt;PyPy&lt;/a&gt;.
The framework has a rich ecosystem around it consisting of various generic
libraries and tools that are developed as separate projects. For more
information about Robot Framework and the ecosystem, see
&lt;a href="http://robotframework.org" rel="nofollow"&gt;http://robotframework.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Robot Framework project is hosted on &lt;a href="https://github.com/robotframework/robotframework"&gt;GitHub&lt;/a&gt; where you can find source code,
an issue tracker, and some further documentation. See &lt;a href="CONTRIBUTING.rst"&gt;CONTRIBUTING.rst&lt;/a&gt;
if you are interested to contribute. Downloads are hosted on &lt;a href="https://pypi.python.org/pypi/robotframework" rel="nofollow"&gt;PyPI&lt;/a&gt;, except
for the standalone JAR distribution that is on &lt;a href="http://search.maven.org/#search%7Cga%7C1%7Ca%3Arobotframework" rel="nofollow"&gt;Maven central&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Robot Framework development is sponsored by &lt;a href="http://robotframework.org/foundation" rel="nofollow"&gt;Robot Framework Foundation&lt;/a&gt;.&lt;/p&gt;
&lt;a href="https://pypi.python.org/pypi/robotframework" rel="nofollow"&gt;&lt;img alt="Latest version" src="https://camo.githubusercontent.com/ec5354e88ee7bbd5457713ca62ac507315db1ca5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f726f626f746672616d65776f726b2e7376673f6c6162656c3d76657273696f6e" data-canonical-src="https://img.shields.io/pypi/v/robotframework.svg?label=version" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.apache.org/licenses/LICENSE-2.0.html" rel="nofollow"&gt;&lt;img alt="License" src="https://camo.githubusercontent.com/4dc279c7e634593c6b0dc6928b38f3f0cedbb377/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f726f626f746672616d65776f726b2e737667" data-canonical-src="https://img.shields.io/pypi/l/robotframework.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a name="user-content-installation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id8"&gt;Installation&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you already have &lt;a href="http://python.org" rel="nofollow"&gt;Python&lt;/a&gt; with &lt;a href="http://pip-installer.org" rel="nofollow"&gt;pip&lt;/a&gt; installed,
you can simply run:&lt;/p&gt;
&lt;pre&gt;pip install robotframework
&lt;/pre&gt;
&lt;p&gt;Alternatively you can get Robot Framework source code by downloading the source
distribution from &lt;a href="https://pypi.python.org/pypi/robotframework" rel="nofollow"&gt;PyPI&lt;/a&gt; and extracting it, or by cloning the project repository
from &lt;a href="https://github.com/robotframework/robotframework"&gt;GitHub&lt;/a&gt;. After that you can install the framework with:&lt;/p&gt;
&lt;pre&gt;python setup.py install
&lt;/pre&gt;
&lt;p&gt;For more detailed installation instructions, including installing Python,
Jython, IronPython and PyPy or installing from git, see &lt;a href="INSTALL.rst"&gt;INSTALL.rst&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-example"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id9"&gt;Example&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Below is a simple example test case for testing login to some system.
You can find more examples with links to related demo projects from
&lt;a href="http://robotframework.org" rel="nofollow"&gt;http://robotframework.org&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-text-robot"&gt;&lt;pre&gt;&lt;span class="pl-s"&gt;*** Settings ***&lt;/span&gt;
&lt;span class="pl-c"&gt;Documentation     A test suite with a single test for valid login.&lt;/span&gt;
&lt;span class="pl-c"&gt;...&lt;/span&gt;
&lt;span class="pl-c"&gt;...               This test has a workflow that is created using keywords in&lt;/span&gt;
&lt;span class="pl-c"&gt;...               the imported resource file.&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;/span&gt;&lt;span class="pl-k"&gt;Resource&lt;/span&gt;          resource.robot

&lt;span class="pl-s"&gt;*** Test Cases ***&lt;/span&gt;
&lt;span class="pl-k"&gt;Valid Login&lt;/span&gt;
    Open Browser To Login Page
    Input Username    demo
    Input Password    mode
    Submit Credentials
    Welcome Page Should Be Open
    &lt;span class="pl-k"&gt;[Teardown]&lt;/span&gt;    Close Browser&lt;/pre&gt;&lt;/div&gt;
&lt;a name="user-content-usage"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id10"&gt;Usage&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Tests (or tasks) are executed from the command line using the &lt;code&gt;robot&lt;/code&gt;
command or by executing the &lt;code&gt;robot&lt;/code&gt; module directly like &lt;code&gt;python -m robot&lt;/code&gt;
or &lt;code&gt;jython -m robot&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The basic usage is giving a path to a test (or task) file or directory as an
argument with possible command line options before the path:&lt;/p&gt;
&lt;pre&gt;robot tests.robot
robot --variable BROWSER:Firefox --outputdir results path/to/tests/
&lt;/pre&gt;
&lt;p&gt;Additionally there is the &lt;code&gt;rebot&lt;/code&gt; tool for combining results and otherwise
post-processing outputs:&lt;/p&gt;
&lt;pre&gt;rebot --name Example output1.xml output2.xml
&lt;/pre&gt;
&lt;p&gt;Run &lt;code&gt;robot --help&lt;/code&gt; and &lt;code&gt;rebot --help&lt;/code&gt; for more information about the command
line usage. For a complete reference manual see &lt;a href="http://robotframework.org/robotframework/#user-guide" rel="nofollow"&gt;Robot Framework User Guide&lt;/a&gt;.&lt;/p&gt;
&lt;a name="user-content-documentation"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id11"&gt;Documentation&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://robotframework.org/robotframework/#user-guide" rel="nofollow"&gt;Robot Framework User Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://robotframework.org/robotframework/#standard-libraries" rel="nofollow"&gt;Standard libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://robotframework.org/robotframework/#built-in-tools" rel="nofollow"&gt;Built-in tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://robot-framework.readthedocs.org" rel="nofollow"&gt;API documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://robotframework.org/#documentation" rel="nofollow"&gt;General documentation and demos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-support-and-contact"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-support-and-contact" class="anchor" aria-hidden="true" href="#support-and-contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id12"&gt;Support and contact&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/group/robotframework-users/" rel="nofollow"&gt;robotframework-users&lt;/a&gt; mailing list&lt;/li&gt;
&lt;li&gt;&lt;a href="https://robotframework-slack-invite.herokuapp.com" rel="nofollow"&gt;Slack&lt;/a&gt; community&lt;/li&gt;
&lt;li&gt;&lt;a href="http://webchat.freenode.net/?channels=robotframework&amp;amp;prompt=1" rel="nofollow"&gt;#robotframework&lt;/a&gt;
IRC channel on freenode&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/robotframework" rel="nofollow"&gt;@robotframework&lt;/a&gt; on Twitter&lt;/li&gt;
&lt;li&gt;&lt;a href="http://robotframework.org/#support" rel="nofollow"&gt;Other forums&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a name="user-content-contributing"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id13"&gt;Contributing&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Interested to contribute to Robot Framework? Great! In that case it is a good
start by looking at the &lt;a href="CONTRIBUTING.rst"&gt;Contribution guidelines&lt;/a&gt;. If you
do not already have an issue you would like to work on, you can check
issues with &lt;a href="https://github.com/robotframework/robotframework/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;good new issue&lt;/a&gt; and &lt;a href="https://github.com/robotframework/robotframework/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22"&gt;help wanted&lt;/a&gt; labels.&lt;/p&gt;
&lt;p&gt;Remember also that there are many other tools and libraries in the wider
&lt;a href="http://robotframework.org" rel="nofollow"&gt;Robot Framework ecosystem&lt;/a&gt; that you can
contribute to!&lt;/p&gt;
&lt;a name="user-content-license"&gt;&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#id14"&gt;License&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Robot Framework is open source software provided under the &lt;a href="http://apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;Apache License
2.0&lt;/a&gt;. Robot Framework documentation and other similar content use the
&lt;a href="http://creativecommons.org/licenses/by/3.0" rel="nofollow"&gt;Creative Commons Attribution 3.0 Unported&lt;/a&gt; license. Most libraries and tools
in the ecosystem are also open source, but they may use different licenses.&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;</description><author>robotframework</author><guid isPermaLink="false">https://github.com/robotframework/robotframework</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>microsoft/nni #23 in Python, Today</title><link>https://github.com/microsoft/nni</link><description>&lt;p&gt;&lt;i&gt;An open source AutoML toolkit for neural architecture search and hyper-parameter tuning.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="docs/img/nni_logo.png"&gt;&lt;img src="docs/img/nni_logo.png" width="300" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href="LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/e7302c620b3589a361fc5503732f3505347205d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e737667" alt="MIT licensed" data-canonical-src="https://img.shields.io/badge/license-MIT-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=6" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/06e7c289fa68f09d7cc3639a89723662a7c9447c/68747470733a2f2f6d7372617372672e76697375616c73747564696f2e636f6d2f4e4e494f70656e536f757263652f5f617069732f6275696c642f7374617475732f4d6963726f736f66742e6e6e69" alt="Build Status" data-canonical-src="https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/Microsoft.nni" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/Microsoft/nni/issues?q=is%3Aissue+is%3Aopen"&gt;&lt;img src="https://camo.githubusercontent.com/4b812e57a0550f4e2ccf49f72cdaea32f041011b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d7261772f4d6963726f736f66742f6e6e692e737667" alt="Issues" data-canonical-src="https://img.shields.io/github/issues-raw/Microsoft/nni.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/Microsoft/nni/issues?q=is%3Aissue+is%3Aopen+label%3Abug"&gt;&lt;img src="https://camo.githubusercontent.com/ad1744ebae5577ce96c0b521c54b741924524658/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4d6963726f736f66742f6e6e692f6275672e737667" alt="Bugs" data-canonical-src="https://img.shields.io/github/issues/Microsoft/nni/bug.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/Microsoft/nni/pulls?q=is%3Apr+is%3Aopen"&gt;&lt;img src="https://camo.githubusercontent.com/0cd66d42420936cd16ef68893bad1047a17e7868/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722d7261772f4d6963726f736f66742f6e6e692e737667" alt="Pull Requests" data-canonical-src="https://img.shields.io/github/issues-pr-raw/Microsoft/nni.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/Microsoft/nni/releases"&gt;&lt;img src="https://camo.githubusercontent.com/904e0607b389793e314a8168cf4fd8a2cd7d5568/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4d6963726f736f66742f6e6e692e737667" alt="Version" data-canonical-src="https://img.shields.io/github/release/Microsoft/nni.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/nni?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ea343fc71d08470b889fe80c10e8f2f074d8b0fa/68747470733a2f2f6261646765732e6769747465722e696d2f4d6963726f736f66742f6e6e692e737667" alt="Join the chat at https://gitter.im/Microsoft/nni" data-canonical-src="https://badges.gitter.im/Microsoft/nni.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://nni.readthedocs.io/en/latest/?badge=latest" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7dbc0b202e174a5f1c1979d1601a3bd047fd468b/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6e6e692f62616467652f3f76657273696f6e3d6c6174657374" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/nni/badge/?version=latest" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="README_zh_CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NNI (Neural Network Intelligence) is a toolkit to help users run automated machine learning (AutoML) experiments.
The tool dispatches and runs trial jobs generated by tuning algorithms to search the best neural architecture and/or hyper-parameters in different environments like local machine, remote servers and cloud.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-nni-v11-has-been-released-" class="anchor" aria-hidden="true" href="#nni-v11-has-been-released-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;NNI v1.1 has been released! ¬†&lt;a href="#nni-released-reminder"&gt;&lt;img width="48" src="docs/img/release_icon.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p align="center"&gt;
  &lt;a href="#nni-has-been-released"&gt;&lt;img src="docs/img/overview.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr align="center" valign="bottom"&gt;
    &lt;td&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;b&gt;Frameworks &amp;amp; Libraries&lt;/b&gt;
        &lt;a target="_blank" rel="noopener noreferrer" href="docs/img/bar.png"&gt;&lt;img src="docs/img/bar.png" style="max-width:100%;"&gt;&lt;/a&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;b&gt;Tuning Algorithms&lt;/b&gt;
        &lt;a target="_blank" rel="noopener noreferrer" href="docs/img/bar.png"&gt;&lt;img src="docs/img/bar.png" style="max-width:100%;"&gt;&lt;/a&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;b&gt;Training Services&lt;/b&gt;
        &lt;a target="_blank" rel="noopener noreferrer" href="docs/img/bar.png"&gt;&lt;img src="docs/img/bar.png" style="max-width:100%;"&gt;&lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    
    &lt;tr valign="top"&gt;
    &lt;td align="center" valign="middle"&gt;
    &lt;b&gt;Built-in&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
      &lt;ul&gt;&lt;li&gt;&lt;b&gt;Supported Frameworks&lt;/b&gt;&lt;/li&gt;
        &lt;ul&gt;
          &lt;li&gt;PyTorch&lt;/li&gt;
          &lt;li&gt;Keras&lt;/li&gt;
          &lt;li&gt;TensorFlow&lt;/li&gt;
          &lt;li&gt;MXNet&lt;/li&gt;
          &lt;li&gt;Caffe2&lt;/li&gt;
          &lt;a href="docs/en_US/SupportedFramework_Library.md"&gt;More...&lt;/a&gt;&lt;br&gt;
        &lt;/ul&gt;
        &lt;/ul&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;b&gt;Supported Libraries&lt;/b&gt;&lt;/li&gt;
          &lt;ul&gt;
           &lt;li&gt;Scikit-learn&lt;/li&gt;
           &lt;li&gt;XGBoost&lt;/li&gt;
           &lt;li&gt;LightGBM&lt;/li&gt;
           &lt;a href="docs/en_US/SupportedFramework_Library.md"&gt;More...&lt;/a&gt;&lt;br&gt;
          &lt;/ul&gt;
      &lt;/ul&gt;
        &lt;ul&gt;
        &lt;li&gt;&lt;b&gt;Examples&lt;/b&gt;&lt;/li&gt;
         &lt;ul&gt;
           &lt;li&gt;&lt;a href="examples/trials/mnist-pytorch"&gt;MNIST-pytorch&lt;/a&gt;&lt;/li&gt;
           &lt;li&gt;&lt;a href="examples/trials/mnist"&gt;MNIST-tensorflow&lt;/a&gt;&lt;/li&gt;
           &lt;li&gt;&lt;a href="examples/trials/mnist-keras"&gt;MNIST-keras&lt;/a&gt;&lt;/li&gt;
           &lt;li&gt;&lt;a href="docs/en_US/TrialExample/GbdtExample.md"&gt;Auto-gbdt&lt;/a&gt;&lt;/li&gt;
           &lt;li&gt;&lt;a href="docs/en_US/TrialExample/Cifar10Examples.md"&gt;Cifar10-pytorch&lt;/a&gt;&lt;/li&gt;
           &lt;li&gt;&lt;a href="docs/en_US/TrialExample/SklearnExamples.md"&gt;Scikit-learn&lt;/a&gt;&lt;/li&gt;
              &lt;a href="docs/en_US/SupportedFramework_Library.md"&gt;More...&lt;/a&gt;&lt;br&gt;
          &lt;/ul&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
      &lt;td align="left"&gt;
        &lt;a href="docs/en_US/Tuner/BuiltinTuner.md"&gt;Tuner&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;b&gt;General Tuner&lt;/b&gt;&lt;/li&gt;
          &lt;ul&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#Random"&gt;Random Search&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#Evolution"&gt;Na√Øve Evolution&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;    
          &lt;li&gt;&lt;b&gt;Tuner for &lt;a href="docs/en_US/CommunitySharings/HpoComparision.md"&gt;HPO&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
          &lt;ul&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#TPE"&gt;TPE&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#Anneal"&gt;Anneal&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#SMAC"&gt;SMAC&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#Batch"&gt;Batch&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#GridSearch"&gt;Grid Search&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#Hyperband"&gt;Hyperband&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#MetisTuner"&gt;Metis Tuner&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#BOHB"&gt;BOHB&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#GPTuner"&gt;GP Tuner&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
          &lt;li&gt;&lt;b&gt;Tuner for &lt;a href="docs/en_US/AdvancedFeature/GeneralNasInterfaces.md"&gt;NAS&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
          &lt;ul&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md#NetworkMorphism"&gt;Network Morphism&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="examples/tuners/enas_nni/README.md"&gt;ENAS&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/ul&gt;
          &lt;a href="docs/en_US/Assessor/BuiltinAssessor.md"&gt;Assessor&lt;/a&gt;
          &lt;ul&gt;
          &lt;ul&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Assessor/BuiltinAssessor.md#Medianstop"&gt;Median Stop&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href="docs/en_US/Assessor/BuiltinAssessor.md#Curvefitting"&gt;Curve Fitting&lt;/a&gt;&lt;/li&gt;   
          &lt;/ul&gt;
          &lt;/ul&gt;  
      &lt;/td&gt;
      &lt;td&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href="docs/en_US/TrainingService/LocalMode.md"&gt;Local Machine&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href="docs/en_US/TrainingService/RemoteMachineMode.md"&gt;Remote Servers&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;Kubernetes based services&lt;/b&gt;&lt;/li&gt;
            &lt;ul&gt;&lt;li&gt;&lt;a href="docs/en_US/TrainingService/PaiMode.md"&gt;OpenPAI&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href="docs/en_US/TrainingService/KubeflowMode.md"&gt;Kubeflow&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href="docs/en_US/TrainingService/FrameworkControllerMode.md"&gt;FrameworkController on K8S (AKS etc.)&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
      &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt; 
      &lt;tr align="center" valign="bottom"&gt;
      
      &lt;/tr&gt;
      &lt;tr valign="top"&gt;
       &lt;td valign="middle"&gt;
    &lt;b&gt;References&lt;/b&gt;
      &lt;/td&gt;
     &lt;td&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href="docs/en_US/sdk_reference.rst"&gt;Python API&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href="docs/en_US/Tutorial/AnnotationSpec.md"&gt;NNI Annotation&lt;/a&gt;&lt;/li&gt;
         &lt;li&gt;&lt;a href="docs/en_US/Tutorial/Installation.md"&gt;Supported OS&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/td&gt;
       &lt;td&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href="docs/en_US/Tuner/CustomizeTuner.md"&gt;CustomizeTuner&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href="docs/en_US/Assessor/CustomizeAssessor.md"&gt;CustomizeAssessor&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/td&gt;
        &lt;td&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href="docs/en_US/TrainingService/SupportTrainingService.md"&gt;Support TrainingService&lt;/a&gt;&lt;/li&gt;&lt;a href="docs/en_US/TrainingService/SupportTrainingService.md"&gt;
        &lt;/a&gt;&lt;li&gt;&lt;a href="docs/en_US/TrainingService/SupportTrainingService.md"&gt;&lt;/a&gt;&lt;a href="docs/en_US/TrainingService/HowToImplementTrainingService.md"&gt;Implement TrainingService&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
      &lt;/td&gt;     
    &lt;/tr&gt; 
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-who-should-consider-using-nni" class="anchor" aria-hidden="true" href="#who-should-consider-using-nni"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Who should consider using NNI&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Those who want to try different AutoML algorithms in their training code (model) at their local machine.&lt;/li&gt;
&lt;li&gt;Those who want to run AutoML trial jobs in different environments to speed up search (e.g. remote servers and cloud).&lt;/li&gt;
&lt;li&gt;Researchers and data scientists who want to implement their own AutoML algorithms and compare it with other algorithms.&lt;/li&gt;
&lt;li&gt;ML Platform owners who want to support AutoML in their platform.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-related-projects" class="anchor" aria-hidden="true" href="#related-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related Projects&lt;/h2&gt;
&lt;p&gt;Targeting at openness and advancing state-of-art technology, &lt;a href="https://www.microsoft.com/en-us/research/group/systems-research-group-asia/" rel="nofollow"&gt;Microsoft Research (MSR)&lt;/a&gt; had also released few other open source projects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/pai"&gt;OpenPAI&lt;/a&gt; : an open source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud and hybrid environments in various scale.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/frameworkcontroller"&gt;FrameworkController&lt;/a&gt; : an open source general-purpose Kubernetes Pod Controller that orchestrate all kinds of applications on Kubernetes by a single controller.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/MMdnn"&gt;MMdnn&lt;/a&gt; : A comprehensive, cross-framework solution to convert, visualize and diagnose deep neural network models. The "MM" in MMdnn stands for model management and "dnn" is an acronym for deep neural network.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Microsoft/SPTAG"&gt;SPTAG&lt;/a&gt; : Space Partition Tree And Graph (SPTAG) is an open source library for large scale vector approximate nearest neighbor search scenario.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We encourage researchers and students leverage these projects to accelerate the AI development and research.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-install--verify" class="anchor" aria-hidden="true" href="#install--verify"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Install &amp;amp; Verify&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Install through pip&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We support Linux, MacOS and Windows (local, remote and pai mode) in current stage, Ubuntu 16.04 or higher, MacOS 10.14.1 along with Windows 10.1809 are tested and supported. Simply run the following &lt;code&gt;pip install&lt;/code&gt; in an environment that has &lt;code&gt;python &amp;gt;= 3.5&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Linux and MacOS&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python3 -m pip install --upgrade nni&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Windows&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;python -m pip install --upgrade nni&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--user&lt;/code&gt; can be added if you want to install NNI in your home directory, which does not require any special privileges.&lt;/li&gt;
&lt;li&gt;Currently NNI on Windows support local, remote and pai mode. Anaconda or Miniconda is highly recommended to install NNI on Windows.&lt;/li&gt;
&lt;li&gt;If there is any error like &lt;code&gt;Segmentation fault&lt;/code&gt;, please refer to &lt;a href="docs/en_US/Tutorial/FAQ.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Install through source code&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We support Linux (Ubuntu 16.04 or higher), MacOS (10.14.1) and Windows (10.1809) in our current stage.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Linux and MacOS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the following commands in an environment that has &lt;code&gt;python &amp;gt;= 3.5&lt;/code&gt;, &lt;code&gt;git&lt;/code&gt; and &lt;code&gt;wget&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;    git clone -b v1.1 https://github.com/Microsoft/nni.git
    &lt;span class="pl-c1"&gt;cd&lt;/span&gt; nni
    &lt;span class="pl-c1"&gt;source&lt;/span&gt; install.sh&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Windows&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the following commands in an environment that has &lt;code&gt;python &amp;gt;=3.5&lt;/code&gt;, &lt;code&gt;git&lt;/code&gt; and &lt;code&gt;PowerShell&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;  git clone -b v1.1 https://github.com/Microsoft/nni.git
  &lt;span class="pl-c1"&gt;cd&lt;/span&gt; nni
  powershell -ExecutionPolicy Bypass -file install.ps1&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For the system requirements of NNI, please refer to &lt;a href="docs/en_US/Tutorial/Installation.md"&gt;Install NNI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For NNI on Windows, please refer to &lt;a href="docs/en_US/Tutorial/NniOnWindows.md"&gt;NNI on Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Verify install&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The following example is an experiment built on TensorFlow. Make sure you have &lt;strong&gt;TensorFlow 1.x installed&lt;/strong&gt; before running it. Note that &lt;strong&gt;currently Tensorflow 2.0 is NOT supported&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the examples via clone the source code.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;    git clone -b v1.1 https://github.com/Microsoft/nni.git&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Linux and MacOS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the MNIST example.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;    nnictl create --config nni/examples/trials/mnist/config.yml&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Windows&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the MNIST example.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;    nnictl create --config nni&lt;span class="pl-cce"&gt;\e&lt;/span&gt;xamples&lt;span class="pl-cce"&gt;\t&lt;/span&gt;rials&lt;span class="pl-cce"&gt;\m&lt;/span&gt;nist&lt;span class="pl-cce"&gt;\c&lt;/span&gt;onfig_windows.yml&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Wait for the message &lt;code&gt;INFO: Successfully started experiment!&lt;/code&gt; in the command line. This message indicates that your experiment has been successfully started. You can explore the experiment using the &lt;code&gt;Web UI url&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre lang="text"&gt;&lt;code&gt;INFO: Starting restful server...
INFO: Successfully started Restful server!
INFO: Setting local config...
INFO: Successfully set local config!
INFO: Starting experiment...
INFO: Successfully started experiment!
-----------------------------------------------------------------------
The experiment id is egchD4qy
The Web UI urls are: http://223.255.255.1:8080   http://127.0.0.1:8080
-----------------------------------------------------------------------

You can use these commands to get more information about the experiment
-----------------------------------------------------------------------
         commands                       description
1. nnictl experiment show        show the information of experiments
2. nnictl trial ls               list all of trial jobs
3. nnictl top                    monitor the status of running experiments
4. nnictl log stderr             show stderr log content
5. nnictl log stdout             show stdout log content
6. nnictl stop                   stop an experiment
7. nnictl trial kill             kill a trial job by id
8. nnictl --help                 get help information about nnictl
-----------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Open the &lt;code&gt;Web UI url&lt;/code&gt; in your browser, you can view detail information of the experiment and all the submitted trial jobs as shown below. &lt;a href="docs/en_US/Tutorial/WebUI.md"&gt;Here&lt;/a&gt; are more Web UI pages.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/img/webui_overview_page.png"&gt;&lt;img src="./docs/img/webui_overview_page.png" alt="drawing" width="395" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
    &lt;th&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/img/webui_trialdetail_page.png"&gt;&lt;img src="./docs/img/webui_trialdetail_page.png" alt="drawing" width="410" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Our primary documentation is at &lt;a href="https://nni.readthedocs.io/en/latest/Overview.html" rel="nofollow"&gt;here&lt;/a&gt; and is generated from this repository.&lt;br&gt;
Maybe you want to read:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en_US/Overview.md"&gt;NNI overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/QuickStart.md"&gt;Quick start&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/WebUI.md"&gt;WebUI tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/Contributing.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-how-to" class="anchor" aria-hidden="true" href="#how-to"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;How to&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/Installation.md"&gt;Install NNI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/Nnictl.md"&gt;Use command line tool nnictl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrialExample/Trials.md"&gt;Define a trial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/ExperimentConfig.md"&gt;Config an experiment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/SearchSpaceSpec.md"&gt;Define search space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md"&gt;choose tuner/search-algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrialExample/Trials.md#nni-python-annotation"&gt;Use annotation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/WebUI.md"&gt;Use NNIBoard&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-tutorials" class="anchor" aria-hidden="true" href="#tutorials"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Tutorials&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrainingService/LocalMode.md"&gt;Run an experiment on local (with multiple GPUs)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrainingService/PaiMode.md"&gt;Run an experiment on OpenPAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrainingService/KubeflowMode.md"&gt;Run an experiment on Kubeflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrainingService/RemoteMachineMode.md"&gt;Run an experiment on multiple machines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tuner/BuiltinTuner.md"&gt;Try different tuners&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Assessor/BuiltinAssessor.md"&gt;Try different assessors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tuner/CustomizeTuner.md"&gt;Implement a customized tuner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Assessor/CustomizeAssessor.md"&gt;Implement a customized assessor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrainingService/HowToImplementTrainingService.md"&gt;Implement TrainingService in NNI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrialExample/SquadEvolutionExamples.md"&gt;Use Genetic Algorithm to find good model architectures for Reading Comprehension task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/AdvancedFeature/AdvancedNas.md"&gt;Advanced Neural Architecture Search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contribute" class="anchor" aria-hidden="true" href="#contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Contribute&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;This project welcomes contributions and there are many ways in which you can participate in the project, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open &lt;a href="https://github.com/microsoft/nni/issues/new/choose"&gt;bug reports&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Request a &lt;a href="https://github.com/microsoft/nni/issues/new/choose"&gt;new feature&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Suggest or ask some questions on the &lt;a href="docs/en_US/Tutorial/HowToDebug.md"&gt;How to Debug&lt;/a&gt; guidance document.&lt;/li&gt;
&lt;li&gt;Find the issues tagged with &lt;a href="https://github.com/Microsoft/nni/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;'good first issue'&lt;/a&gt; or &lt;a href="https://github.com/microsoft/nni/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;'help-wanted'&lt;/a&gt;, these are simple and easy to start , we recommend new contributors to start with.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before providing your hacks, you can review the &lt;a href="docs/en_US/Tutorial/Contributing.md"&gt;Contributing Instruction&lt;/a&gt; to get more information. In addition, we also provide you with the following documents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/SetupNniDeveloperEnvironment.md"&gt;NNI developer environment installation tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tutorial/HowToDebug.md"&gt;How to debug&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tuner/CustomizeAdvisor.md"&gt;Customize Your Own Advisor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/Tuner/CustomizeTuner.md"&gt;Customize Your Own Tuner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/TrainingService/HowToImplementTrainingService.md"&gt;Implement customized TrainingService&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-external-repositories-and-references" class="anchor" aria-hidden="true" href="#external-repositories-and-references"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;External Repositories and References&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;With authors' permission, we listed a set of NNI usage examples and relevant articles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h3&gt;&lt;a id="user-content-external-repositories" class="anchor" aria-hidden="true" href="#external-repositories"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;External Repositories&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Run &lt;a href="examples/tuners/enas_nni/README.md"&gt;ENAS&lt;/a&gt; with NNI&lt;/li&gt;
&lt;li&gt;Run &lt;a href="examples/trials/nas_cifar10/README.md"&gt;Neural Network Architecture Search&lt;/a&gt; with NNI&lt;/li&gt;
&lt;li&gt;&lt;a href="examples/trials/auto-feature-engineering/README.md"&gt;Automatic Feature Engineering&lt;/a&gt; with NNI&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/microsoft/recommenders/blob/master/notebooks/04_model_select_and_optimize/nni_surprise_svd.ipynb"&gt;Hyperparameter Tuning for Matrix Factorization&lt;/a&gt; with NNI&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3&gt;&lt;a id="user-content-relevant-articles" class="anchor" aria-hidden="true" href="#relevant-articles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Relevant Articles&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/en_US/CommunitySharings/HpoComparision.md"&gt;Hyper Parameter Optimization Comparison&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/CommunitySharings/NasComparision.md"&gt;Neural Architecture Search Comparison&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/CommunitySharings/ParallelizingTpeSearch.md"&gt;Parallelizing a Sequential Algorithm TPE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/CommunitySharings/RecommendersSvd.md"&gt;Automatically tuning SVD with NNI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/en_US/CommunitySharings/SptagAutoTune.md"&gt;Automatically tuning SPTAG with NNI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Blog (in Chinese)&lt;/strong&gt; - &lt;a href="http://gaocegege.com/Blog/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/katib-new#%E6%80%BB%E7%BB%93%E4%B8%8E%E5%88%86%E6%9E%90" rel="nofollow"&gt;AutoML tools (Advisor, NNI and Google Vizier) comparison&lt;/a&gt; by &lt;a href="https://github.com/gaocegege"&gt;@gaocegege&lt;/a&gt; - ÊÄªÁªì‰∏éÂàÜÊûê section of design and implementation of kubeflow/katib&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-feedback" class="anchor" aria-hidden="true" href="#feedback"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;Feedback&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Discuss on the NNI &lt;a href="https://gitter.im/Microsoft/nni?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;Gitter&lt;/a&gt; in NNI.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/microsoft/nni/issues/new/choose"&gt;File an issue&lt;/a&gt; on GitHub.&lt;/li&gt;
&lt;li&gt;Ask a question with NNI tags on &lt;a href="https://stackoverflow.com/questions/tagged/nni?sort=Newest&amp;amp;edited=true" rel="nofollow"&gt;Stack Overflow&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;strong&gt;License&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The entire codebase is under &lt;a href="LICENSE"&gt;MIT license&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>microsoft</author><guid isPermaLink="false">https://github.com/microsoft/nni</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>TuSimple/simpledet #24 in Python, Today</title><link>https://github.com/TuSimple/simpledet</link><description>&lt;p&gt;&lt;i&gt;A Simple and Versatile Framework for Object Detection and Instance Recognition&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-simpledet---a-simple-and-versatile-framework-for-object-detection-and-instance-recognition" class="anchor" aria-hidden="true" href="#simpledet---a-simple-and-versatile-framework-for-object-detection-and-instance-recognition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SimpleDet - A Simple and Versatile Framework for Object Detection and Instance Recognition&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-major-features" class="anchor" aria-hidden="true" href="#major-features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Major Features&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./doc/image/diagram_v2.png"&gt;&lt;img src="./doc/image/diagram_v2.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FP16 training for memory saving and up to &lt;strong&gt;2.5X&lt;/strong&gt; acceleration&lt;/li&gt;
&lt;li&gt;Highly scalable distributed training available &lt;strong&gt;out of box&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Full coverage of state-of-the-art models including FasterRCNN, MaskRCNN, CascadeRCNN, RetinaNet, &lt;a href="./models/dcn"&gt;DCNv1/v2&lt;/a&gt;, &lt;strong&gt;&lt;a href="./models/tridentnet"&gt;TridentNet&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="./models/NASFPN"&gt;NASFPN&lt;/a&gt;&lt;/strong&gt; , &lt;strong&gt;&lt;a href="./models/efficientnet"&gt;EfficientNet&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a href="./models/KD"&gt;Kownledge Distillation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Extensive feature set including &lt;strong&gt;large batch BN&lt;/strong&gt;, &lt;strong&gt;loss synchronization&lt;/strong&gt;, &lt;strong&gt;automatic BN fusion&lt;/strong&gt;, soft NMS, multi-scale train/test&lt;/li&gt;
&lt;li&gt;Modular design for coding-free exploration of new experiment settings&lt;/li&gt;
&lt;li&gt;Extensive documentations including &lt;a href="./doc/fully_annotated_config.py"&gt;annotated config&lt;/a&gt;, &lt;a href="./doc/FINETUNE.md"&gt;Fintuning Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-recent-updates" class="anchor" aria-hidden="true" href="#recent-updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Recent Updates&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Add RPN test (2019.05.28)&lt;/li&gt;
&lt;li&gt;Add &lt;a href="https://github.com/TuSimple/simpledet/tree/master/models/NASFPN"&gt;NASFPN&lt;/a&gt; (2019.06.04)&lt;/li&gt;
&lt;li&gt;Add new ResNetV1b baselines from GluonCV (2019.06.07)&lt;/li&gt;
&lt;li&gt;Add Cascade R-CNN with FPN backbone (2019.06.11)&lt;/li&gt;
&lt;li&gt;Speed up FPN up to 70% (2019.06.16)&lt;/li&gt;
&lt;li&gt;Update &lt;a href="https://github.com/TuSimple/simpledet/tree/master/models/NASFPN"&gt;NASFPN&lt;/a&gt; to include larger models (2019.07.01)&lt;/li&gt;
&lt;li&gt;Automatic BN fusion for fixed BN training, saving up to 50% GPU memory (2019.07.04)&lt;/li&gt;
&lt;li&gt;Speed up MaskRCNN by 80% (2019.07.23)&lt;/li&gt;
&lt;li&gt;Update MaskRCNN baselines (2019.07.25)&lt;/li&gt;
&lt;li&gt;Add EfficientNet and DCN (2019.08.06)&lt;/li&gt;
&lt;li&gt;Add python wheel for easy local installation (2019.08.20)&lt;/li&gt;
&lt;li&gt;Add FitNet based Knowledge Distill (2019.08.27)&lt;/li&gt;
&lt;li&gt;Add SE and train from scratch (2019.08.30)&lt;/li&gt;
&lt;li&gt;Add a lot of docs (2019.09.03)&lt;/li&gt;
&lt;li&gt;Add support for INT8 training (2019.10.24)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-all-in-one-script" class="anchor" aria-hidden="true" href="#all-in-one-script"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;All-in-one Script&lt;/h4&gt;
&lt;p&gt;We provide a &lt;a href="./scripts/setup.sh"&gt;setup script&lt;/a&gt; for install simpledet and preppare the coco dataset. If you use this script, you can skip to the Quick Start.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h4&gt;
&lt;p&gt;We provide a local installation here for Debian/Ubuntu system. To use a pre-built docker or singularity images, please refer to &lt;a href="./doc/INSTALL.md"&gt;INSTALL.md&lt;/a&gt; for more information.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install dependency&lt;/span&gt;
sudo apt update &lt;span class="pl-k"&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo apt install -y git wget make python3-dev libglib2.0-0 libsm6 libxext6 libxrender-dev unzip

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install python dependency&lt;/span&gt;
pip3 install &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;matplotlib&amp;lt;3.1&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; opencv-python pytz --user

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; download and intall pre-built wheel for CUDA 10.0&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; check INSTALL.md for wheels for other CUDA version&lt;/span&gt;
wget https://bit.ly/2jRGqdc -O mxnet_cu100-1.6.0b20190820-py2.py3-none-manylinux1_x86_64.whl
pip3 install mxnet_cu100-1.6.0b20190820-py2.py3-none-manylinux1_x86_64.whl --user

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install pycocotools&lt;/span&gt;
pip3 install &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git+https://github.com/RogerChern/cocoapi.git#subdirectory=PythonAPI&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; --user

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; install mxnext, a wrapper around MXNet symbolic API&lt;/span&gt;
pip3 install &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;git+https://github.com/RogerChern/mxnext#egg=mxnext&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; --user

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; get simpledet&lt;/span&gt;
git clone https://github.com/tusimple/simpledet
&lt;span class="pl-c1"&gt;cd&lt;/span&gt; simpledet
make

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; test simpledet installation&lt;/span&gt;
mkdir -p experiments/faster_r50v1_fpn_1x
python3 detection_infer_speed.py --config config/faster_r50v1_fpn_1x.py --shape 800 1333&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If the last line execute successfully, the average running speed of Faster R-CNN R-50 FPN will be reported. And you have successfuly setup SimpleDet. Now you can head up to the next section to prepare your dataset.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-preparing-data" class="anchor" aria-hidden="true" href="#preparing-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preparing Data&lt;/h4&gt;
&lt;p&gt;We provide a step by step preparation for the COCO dataset below.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;cd&lt;/span&gt; simpledet

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; make data dir&lt;/span&gt;
mkdir -p data/coco/images data/src

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; skip this if you have the zip files&lt;/span&gt;
wget -c http://images.cocodataset.org/zips/train2017.zip -O data/src/train2017.zip
wget -c http://images.cocodataset.org/zips/val2017.zip -O data/src/val2017.zip
wget -c http://images.cocodataset.org/zips/test2017.zip -O data/src/test2017.zip
wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O data/src/annotations_trainval2017.zip
wget -c http://images.cocodataset.org/annotations/image_info_test2017.zip -O data/src/image_info_test2017.zip

unzip data/src/train2017.zip -d data/coco/images
unzip data/src/val2017.zip -d data/coco/images
unzip data/src/test2017.zip -d data/coco/images
unzip data/src/annotations_trainval2017.zip -d data/coco
unzip data/src/image_info_test2017.zip -d data/coco

python3 utils/create_coco_roidb.py --dataset coco --dataset-split train2017
python3 utils/create_coco_roidb.py --dataset coco --dataset-split val2017
python3 utils/create_coco_roidb.py --dataset coco --dataset-split test-dev2017&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For other datasets or your own data, please check &lt;a href="doc/DATASET.md"&gt;DATASET.md&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h4&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; train&lt;/span&gt;
python3 detection_train.py --config config/faster_r50v1_fpn_1x.py

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; test&lt;/span&gt;
python3 detection_test.py --config config/faster_r50v1_fpn_1x.py&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-finetune" class="anchor" aria-hidden="true" href="#finetune"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Finetune&lt;/h4&gt;
&lt;p&gt;Please check &lt;a href="doc/FINETUNE.md"&gt;FINTUNE.md&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-model-zoo" class="anchor" aria-hidden="true" href="#model-zoo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Model Zoo&lt;/h4&gt;
&lt;p&gt;Please refer to &lt;a href="./MODEL_ZOO.md"&gt;MODEL_ZOO.md&lt;/a&gt; for available models&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-distributed-training" class="anchor" aria-hidden="true" href="#distributed-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Distributed Training&lt;/h3&gt;
&lt;p&gt;Please refer to &lt;a href="./doc/DISTRIBUTED.md"&gt;DISTRIBUTED.md&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-project-organization" class="anchor" aria-hidden="true" href="#project-organization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Project Organization&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-code-structure" class="anchor" aria-hidden="true" href="#code-structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code Structure&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;detection_train.py
detection_test.py
config/
    detection_config.py
core/
    detection_input.py
    detection_metric.py
    detection_module.py
models/
    FPN/
    tridentnet/
    maskrcnn/
    cascade_rcnn/
    retinanet/
mxnext/
symbol/
    builder.py
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-config" class="anchor" aria-hidden="true" href="#config"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Config&lt;/h4&gt;
&lt;p&gt;Everything is configurable from the config file, all the changes should be &lt;strong&gt;out of source&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-experiments" class="anchor" aria-hidden="true" href="#experiments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Experiments&lt;/h4&gt;
&lt;p&gt;One experiment is a directory in &lt;strong&gt;experiments&lt;/strong&gt; folder with the same name as the config file.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;E.g. r50_fixbn_1x.py is the name of a config file&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;config/
    r50_fixbn_1x.py
experiments/
    r50_fixbn_1x/
        checkpoint.params
        log.txt
        coco_minival2014_result.json
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Models&lt;/h4&gt;
&lt;p&gt;The &lt;code&gt;models&lt;/code&gt; directory contains SOTA models implemented in SimpletDet.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-how-is-faster-r-cnn-built" class="anchor" aria-hidden="true" href="#how-is-faster-r-cnn-built"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How is Faster R-CNN built&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc/image/detector.png"&gt;&lt;img src="doc/image/detector.png" alt="Faster R-CNN" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Simpledet&lt;/strong&gt; supports many popular detection methods and here we take &lt;a href="https://arxiv.org/abs/1506.01497" rel="nofollow"&gt;&lt;strong&gt;Faster R-CNN&lt;/strong&gt;&lt;/a&gt; as a typical example to show how a detector is built.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Preprocessing&lt;/em&gt;. The preprocessing methods of the detector is implemented through &lt;code&gt;DetectionAugmentation&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;Image/bbox-related preprocessing, such as &lt;code&gt;Norm2DImage&lt;/code&gt; and &lt;code&gt;Resize2DImageBbox&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Anchor generator &lt;code&gt;AnchorTarget2D&lt;/code&gt;, which generates anchors and corresponding anchor targets for training RPN.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Network Structure&lt;/em&gt;. The training and testing symbols of Faster-RCNN detector is defined in &lt;code&gt;FasterRcnn&lt;/code&gt;. The key components are listed as follow:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Backbone&lt;/em&gt;. &lt;code&gt;Backbone&lt;/code&gt; provides interfaces to build backbone networks, &lt;em&gt;e.g.&lt;/em&gt; ResNet and ResNext.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Neck&lt;/em&gt;. &lt;code&gt;Neck&lt;/code&gt; provides interfaces to build complementary feature extraction layers for backbone networks, &lt;em&gt;e.g.&lt;/em&gt; &lt;code&gt;FPNNeck&lt;/code&gt; builds Top-down pathway for &lt;a href="https://arxiv.org/abs/1612.03144" rel="nofollow"&gt;Feature Pyramid Network&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;RPN head&lt;/em&gt;. &lt;code&gt;RpnHead&lt;/code&gt; aims to build classification and regression layers to generate proposal outputs for RPN. Meanwhile, it also provides interplace to generate sampled proposals for the subsequent R-CNN.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Roi Extractor&lt;/em&gt;. &lt;code&gt;RoiExtractor&lt;/code&gt; extracts features for each roi (proposal) based on the R-CNN features generated by &lt;code&gt;Backbone&lt;/code&gt; and &lt;code&gt;Neck&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Bounding Box Head&lt;/em&gt;. &lt;code&gt;BboxHead&lt;/code&gt; builds the R-CNN layers for proposal refinement.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-how-to-build-a-custom-detector" class="anchor" aria-hidden="true" href="#how-to-build-a-custom-detector"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to build a custom detector&lt;/h4&gt;
&lt;p&gt;The flexibility of &lt;strong&gt;simpledet&lt;/strong&gt; framework makes it easy to build different detectors. We take &lt;a href="https://arxiv.org/abs/1901.01892" rel="nofollow"&gt;&lt;strong&gt;TridentNet&lt;/strong&gt;&lt;/a&gt; as an example to demonstrate how to build a custom detector simply based on the Faster R-CNN framework.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Preprocessing&lt;/em&gt;. The additional processing methods could be provided accordingly by inheriting from &lt;code&gt;DetectionAugmentation&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;In TridentNet, a new &lt;code&gt;TridentAnchorTarget2D&lt;/code&gt; is implemented to generate anchors for multiple branches and filter anchors for scale-aware training scheme.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Network Structure&lt;/em&gt;. The new network structure could be constructed easily for a custom detector by modifying some required components as needed and
&lt;ul&gt;
&lt;li&gt;For TridentNet, we build trident blocks in the &lt;code&gt;Backbone&lt;/code&gt; according to the descriptions in the paper. We also provide a &lt;code&gt;TridentRpnHead&lt;/code&gt; to generate filtered proposals in RPN to implement the scale-aware scheme. Other components are shared the same with original Faster-RCNN.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h3&gt;
&lt;p&gt;Yuntao Chen, Chenxia Han, Yanghao Li, Zehao Huang, Yi Jiang, Naiyan Wang&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license-and-citation" class="anchor" aria-hidden="true" href="#license-and-citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License and Citation&lt;/h3&gt;
&lt;p&gt;This project is release under the Apache 2.0 license for non-commercial usage. For commercial usage, please contact us for another license.&lt;/p&gt;
&lt;p&gt;If you find our project helpful, please consider cite our tech report.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{chen2019simpledet,
  title={SimpleDet: A Simple and Versatile Distributed Framework for Object Detection and Instance Recognition},
  author={Chen, Yuntao and and Han, Chenxia and Li, Yanghao and Huang, Zehao and Jiang, Yi and Wang, Naiyan and Zhang, Zhaoxiang},
  journal={Journal of Machine Learning Research(156):1‚àí8, 2019},
  year={2019}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>TuSimple</author><guid isPermaLink="false">https://github.com/TuSimple/simpledet</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item><item><title>WenDesi/lihang_book_algorithm #25 in Python, Today</title><link>https://github.com/WenDesi/lihang_book_algorithm</link><description>&lt;p&gt;&lt;i&gt;Ëá¥Âäõ‰∫éÂ∞ÜÊùéËà™ÂçöÂ£´„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„Äã‰∏Ä‰π¶‰∏≠ÊâÄÊúâÁÆóÊ≥ïÂÆûÁé∞‰∏ÄÈÅç&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;h1&gt;&lt;a id="user-content-lihang_book_algorithm" class="anchor" aria-hidden="true" href="#lihang_book_algorithm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;lihang_book_algorithm&lt;/h1&gt;
&lt;p&gt;Ë¢´ÊùéËà™ËÄÅÂ∏àËÇØÂÆöÂï¶ÔºÅÔºÅÂºÄÂøÉÔºÅ
&lt;br&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/WenDesi/lihang_book_algorithm/master/weibo.png"&gt;&lt;img src="https://raw.githubusercontent.com/WenDesi/lihang_book_algorithm/master/weibo.png" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-ÁÆÄ‰ªã" class="anchor" aria-hidden="true" href="#ÁÆÄ‰ªã"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ÁÆÄ‰ªã&lt;/h2&gt;
&lt;p&gt;ÊàëËøôÈáå‰∏ç‰ªãÁªç‰ªª‰ΩïÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑÂéüÁêÜÔºåÂè™ÊòØÂ∞Ü„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„Äã‰∏≠ÊØè‰∏ÄÁ´†ÁöÑÁÆóÊ≥ïÁî®ÊàëËá™Â∑±ÁöÑÊñπÂºèÂÆûÁé∞‰∏ÄÈÅç„ÄÇ
Èô§‰∫ÜÊùéËà™‰π¶‰∏äÁöÑÁÆóÊ≥ïÂ§ñÔºåËøòÂÆûÁé∞‰∫Ü‰∏Ä‰∫õÂÖ∂‰ªñÊú∫Âô®Â≠¶‰π†ÁöÑÁÆóÊ≥ï„ÄÇ&lt;/p&gt;
&lt;p&gt;ÈÇ£‰πàÊàë‰ª¨Â∞±ÊåâÁ´†ËäÇÊù•‰∫Ü&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-Á´†ËäÇ" class="anchor" aria-hidden="true" href="#Á´†ËäÇ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á´†ËäÇ&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨‰∫åÁ´†-ÊÑüÁü•Âô®Ê®°Âûã" class="anchor" aria-hidden="true" href="#Á¨¨‰∫åÁ´†-ÊÑüÁü•Âô®Ê®°Âûã"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨‰∫åÁ´† ÊÑüÁü•Âô®Ê®°Âûã&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/51923546" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨‰∫åÁ´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞ÊÑüÁü•Âô®Ê®°ÂûãÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/perceptron/binary_perceptron.py"&gt;perceptron/binary_perceptron.py&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨‰∏âÁ´†-kËøëÈÇªÊ≥ï" class="anchor" aria-hidden="true" href="#Á¨¨‰∏âÁ´†-kËøëÈÇªÊ≥ï"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨‰∏âÁ´† KËøëÈÇªÊ≥ï&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/51933044" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨‰∏âÁ´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞KNNÁÆóÊ≥ïÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/knn/knn.py"&gt;knn/knn.py&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨ÂõõÁ´†-Êú¥Á¥†Ë¥ùÂè∂ÊñØ" class="anchor" aria-hidden="true" href="#Á¨¨ÂõõÁ´†-Êú¥Á¥†Ë¥ùÂè∂ÊñØ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨ÂõõÁ´† Êú¥Á¥†Ë¥ùÂè∂ÊñØ&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/51967839" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨ÂõõÁ´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®ÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/naive_bayes/naive_bayes.py"&gt;naive_bayes/naive_bayes.py&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨‰∫îÁ´†-ÂÜ≥Á≠ñÊ†ë" class="anchor" aria-hidden="true" href="#Á¨¨‰∫îÁ´†-ÂÜ≥Á≠ñÊ†ë"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨‰∫îÁ´† ÂÜ≥Á≠ñÊ†ë&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/52849400" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨‰∫îÁ´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞ÂÜ≥Á≠ñÊ†ëÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/decision_tree/decision_tree.py"&gt;decision_tree/decision_tree.py&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨ÂÖ≠Á´†-ÈÄªËæëÊñØÊèêÂõûÂΩí" class="anchor" aria-hidden="true" href="#Á¨¨ÂÖ≠Á´†-ÈÄªËæëÊñØÊèêÂõûÂΩí"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨ÂÖ≠Á´† ÈÄªËæëÊñØÊèêÂõûÂΩí&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/53084871" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨ÂÖ≠Á´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞ÈÄªËæëÊñØË∞õÂõûÂΩíÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/logistic_regression/logistic_regression.py"&gt;logistic_regression/logistic_regression.py&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨ÂÖ≠Á´†-ÊúÄÂ§ßÁÜµÊ®°Âûã" class="anchor" aria-hidden="true" href="#Á¨¨ÂÖ≠Á´†-ÊúÄÂ§ßÁÜµÊ®°Âûã"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨ÂÖ≠Á´† ÊúÄÂ§ßÁÜµÊ®°Âûã&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/53106579" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨ÂÖ≠Á´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞ÊúÄÂ§ßÁÜµÊ®°ÂûãÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/maxENT/maxENT.py"&gt;maxENT/maxENT.py&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨‰∏ÉÁ´†-ÊîØÊåÅÂêëÈáèÊú∫" class="anchor" aria-hidden="true" href="#Á¨¨‰∏ÉÁ´†-ÊîØÊåÅÂêëÈáèÊú∫"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨‰∏ÉÁ´† ÊîØÊåÅÂêëÈáèÊú∫&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/53156589" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨‰∏ÉÁ´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞ÊîØÊåÅÂêëÈáèÊú∫Ê®°ÂûãÔºà‰º™ÈÄ†Êï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/svm/svm.py"&gt;svm/svm.py&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨ÂÖ´Á´†-ÊèêÂçáÊñπÊ≥ï" class="anchor" aria-hidden="true" href="#Á¨¨ÂÖ´Á´†-ÊèêÂçáÊñπÊ≥ï"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨ÂÖ´Á´† ÊèêÂçáÊñπÊ≥ï&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/53195725" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨ÂÖ´Á´†‚Äî‚ÄîÁî®Python+CppÂÆûÁé∞AdaBoostÁÆóÊ≥ïÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;Á∫ØPython‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/AdaBoost/adaboost.py"&gt;AdaBoost/adaboost.py&lt;/a&gt;
&lt;br&gt;Python C++‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/AdaBoost/adaboost_cpp.py"&gt;AdaBoost/adaboost_cpp.py&lt;/a&gt;,&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/AdaBoost/Sign/Sign/sign.h"&gt;AdaBoost/Sign/Sign/sign.h&lt;/a&gt;,&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/AdaBoost/Sign/Sign/sign.cpp"&gt;AdaBoost/Sign/Sign/sign.cpp&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-Á¨¨ÂçÅÁ´†-ÈöêÈ©¨Â∞îÁßëÂ§´Ê®°Âûã" class="anchor" aria-hidden="true" href="#Á¨¨ÂçÅÁ´†-ÈöêÈ©¨Â∞îÁßëÂ§´Ê®°Âûã"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Á¨¨ÂçÅÁ´† ÈöêÈ©¨Â∞îÁßëÂ§´Ê®°Âûã&lt;/h3&gt;
&lt;p&gt;ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/75212599" rel="nofollow"&gt;ÊùéËà™„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„ÄãÁ¨¨ÂçÅÁ´†‚Äî‚ÄîÁî®PythonÂÆûÁé∞ÈöêÈ©¨Â∞îÁßëÂ§´Ê®°Âûã&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/hmm/hmm.py"&gt;hmm/hmm.py&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-È¢ùÂ§ñÁ´†ËäÇ" class="anchor" aria-hidden="true" href="#È¢ùÂ§ñÁ´†ËäÇ"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;È¢ùÂ§ñÁ´†ËäÇ&lt;/h2&gt;
&lt;p&gt;###softmaxÂàÜÁ±ªÂô®
ÂçöÂÆ¢Ôºö&lt;a href="http://blog.csdn.net/wds2006sdo/article/details/53699778" rel="nofollow"&gt;python ÂÆûÁé∞ softmaxÂàÜÁ±ªÂô®ÔºàMNISTÊï∞ÊçÆÈõÜÔºâ&lt;/a&gt;
&lt;br&gt;‰ª£Á†ÅÔºö&lt;a href="https://github.com/WenDesi/lihang_book_algorithm/blob/master/softmax/softmax.py"&gt;softmax/softmax.py&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>WenDesi</author><guid isPermaLink="false">https://github.com/WenDesi/lihang_book_algorithm</guid><pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate></item></channel></rss>