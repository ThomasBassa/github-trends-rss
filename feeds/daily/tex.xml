<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: TeX, Today</title><link>https://github.com/trending/tex?since=daily</link><description>The top repositories on GitHub for tex, measured daily</description><pubDate>Mon, 28 Oct 2019 03:42:22 GMT</pubDate><lastBuildDate>Mon, 28 Oct 2019 03:42:22 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>1400</ttl><item><title>exacity/deeplearningbook-chinese #1 in TeX, Today</title><link>https://github.com/exacity/deeplearningbook-chinese</link><description>&lt;p&gt;&lt;i&gt;Deep Learning Book Chinese Translation&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deep-learning-中文翻译" class="anchor" aria-hidden="true" href="#deep-learning-中文翻译"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning 中文翻译&lt;/h1&gt;
&lt;p&gt;在众多网友的帮助和校对下，中文版终于出版了。尽管还有很多问题，但至少90%的内容是可读的，并且是准确的。
我们尽可能地保留了原书&lt;a href="http://www.deeplearningbook.org/" rel="nofollow"&gt;Deep Learning&lt;/a&gt;中的意思并保留原书的语句。&lt;/p&gt;
&lt;p&gt;然而我们水平有限，我们无法消除众多读者的方差。我们仍需要大家的建议和帮助，一起减小翻译的偏差。&lt;/p&gt;
&lt;p&gt;大家所要做的就是阅读，然后汇总你的建议，提issue（最好不要一个一个地提）。如果你确定你的建议不需要商量，可以直接发起PR。&lt;/p&gt;
&lt;p&gt;对应的翻译者：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第1、4、7、10、14、20章及第12.4、12.5节由 @swordyork 负责&lt;/li&gt;
&lt;li&gt;第2、5、8、11、15、18章由 @liber145 负责&lt;/li&gt;
&lt;li&gt;第3、6、9章由 @KevinLee1110 负责&lt;/li&gt;
&lt;li&gt;第13、16、17、19章及第12.1至12.3节由 @futianfan 负责&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-面向的读者" class="anchor" aria-hidden="true" href="#面向的读者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;面向的读者&lt;/h2&gt;
&lt;p&gt;请直接下载&lt;a href="https://github.com/exacity/deeplearningbook-chinese/releases/download/v0.5-beta/dlbook_cn_v0.5-beta.pdf"&gt;PDF&lt;/a&gt;阅读。
不打算提供EPUB等格式，如有需要请自行修改。&lt;/p&gt;
&lt;p&gt;这一版准确性已经有所提高，读者可以以中文版为主、英文版为辅来阅读学习，但我们仍建议研究者阅读&lt;a href="http://www.deeplearningbook.org/" rel="nofollow"&gt;原版&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-出版及开源原因" class="anchor" aria-hidden="true" href="#出版及开源原因"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;出版及开源原因&lt;/h2&gt;
&lt;p&gt;本书由人民邮电出版社出版，如果你觉得中文版PDF对你有所帮助，希望你能支持下纸质正版书籍。
如果你觉得中文版不行，希望你能多提建议。非常感谢各位！
纸质版也会进一步更新，需要大家更多的建议和意见，一起完善中文版。&lt;/p&gt;
&lt;p&gt;纸质版目前在人民邮电出版社的异步社区出售，见&lt;a href="http://www.epubit.com.cn/book/details/4278" rel="nofollow"&gt;地址&lt;/a&gt;。
价格不低，但看了样本之后，我们认为物有所值。
注意，我们不会通过媒体进行宣传，希望大家先看电子版内容，再判断是否购买纸质版。&lt;/p&gt;
&lt;p&gt;以下是开源的具体原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们不是文学工作者，不专职翻译。单靠我们，无法给出今天的翻译，众多网友都给我们提出了宝贵的建议，因此开源帮了很大的忙。出版社会给我们稿费（我们也不知道多少，可能2万左右），我们也不好意思自己用，商量之后觉得捐出是最合适的，以所有贡献过的网友的名义（我们把稿费捐给了杉树公益，用于4名贵州高中生三年的生活费，见&lt;a href="https://github.com/exacity/deeplearningbook-chinese/blob/master/donation.pdf"&gt;捐赠情况&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;PDF电子版对于技术类书籍来说是很重要的，随时需要查询，拿着纸质版到处走显然不合适。国外很多技术书籍都有对应的电子版（虽然不一定是正版），而国内的几乎没有。个人认为这是出版社或者作者认为国民素质还没有高到主动为知识付费的境界，所以不愿意"泄露"电子版。时代在进步，我们也需要改变。特别是翻译作品普遍质量不高的情况下，要敢为天下先。&lt;/li&gt;
&lt;li&gt;深度学习发展太快，日新月异，所以我们希望大家更早地学到相关的知识。我觉得原作者开放PDF电子版也有类似的考虑，也就是先阅读后付费。我们认为中国人口素质已经足够高，懂得为知识付费。当然这不是付给我们的，是付给出版社的，出版社再付给原作者。我们不希望中文版的销量因PDF电子版的存在而下滑。出版社只有值回了版权才能在以后引进更多的优秀书籍。我们这个开源翻译先例也不会成为一个反面案例，以后才会有更多的PDF电子版。&lt;/li&gt;
&lt;li&gt;开源也涉及版权问题，出于版权原因，我们不再更新此初版PDF文件，请大家以最终的纸质版为准。（但源码会一直更新）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-致谢" class="anchor" aria-hidden="true" href="#致谢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;致谢&lt;/h2&gt;
&lt;p&gt;我们有3个类别的校对人员。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负责人也就是对应的翻译者。&lt;/li&gt;
&lt;li&gt;简单阅读，对语句不通顺或难以理解的地方提出修改意见。&lt;/li&gt;
&lt;li&gt;中英对比，进行中英对应阅读，排除少翻错翻的情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有校对建议都保存在各章的&lt;code&gt;annotations.txt&lt;/code&gt;文件中。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;章节&lt;/th&gt;
&lt;th&gt;负责人&lt;/th&gt;
&lt;th&gt;简单阅读&lt;/th&gt;
&lt;th&gt;中英对比&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter1_introduction/" rel="nofollow"&gt;第一章 前言&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@swordyork&lt;/td&gt;
&lt;td&gt;lc, @SiriusXDJ, @corenel, @NeutronT&lt;/td&gt;
&lt;td&gt;@linzhp&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter2_linear_algebra/" rel="nofollow"&gt;第二章 线性代数&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@liber145&lt;/td&gt;
&lt;td&gt;@SiriusXDJ, @angrymidiao&lt;/td&gt;
&lt;td&gt;@badpoem&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter3_probability_and_information_theory/" rel="nofollow"&gt;第三章 概率与信息论&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@KevinLee1110&lt;/td&gt;
&lt;td&gt;@SiriusXDJ&lt;/td&gt;
&lt;td&gt;@kkpoker, @Peiyan&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter4_numerical_computation/" rel="nofollow"&gt;第四章 数值计算&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@swordyork&lt;/td&gt;
&lt;td&gt;@zhangyafeikimi&lt;/td&gt;
&lt;td&gt;@hengqujushi&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter5_machine_learning_basics/" rel="nofollow"&gt;第五章 机器学习基础&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@liber145&lt;/td&gt;
&lt;td&gt;@wheaio, @huangpingchun&lt;/td&gt;
&lt;td&gt;@fairmiracle, @linzhp&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter6_deep_feedforward_networks/" rel="nofollow"&gt;第六章 深度前馈网络&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@KevinLee1110&lt;/td&gt;
&lt;td&gt;David_Chow, @linzhp, @sailordiary&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter7_regularization/" rel="nofollow"&gt;第七章 深度学习中的正则化&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@swordyork&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;@NBZCC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter8_optimization_for_training_deep_models/" rel="nofollow"&gt;第八章 深度模型中的优化&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@liber145&lt;/td&gt;
&lt;td&gt;@happynoom, @codeVerySlow&lt;/td&gt;
&lt;td&gt;@huangpingchun&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter9_convolutional_networks/" rel="nofollow"&gt;第九章 卷积网络&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@KevinLee1110&lt;/td&gt;
&lt;td&gt;@zhaoyu611, @corenel&lt;/td&gt;
&lt;td&gt;@zhiding&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter10_sequence_modeling_rnn/" rel="nofollow"&gt;第十章 序列建模：循环和递归网络&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@swordyork&lt;/td&gt;
&lt;td&gt;lc&lt;/td&gt;
&lt;td&gt;@zhaoyu611, @yinruiqing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter11_practical_methodology/" rel="nofollow"&gt;第十一章 实践方法论&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@liber145&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter12_applications/" rel="nofollow"&gt;第十二章 应用&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@swordyork, @futianfan&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;@corenel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter13_linear_factor_models/" rel="nofollow"&gt;第十三章 线性因子模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@futianfan&lt;/td&gt;
&lt;td&gt;@cloudygoose&lt;/td&gt;
&lt;td&gt;@ZhiweiYang&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter14_autoencoders/" rel="nofollow"&gt;第十四章 自编码器&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@swordyork&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;@Seaball, @huangpingchun&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter15_representation_learning/" rel="nofollow"&gt;第十五章 表示学习&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@liber145&lt;/td&gt;
&lt;td&gt;@cnscottzheng&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter16_structured_probabilistic_modelling/" rel="nofollow"&gt;第十六章 深度学习中的结构化概率模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@futianfan&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter17_monte_carlo_methods/" rel="nofollow"&gt;第十七章 蒙特卡罗方法&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@futianfan&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;@sailordiary&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter18_confronting_the_partition_function/" rel="nofollow"&gt;第十八章 面对配分函数&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@liber145&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;@tankeco&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter19_approximate_inference/" rel="nofollow"&gt;第十九章 近似推断&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@futianfan&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;@sailordiary, @hengqujushi, huanghaojun&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://exacity.github.io/deeplearningbook-chinese/Chapter20_deep_generative_models/" rel="nofollow"&gt;第二十章 深度生成模型&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;@swordyork&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;参考文献&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;@pkuwwt&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我们会在纸质版正式出版的时候，在书中致谢，正式感谢各位作出贡献的同学！&lt;/p&gt;
&lt;p&gt;还有很多同学提出了不少建议，我们都列在此处。&lt;/p&gt;
&lt;p&gt;@tttwwy @tankeco @fairmiracle @GageGao @huangpingchun @MaHongP @acgtyrant @yanhuibin315 @Buttonwood @titicacafz
@weijy026a @RuiZhang1993 @zymiboxpay @xingkongliang @oisc @tielei @yuduowu @Qingmu @HC-2016 @xiaomingabc
@bengordai @Bojian @JoyFYan @minoriwww @khty2000 @gump88 @zdx3578 @PassStory @imwebson @wlbksy @roachsinai @Elvinczp
@endymecy name:YUE-DaJiong @9578577 @linzhp @cnscottzheng @germany-zhu  @zhangyafeikimi @showgood163 @gump88
@kangqf @NeutronT @badpoem @kkpoker @Seaball @wheaio @angrymidiao @ZhiweiYang @corenel @zhaoyu611 @SiriusXDJ @dfcv24 EmisXXY
FlyingFire vsooda @friskit-china @poerin @ninesunqian @JiaqiYao @Sofring @wenlei @wizyoung @imageslr @@indam @XuLYC
@zhouqingping @freedomRen @runPenguin @pkuwwt @wuqi @tjliupeng @neo0801 @jt827859032 @demolpc @fishInAPool
@xiaolangyuxin @jzj1993 @whatbeg LongXiaJun jzd&lt;/p&gt;
&lt;p&gt;如有遗漏，请务必通知我们，可以发邮件至&lt;code&gt;echo c3dvcmQueW9ya0BnbWFpbC5jb20K | base64 --decode&lt;/code&gt;。
这是我们必须要感谢的，所以不要不好意思。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODO&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;排版&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-注意" class="anchor" aria-hidden="true" href="#注意"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;注意&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;各种问题或者建议可以提issue，建议使用中文。&lt;/li&gt;
&lt;li&gt;由于版权问题，我们不能将图片和bib上传，请见谅。&lt;/li&gt;
&lt;li&gt;Due to copyright issues, we would not upload figures and the bib file.&lt;/li&gt;
&lt;li&gt;可用于学习研究目的，不得用于任何商业行为。谢谢！&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-markdown格式" class="anchor" aria-hidden="true" href="#markdown格式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Markdown格式&lt;/h2&gt;
&lt;p&gt;这种格式确实比较重要，方便查阅，也方便索引。初步转换后，生成网页，具体见&lt;a href="https://exacity.github.io/deeplearningbook-chinese" rel="nofollow"&gt;deeplearningbook-chinese&lt;/a&gt;。
注意，这种转换没有把图放进去，也不会放图。目前使用单个&lt;a href="scripts/convert2md.sh"&gt;脚本&lt;/a&gt;，基于latex文件转换，以后可能会更改但原则是不直接修改&lt;a href="docs/_posts"&gt;md文件&lt;/a&gt;。
需要的同学可以自行修改&lt;a href="scripts/convert2md.sh"&gt;脚本&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-html格式" class="anchor" aria-hidden="true" href="#html格式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTML格式&lt;/h2&gt;
&lt;p&gt;读者可以使用&lt;a href="https://github.com/coolwanglu/pdf2htmlEX"&gt;pdf2htmlEX&lt;/a&gt;进行转换，直接将PDF转换为HTML。&lt;/p&gt;
&lt;p&gt;Updating.....&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>exacity</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>sb2nov/resume #2 in TeX, Today</title><link>https://github.com/sb2nov/resume</link><description>&lt;p&gt;&lt;i&gt;Software developer resume in Latex&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;A single-page, one-column resume for software developers. It uses the base latex templates and fonts to provide ease of use and installation when trying to update the resume. The different sections are clearly documented and custom commands are used to provide consistent formatting. The three main sections in the resume are education, experience, and projects.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h3&gt;
&lt;p&gt;I created this template as managing a resume on Google Docs was hard and changing any formatting was too difficult since it had to be applied in multiple places. Most currently available templates either focus on two columns, or are multiple pages long. I personally found the two-column templates hard to focus while multiple-page resumes were just too long to be used in career fairs.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-preview" class="anchor" aria-hidden="true" href="#preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preview&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/resume_preview.png"&gt;&lt;img src="/resume_preview.png" alt="Resume Screenshot" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h3&gt;
&lt;p&gt;Format is MIT but all the data is owned by Sourabh Bajaj.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>sb2nov</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>lervag/vimtex #3 in TeX, Today</title><link>https://github.com/lervag/vimtex</link><description>&lt;p&gt;&lt;i&gt;A modern vim plugin for editing LaTeX files.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-vimtex" class="anchor" aria-hidden="true" href="#vimtex"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;vimtex&lt;/h1&gt;
&lt;p&gt;vimtex is a &lt;a href="http://www.vim.org/" rel="nofollow"&gt;Vim&lt;/a&gt; plugin that provides support for writing
LaTeX documents. It is based on
&lt;a href="https://github.com/LaTeX-Box-Team/LaTeX-Box"&gt;LaTeX-Box&lt;/a&gt; and it shares a
similar goal: to provide a simple and lightweight LaTeX plugin. It has been
rewritten from scratch to provide a more modern and modular code base. See
&lt;a href="#alternatives"&gt;here&lt;/a&gt; for some more comments on the difference between vimtex
and other LaTeX plugins for Vim.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/lervag/vimtex/workflows/main.yml/badge.svg"&gt;&lt;img src="https://github.com/lervag/vimtex/workflows/main.yml/badge.svg" alt="Build Status" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=5N4MFVXN7U8NW" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d5d24e33e2f4b6fe53987419a21b203c03789a8f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e737667" alt="Donate" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#features"&gt;Features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-relevant-plugins"&gt;Other relevant plugins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#alternatives"&gt;Alternatives&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;If you use &lt;a href="https://github.com/junegunn/vim-plug"&gt;vim-plug&lt;/a&gt;, then add the
following line to your &lt;code&gt;vimrc&lt;/code&gt; file:&lt;/p&gt;
&lt;div class="highlight highlight-source-viml"&gt;&lt;pre&gt;Plug &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;lervag/vimtex&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or use some other plugin manager:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gmarik/vundle"&gt;vundle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Shougo/neobundle.vim"&gt;neobundle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tpope/vim-pathogen"&gt;pathogen&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you use the new package feature in Vim, please note the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make sure to read and understand the package feature: &lt;code&gt;:help package&lt;/code&gt;!&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;/pack/foo/start&lt;/code&gt; subdirectory to make sure the filetype plugin is automatically loaded for the &lt;code&gt;tex&lt;/code&gt; filetypes.&lt;/li&gt;
&lt;li&gt;Helptags are not generated automatically. Run &lt;code&gt;:helptags&lt;/code&gt; to generate them.&lt;/li&gt;
&lt;li&gt;Please note that by default Vim puts custom &lt;code&gt;/start/&lt;/code&gt; plugin directories at the end of the &lt;code&gt;&amp;amp;runtimepath&lt;/code&gt;. This means the built in filetype plugin is loaded, which prevents Vimtex from loading. See &lt;a href="https://github.com/lervag/vimtex/issues/1413"&gt;#1413&lt;/a&gt; for two suggested solutions to this. To see which scripts are loaded and in which order, use &lt;code&gt;:scriptnames&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;For more information on how to use the Vim native package solution, see &lt;a href="https://vi.stackexchange.com/questions/9522/what-is-the-vim8-package-feature-and-how-should-i-use-it" rel="nofollow"&gt;here&lt;/a&gt; and &lt;a href="https://shapeshed.com/vim-packages/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;The following is a simple guide for how to use vimtex. It only displays the
most basic features. Users are &lt;em&gt;strongly&lt;/em&gt; encouraged to read or at least skim
through the documentation to learn about the different features and
possibilities provided by vimtex (see &lt;a href="doc/vimtex.txt"&gt;&lt;code&gt;:h vimtex&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Note: Vimtex supports neovim; see the &lt;a href="https://github.com/lervag/vimtex/wiki/introduction#neovim"&gt;related wiki
section&lt;/a&gt; or &lt;code&gt;:h vimtex-faq-neovim&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="media/quick_start.gif?raw=true"&gt;&lt;img src="media/quick_start.gif?raw=true" alt="Quick start gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;p&gt;Below is a list of features offered by vimtex.  The features are accessible as
both commands and mappings.  The mappings generally start with
&lt;code&gt;&amp;lt;localleader&amp;gt;l&lt;/code&gt;, but if desired one can disable default mappings to define
custom mappings.  All features are enabled by default, but each feature may be
disabled if desired.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Document compilation with
&lt;a href="http://users.phys.psu.edu/~collins/software/latexmk-jcc/" rel="nofollow"&gt;latexmk&lt;/a&gt;,
&lt;a href="https://github.com/aclements/latexrun"&gt;latexrun&lt;/a&gt;,
&lt;a href="https://tectonic-typesetting.github.io" rel="nofollow"&gt;tectonic&lt;/a&gt;, or
&lt;a href="https://github.com/cereda/arara"&gt;arara&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LaTeX log parsing for quickfix entries using
&lt;ul&gt;
&lt;li&gt;internal method&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/stefanhepp/pplatex"&gt;pplatex&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compilation of selected part of document&lt;/li&gt;
&lt;li&gt;Support for several PDF viewers with forward search
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.mupdf.com/" rel="nofollow"&gt;MuPDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://okular.kde.org/" rel="nofollow"&gt;Okular&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://launchpad.net/qpdfview" rel="nofollow"&gt;qpdfview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://skim-app.sourceforge.net/" rel="nofollow"&gt;Skim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.sumatrapdfreader.org/free-pdf-reader.html" rel="nofollow"&gt;SumatraPDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pwmt.org/projects/zathura/" rel="nofollow"&gt;Zathura&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Other viewers are supported through a general interface&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Completion of
&lt;ul&gt;
&lt;li&gt;citations&lt;/li&gt;
&lt;li&gt;labels&lt;/li&gt;
&lt;li&gt;commands&lt;/li&gt;
&lt;li&gt;file names for figures, input/include, includepdf, includestandalone&lt;/li&gt;
&lt;li&gt;glossary entries&lt;/li&gt;
&lt;li&gt;package and documentclass names based on available &lt;code&gt;.sty&lt;/code&gt; and &lt;code&gt;.cls&lt;/code&gt; files&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Document navigation through
&lt;ul&gt;
&lt;li&gt;table of content&lt;/li&gt;
&lt;li&gt;table of labels&lt;/li&gt;
&lt;li&gt;proper settings for &lt;code&gt;'include'&lt;/code&gt;, &lt;code&gt;'includexpr'&lt;/code&gt;, &lt;code&gt;'suffixesadd'&lt;/code&gt; and
&lt;code&gt;'define'&lt;/code&gt;, which among other things
&lt;ul&gt;
&lt;li&gt;allow &lt;code&gt;:h include-search&lt;/code&gt; and &lt;code&gt;:h definition-search&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;give enhanced &lt;code&gt;gf&lt;/code&gt; command&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Easy access to (online) documentation of packages&lt;/li&gt;
&lt;li&gt;Word count (through &lt;code&gt;texcount&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Motions
&lt;ul&gt;
&lt;li&gt;Move between section boundaries with &lt;code&gt;[[&lt;/code&gt;, &lt;code&gt;[]&lt;/code&gt;, &lt;code&gt;][&lt;/code&gt;, and &lt;code&gt;]]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Move between environment boundaries with &lt;code&gt;[m&lt;/code&gt;, &lt;code&gt;[M&lt;/code&gt;, &lt;code&gt;]m&lt;/code&gt;, and &lt;code&gt;]M&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Move between comment boundaries with &lt;code&gt;[*&lt;/code&gt; and &lt;code&gt;]*&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Move between matching delimiters with &lt;code&gt;%&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Text objects
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ic ac&lt;/code&gt; Commands&lt;/li&gt;
&lt;li&gt;&lt;code&gt;id ad&lt;/code&gt; Delimiters&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ie ae&lt;/code&gt; LaTeX environments&lt;/li&gt;
&lt;li&gt;&lt;code&gt;i$ a$&lt;/code&gt; Inline math structures&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iP aP&lt;/code&gt; Sections&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other mappings
&lt;ul&gt;
&lt;li&gt;Delete the surrounding command, environment or delimiter with
&lt;code&gt;dsc&lt;/code&gt;/&lt;code&gt;dse&lt;/code&gt;/&lt;code&gt;ds$&lt;/code&gt;/&lt;code&gt;dsd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Change the surrounding command, environment or delimiter with
&lt;code&gt;csc&lt;/code&gt;/&lt;code&gt;cse&lt;/code&gt;/&lt;code&gt;cs$&lt;/code&gt;/&lt;code&gt;csd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Toggle starred command or environment with &lt;code&gt;tsc&lt;/code&gt;/&lt;code&gt;tse&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Toggle between e.g. &lt;code&gt;()&lt;/code&gt; and &lt;code&gt;\left(\right)&lt;/code&gt; with &lt;code&gt;tsd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Close the current environment/delimiter in insert mode with &lt;code&gt;]]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Insert new command with &lt;code&gt;&amp;lt;F7&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Convenient insert mode mappings for faster typing of e.g. maths&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Improved folding (&lt;code&gt;:h 'foldexpr'&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Improved indentation (&lt;code&gt;:h 'indentexpr'&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Improved syntax highlighting
&lt;ul&gt;
&lt;li&gt;Highlight matching delimiters&lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;biblatex&lt;/code&gt;/&lt;code&gt;natbib&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;cleveref&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;listings&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Nested syntax highlighting (&lt;code&gt;minted&lt;/code&gt;, &lt;code&gt;dot2tex&lt;/code&gt;, &lt;code&gt;lualatex&lt;/code&gt;,
&lt;code&gt;gnuplottex&lt;/code&gt;, &lt;code&gt;asymptote&lt;/code&gt;, &lt;code&gt;pythontex&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support for multi-file project packages
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ctan.uib.no/macros/latex/contrib/import/import.pdf" rel="nofollow"&gt;import&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ctan.uib.no/macros/latex/contrib/subfiles/subfiles.pdf" rel="nofollow"&gt;subfiles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See the documentation for a thorough introduction to vimtex (e.g. &lt;code&gt;:h vimtex&lt;/code&gt;).&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-other-relevant-plugins" class="anchor" aria-hidden="true" href="#other-relevant-plugins"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other relevant plugins&lt;/h2&gt;
&lt;p&gt;Even though vimtex provides a lot of nice features for working with LaTeX
documents, there are several features that are better served by other,
dedicated plugins. For a more detailed listing of these, please see &lt;a href="doc/vimtex.txt#L156"&gt;&lt;code&gt;:help vimtex-non-features&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-linting-and-syntax-checking" class="anchor" aria-hidden="true" href="#linting-and-syntax-checking"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linting and syntax checking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/w0rp/ale"&gt;ale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/neomake/neomake"&gt;neomake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vim-syntastic/syntastic"&gt;syntastic&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-snippets-and-templates" class="anchor" aria-hidden="true" href="#snippets-and-templates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Snippets and templates&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/SirVer/ultisnips"&gt;UltiSnips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Shougo/neosnippet.vim"&gt;neosnippet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-tag-navigation" class="anchor" aria-hidden="true" href="#tag-navigation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tag navigation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ludovicchabant/vim-gutentags"&gt;vim-gutentags&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-alternatives" class="anchor" aria-hidden="true" href="#alternatives"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternatives&lt;/h2&gt;
&lt;p&gt;The following are some alternative LaTeX plugins for Vim:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/LaTeX-Box-Team/LaTeX-Box"&gt;LaTeX-Box&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;vimtex currently has most of the features of LaTeX-Box, as well as
some additional ones. See &lt;a href="#features"&gt;here&lt;/a&gt; for a relatively complete list
of features.&lt;/p&gt;
&lt;p&gt;One particular feature that LaTeX-Box has but vimtex misses, is the ability
to do single-shot compilation &lt;em&gt;with callback&lt;/em&gt;. This functionality was
removed because it adds a lot of complexity for relatively little gain
(IMHO).&lt;/p&gt;
&lt;p&gt;Note: LaTeX-Box is included with
&lt;a href="https://github.com/sheerun/vim-polyglot"&gt;vim-polyglot&lt;/a&gt;. Some users are not
quite aware of this and end up trying vimtex with LaTeX-Box enabled. This
will not work --- please disable LaTeX-Box first!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://vim-latex.sourceforge.net" rel="nofollow"&gt;LaTeX-Suite&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The main difference between vimtex and LaTeX-Suite (aka vim-latex) is
probably that vimtex does not try to implement a full fledged IDE for LaTeX
inside Vim. E.g.:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;vimtex does not provide a full snippet feature, because this is better
handled by &lt;a href="https://github.com/SirVer/ultisnips"&gt;UltiSnips&lt;/a&gt; or
&lt;a href="https://github.com/Shougo/neosnippet.vim"&gt;neosnippet&lt;/a&gt; or similar snippet
engines.&lt;/li&gt;
&lt;li&gt;vimtex builds upon Vim principles: It provides text objects for
environments, inline math, it provides motions for sections and
paragraphs&lt;/li&gt;
&lt;li&gt;vimtex uses &lt;code&gt;latexmk&lt;/code&gt;, &lt;code&gt;latexrun&lt;/code&gt;, &lt;code&gt;tectonic&lt;/code&gt; or &lt;code&gt;arara&lt;/code&gt; for compilation
with a callback feature to get instant feedback on compilation errors&lt;/li&gt;
&lt;li&gt;vimtex is very modular: if you don't like a feature, you can turn it off.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://atp-vim.sourceforge.net" rel="nofollow"&gt;AutomaticTexPlugin&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/xuhdev/vim-latex-live-preview"&gt;vim-latex-live-preview&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more alternatives and more information and discussions regarding LaTeX
plugins for Vim, see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://vi.stackexchange.com/questions/2047/what-are-the-differences-between-latex-plugins" rel="nofollow"&gt;What are the differences between LaTeX
plugins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tex.stackexchange.com/questions/339/latex-editors-ides" rel="nofollow"&gt;List of LaTeX editors (not only
Vim)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lervag</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>xueruini/thuthesis #4 in TeX, Today</title><link>https://github.com/xueruini/thuthesis</link><description>&lt;p&gt;&lt;i&gt;LaTeX Thesis Template for Tsinghua University&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://travis-ci.org/xueruini/thuthesis" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5da8c22b95bd0e5eb940bc5fea16af8feb2ed401/68747470733a2f2f7472617669732d63692e6f72672f7875657275696e692f7468757468657369732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/xueruini/thuthesis.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/thuthesis/Lobby" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f93c05a42da86d653b4d5ad075031b2f4a9c60a1/68747470733a2f2f6261646765732e6769747465722e696d2f7468757468657369732f4c6f6262792e737667" alt="Join the chat at https://gitter.im/thuthesis/Lobby" data-canonical-src="https://badges.gitter.im/thuthesis/Lobby.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/xueruini/thuthesis/releases"&gt;&lt;img src="https://camo.githubusercontent.com/495c01faee6697531e60e3f0ca1e66743582e890/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f7875657275696e692f7468757468657369732f746f74616c2e737667" alt="Github downloads" data-canonical-src="https://img.shields.io/github/downloads/xueruini/thuthesis/total.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/xueruini/thuthesis/releases/latest"&gt;&lt;img src="https://camo.githubusercontent.com/a08197fcf9be7d3e34ac0526686304fbd4817146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f7875657275696e692f7468757468657369732f616c6c2e737667" alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/xueruini/thuthesis/all.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/xueruini/thuthesis/commits/master"&gt;&lt;img src="https://camo.githubusercontent.com/13a6034e83188b5338130101b729835496b5110f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f7875657275696e692f7468757468657369732f6c61746573742e737667" alt="GitHub commits" data-canonical-src="https://img.shields.io/github/commits-since/xueruini/thuthesis/latest.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-whats-thuthesis" class="anchor" aria-hidden="true" href="#whats-thuthesis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's ThuThesis?&lt;/h1&gt;
&lt;p&gt;ThuThesis is an abbreviation of &lt;b&gt;T&lt;/b&gt;sing&lt;b&gt;h&lt;/b&gt;ua &lt;b&gt;U&lt;/b&gt;niversity &lt;b&gt;Thesis&lt;/b&gt; LaTeX Template.&lt;/p&gt;
&lt;p&gt;This package establishes a simple and easy-to-use LaTeX template for Tsinghua dissertations, including general undergraduate research papers, masters theses, doctoral theses, doctoral dissertations, and post-doc reports. Additional support for other formats (what else is there?) will be added continuously. An English translation of this README follows the Chinese below.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-thuthesis是什么" class="anchor" aria-hidden="true" href="#thuthesis是什么"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ThuThesis是什么？&lt;/h1&gt;
&lt;p&gt;ThuThesis为 &lt;b&gt;T&lt;/b&gt;sing&lt;b&gt;h&lt;/b&gt;ua &lt;b&gt;U&lt;/b&gt;niversity &lt;b&gt;Thesis&lt;/b&gt; LaTeX Template之缩写。&lt;/p&gt;
&lt;p&gt;此宏包旨在建立一个简单易用的清华大学学位论文LaTeX模板，包括本科综合论文训练、硕士论文、博士论文、博士哲学论文以及博士后出站报告。现在支持本科、硕士、博士论文、博士后出站报告格式，对其它格式（还有么？）的支持会陆续加入。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-文档" class="anchor" aria-hidden="true" href="#文档"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;文档&lt;/h1&gt;
&lt;p&gt;请&lt;a href="https://github.com/xueruini/thuthesis/releases"&gt;下载&lt;/a&gt;模板，里面包括具体使用说明以及示例文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模板使用说明 (thuthesis.pdf)&lt;/li&gt;
&lt;li&gt;示例文档 (main.pdf)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-下载" class="anchor" aria-hidden="true" href="#下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;发行版：&lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;开发版：&lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-升级" class="anchor" aria-hidden="true" href="#升级"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;升级&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-自动更新" class="anchor" aria-hidden="true" href="#自动更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;自动更新&lt;/h2&gt;
&lt;p&gt;通过 TeX 发行版工具自动从 &lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt; 更新。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-手动更新" class="anchor" aria-hidden="true" href="#手动更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;手动更新&lt;/h2&gt;
&lt;p&gt;从 &lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt; 下载放入论文目录，执行命令（Windows 用户在文件夹空白处按&lt;code&gt;Shift+鼠标右键&lt;/code&gt;，点击“在此处打开命令行窗口”）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xetex thuthesis.ins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;即可得到 &lt;code&gt;thuthesis.cls&lt;/code&gt; 等模板文件。&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-提问" class="anchor" aria-hidden="true" href="#提问"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;提问&lt;/h1&gt;
&lt;p&gt;按推荐顺序排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先到 &lt;a href="https://github.com/xueruini/thuthesis/wiki/FAQ"&gt;FAQ&lt;/a&gt; 看看常见问题&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/xueruini/thuthesis/issues"&gt;Github Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.newsmth.net/nForum/#!board/TeX" rel="nofollow"&gt;TeX@newsmth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://groups.google.com/group/thuthesis" rel="nofollow"&gt;ThuThesis@Google Groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-makefile的用法" class="anchor" aria-hidden="true" href="#makefile的用法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Makefile的用法&lt;/h1&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make [{all&lt;span class="pl-k"&gt;|&lt;/span&gt;thesis&lt;span class="pl-k"&gt;|&lt;/span&gt;shuji&lt;span class="pl-k"&gt;|&lt;/span&gt;doc&lt;span class="pl-k"&gt;|&lt;/span&gt;clean&lt;span class="pl-k"&gt;|&lt;/span&gt;cleanall&lt;span class="pl-k"&gt;|&lt;/span&gt;distclean}]&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-目标" class="anchor" aria-hidden="true" href="#目标"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;目标&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;make all&lt;/code&gt;       等于 &lt;code&gt;make thesis &amp;amp;&amp;amp; make shuji &amp;amp;&amp;amp; make doc&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cls&lt;/code&gt;       生成模板文件；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make thesis&lt;/code&gt;    生成论文 main.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make shuji&lt;/code&gt;     生成书脊 shuji.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make doc&lt;/code&gt;       生成使用说明书 thuthesis.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;     删除示例文件的中间文件（不含 main.pdf）；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cleanall&lt;/code&gt;  删除示例文件的中间文件和 main.pdf；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt; 删除示例文件和模板的所有中间文件和 PDF。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h1&gt;
&lt;p&gt;Download and unzip the template. Specific usage documentation and examples can be found in the files below. At present, these documents are &lt;b&gt;only available in Chinese&lt;/b&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Template usage (thuthesis.pdf)&lt;/li&gt;
&lt;li&gt;Template example (main.pdf)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-downloads" class="anchor" aria-hidden="true" href="#downloads"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Downloads&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Published version: &lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Developer version: &lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-updates" class="anchor" aria-hidden="true" href="#updates"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Updates&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-automatic" class="anchor" aria-hidden="true" href="#automatic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic&lt;/h2&gt;
&lt;p&gt;Get the most up-to-date published version of the TeX tools from &lt;a href="http://www.ctan.org/pkg/thuthesis" rel="nofollow"&gt;CTAN&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-manual" class="anchor" aria-hidden="true" href="#manual"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manual&lt;/h2&gt;
&lt;p&gt;Download the package from &lt;a href="https://github.com/xueruini/thuthesis"&gt;GitHub&lt;/a&gt; to the root directory of your thesis, then execute the command (Windows users &lt;code&gt;Shift + right click&lt;/code&gt; white area in the file window and click "Open command line window here from the popup menu"):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xetex thuthesis.ins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You'll get &lt;code&gt;thuthesis.cls&lt;/code&gt; along with other template files.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-reporting-issues" class="anchor" aria-hidden="true" href="#reporting-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reporting Issues&lt;/h1&gt;
&lt;p&gt;Please follow the procedure below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check the  &lt;a href="https://github.com/xueruini/thuthesis/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/xueruini/thuthesis/issues"&gt;Github Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.newsmth.net/nForum/#!board/TeX" rel="nofollow"&gt;TeX@newsmth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://groups.google.com/group/thuthesis" rel="nofollow"&gt;ThuThesis@Google Groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-makefile-usage" class="anchor" aria-hidden="true" href="#makefile-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Makefile Usage&lt;/h1&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make [{all&lt;span class="pl-k"&gt;|&lt;/span&gt;thesis&lt;span class="pl-k"&gt;|&lt;/span&gt;shuji&lt;span class="pl-k"&gt;|&lt;/span&gt;doc&lt;span class="pl-k"&gt;|&lt;/span&gt;clean&lt;span class="pl-k"&gt;|&lt;/span&gt;cleanall&lt;span class="pl-k"&gt;|&lt;/span&gt;distclean}]&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-targets" class="anchor" aria-hidden="true" href="#targets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;make all&lt;/code&gt;       same as &lt;code&gt;make thesis &amp;amp;&amp;amp; make shuji &amp;amp;&amp;amp; make doc&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cls&lt;/code&gt;       generate template file;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make thesis&lt;/code&gt;    generate thesis main.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make shuji&lt;/code&gt;     generate book spine for printing shuji.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make doc&lt;/code&gt;       generate documentation thuthesis.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;     delete all examples' files (excluding main.pdf);&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make cleanall&lt;/code&gt;  delete all examples' files and main.pdf;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt; delete all examples' and templates' files and PDFs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>xueruini</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>tuhdo/os01 #5 in TeX, Today</title><link>https://github.com/tuhdo/os01</link><description>&lt;p&gt;&lt;i&gt;Bootstrap yourself to write an OS from scratch. A book for self-learner.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_donations&amp;amp;business=tuhdo1710%40gmail%2ecom&amp;amp;lc=VN&amp;amp;item_number=tuhdo&amp;amp;currency_code=USD&amp;amp;bn=PP%2dDonationsBF%3aDonate%2dPayPal%2dgreen%2esvg%3aNonHosted" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d5d24e33e2f4b6fe53987419a21b203c03789a8f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e737667" alt="Donate" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-operating-systems-from-0-to-1" class="anchor" aria-hidden="true" href="#operating-systems-from-0-to-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://tuhdo.github.io/os01/" rel="nofollow"&gt;Operating Systems: From 0 to 1&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;This book helps you gain the foundational knowledge required to write an
operating system from scratch. Hence the title, 0 to 1.&lt;/p&gt;
&lt;p&gt;After completing this book, at the very least you will learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;How to write an operating system from scratch by reading hardware datasheets.
In the real world, it works like that. You won't be able to consult Google for
a quick answer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A big picture of how each layer of a computer is related to the other, from hardware to software.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Write code independently. It's pointless to copy and paste code. Real learning
happens when you solve problems on your own. Some examples are given to kick
start, but most problems are yours to conquer. However, the solutions are
available online for you to examine after giving it a good try.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linux as a development environment and how to use common tools for low-level
programming.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;x86 assembly in-depth.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How a program is structured so that an operating system can run.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How to debug a program running directly on hardware with gdb and QEMU.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linking and loading on bare metal x86_64, with pure C. No standard library. No
runtime overhead.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/tuhdo/os01/blob/master/Operating_Systems_From_0_to_1.pdf"&gt;Download the book&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-the-pedagogy-of-the-book" class="anchor" aria-hidden="true" href="#the-pedagogy-of-the-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The pedagogy of the book&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;You give a poor man a fish and you feed him for a day. You teach him to fish
and you give him an occupation that will feed him for a lifetime.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This has been the guiding principle of the book when I was writing it. The book does
not try to teach you everything, but enough to enable you to learn by yourself.
The book itself, at this point, is quite "complete": once you master part 1 and
part 2 (which consist of 8 chapters), you can drop the book and learn by
yourself. At this point, smart readers should be able to continue on their own.
For example, they can continue their journeys
on &lt;a href="http://wiki.osdev.org/Main_Page" rel="nofollow"&gt;OSDev wiki&lt;/a&gt;; in fact, after you study
everything in part 1 and part 2, you only meet
the &lt;a href="http://wiki.osdev.org/Required_Knowledge" rel="nofollow"&gt;minimum requirement&lt;/a&gt; by OSDev
Wiki (well, not quite, the book actually goes deeper for the suggested topics).
Or, if you consider developing an OS for fun is impractical, you can continue
with a Linux-specific book, such as this free
book &lt;a href="https://0xax.gitbooks.io/linux-insides/content/" rel="nofollow"&gt;Linux Insides&lt;/a&gt;, or other
popular Linux kernel books. The book tries hard to provide you a strong
foundation, and that's why part 1 and part 2 were released first.&lt;/p&gt;
&lt;p&gt;The book teaches you core concepts, such as x86 Assembly, ELF, linking and
debugging on bare metal, etc., but more importantly, where such information
come from. For example, instead of just teaching x86 Assembly, it also teaches
how to use reference manuals from Intel. Learning to read the official
manuals is important because only the hardware manufacturers themselves
understand how their hardware work. If you only learn from the secondary
resources because it is easier, you will never gain a complete understanding of
the hardware you are programming for. Have you ever read a book on Assembly, and
wondered where all the information came from? How does the author know
everything he says is correct? And how one seems to magically know so much about
hardware programming? This book gives pointers to such questions.&lt;/p&gt;
&lt;p&gt;As an example, you should skim through chapter 4, "x86 Assembly and C", to see
how it makes use of the Intel manual, Volume 2. And in
the process, it guides you how to use the official manuals.&lt;/p&gt;
&lt;p&gt;Part 3 is planned as a series of specifications that a reader will implement to
complete each operating system component. It does not contain code aside from a
few examples. Part 3 is just there to shorten the reader's time when reading the
official manuals by giving hints where to read, explaining difficult concepts
and how to use the manuals to debug. In short, the implementation is up to the
reader to work on his or her own; the chapters are just like university assignments.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-prerequisites" class="anchor" aria-hidden="true" href="#prerequisites"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;Know some circuit concepts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basic Concepts of Electricity: atoms, electrons, protons, neutrons, current flow.&lt;/li&gt;
&lt;li&gt;Ohm's law&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, if you know absolutely nothing about electricity, you can quickly learn it here:
&lt;a href="http://www.allaboutcircuits.com/textbook/" rel="nofollow"&gt;http://www.allaboutcircuits.com/textbook/&lt;/a&gt;, by reading chapter 1 and chapter 2.&lt;/p&gt;
&lt;p&gt;C programming. In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Variable and function declarations/definitions&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;While and for loops&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pointers and function pointers&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fundamental algorithms and data structures in C&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Linux basics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Know how to navigate directory with the command line&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Know how to invoke a command with options&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Know how to pipe output to another program&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Touch typing. Since we are going to use Linux, touch typing helps. I know typing
speed does not relate to problem-solving, but at least your typing speed should
be fast enough not to let it get it the way and degrade the learning experience.&lt;/p&gt;
&lt;p&gt;In general, I assume that the reader has basic C programming knowledge, and can
use an IDE to build and run a program.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-status" class="anchor" aria-hidden="true" href="#status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Status:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Part 1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chapter 1: Complete&lt;/li&gt;
&lt;li&gt;Chapter 2: Complete&lt;/li&gt;
&lt;li&gt;Chapter 3: Almost. Currently, the book relies on the Intel Manual for fully explaining x86 execution environment.&lt;/li&gt;
&lt;li&gt;Chapter 4: Complete&lt;/li&gt;
&lt;li&gt;Chapter 5: Complete&lt;/li&gt;
&lt;li&gt;Chapter 6: Complete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chapter 7: Complete&lt;/li&gt;
&lt;li&gt;Chapter 8: Complete&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 3&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chapter 9: Incomplete&lt;/li&gt;
&lt;li&gt;Chapter 10: Incomplete&lt;/li&gt;
&lt;li&gt;Chapter 11: Incomplete&lt;/li&gt;
&lt;li&gt;Chapter 12: Incomplete&lt;/li&gt;
&lt;li&gt;Chapter 13: Incomplete&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;... and future chapters not included yet ...&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the future, I hope to expand part 3 to cover more than the first 2 parts. But
for the time being, I will try to finish the above chapters first.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-sample-os" class="anchor" aria-hidden="true" href="#sample-os"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sample OS&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/tuhdo/sample-os"&gt;This repository&lt;/a&gt; is the sample OS of the
book that is intended as a reference material for part 3. It covers 10 chapters
of the "System Programming Guide" (Intel Manual Volume 3), along with a simple
keyboard and video driver for input and output. However, at the moment, only the
following features are implemented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Protected mode.&lt;/li&gt;
&lt;li&gt;Creating and managing processes with TSS (Task State Structure).&lt;/li&gt;
&lt;li&gt;Interrupts&lt;/li&gt;
&lt;li&gt;LAPIC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paging and I/O are not yet implemented. I will try to implement it as the book progresses.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h1&gt;
&lt;p&gt;If you find any grammatical issues, please report it using Github Issues. Or, if
some sentence or paragraph is difficult to understand, feel free to open an
issue with the following title format: &lt;code&gt;[page number][type] Descriptive Title&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example: &lt;code&gt;[pg.9][grammar] Incorrect verb usage&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;type&lt;/code&gt; can be one of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Typo&lt;/code&gt;: indicates typing mistake.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Grammar&lt;/code&gt;: indicates incorrect grammar usage.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Style&lt;/code&gt;: indicates a style improvement.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Content&lt;/code&gt;: indicates problems with the content.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Even better, you can make a pull request with the provided book source. The main
content of the book is in the file "Operating Systems: From 0 to 1.lyx". You can
edit the .txt file, then I will integrate the changes manually. It is a
workaround for now since Lyx can cause a huge diff which makes it impossible to
review changes.&lt;/p&gt;
&lt;p&gt;The book is in development, so please bear with me if the English irritates you.
I really appreciate it.&lt;/p&gt;
&lt;p&gt;Finally, if you like the project and if it is possible, please donate to help
this project and keep it going.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-got-questions" class="anchor" aria-hidden="true" href="#got-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Got questions?&lt;/h1&gt;
&lt;p&gt;If you have any question related to the material or the development of the book,
feel free to &lt;a href="https://github.com/tuhdo/os01/issues/new"&gt;open a Github issue&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>tuhdo</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>lib-pku/libpku #6 in TeX, Today</title><link>https://github.com/lib-pku/libpku</link><description>&lt;p&gt;&lt;i&gt;贵校课程资料民间整理&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-libpku---贵校课程资料民间整理" class="anchor" aria-hidden="true" href="#libpku---贵校课程资料民间整理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;libpku - 贵校课程资料民间整理&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-preface" class="anchor" aria-hidden="true" href="#preface"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preface&lt;/h2&gt;
&lt;p&gt;（引用自 &lt;a href="https://github.com/QSCTech/zju-icicles"&gt;QSCTech/zju-icicles&lt;/a&gt; ）&lt;/p&gt;
&lt;p&gt;来到一所大学，从第一次接触许多课，直到一门一门完成，这个过程中我们时常收集起许多资料和情报。&lt;/p&gt;
&lt;p&gt;有些是需要在网上搜索的电子书，每次见到一门新课程，Google 一下教材名称，有的可以立即找到，有的却是要花费许多眼力；有些是历年试卷或者 A4 纸，前人精心收集制作，抱着能对他人有用的想法公开，却需要在各个群或者私下中摸索以至于从学长手中代代相传；有些是上完一门课才恍然领悟的技巧，原来这门课重点如此，当初本可以更轻松地完成得更好……&lt;/p&gt;
&lt;p&gt;我也曾很努力地收集各种课程资料，但到最后，某些重要信息的得到却往往依然是纯属偶然。这种状态时常令我感到后怕与不安。我也曾在课程结束后终于有了些许方法与总结，但这些想法无处诉说，最终只能把花费时间与精力才换来的经验耗散在了漫漫的遗忘之中。&lt;/p&gt;
&lt;p&gt;我为这一年一年，这么多人孤军奋战的重复劳动感到不平。&lt;/p&gt;
&lt;p&gt;我希望能够将这些隐晦的、不确定的、口口相传的资料和经验，变为公开的、易于获取的和大家能够共同完善、积累的共享资料。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我希望只要是前人走过的弯路，后人就不必再走。&lt;/strong&gt; 这是我的信念，也是我建立这个项目的原因。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;使用方法：访问 &lt;a href="https://lib-pku.github.io/" rel="nofollow"&gt;https://lib-pku.github.io/&lt;/a&gt; ，点击资料链接即可下载。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://minhaskamal.github.io/DownGit/#/home" rel="nofollow"&gt;https://minhaskamal.github.io/DownGit/#/home&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution" class="anchor" aria-hidden="true" href="#contribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;欢迎贡献！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;——因为很重要所以说了三遍&lt;/p&gt;
&lt;p&gt;Issue、PR、纠错、资料、选课/考试攻略，完全欢迎！&lt;/p&gt;
&lt;p&gt;来自大家的关注、维护和贡献，才是让这个攻略继续存在的动力~&lt;/p&gt;
&lt;p&gt;对于课程的评价可写在对应课程文件夹的 &lt;code&gt;README.md&lt;/code&gt; 中。如果想上传课件（请确保无版权问题），推荐使用 PDF 格式，避免系统差。&lt;/p&gt;
&lt;p&gt;由于本项目体积很大，故推荐采用在 &lt;strong&gt;GitHub Web 端直接上传&lt;/strong&gt; 的方式，具体操作如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;首先 Fork 本项目&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;上传文件到已有文件夹：打开对应文件夹，点击绿色 Download 按钮旁的 upload，上传你的文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;上传文件到新文件夹：打开任意文件夹，点击绿色 Download 按钮旁的 upload，&lt;strong&gt;把浏览器地址栏中文件夹名称改为你想要新建的文件夹名称，然后回车&lt;/strong&gt;，上传你的文件。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;提交 PR：Fork 本项目，然后在 GitHub 网页端点击 Upload File 上传文件，发起 PR 即可。留意一下项目的文件组织喔。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;或者也可以直接附加在 &lt;strong&gt;Issue&lt;/strong&gt; 中，由维护者进行添加。&lt;/p&gt;
&lt;p&gt;或者也可以发送邮件至 &lt;strong&gt;&lt;a href="mailto:libpku@protonmail.com"&gt;libpku@protonmail.com&lt;/a&gt;&lt;/strong&gt; ，由维护者进行添加。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-disclaimer" class="anchor" aria-hidden="true" href="#disclaimer"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;这不是北京大学图书馆。
我们也不对项目中信息的准确性或真实性做任何承诺。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果有侵权情况，麻烦您发送必要的信息至 &lt;a href="mailto:libpku@protonmail.com"&gt;libpku@protonmail.com&lt;/a&gt; ，带来不便还请您谅解。&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;资料来自网络，相关权利由原作者所有，这个 repo 仅用于收集现有资料。&lt;/p&gt;
&lt;p&gt;当然，我们不会为收集到的资料收费，或是尝试收取捐赠。&lt;/p&gt;
&lt;p&gt;我们只是尝试为后来的同学节省一些时间。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-related-works" class="anchor" aria-hidden="true" href="#related-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related Works&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/QSCTech/zju-icicles"&gt;浙江大学课程攻略共享计划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/martinwu42/project-hover"&gt;气垫船计划——免费、去中心化的北京大学往年题资料库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/EECS-PKU-XSB/Shared-learning-materials"&gt;北京大学信科学生会学术部资料库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tongtzeho/PKUCourse"&gt;北大计算机课程大作业&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PKUanonym/REKCARC-TSC-UHT"&gt;清华大学计算机系课程攻略&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zjdx1998/seucourseshare"&gt;东南大学课程共享计划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/USTC-Resource/USTC-Course"&gt;中国科学技术大学计算机学院课程资源&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/CoolPhilChen/SJTU-Courses/"&gt;上海交通大学课程资料分享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sysuexam/SYSU-Exam"&gt;中山大学课程资料分享&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/idealclover/NJU-Review-Materials"&gt;南京大学课程复习资料&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/CooperNiu/ZZU-Courses-Resource"&gt;郑州大学课程复习资料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(more to be added....)&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lib-pku</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>deedy/Deedy-Resume #7 in TeX, Today</title><link>https://github.com/deedy/Deedy-Resume</link><description>&lt;p&gt;&lt;i&gt;A one page , two asymmetric column resume template in XeTeX that caters to an undergraduate Computer Science student&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deedy-resume" class="anchor" aria-hidden="true" href="#deedy-resume"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deedy-Resume&lt;/h1&gt;
&lt;p&gt;A &lt;strong&gt;one-page&lt;/strong&gt;, &lt;strong&gt;two asymmetric column&lt;/strong&gt; resume template in &lt;strong&gt;XeTeX&lt;/strong&gt; that caters particularly to an &lt;strong&gt;undergraduate Computer Science&lt;/strong&gt; student.
As of &lt;strong&gt;v1.2&lt;/strong&gt;, there is an option to choose from two templates:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;MacFonts&lt;/strong&gt; - uses fonts native to OSX - &lt;em&gt;Helvetica&lt;/em&gt;, &lt;em&gt;Helvetica Neue&lt;/em&gt; (and it's Light and Ultralight versions) and the CJK fonts &lt;em&gt;Heiti SC&lt;/em&gt;, and &lt;em&gt;Heiti TC&lt;/em&gt;. The EULA of these fonts prevents distribution on Open Source.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenFonts&lt;/strong&gt; - uses free, open-source fonts that resemble the above - &lt;em&gt;Lato&lt;/em&gt; (and its various variants) and &lt;em&gt;Raleway&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It is licensed under the Apache License 2.0.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Common LaTeX resume-builders such as &lt;a href="http://www.latextemplates.com/template/moderncv-cv-and-cover-letter" rel="nofollow"&gt;&lt;strong&gt;moderncv&lt;/strong&gt;&lt;/a&gt;  and the &lt;a href="https://github.com/afriggeri/cv"&gt;&lt;strong&gt;friggeri-cv&lt;/strong&gt;&lt;/a&gt; look great if you're looking for a multi-page resume with numerous citations, but usually imperfect for making a thorough, single-page one. A lot of companies today search resumes based on &lt;a href="http://www.businessinsider.com/most-big-companies-have-a-tracking-system-that-scans-your-resume-for-keywords-2012-1" rel="nofollow"&gt;keywords&lt;/a&gt; but at the same time require/prefer a one-page resume, especially for undergraduates.&lt;/p&gt;
&lt;p&gt;This template attempts to &lt;strong&gt;look clean&lt;/strong&gt;, highlight &lt;strong&gt;details&lt;/strong&gt;, be a &lt;strong&gt;single page&lt;/strong&gt;, and allow useful &lt;strong&gt;LaTeX templating&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-preview" class="anchor" aria-hidden="true" href="#preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preview&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-openfonts" class="anchor" aria-hidden="true" href="#openfonts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenFonts&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/OpenFonts/sample-image.png"&gt;&lt;img src="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/OpenFonts/sample-image.png" alt="alt tag" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-macfonts" class="anchor" aria-hidden="true" href="#macfonts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MacFonts&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/MacFonts/sample-image.png"&gt;&lt;img src="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/MacFonts/sample-image.png" alt="alt tag" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Compiles only with &lt;strong&gt;XeTeX&lt;/strong&gt; and required &lt;strong&gt;BibTex&lt;/strong&gt; for compiling publications and the .bib filetype.&lt;/li&gt;
&lt;li&gt;Uses fonts that are usually only available to &lt;strong&gt;Mac&lt;/strong&gt; users such as Helvetica Neue Light.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-availability" class="anchor" aria-hidden="true" href="#availability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;MacFonts version - &lt;a href="http://debarghyadas.com/resume/debarghya-das-resume.pdf" rel="nofollow"&gt;as an online preview&lt;/a&gt; and &lt;a href="https://github.com/deedydas/Deedy-Resume/raw/master/MacFonts/deedy_resume.pdf"&gt;as a direct download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenFonts version - &lt;a href="https://github.com/deedydas/Deedy-Resume/raw/master/OpenFonts/deedy_resume-openfont.pdf"&gt;as a direct download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Overleaf&lt;/strong&gt;.com (formerly &lt;strong&gt;WriteLatex&lt;/strong&gt;.com) (v1 fonts/colors changed) - &lt;a href="https://www.writelatex.com/templates/deedy-resume/sqdbztjjghvz#.U2H9Kq1dV18" rel="nofollow"&gt;compilable online&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ShareLatex&lt;/strong&gt;.com (v1 fonts changes) - &lt;a href="https://www.sharelatex.com/templates/cv-or-resume/deedy-resume" rel="nofollow"&gt;compilable online&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-changelog" class="anchor" aria-hidden="true" href="#changelog"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Changelog&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-v12" class="anchor" aria-hidden="true" href="#v12"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v1.2&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Added publications in place of societies.&lt;/li&gt;
&lt;li&gt;Collapsed a portion of education.&lt;/li&gt;
&lt;li&gt;Fixed a bug with alignment of overflowing long last updated dates on the top right.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-v11" class="anchor" aria-hidden="true" href="#v11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v1.1&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Fixed several compilation bugs with \renewcommand&lt;/li&gt;
&lt;li&gt;Got Open-source fonts (Windows/Linux support)&lt;/li&gt;
&lt;li&gt;Added Last Updated&lt;/li&gt;
&lt;li&gt;Moved Title styling into .sty&lt;/li&gt;
&lt;li&gt;Commented .sty file.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODO&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Merge OpenFont and MacFonts as a single sty with options.&lt;/li&gt;
&lt;li&gt;Figure out a smoother way for the document to flow onto the next page.&lt;/li&gt;
&lt;li&gt;Add styling information for a "Projects/Hacks" section.&lt;/li&gt;
&lt;li&gt;Add location/address information&lt;/li&gt;
&lt;li&gt;Fix the hacky 'References' omission outside the .cls file in the MacFonts version.&lt;/li&gt;
&lt;li&gt;Add various styling and section options and allow for multiple pages smoothly.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-known-issues" class="anchor" aria-hidden="true" href="#known-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Known Issues:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Overflows onto second page if any column's contents are more than the vertical limit&lt;/li&gt;
&lt;li&gt;Hacky space on the first bullet point on the second column.&lt;/li&gt;
&lt;li&gt;Hacky redefinition of \refname to omit 'References' text for publications in the MacFonts version.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2014 Debarghya Das

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>deedy</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>thunlp/NRLPapers #8 in TeX, Today</title><link>https://github.com/thunlp/NRLPapers</link><description>&lt;p&gt;&lt;i&gt;Must-read papers on network representation learning (NRL) / network embedding (NE)&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-must-read-papers-on-nrlne" class="anchor" aria-hidden="true" href="#must-read-papers-on-nrlne"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Must-read papers on NRL/NE.&lt;/h2&gt;
&lt;p&gt;NRL: network representation learning. NE: network embedding.&lt;/p&gt;
&lt;p&gt;Contributed by &lt;a href="http://thunlp.org/~tcc/" rel="nofollow"&gt;Cunchao Tu&lt;/a&gt;, Yuan Yao, Zhengyan Zhang, GanquCui, Hao Wang (BUPT), Changxin Tian (BUPT), Jie Zhou and Cheng Yang (BUPT).&lt;/p&gt;
&lt;p&gt;We release &lt;a href="https://github.com/thunlp/openne"&gt;OpenNE&lt;/a&gt;, an open source toolkit for NE/NRL. This repository provides a standard NE/NRL(Network Representation Learning）training and testing framework. Currently, the implemented models in OpenNE include DeepWalk, LINE, node2vec, GraRep, TADW and GCN.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-content" class="anchor" aria-hidden="true" href="#content"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#survey-papers"&gt;Survey Papers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#models"&gt;Models&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#bacis-models"&gt;Bacis Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#attributed-network"&gt;Attributed Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dynamic-network"&gt;Dynamic Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#heterogeneous-information-network"&gt;Heterogeneous Information Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bipartite-network"&gt;Bipartite Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#directed-network"&gt;Directed Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-models"&gt;Other Models&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#applications"&gt;Applications&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#natural-language-processing"&gt;Natural Language Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#knowledge-graph"&gt;Knowledge Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#social-network"&gt;Social Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#graph-clustering"&gt;Graph Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#community-detection"&gt;Community Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommendation"&gt;Recommendation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-applications"&gt;Other Applications&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-survey-papers" class="anchor" aria-hidden="true" href="#survey-papers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Survey Papers&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Representation Learning on Graphs: Methods and Applications.&lt;/strong&gt;
&lt;em&gt;William L. Hamilton, Rex Ying, Jure Leskovec.&lt;/em&gt; IEEE Data(base) Engineering Bulletin 2017. &lt;a href="https://arxiv.org/pdf/1709.05584.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Embedding Techniques, Applications, and Performance: A Survey.&lt;/strong&gt;
&lt;em&gt;Palash Goyal, Emilio Ferrara.&lt;/em&gt; Knowledge Based Systems 2017. &lt;a href="https://arxiv.org/pdf/1705.02801.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications.&lt;/strong&gt;
&lt;em&gt;Hongyun Cai, Vincent W. Zheng, Kevin Chen-Chuan Chang.&lt;/em&gt; TKDE 2017. &lt;a href="https://arxiv.org/pdf/1709.07604.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network Representation Learning: A Survey.&lt;/strong&gt;
&lt;em&gt;Daokun Zhang, Jie Yin, Xingquan Zhu, Chengqi Zhang.&lt;/em&gt; IEEE Transactions on Big Data 2018. &lt;a href="https://arxiv.org/pdf/1801.05852.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A Tutorial on Network Embeddings.&lt;/strong&gt;
&lt;em&gt;Haochen Chen, Bryan Perozzi, Rami Al-Rfou, Steven Skiena.&lt;/em&gt; arxiv 2018. &lt;a href="https://arxiv.org/pdf/1808.02590.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network Representation Learning: An Overview.(In Chinese)&lt;/strong&gt;
&lt;em&gt;Cunchao Tu, Cheng Yang, Zhiyuan Liu, Maosong Sun.&lt;/em&gt; 2017. &lt;a href="http://engine.scichina.com/publisher/scp/journal/SSI/47/8/10.1360/N112017-00145" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Relational inductive biases, deep learning, and graph networks.&lt;/strong&gt;
&lt;em&gt;Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu.&lt;/em&gt; arxiv 2018. &lt;a href="https://arxiv.org/pdf/1806.01261.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-models" class="anchor" aria-hidden="true" href="#models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Models&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-bacis-models" class="anchor" aria-hidden="true" href="#bacis-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Bacis Models&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SepNE: Bringing Separability to Network Embedding.&lt;/strong&gt;
&lt;em&gt;Ziyao Li, Liang Zhang, Guojie Song.&lt;/em&gt; AAAI 2019. &lt;a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4333" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Robust Negative Sampling for Network Embedding.&lt;/strong&gt;
&lt;em&gt;Mohammadreza Armandpour, Patrick Ding, Jianhua Huang, Xia Hu.&lt;/em&gt; AAAI 2019. &lt;a href="https://www.stat.tamu.edu/~armand/R-NS.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network Structure and Transfer Behaviors Embedding via Deep Prediction Model.&lt;/strong&gt;
&lt;em&gt;Xin Sun, Zenghui Song, Junyu Dong, Yongbo Yu, Claudia Plant, Christian Böhm.&lt;/em&gt; AAAI 2019. &lt;a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4436" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Simplifying Graph Convolutional Networks.&lt;/strong&gt;
&lt;em&gt;Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, Kilian Weinberger.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/wu19e/wu19e.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GMNN: Graph Markov Neural Networks.&lt;/strong&gt;
&lt;em&gt;Meng Qu, Yoshua Bengio, Jian Tang.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/qu19a/qu19a.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stochastic Blockmodels meet Graph Neural Networks.&lt;/strong&gt;
&lt;em&gt;Nikhil Mehta, Lawrence Carin Duke, Piyush Rai.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/mehta19a/mehta19a.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Disentangled Graph Convolutional Networks.&lt;/strong&gt;
&lt;em&gt;Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, Wenwu Zhu.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/ma19a/ma19a.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Position-aware Graph Neural Networks.&lt;/strong&gt;
&lt;em&gt;Jiaxuan You, Rex Ying, Jure Leskovec.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/you19b/you19b.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing.&lt;/strong&gt;
&lt;em&gt;Sami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Kristina Lerman, Hrayr Harutyunyan, Greg Ver Steeg, Aram Galstyan.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/abu-el-haija19a/abu-el-haija19a.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph U-Nets.&lt;/strong&gt;
&lt;em&gt;Hongyang Gao, Shuiwang Ji.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/gao19a/gao19a.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Self-Attention Graph Pooling.&lt;/strong&gt;
&lt;em&gt;Junhyun Lee, Inyeop Lee, Jaewoo Kang.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/lee19c/lee19c.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking.&lt;/strong&gt;
&lt;em&gt;Aleksandar Bojchevski, Stephan Günnemann.&lt;/em&gt; ICLR 2018. &lt;a href="https://arxiv.org/pdf/1707.03815.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling.&lt;/strong&gt;
&lt;em&gt;Jie Chen, Tengfei Ma, Cao Xiao.&lt;/em&gt; ICLR 2018. &lt;a href="https://arxiv.org/pdf/1801.10247.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Attention Networks.&lt;/strong&gt;
&lt;em&gt;Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, Yoshua Bengio.&lt;/em&gt; ICLR 2018. &lt;a href="https://arxiv.org/pdf/1710.10903.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stochastic Training of Graph Convolutional Networks with Variance Reduction.&lt;/strong&gt;
&lt;em&gt;Jianfei Chen, Jun Zhu, Le Song.&lt;/em&gt; ICML 2018. &lt;a href="https://arxiv.org/pdf/1710.10568.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarially Regularized Graph Autoencoder for Graph Embedding.&lt;/strong&gt;
&lt;em&gt;Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, Lina Yao, Chengqi Zhang.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0362.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Discrete Network Embedding.&lt;/strong&gt;
&lt;em&gt;Xiaobo Shen, Shirui Pan, Weiwei Liu, Yew-Soon Ong, Quan-Sen Sun.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0493.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feature Hashing for Network Representation Learning.&lt;/strong&gt;
&lt;em&gt;Qixiang Wang, Shanfeng Wang, Maoguo Gong, Yue Wu.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0390.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Inductive Network Representation Learning.&lt;/strong&gt;
&lt;em&gt;Ryan A. Rossi, Rong Zhou, Nesreen K. Ahmed.&lt;/em&gt; WWW 2018. &lt;a href="http://ryanrossi.com/pubs/rossi-et-al-WWW18-BigNet.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Active Discriminative Network Representation Learning.&lt;/strong&gt;
&lt;em&gt;Li Gao, Hong Yang, Chuan Zhou, Jia Wu, Shirui Pan, Yue Hu.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0296.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MILE: A Multi-Level Framework for Scalable Graph Embedding.&lt;/strong&gt;
&lt;em&gt;Jiongqian Liang, Saket Gurukar, Srinivasan Parthasarathy.&lt;/em&gt; arxiv 2018. &lt;a href="https://arxiv.org/pdf/1802.09612.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Out-of-sample extension of graph adjacency spectral embedding.&lt;/strong&gt;
&lt;em&gt;Keith Levin, Farbod Roosta-Khorasani, Michael W. Mahoney, Carey E. Priebe.&lt;/em&gt; ICML 2018. &lt;a href="https://arxiv.org/pdf/1802.06307.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DeepWalk: Online Learning of Social Representations.&lt;/strong&gt;
&lt;em&gt;Bryan Perozzi, Rami Al-Rfou, Steven Skiena.&lt;/em&gt; KDD 2014. &lt;a href="https://arxiv.org/pdf/1403.6652" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/phanein/deepwalk"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Non-transitive Hashing with Latent Similarity Componets.&lt;/strong&gt;
&lt;em&gt;Mingdong Ou, Peng Cui, Fei Wang, Jun Wang, Wenwu Zhu.&lt;/em&gt; KDD 2015. &lt;a href="http://cuip.thumedialab.com/papers/KDD-NonTransitiveHashing.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GraRep: Learning Graph Representations with Global Structural Information.&lt;/strong&gt;
&lt;em&gt;Shaosheng Cao, Wei Lu, Qiongkai Xu.&lt;/em&gt; CIKM 2015. &lt;a href="https://www.researchgate.net/profile/Qiongkai_Xu/publication/301417811_GraRep/links/5847ecdb08ae8e63e633b5f2/GraRep.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/ShelsonCao/GraRep"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LINE: Large-scale Information Network Embedding.&lt;/strong&gt;
&lt;em&gt;Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Qiaozhu Me.&lt;/em&gt; WWW 2015. &lt;a href="https://arxiv.org/pdf/1503.03578.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/tangjianpku/LINE"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Neural Networks for Learning Graph Representations.&lt;/strong&gt;
&lt;em&gt;Shaosheng Cao, Wei Lu, Xiongkai Xu.&lt;/em&gt; AAAI 2016. &lt;a href="https://pdfs.semanticscholar.org/1a37/f07606d60df365d74752857e8ce909f700b3.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/ShelsonCao/DNGR"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Revisiting Semi-supervised Learning with Graph Embeddings.&lt;/strong&gt;
&lt;em&gt;Zhilin Yang, William W. Cohen, Ruslan Salakhutdinov.&lt;/em&gt; ICML 2016. &lt;a href="http://www.jmlr.org/proceedings/papers/v48/yanga16.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Max-Margin DeepWalk: Discriminative Learning of Network Representation.&lt;/strong&gt;
&lt;em&gt;Cunchao Tu, Weicheng Zhang, Zhiyuan Liu, Maosong Sun.&lt;/em&gt; IJCAI 2016. &lt;a href="http://thunlp.org/~tcc/publications/ijcai2016_mmdw.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/thunlp/mmdw"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Discriminative Deep RandomWalk for Network Classification.&lt;/strong&gt;
&lt;em&gt;Juzheng Li, Jun Zhu, Bo Zhang.&lt;/em&gt; ACL 2016. &lt;a href="http://www.aclweb.org/anthology/P16-1095" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Structural Deep Network Embedding.&lt;/strong&gt;
&lt;em&gt;Daixin Wang, Peng Cui, Wenwu Zhu.&lt;/em&gt; KDD 2016. &lt;a href="http://cuip.thumedialab.com/papers/SDNE.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Structural Neighborhood Based Classification of Nodes in a Network.&lt;/strong&gt;
&lt;em&gt;Sharad Nandanwar, M. N. Murty.&lt;/em&gt; KDD 2016. &lt;a href="http://www.kdd.org/kdd2016/papers/files/Paper_679.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Community Preserving Network Embedding.&lt;/strong&gt;
&lt;em&gt;Xiao Wang, Peng Cui, Jing Wang, Jian Pei, Wenwu Zhu, Shiqiang Yang.&lt;/em&gt; AAAI 2017. &lt;a href="http://cuip.thumedialab.com/papers/NE-Community.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Semi-supervised Classification with Graph Convolutional Networks.&lt;/strong&gt;
&lt;em&gt;Thomas N. Kipf, Max Welling.&lt;/em&gt; ICLR 2017. &lt;a href="https://arxiv.org/pdf/1609.02907.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/tkipf/gcn"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fast Network Embedding Enhancement via High Order Proximity Approximation.&lt;/strong&gt;
&lt;em&gt;Cheng Yang, Maosong Sun, Zhiyuan Liu, Cunchao Tu.&lt;/em&gt; IJCAI 2017. &lt;a href="http://thunlp.org/~tcc/publications/ijcai2017_neu.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/thunlp/neu"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CANE: Context-Aware Network Embedding for Relation Modeling.&lt;/strong&gt;
&lt;em&gt;Cunchao Tu, Han Liu, Zhiyuan Liu, Maosong Sun.&lt;/em&gt; ACL 2017. &lt;a href="http://thunlp.org/~tcc/publications/acl2017_cane.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/thunlp/cane"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A General View for Network Embedding as Matrix Factorization.&lt;/strong&gt;
&lt;em&gt;Xin Liu, Tsuyoshi Murata, Kyoung-Sook Kim, Chatchawan Kotarasu, Chenyi Zhuang.&lt;/em&gt; WSDM 2019. &lt;a href="https://dl.acm.org/citation.cfm?doid=3289600.3291029" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Co-Embedding Attributed Networks.&lt;/strong&gt;
&lt;em&gt;Zaiqiao Meng, Shangsong Liang, Xiangliang Zhang, Hongyan Bao.&lt;/em&gt; WSDM 2019. &lt;a href="https://mine.kaust.edu.sa/Documents/papers/WSDM19attribute.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Enhanced Network Embeddings via Exploiting Edge Labels.&lt;/strong&gt;
&lt;em&gt;Haochen Chen, Xiaofei Sun, Yingtao Tian, Bryan Perozzi, Muhao Chen, Steven Skiena.&lt;/em&gt; CIKM 2018. &lt;a href="https://arxiv.org/pdf/1809.05124.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Improve Network Embeddings with Regularization.&lt;/strong&gt;
&lt;em&gt;Yi Zhang, Jianguo Lu, Ofer Shai.&lt;/em&gt; CIKM 2018. &lt;a href="https://jlu.myweb.cs.uwindsor.ca/n2v.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Modeling Multi-way Relations with Hypergraph Embedding.&lt;/strong&gt;
&lt;em&gt;Chia-An Yu, Ching-Lun Tai, Tak-Shing Chan, Yi-Hsuan Yang.&lt;/em&gt; CIKM 2018. &lt;a href="https://dl.acm.org/citation.cfm?id=3269274" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/chia-an/HGE"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;REGAL: Representation Learning-based Graph Alignment.&lt;/strong&gt;
&lt;em&gt;Mark Heimann, Haoming Shen, Tara Safavi, Danai Koutra.&lt;/em&gt; CIKM 2018. &lt;a href="https://arxiv.org/pdf/1802.06257.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Network Embedding.&lt;/strong&gt;
&lt;em&gt;Quanyu Dai, Qiang Li, Jian Tang, Dan Wang.&lt;/em&gt; AAAI 2018. &lt;a href="https://arxiv.org/pdf/1711.07838.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/sachinbiradar9/Adverserial-Inductive-Deep-Walk"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bernoulli Embeddings for Graphs.&lt;/strong&gt;
&lt;em&gt;Vinith Misra, Sumit Bhatia.&lt;/em&gt; AAAI 2018. &lt;a href="http://sumitbhatia.net/papers/aaai18.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GraphGAN: Graph Representation Learning with Generative Adversarial Nets.&lt;/strong&gt;
&lt;em&gt;Hongwei Wang, jia Wang, jialin Wang, MIAO ZHAO, Weinan Zhang, Fuzheng Zhang, Xie Xing, Minyi Guo.&lt;/em&gt; AAAI 2018. &lt;a href="https://arxiv.org/pdf/1711.08267.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HARP: Hierarchical Representation Learning for Networks.&lt;/strong&gt;
&lt;em&gt;Haochen Chen, Bryan Perozzi, Yifan Hu, Steven Skiena.&lt;/em&gt; AAAI 2018. &lt;a href="https://arxiv.org/pdf/1706.07845.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/GTmac/HARP"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Social Rank Regulated Large-scale Network Embedding.&lt;/strong&gt;
&lt;em&gt;Yupeng Gu, Yizhou Sun, Yanen Li, Yang Yang.&lt;/em&gt; WWW 2018. &lt;a href="http://yangy.org/works/ge/rare.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Latent Network Summarization: Bridging Network Embedding and Summarization.&lt;/strong&gt;
&lt;em&gt;Di Jin,Ryan Rossi,Danai Koutra,Eunyee Koh,Sungchul Kim,Anup Rao&lt;/em&gt; KDD 2019. &lt;a href="https://arxiv.org/pdf/1811.04461.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NodeSketch: Highly-Efficient Graph Embeddings via Recursive Sketching.&lt;/strong&gt;
&lt;em&gt;Dingqi Yang,Paolo Rosso,Bin Li,Philippe Cudre-Mauroux.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330951/p1162-yang.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ProGAN: Network Embedding via Proximity Generative Adversarial Network.&lt;/strong&gt;
&lt;em&gt;Hongchang Gao,Jian Pei,Heng Huang.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330866/p1308-gao.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalable Global Alignment Graph Kernel Using Random Features: From Node Embedding to Graph Embedding.&lt;/strong&gt;
&lt;em&gt;Lingfei Wu,Ian En-Hsu Yen,Zhen Zhang,Kun Xu,Liang Zhao,Xi Peng,Yinglong Xia,Charu Aggarwal.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330918/p1418-wu.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalable Graph Embeddings via Sparse Transpose Proximities.&lt;/strong&gt;
&lt;em&gt;Yuan Yin,Zhewei Wei.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330860/p1429-yin.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;AutoNRL: Hyperparameter Optimization for Massive Network Representation Learning.&lt;/strong&gt;
&lt;em&gt;Ke Tu,Jianxin Ma,Peng Cui,Jian Pei,Wenwu Zhu.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330848/p216-tu.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Representation Learning via Hard and Channel-Wise Attention Networks.&lt;/strong&gt;
&lt;em&gt;Hongyang Gao,Shuiwang Ji.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330897/p741-gao.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Training Methods for Network Embedding.&lt;/strong&gt;
&lt;em&gt;Quanyu Dai,Xiao Shen,Liang Zhang,Qiang Li,Dan Wang.&lt;/em&gt; WWW 2019. &lt;a href="https://arxiv.org/pdf/1908.11514.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multi-relational Network Embeddings with Relational Proximity and Node Attributes.&lt;/strong&gt;
&lt;em&gt;Ming-Han Feng,Chin-Chi Hsu,Cheng-Te Li,Mi-Yen Yeh,Shou-De Lin.&lt;/em&gt; WWW 2019. &lt;a href="https://pdfs.semanticscholar.org/6274/3cbebc142897c6c005f3c12c00b9202ca43f.pdf?_ga=2.108748866.1527570260.1569422306-1231101604.1568798295" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sampled in Pairs and Driven by Text: A New Graph Embedding Framework.&lt;/strong&gt;
&lt;em&gt;Liheng Chen,Yanru Qu,Zhenghui Wang,Weinan Zhang,Ken Chen,Shaodian Zhang,Yong Yu.&lt;/em&gt; WWW 2019. &lt;a href="https://sci-hub.tw/10.1145/3308558.3313520#" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DDGK: Learning Graph Representations via Deep Divergence Graph Kernels.&lt;/strong&gt;
&lt;em&gt;Rami Al-Rfou,Dustin Zelle,Bryan Perozzi.&lt;/em&gt; WWW 2019. &lt;a href="https://arxiv.org/pdf/1904.09671.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tag2Vec: Learning Tag Representations in Tag Networks.&lt;/strong&gt;
&lt;em&gt;Junshan Wang,Zhicong Lu,Guojia Song,Yue Fan,Lun Du,Wei Lin.&lt;/em&gt; WWW 2019. &lt;a href="https://arxiv.org/pdf/1905.03041.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;struc2vec: Learning Node Representations from Structural Identity.&lt;/strong&gt;
&lt;em&gt;Leonardo F. R. Ribeiro, Pedro H. P. Saverese, Daniel R. Figueiredo.&lt;/em&gt; KDD 2017. &lt;a href="https://arxiv.org/pdf/1704.03165.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Inductive Representation Learning on Large Graphs.&lt;/strong&gt;
&lt;em&gt;William L. Hamilton, Rex Ying, Jure Leskovec.&lt;/em&gt; NIPS 2017. &lt;a href="https://arxiv.org/pdf/1706.02216.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Graph Embeddings with Embedding Propagation.&lt;/strong&gt;
&lt;em&gt;Alberto Garcia Duran, Mathias Niepert.&lt;/em&gt; NIPS 2017. &lt;a href="https://arxiv.org/pdf/1710.03059.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Enhancing the Network Embedding Quality with Structural Similarity.&lt;/strong&gt;
&lt;em&gt;Tianshu Lyu, Yuan Zhang, Yan Zhang.&lt;/em&gt; CIKM 2017. &lt;a href="https://pdfs.semanticscholar.org/e54a/374d7e24260450e2081b93005a491d1b9116.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;An Attention-based Collaboration Framework for Multi-View Network Representation Learning.&lt;/strong&gt;
&lt;em&gt;Meng Qu, Jian Tang, Jingbo Shang, Xiang Ren, Ming Zhang, Jiawei Han.&lt;/em&gt; CIKM 2017. &lt;a href="https://arxiv.org/pdf/1709.06636.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;On Embedding Uncertain Graphs.&lt;/strong&gt;
&lt;em&gt;Jiafeng Hu, Reynold Cheng, Zhipeng Huang, Yixang Fang, Siqiang Luo.&lt;/em&gt; CIKM 2017. &lt;a href="https://i.cs.hku.hk/~zphuang/pub/CIKM17.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec.&lt;/strong&gt;
&lt;em&gt;Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, Jie Tang.&lt;/em&gt; WSDM 2018. &lt;a href="https://arxiv.org/pdf/1710.02971.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Conditional Network Embeddings.&lt;/strong&gt;
&lt;em&gt;Bo Kang, Jefrey Lijffijt, Tijl De Bie.&lt;/em&gt; ICLR 2019. &lt;a href="https://arxiv.org/abs/1805.07544" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Graph Infomax.&lt;/strong&gt;
&lt;em&gt;Petar Veličković, William Fedus, William L. Hamilton, Pietro Liò, Yoshua Bengio, R Devon Hjelm.&lt;/em&gt; ICLR 2019. &lt;a href="https://arxiv.org/abs/1809.10341" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Anonymous Walk Embeddings.&lt;/strong&gt;
&lt;em&gt;Sergey Ivanov, Evgeny Burnaev.&lt;/em&gt; ICML 2018. &lt;a href="https://arxiv.org/pdf/1805.11921.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fairwalk: Towards Fair Graph Embedding.&lt;/strong&gt;
&lt;em&gt;Tahleen Rahman, Bartlomiej Surma, Michael Backes, Yang Zhang.&lt;/em&gt; IJCAI 2019. &lt;a href="https://yangzhangalmo.github.io/papers/IJCAI19.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph and Autoencoder Based Feature Extraction for Zero-shot Learning.&lt;/strong&gt;
&lt;em&gt;Yang Liu, Deyan Xie, Quanxue Gao, Jungong Han, Shujian Wang, Xinbo Gao.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0421.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Space Embedding.&lt;/strong&gt;
&lt;em&gt;João Pereira, Evgeni Levin, Erik Stroes, Albert Groen.&lt;/em&gt; IJCAI 2019. &lt;a href="https://arxiv.org/abs/1907.13443" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Arbitrary-Order Proximity Preserved Network Embedding.&lt;/strong&gt;
&lt;em&gt;Ziwei Zhang, Peng Cui, Xiao Wang, Jian Pei, Xuanrong Yao, Wenwu Zhu.&lt;/em&gt; KDD 2018. &lt;a href="http://cuip.thumedialab.com/papers/NE-ArbitraryProximity.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Variational Network Embedding in Wasserstein Space.&lt;/strong&gt;
&lt;em&gt;Dingyuan Zhu, Peng Cui, Daixin Wang, Wenwu Zhu.&lt;/em&gt; KDD 2018. &lt;a href="http://cuip.thumedialab.com/papers/NE-DeepVariational.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MEGAN: A Generative Adversarial Network for Multi-View Network Embedding.&lt;/strong&gt;
&lt;em&gt;Yiwei Sun, Suhang Wang, Tsung-Yu Hsieh, Xianfeng Tang, Vasant Honavar.&lt;/em&gt; IJCAI 2019. &lt;a href="https://arxiv.org/abs/1909.01084" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network Embedding under Partial Monitoring for Evolving Networks&lt;/strong&gt;
&lt;em&gt;Yu Han, Jie Tang, Qian Chen.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0342.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network Embedding with Dual Generation Tasks.&lt;/strong&gt;
&lt;em&gt;Jie Liu, Na Li, Zhicheng He.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0709.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Triplet Enhanced AutoEncoder: Model-free Discriminative Network Embedding.&lt;/strong&gt;
&lt;em&gt;Yao Yang, Haoran Chen, Junming Shao.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0745.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Recursive Network Embedding with Regular Equivalence.&lt;/strong&gt;
&lt;em&gt;Ke Tu, Peng Cui, Xiao Wang, Philip S. Yu, Wenwu Zhu.&lt;/em&gt; KDD 2018. &lt;a href="http://cuip.thumedialab.com/papers/NE-RegularEquivalence.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Structural Node Embeddings via Diffusion Wavelets.&lt;/strong&gt;
&lt;em&gt;Claire Donnat, Marinka Zitnik, David Hallac, Jure Leskovec.&lt;/em&gt; KDD 2018. &lt;a href="https://arxiv.org/pdf/1710.10321.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Self-Paced Network Embedding.&lt;/strong&gt;
&lt;em&gt;Hongchang Gao, Heng Huang.&lt;/em&gt; KDD 2018. &lt;a href="https://par.nsf.gov/servlets/purl/10074506" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Deep Network Representations with Adversarially Regularized Autoencoders.&lt;/strong&gt;
&lt;em&gt;Wenchao Yu, Cheng Zheng, Wei Cheng, Charu Aggarwal, Dongjin Song, Bo Zong, Haifeng Chen, Wei Wang.&lt;/em&gt; KDD 2018. &lt;a href="https://sites.cs.ucsb.edu/~bzong/doc/kdd-18.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Large-Scale Learnable Graph Convolutional Networks.&lt;/strong&gt;
&lt;em&gt;Hongyang Gao, Zhengyang Wang, Shuiwang Ji.&lt;/em&gt; KDD 2018. &lt;a href="https://arxiv.org/pdf/1808.03965" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-attributed-network" class="anchor" aria-hidden="true" href="#attributed-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Attributed Network&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Outlier Aware Network Embedding for Attributed Networks.&lt;/strong&gt;
&lt;em&gt;Sambaran Bandyopadhyay, N. Lokesh, M. N. Murty.&lt;/em&gt; AAAI 2019. &lt;a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/3763" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Large-Scale Heterogeneous Feature Embedding.&lt;/strong&gt;
&lt;em&gt;Xiao Huang, Qingquan Song, Fan Yang, Xia Hu.&lt;/em&gt; AAAI 2019. &lt;a href="https://aaai.org/ojs/index.php/AAAI/article/view/4276" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Bayesian Optimization on Attributed Graphs.&lt;/strong&gt;
&lt;em&gt;Jiaxu Cui, Bo Yang, Xia Hu.&lt;/em&gt; AAAI 2019. &lt;a href="https://arxiv.org/pdf/1905.13403.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Efficient Attributed Network Embedding via Recursive Randomized Hashing.&lt;/strong&gt;
&lt;em&gt;Wei Wu, Bin Li, Ling Chen, Chengqi Zhang.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0397.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Attributed Network Embedding.&lt;/strong&gt;
&lt;em&gt;Hongchang Gao, Heng Huang.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0467.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ANRL: Attributed Network Representation Learning via Deep Neural Networks.&lt;/strong&gt;
&lt;em&gt;Zhen Zhang, Hongxia Yang, Jiajun Bu, Sheng Zhou, Pinggang Yu, Jianwei Zhang, Martin Ester, Can Wang.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0438.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Integrative Network Embedding via Deep Joint Reconstruction.&lt;/strong&gt;
&lt;em&gt;Di Jin, Meng Ge, Liang Yang, Dongxiao He, Longbiao Wang, Weixiong Zhang.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0473.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;node2vec: Scalable Feature Learning for Networks.&lt;/strong&gt;
&lt;em&gt;Aditya Grover, Jure Leskovec.&lt;/em&gt; KDD 2016. &lt;a href="http://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/aditya-grover/node2vec"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network Representation Learning with Rich Text Information.&lt;/strong&gt;
&lt;em&gt;Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, Edward Y. Chang.&lt;/em&gt; IJCAI 2015. &lt;a href="http://thunlp.org/~yangcheng/publications/ijcai15.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/thunlp/tadw"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tri-Party Deep Network Representation.&lt;/strong&gt;
&lt;em&gt;Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang, Yang Wang.&lt;/em&gt; IJCAI 2016. &lt;a href="https://www.ijcai.org/Proceedings/16/Papers/271.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TransNet: Translation-Based Network Representation Learning for Social Relation Extraction.&lt;/strong&gt;
&lt;em&gt;Cunchao Tu, Zhengyan Zhang, Zhiyuan Liu, Maosong Sun.&lt;/em&gt; IJCAI 2017. &lt;a href="http://thunlp.org/~tcc/publications/ijcai2017_transnet.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/thunlp/transnet"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PRRE: Personalized Relation Ranking Embedding for Attributed Networks.&lt;/strong&gt;
&lt;em&gt;Sheng Zhou, Hongxia Yang, Xin Wang, Jiajun Bu, Martin Ester, Pinggang Yu, Jianwei Zhang, Can Wang.&lt;/em&gt; CIKM 2018. &lt;a href="https://dl.acm.org/citation.cfm?id=3271741" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/zhoushengisnoob/PRRE"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RSDNE: Exploring Relaxed Similarity and Dissimilarity from Completely-imbalanced Labels for Network Embedding.&lt;/strong&gt;
&lt;em&gt;Zheng Wang, Xiaojun Ye, Chaokun Wang, YueXin Wu, Changping Wang, Kaiwen Liang.&lt;/em&gt; AAAI 2018. &lt;a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16062/15722" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/zhengwang100/RSDNE"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Semi-supervised embedding in attributed networks with outliers.&lt;/strong&gt;
&lt;em&gt;Jiongqian Liang, Peter Jacobs, Jiankai Sun, and Srinivasan Parthasarathy.&lt;/em&gt; SDM 2018. &lt;a href="https://arxiv.org/pdf/1703.08100.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="http://jiongqianliang.com/SEANO/" rel="nofollow"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A Representation Learning Framework for Property Graphs.&lt;/strong&gt;
&lt;em&gt;Yifan Hou,Hongzhi Chen,Changji Li,James Cheng,Ming-Chang Yang.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330948/p65-hou.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning from Labeled and Unlabeled Vertices in Networks.&lt;/strong&gt;
&lt;em&gt;Wei Ye, Linfei Zhou, Dominik Mautz, Claudia Plant, Christian B?hm.&lt;/em&gt; KDD 2017. &lt;a href="https://dl.acm.org/citation.cfm?id=3098142" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Label Informed Attributed Network Embedding.&lt;/strong&gt;
&lt;em&gt;Xiao Huang, Jundong Li, Xia Hu.&lt;/em&gt; WSDM 2017. &lt;a href="http://www.public.asu.edu/~jundongl/paper/WSDM17_LANE.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Accelerated Attributed Network Embedding.&lt;/strong&gt;
&lt;em&gt;Xiao Huang, Jundong Li, Xia Hu.&lt;/em&gt; SDM 2017. &lt;a href="http://www.public.asu.edu/~jundongl/paper/SDM17_AANE.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Variation Autoencoder Based Network Representation Learning for Classification.&lt;/strong&gt;
&lt;em&gt;Hang Li, Haozheng Wang, Zhenglu Yang, Masato Odagaki.&lt;/em&gt; ACL 2017. &lt;a href="https://aclweb.org/anthology/P17-3010" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Attributed Signed Network Embedding.&lt;/strong&gt;
&lt;em&gt;Suhang Wang, Charu Aggarwal, Jiliang Tang, Huan Liu.&lt;/em&gt; CIKM 2017. &lt;a href="https://suhangwang.ist.psu.edu/publications/SNEA.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;From Properties to Links: Deep Network Embedding on Incomplete Graphs.&lt;/strong&gt;
&lt;em&gt;Dejian Yang, Senzhang Wang, Chaozhuo Li, Xiaoming Zhang, Zhoujun Li.&lt;/em&gt; CIKM 2017. &lt;a href="https://dl.acm.org/citation.cfm?id=3132847.3132975" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Exploring Expert Cognition for Attributed Network Embedding.&lt;/strong&gt;
&lt;em&gt;Xiao Huang, Qingquan Song, Jundong Li, Xia Ben Hu.&lt;/em&gt; WSDM 2018. &lt;a href="http://www.public.asu.edu/~jundongl/paper/WSDM18_NEEC.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical Taxonomy Aware Network Embedding.&lt;/strong&gt;
&lt;em&gt;Jianxin Ma, Peng Cui, Xiao Wang, Wenwu Zhu.&lt;/em&gt; KDD 2018. &lt;a href="https://jianxinma.github.io/assets/NetHiex.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network-Specific Variational Auto-Encoder for Embedding in Attribute Networks.&lt;/strong&gt;
&lt;em&gt;Di Jin, Bingyi Li, Pengfei Jiao, Dongxiao He, Weixiong Zhang.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0370.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SPINE: Structural Identity Preserved Inductive Network Embedding.&lt;/strong&gt;
&lt;em&gt;Junliang Guo, Linli Xu, Jingchang Liu.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0333.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Content to Node: Self-translation Network Embedding.&lt;/strong&gt;
&lt;em&gt;Jie Liu, Zhicheng He, Lai Wei, Yalou Huang.&lt;/em&gt; KDD 2018. &lt;a href="https://dl.acm.org/citation.cfm?id=3219988" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-dynamic-network" class="anchor" aria-hidden="true" href="#dynamic-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Dynamic Network&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Network Embedding : An Extended Approach for Skip-gram based Network Embedding.&lt;/strong&gt;
&lt;em&gt;Lun Du, Yun Wang, Guojie Song, Zhicong Lu, Junshan Wang.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0288.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Network Embedding by Modeling Triadic Closure Process.&lt;/strong&gt;
&lt;em&gt;Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, Yueting Zhuang.&lt;/em&gt; AAAI 2018. &lt;a href="http://yangy.org/works/dynamictriad/dynamic_triad.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DepthLGP: Learning Embeddings of Out-of-Sample Nodes in Dynamic Networks.&lt;/strong&gt;
&lt;em&gt;Jianxin Ma, Peng Cui, Wenwu Zhu.&lt;/em&gt; AAAI 2018. &lt;a href="https://jianxinma.github.io/assets/DepthLGP.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TIMERS: Error-Bounded SVD Restart on Dynamic Networks.&lt;/strong&gt;
&lt;em&gt;Ziwei Zhang, Peng Cui, Jian Pei, Xiao Wang, Wenwu Zhu.&lt;/em&gt; AAAI 2018. &lt;a href="https://arxiv.org/pdf/1711.09541.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks.&lt;/strong&gt;
&lt;em&gt;Srijan Kumar,Xikun Zhang,Jure Leskovec.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330895/p1269-kumar.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Attributed Network Embedding for Learning in a Dynamic Environment.&lt;/strong&gt;
&lt;em&gt;Jundong Li, Harsh Dani, Xia Hu, Jiliang Tang, Yi Chang, Huan Liu.&lt;/em&gt; CIKM 2017. &lt;a href="https://arxiv.org/pdf/1706.01860.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DyRep: Learning Representations over Dynamic Graphs.&lt;/strong&gt;
&lt;em&gt;Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, Hongyuan Zha.&lt;/em&gt; ICLR 2019. &lt;a href="https://openreview.net/forum?id=HyePrhR5KX" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Embedding Temporal Network via Neighborhood Formation.&lt;/strong&gt;
&lt;em&gt;Yuan Zuo, Guannan Liu, Hao Lin, Jia Guo, Xiaoqian Hu, Junjie Wu.&lt;/em&gt; KDD 2018. &lt;a href="https://zuoyuan.github.io/files/htne_kdd18.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Node Embedding over Temporal Graphs.&lt;/strong&gt;
&lt;em&gt;Uriel Singer, Ido Guy, Kira Radinsky.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0640.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Embeddings for User Profiling in Twitter.&lt;/strong&gt;
&lt;em&gt;Shangsong Liang, Xiangliang Zhang, Zhaochun Ren, Evangelos Kanoulas.&lt;/em&gt; KDD 2018. &lt;a href="https://repository.kaust.edu.sa/bitstream/handle/10754/628781/p1764-liang.pdf?sequence=1&amp;amp;isAllowed=y" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NetWalk: A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks.&lt;/strong&gt;
&lt;em&gt;Wenchao Yu, Wei Cheng, Charu Aggarwal, Kai Zhang, Haifeng Chen, Wei Wang.&lt;/em&gt; KDD 2018. &lt;a href="http://www.shichuan.org/hin/topic/Embedding/2018.KDD%202018%20NetWalk_A%20Flexible%20Deep%20Embedding%20Approach%20for%20Anomaly%20Detection%20in%20Dynamic%20Networks.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalable Optimization for Embedding Highly-Dynamic and Recency-Sensitive Data.&lt;/strong&gt;
&lt;em&gt;Xumin Chen, Peng Cui, Shiqiang Yang.&lt;/em&gt; KDD 2018. &lt;a href="http://pengcui.thumedialab.com/papers/NE-ScalableOptimization.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-heterogeneous-information-network" class="anchor" aria-hidden="true" href="#heterogeneous-information-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Heterogeneous Information Network&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Relation Structure-Aware Heterogeneous Information Network Embedding.&lt;/strong&gt;
&lt;em&gt;Yuanfu Lu, Chuan Shi, Linmei Hu, Zhiyuan Liu.&lt;/em&gt; AAAI 2019. &lt;a href="https://arxiv.org/abs/1905.08027" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hyperbolic Heterogeneous Information Network Embedding.&lt;/strong&gt;
&lt;em&gt;Xiao Wang, Yiding Zhang, Chuan Shi.&lt;/em&gt; AAAI 2019. &lt;a href="http://shichuan.org/doc/65.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Latent Representations of Nodes for Classifying in Heterogeneous Social Networks.&lt;/strong&gt;
&lt;em&gt;Yann Jacob, Ludovic Denoyer, Patrick Gallinar.&lt;/em&gt; WSDM 2014. &lt;a href="http://webia.lip6.fr/~gallinar/gallinari/uploads/Teaching/WSDM2014-jacob.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Heterogeneous Network Embedding via Deep Architectures.&lt;/strong&gt;
&lt;em&gt;Shiyu Chang, Wei Han, Jiliang Tang, Guo-Jun Qi, Charu C. Aggarwal, Thomas S. Huang.&lt;/em&gt; KDD 2015. &lt;a href="http://www.ifp.illinois.edu/~chang87/papers/kdd_2015.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;metapath2vec: Scalable Representation Learning for Heterogeneous Networks.&lt;/strong&gt;
&lt;em&gt;Yuxiao Dong, Nitesh V. Chawla, Ananthram Swami.&lt;/em&gt; KDD 2017. &lt;a href="https://www3.nd.edu/~dial/publications/dong2017metapath2vec.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://ericdongyx.github.io/metapath2vec/m2v.html" rel="nofollow"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SHNE: Representation Learning for Semantic-Associated Heterogeneous Networks.&lt;/strong&gt;
&lt;em&gt;Chuxu Zhang, Ananthram Swami, Nitesh V. Chawla.&lt;/em&gt; WSDM 2019. &lt;a href="https://dl.acm.org/citation.cfm?id=3291001" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/chuxuzhang/WSDM2019_SHNE"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Are Meta-Paths Necessary?: Revisiting Heterogeneous Graph Embeddings.&lt;/strong&gt;
&lt;em&gt;Rana Hussein, Dingqi Yang, Philippe Cudré-Mauroux.&lt;/em&gt; CIKM 2018. &lt;a href="https://exascale.info/assets/pdf/hussein2018cikm.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Abnormal Event Detection via Heterogeneous Information Network Embedding.&lt;/strong&gt;
&lt;em&gt;Shaohua Fan, Chuan Shi, Xiao Wang.&lt;/em&gt; CIKM 2018. &lt;a href="http://shichuan.org/doc/62.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multidimensional Network Embedding with Hierarchical Structures.&lt;/strong&gt;
&lt;em&gt;Yao Ma, Zhaochun Ren, Ziheng Jiang, Jiliang Tang, Dawei Yin.&lt;/em&gt; WSDM 2018. &lt;a href="http://cse.msu.edu/~mayao4/downloads/Multidimensional_Network_Embedding_with_Hierarchical_Structure.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Curriculum Learning for Heterogeneous Star Network Embedding via Deep Reinforcement Learning.&lt;/strong&gt;
&lt;em&gt;Meng Qu, Jian Tang, Jiawei Han.&lt;/em&gt; WSDM 2018. &lt;a href="http://delivery.acm.org/10.1145/3160000/3159711/p468-qu.pdf?ip=203.205.141.123&amp;amp;id=3159711&amp;amp;acc=ACTIVE%20SERVICE&amp;amp;key=39FCDE838982416F%2E39FCDE838982416F%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;amp;__acm__=1519788484_7383495a5c522cbe124e62e4d768f8cc" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Generative Adversarial Network based Heterogeneous Bibliographic Network Representation for Personalized Citation Recommendation.&lt;/strong&gt;
&lt;em&gt;J. Han, Xiaoyan Cai, Libin Yang.&lt;/em&gt; AAAI 2018. &lt;a href="https://pdfs.semanticscholar.org/1596/d6487012696ba400fb69904a2c372a08a2be.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Distance-aware DAG Embedding for Proximity Search on Heterogeneous Graphs.&lt;/strong&gt;
&lt;em&gt;Zemin Liu, Vincent W. Zheng, Zhou Zhao, Fanwei Zhu, Kevin Chen-Chuan Chang, Minghui Wu, Jing Ying.&lt;/em&gt; AAAI 2018. &lt;a href="https://pdfs.semanticscholar.org/b1cc/127a65c40e71121106d0c663f9b5baf9d6f9.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Representation Learning for Attributed Multiplex Heterogeneous Network.&lt;/strong&gt;
&lt;em&gt;Yukuo Cen,Xu Zou,Jianwei Zhang,Hongxia Yang,Jingren Zhou,Jie Tang.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330964/p1358-cen.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Learning on Heterogeneous Information Networks.&lt;/strong&gt;
&lt;em&gt;Binbin Hu,Yuan Fang,Chuan Shi&lt;/em&gt; KDD 2019 &lt;a href="http://delivery.acm.org/10.1145/3340000/3330970/p120-hu.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HetGNN: Heterogeneous Graph Neural Network.&lt;/strong&gt;
&lt;em&gt;Chuxu Zhang,Dongjin Song,Chao Huang,Ananthram Swami,Nitesh V. Chawla.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330961/p793-zhang.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;IntentGC: a Scalable Graph Convolution Framework Fusing Heterogeneous Information for Recommendation&lt;/strong&gt;
&lt;em&gt;Jun Zhao, Zhou Zhou, Ziyu Guan, Wei Zhao, Ning Wei, Guang Qiu and Xiaofei He.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330686/p2347-zhao.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation.&lt;/strong&gt;
&lt;em&gt;Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi, Linmei Hu, Biyu Ma and Yongliang Li.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330673/p2478-fan.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Your Style Your Identity: Leveraging Writing and Photography Styles for Drug Trafficker Identification in Darknet Markets over Attributed Heterogeneous Information Network.&lt;/strong&gt;
&lt;em&gt;Yiming Zhang, Yujie Fan,Wei Song, Shifu HouYanfang Ye, Xin Li,Liang Zhao,Chuan Shi,Jiabin Wang, Qi Xiong.&lt;/em&gt; WWW 2019. &lt;a href="https://www.gwern.net/docs/sr/2019-zhang.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning.&lt;/strong&gt;
&lt;em&gt;Tao-yang Fu, Wang-Chien Lee, Zhen Lei.&lt;/em&gt; CIKM 2017. &lt;a href="http://shichuan.org/hin/topic/Embedding/2017.%20CIKM%20HIN2Vec.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SHINE: Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction.&lt;/strong&gt;
&lt;em&gt;Hongwei Wang, Fuzheng Zhang, Min Hou, Xing Xie, Minyi Guo, Qi Liu.&lt;/em&gt; WSDM 2018. &lt;a href="https://arxiv.org/pdf/1712.00732.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ActiveHNE: Active Heterogeneous Network Embedding.&lt;/strong&gt;
&lt;em&gt;Xia Chen, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Zhao Li, Xiangliang Zhang.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0294.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Unified Embedding Model over Heterogeneous Information Network for Personalized Recommendation.&lt;/strong&gt;
&lt;em&gt;Zekai Wang, Hongzhi Liu, Yingpeng Du, Zhonghai Wu, Xing Zhang.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0529.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easing Embedding Learning by Comprehensive Transcription of Heterogeneous Information Networks.&lt;/strong&gt;
&lt;em&gt;Yu Shi, Qi Zhu, Fang Guo, Chao Zhang, Jiawei Han.&lt;/em&gt; KDD 2018. &lt;a href="https://yu-shi-homepage.github.io/kdd18.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PME: Projected Metric Embedding on Heterogeneous Networks for Link Prediction.&lt;/strong&gt;
&lt;em&gt;Hongxu Chen, Hongzhi Yin, Weiqing Wang, Hao Wang, Quoc Viet Hung Nguyen, Xue Li.&lt;/em&gt; KDD 2018. &lt;a href="http://net.pku.edu.cn/daim/hongzhi.yin/papers/KDD18-Hongxu.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-bipartite-network" class="anchor" aria-hidden="true" href="#bipartite-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Bipartite Network&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Collaborative Similarity Embedding for Recommender Systems.&lt;/strong&gt;
&lt;em&gt;Chih-Ming Chen,Chuan-Ju Wang,Ming-Feng Tsai,Yi-Hsuan Yang.&lt;/em&gt; WWW 2019. &lt;a href="https://arxiv.org/pdf/1902.06188.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Node Embeddings in Interaction Graphs.&lt;/strong&gt;
&lt;em&gt;Yao Zhang, Yun Xiong, Xiangnan Kong, Yangyong Zhu.&lt;/em&gt; CIKM 2017. &lt;a href="https://web.cs.wpi.edu/~xkong/publications/papers/cikm17.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical Representation Learning for Bipartite Graphs.&lt;/strong&gt;
&lt;em&gt;Chong Li, Kunyang Jia, Dan Shen, C.J. Richard Shi, Hongxia Yang.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0398.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-directed-network" class="anchor" aria-hidden="true" href="#directed-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Directed Network&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ATP: Directed Graph Embedding with Asymmetric Transitivity Preservation.&lt;/strong&gt;
&lt;em&gt;Jiankai Sun, Bortik Bandyopadhyay, Armin Bashizade, Jiongqian Liang, P. Sadayappan, Srinivasan Parthasarathy.&lt;/em&gt; AAAI 2019. &lt;a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/3794" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Asymmetric Transitivity Preserving Graph Embedding.&lt;/strong&gt;
&lt;em&gt;Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, Wenwu Zhu.&lt;/em&gt; KDD 2016. &lt;a href="http://cuip.thumedialab.com/papers/hoppe.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;"Bridge": Enhanced Signed Directed Network Embedding.&lt;/strong&gt;
&lt;em&gt;Yiqi Chen, Tieyun Qian, Huan Liu, Ke Sun.&lt;/em&gt; CIKM 2018. &lt;a href="https://dl.acm.org/citation.cfm?id=3271738" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SIDE: Representation Learning in Signed Directed Networks.&lt;/strong&gt;
&lt;em&gt;Junghwan Kim, Haekyu Park, Ji-Eun Lee, U Kang.&lt;/em&gt; WWW 2018. &lt;a href="https://datalab.snu.ac.kr/side/resources/side.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-other-models" class="anchor" aria-hidden="true" href="#other-models"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Other Models&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalable Multiplex Network Embedding. （Multiplex Network)&lt;/strong&gt;
&lt;em&gt;Hongming Zhang, Liwei Qiu, Lingling Yi, Yangqiu Song.&lt;/em&gt; IJCAI 2018. &lt;a href="http://www.cse.ust.hk/~yqsong/papers/2018-IJCAI-MultiplexNetworkEmbedding.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Structural Deep Embedding for Hyper-Networks. (Hyper-Network)&lt;/strong&gt;
&lt;em&gt;Ke Tu, Peng Cui, Xiao Wang, fei Wang, Wenwu Zhu.&lt;/em&gt; AAAI 2018. &lt;a href="https://arxiv.org/pdf/1711.10146.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Representation Learning for Scale-free Networks. (Scale-free Network)&lt;/strong&gt;
&lt;em&gt;Rui Feng, Yang Yang, Wenjie Hu, Fei Wu, Yueting Zhuang.&lt;/em&gt; AAAI 2018. &lt;a href="https://arxiv.org/pdf/1711.10755.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Co-Regularized Deep Multi-Network Embedding. (Multi-Network)&lt;/strong&gt;
&lt;em&gt;Jingchao Ni, Shiyu Chang, Xiao Liu, Wei Cheng, Haifeng Chen, Dongkuan Xu, Xiang Zhang.&lt;/em&gt; WWW 2018. &lt;a href="https://nijingchao.github.io/paper/www18_dmne.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Joint Link Prediction and Network Alignment via Cross-graph Embedding. (Multi-Network)&lt;/strong&gt;
&lt;em&gt;Xingbo Du, Junchi Yan, Hongyuan Zha.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0312.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DANE: Domain Adaptive Network Embedding. (Multi-Network)&lt;/strong&gt;
&lt;em&gt;Yizhou Zhang, Guojie Song, Lun Du, Shuwen Yang, Yilun Jin.&lt;/em&gt; IJCAI 2019. &lt;a href="https://arxiv.org/abs/1906.00684" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SPARC: Self-Paced Network Representation for Few-Shot Rare Category Characterization. (Few-Shot Learning)&lt;/strong&gt;
&lt;em&gt;Dawei Zhou, Jingrui He, Hongxia Yang, Wei Fan.&lt;/em&gt; KDD 2018. &lt;a href="https://dl.acm.org/authorize?N665885" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-applications" class="anchor" aria-hidden="true" href="#applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Applications&lt;/a&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-natural-language-processing" class="anchor" aria-hidden="true" href="#natural-language-processing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Natural Language Processing&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Personalized Question Routing via Heterogeneous Network Embedding.&lt;/strong&gt;
&lt;em&gt;Zeyu Li, Jyun-Yu Jiang, Yizhou Sun, Wei Wang.&lt;/em&gt; AAAI 2019. &lt;a href="http://web.cs.ucla.edu/~yzsun/papers/2019_AAAI_QR.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PTE: Predictive Text Embedding through Large-scale Heterogeneous Text Networks.&lt;/strong&gt;
&lt;em&gt;Jian Tang, Meng Qu, Qiaozhu Mei.&lt;/em&gt; KDD 2015. &lt;a href="https://arxiv.org/pdf/1508.00200.pdf" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/mnqu/PTE"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-knowledge-graph" class="anchor" aria-hidden="true" href="#knowledge-graph"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Knowledge Graph&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interaction Embeddings for Prediction and Explanation in Knowledge Graphs.&lt;/strong&gt;
&lt;em&gt;Wen Zhang, Bibek Paudel, Wei Zhang, Abraham Bernstein, Huajun Chen.&lt;/em&gt; WSDM 2019. &lt;a href="https://arxiv.org/pdf/1903.04750.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Shared Embedding Based Neural Networks for Knowledge Graph Completion.&lt;/strong&gt;
&lt;em&gt;Saiping Guan, Xiaolong Jin, Yuanzhuo Wang, Xueqi Cheng.&lt;/em&gt; CIKM 2018 &lt;a href="https://dl.acm.org/citation.cfm?id=3271705" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Re-evaluating Embedding-Based Knowledge Graph Completion Methods.&lt;/strong&gt;
&lt;em&gt;Farahnaz Akrami, Lingbing Guo, Wei Hu, Chengkai Li.&lt;/em&gt; CIKM 2018. &lt;a href="http://ranger.uta.edu/~cli/pubs/2018/kgcompletion-cikm18short-akrami.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-social-network" class="anchor" aria-hidden="true" href="#social-network"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Social Network&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Learning for Weakly-Supervised Social Network Alignment.&lt;/strong&gt;
&lt;em&gt;Chaozhuo Li, Senzhang Wang, Yukun Wang, Philip Yu, Yanbo Liang, Yun Liu, Zhoujun Li.&lt;/em&gt; AAAI 2019. &lt;a href="https://aaai.org/ojs/index.php/AAAI/article/view/3889" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TransConv: Relationship Embedding in Social Networks.&lt;/strong&gt;
&lt;em&gt;Yi-Yu Lai, Jennifer Neville, Dan Goldwasser.&lt;/em&gt; AAAI 2019. &lt;a href="https://aaai.org/ojs/index.php/AAAI/article/view/4314" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Semi-supervised User Geolocation via Graph Convolutional Networks.&lt;/strong&gt;
&lt;em&gt;Afshin Rahimi, Trevor Cohn, Timothy Baldwin.&lt;/em&gt; ACL 2018. &lt;a href="https://arxiv.org/pdf/1804.08049.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MASTER: across Multiple social networks, integrate Attribute and STructure Embedding for Reconciliation.&lt;/strong&gt;
&lt;em&gt;Sen Su, Li Sun, Zhongbao Zhang, Gen Li, Jielun Qu.&lt;/em&gt; IJCAI 2018. &lt;a href="https://www.ijcai.org/proceedings/2018/0537.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MEgo2Vec: Embedding Matched Ego Networks for User Alignment Across Social Networks.&lt;/strong&gt;
&lt;em&gt;Jing Zhang, Bo Chen, Xianming Wang, Hong Chen, Cuiping Li, Fengmei Jin, Guojie Song, Yutao Zhang.&lt;/em&gt; CIKM 2018. &lt;a href="https://dl.acm.org/citation.cfm?id=3271705" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Link Prediction via Subgraph Embedding-Based Convex Matrix Completion.&lt;/strong&gt;
&lt;em&gt;Zhu Cao, Linlin Wang, Gerard De melo.&lt;/em&gt; AAAI 2018. &lt;a href="http://iiis.tsinghua.edu.cn/~weblt/papers/link-prediction-subgraphembeddings.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;On Exploring Semantic Meanings of Links for Embedding Social Networks.&lt;/strong&gt;
&lt;em&gt;Linchuan Xu, Xiaokai Wei, Jiannong Cao, Philip S Yu.&lt;/em&gt; WWW 2018. &lt;a href="https://pdfs.semanticscholar.org/ccd3/ede78393628b5f0256ebfccbb4ac293394de.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network.&lt;/strong&gt;
&lt;em&gt;Hao Wang,Tong Xu,Qi Liu,Defu Lian,Enhong Chen,Dongfang Du,Han Wu,Wen Su.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330931/p1064-wang.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Unsupervised Feature Selection in Signed Social Networks.&lt;/strong&gt;
&lt;em&gt;Kewei Cheng, Jundong Li, Huan Liu.&lt;/em&gt; KDD 2017. &lt;a href="http://www.public.asu.edu/~jundongl/paper/KDD17_SignedFS.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Network Embedding with Community Structural Information.&lt;/strong&gt;
&lt;em&gt;Yu Li, Ying Wang, Tingting Zhang, Jiawei Zhang, Yi Chang.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0407.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-graph-clustering" class="anchor" aria-hidden="true" href="#graph-clustering"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Graph Clustering&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Spectral Clustering in Heterogeneous Information Networks.&lt;/strong&gt;
&lt;em&gt;Xiang Li , Ben Kao, Zhaochun Ren, Dawei Yin.&lt;/em&gt; AAAI 2019. &lt;a href="https://www.researchgate.net/profile/Xiang_Li238/publication/332606853_Spectral_Clustering_in_Heterogeneous_Information_Networks/links/5cc035e892851c8d2200aa29/Spectral-Clustering-in-Heterogeneous-Information-Networks.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multi-view Clustering with Graph Embedding for Connectome Analysis.&lt;/strong&gt;
&lt;em&gt;Guixiang Ma, Lifang He, Chun-Ta Lu, Weixiang Shao, Philip S Yu, Alex D Leow, Ann B Ragin.&lt;/em&gt; CIKM 2017. &lt;a href="https://www.cs.uic.edu/~clu/doc/cikm17_mcge.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Graph Embedding for Ensemble Clustering.&lt;/strong&gt;
&lt;em&gt;Zhiqiang Tao, Hongfu Liu, Jun Li, Zhaowen Wang, Yun Fu.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0494.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Variational Graph Embedding and Clustering with Laplacian Eigenmaps.&lt;/strong&gt;
&lt;em&gt;Zitai Chen, Chuan Chen, Zong Zhang, Zibin Zheng, Qingsong Zou.&lt;/em&gt; IJCAI 2019. &lt;a href="https://www.ijcai.org/proceedings/2019/0297.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-community-detection" class="anchor" aria-hidden="true" href="#community-detection"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Community Detection&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Incorporating Network Embedding into Markov Random Field for Better Community Detection.&lt;/strong&gt;
&lt;em&gt;Di Jin, Xinxin You, Weihao Li, Dongxiao He, Peng Cui, Francoise Fogelman-Soulie, Tanmoy Chakraborty.&lt;/em&gt; AAAI 2019. &lt;a href="http://pengcui.thumedialab.com/papers/NE-MRF.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A Unified Framework for Community Detection and Network Representation Learning.&lt;/strong&gt;
&lt;em&gt;Cunchao Tu, Xiangkai Zeng, Hao Wang, Zhengyan Zhang, Zhiyuan Liu, Maosong Sun, Bo Zhang, Leyu Lin.&lt;/em&gt; TKDE 2018. &lt;a href="https://ieeexplore.ieee.org/abstract/document/8403293/" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;COSINE: Community-Preserving Social Network Embedding from Information Diffusion Cascades.&lt;/strong&gt;
&lt;em&gt;Yuan Zhang, Tianshu Lyu, Yan Zhang.&lt;/em&gt; AAAI 2018. &lt;a href="https://pdfs.semanticscholar.org/fec8/24c51b59063ba92b66bb7404010954ced5ac.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multi-facet Network Embedding: Beyond the General Solution of Detection and Representation.&lt;/strong&gt;
&lt;em&gt;Liang Yang, Xiaochun Cao, Yuanfang Guo.&lt;/em&gt; AAAI 2018. &lt;a href="https://yangliang.github.io/pdf/aaai18.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Community Detection in Attributed Graphs: An Embedding Approach.&lt;/strong&gt;
&lt;em&gt;Ye Li, Chaofeng Sha, Xin Huang, Yanchun Zhang.&lt;/em&gt; AAAI 2018. &lt;a href="https://www.comp.hkbu.edu.hk/~xinhuang/publications/pdfs/AAAI18.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Preserving Proximity and Global Ranking for Node Embedding.&lt;/strong&gt;
&lt;em&gt;Yi-An Lai, Chin-Chi Hsu, Wenhao Chen, Mi-Yen Yeh, Shou-De Lin.&lt;/em&gt; NIPS 2017. &lt;a href="https://pdfs.semanticscholar.org/b692/c82115889115ef3e63fb7e6b23c8eb9c85b3.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Community Embedding with Community Detection and Node Embedding on Graphs.&lt;/strong&gt;
&lt;em&gt;Sandro Cavallari, Vincent W. Zheng, Hongyun Cai, Kevin ChenChuan Chang, Erik Cambria.&lt;/em&gt; CIKM 2017. &lt;a href="https://sentic.net/community-embedding.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-recommendation" class="anchor" aria-hidden="true" href="#recommendation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Recommendation&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Convolutional Neural Networks for Web-Scale Recommender Systems.&lt;/strong&gt;
&lt;em&gt;Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, Jure Leskovec.&lt;/em&gt; KDD 2018. &lt;a href="https://arxiv.org/pdf/1806.01973.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding.&lt;/strong&gt;
&lt;em&gt;Ninghao Liu,Qiaoyu Tan,Yuening Li,Hongxia Yang,Jingren Zhou,Xia Hu.&lt;/em&gt; KDD 2019. &lt;a href="https://arxiv.org/pdf/1905.10668.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender System.&lt;/strong&gt;
&lt;em&gt;Qitian Wu,Hengrui Zhang,Xiaofeng Gao,Peng He,Paul Weng,Han Gao,Guihai Chen.&lt;/em&gt; WWW 2019. &lt;a href="https://arxiv.org/pdf/1903.10433.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a id="user-content-other-applications" class="anchor" aria-hidden="true" href="#other-applications"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="#content"&gt;Other Applications&lt;/a&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cash-out User Detection based on Attributed Heterogeneous Information Network with a Hierarchical Attention Mechanism. (Finance)&lt;/strong&gt;
&lt;em&gt;Binbin Hu, Zhiqiang Zhang, Chuan Shi, Jun Zhou, Xiaolong Li, Yuan Qi.&lt;/em&gt; AAAI 2019. &lt;a href="http://shichuan.org/doc/64.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Building Causal Graphs from Medical Literature and Electronic Medical Records. (Medicine)&lt;/strong&gt;
&lt;em&gt;Galia Nordon, Gideon Koren, Varda Shalev, Benny Kimelfeld, Uri Shalit, Kira Radinsky.&lt;/em&gt; AAAI 2019. &lt;a href="http://www.kiraradinsky.com/files/aaai-building-causal.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Attacks on Node Embeddings via Graph Poisoning. (Adversarial)&lt;/strong&gt;
&lt;em&gt;Aleksandar Bojchevski, Stephan Günnemann.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/bojchevski19a/bojchevski19a.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Compositional Fairness Constraints for Graph Embeddings. (Adversarial)&lt;/strong&gt;
&lt;em&gt;Avishek Bose, William Hamilton.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/bose19a/bose19a.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gromov-Wasserstein Learning for Graph Matching and Node Embedding. (Graph Matching)&lt;/strong&gt;
&lt;em&gt;Hongteng Xu, Dixin Luo, Hongyuan Zha, Lawrence Carin Duke.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/xu19b/xu19b.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Matching Networks for Learning the Similarity of Graph Structured Objects. (Graph Matching)&lt;/strong&gt;
&lt;em&gt;Yujia Li, Chenjie Gu, Thomas Dullien, Oriol Vinyals, Pushmeet Kohli.&lt;/em&gt; ICML 2019. &lt;a href="http://proceedings.mlr.press/v97/li19d/li19d.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MolGAN: An implicit generative model for small molecular graphs. (Molecular Generation)&lt;/strong&gt;
&lt;em&gt;Nicola De Cao, Thomas Kipf.&lt;/em&gt; ICML Workshop 2018. &lt;a href="https://arxiv.org/pdf/1805.11973.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Relational recurrent neural networks. (Relational Reasoning)&lt;/strong&gt;
&lt;em&gt;Adam Santoro, Ryan Faulkner, David Raposo, Jack Rae, Mike Chrzanowski, Theophane Weber, Daan Wierstra, Oriol Vinyals, Razvan Pascanu, Timothy Lillicrap.&lt;/em&gt; NeurIPS 2018. &lt;a href="https://arxiv.org/pdf/1806.01822.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Constructing Narrative Event Evolutionary Graph for Script Event Prediction. (Script Event Prediction)&lt;/strong&gt;
&lt;em&gt;Zhongyang Li, Xiao Ding, Ting Liu.&lt;/em&gt; IJCAI 2018. &lt;a href="https://arxiv.org/abs/1805.05081" rel="nofollow"&gt;paper&lt;/a&gt; &lt;a href="https://github.com/eecrazy/ConstructingNEEG_IJCAI_2018"&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A Network-embedding Based Method for Author Disambiguation. (Author Disambiguation)&lt;/strong&gt;
&lt;em&gt;Jun Xu, Siqi Shen, Dongsheng Li, Yongquan Fu.&lt;/em&gt; CIKM 2018. &lt;a href="https://dl.acm.org/citation.cfm?id=3269272" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deep Graph Embedding for Ranking Optimization in E-commerce.(E-commerce)&lt;/strong&gt;
&lt;em&gt;Chen Chu, Zhao Li, Beibei Xin, Fengchao Peng, Chuanren Liu, Remo Rohs, Qiong Luo, Jingren Zhou.&lt;/em&gt; CIKM 2018. &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6330176/" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning Network-to-Network Model for Content-rich Network Embedding.&lt;/strong&gt;
&lt;em&gt;Zhicheng He,Jie Liu,Na Li,Yalou Huang.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330924/p1037-he.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Unifying Inter-region Autocorrelation and Intra-region Structures for Spatial Embedding via Collective Adversarial Learning.&lt;/strong&gt;
&lt;em&gt;Yunchao Zhang,Pengyang Wang,Xiaolin Li,Yu Zheng,Yanjie Fu.&lt;/em&gt; KDD 2019. &lt;a href="http://delivery.acm.org/10.1145/3340000/3330972/p1700-zhang.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Neural IR Meets Graph Embedding: A Ranking Model for Product Search.&lt;/strong&gt;
&lt;em&gt;Yuan Zhang,Dong Wang,Yan Zhang.&lt;/em&gt; WWW 2019. &lt;a href="https://arxiv.org/pdf/1901.08286.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cross-Network Embedding for Multi-Network Alignment.&lt;/strong&gt;
&lt;em&gt;Xiaokai Chu,Xinxin Fan,Di Yao,Zhihua Zhu,Jianhui Huang,Jingping Bi.&lt;/em&gt; WWW 2019. &lt;a href="https://sci-hub.tw/10.1145/3308558.3313499#" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Name Disambiguation in Anonymized Graphs using Network Embedding. (Name Disambiguation)&lt;/strong&gt;
&lt;em&gt;Baichuan Zhang, Mohammad Al Hasan.&lt;/em&gt; CIKM 2017. &lt;a href="https://arxiv.org/pdf/1702.02287.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NetGAN: Generating Graphs via Random Walks. (Graph Generation)&lt;/strong&gt;
&lt;em&gt;Aleksandar Bojchevski, Oleksandr Shchur, Daniel Zügner, Stephan Günnemann.&lt;/em&gt; ICML 2018. &lt;a href="https://arxiv.org/pdf/1803.00816" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Networks as Learnable Physics Engines for Inference and Control. (Physics)&lt;/strong&gt;
&lt;em&gt;Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, Peter Battaglia.&lt;/em&gt; ICML 2018. &lt;a href="https://arxiv.org/pdf/1806.01242.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Relational inductive bias for physical construction in humans and machines. (Human physical reasoning)&lt;/strong&gt;
&lt;em&gt;Jessica B. Hamrick, Kelsey R. Allen, Victor Bapst, Tina Zhu, Kevin R. McKee, Joshua B. Tenenbaum, Peter W. Battaglia.&lt;/em&gt; CogSci 2018. &lt;a href="https://arxiv.org/pdf/1806.01203.pdf" rel="nofollow"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>thunlp</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>hmemcpy/milewski-ctfp-pdf #9 in TeX, Today</title><link>https://github.com/hmemcpy/milewski-ctfp-pdf</link><description>&lt;p&gt;&lt;i&gt;Bartosz Milewski's 'Category Theory for Programmers' unofficial PDF and LaTeX source&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-category-theory-for-programmers" class="anchor" aria-hidden="true" href="#category-theory-for-programmers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Category Theory for Programmers&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/601206/43392303-f770d7be-93fb-11e8-8db8-b7e915b435ba.png"&gt;&lt;img src="https://user-images.githubusercontent.com/601206/43392303-f770d7be-93fb-11e8-8db8-b7e915b435ba.png" alt="image" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;b&gt;Direct link: &lt;a href="https://github.com/hmemcpy/milewski-ctfp-pdf/releases/download/v1.3.0/category-theory-for-programmers.pdf"&gt;category-theory-for-programmers.pdf&lt;/a&gt;&lt;/b&gt;&lt;br&gt;
(Latest release: v1.3.0, August 2019. See &lt;a href="https://github.com/hmemcpy/milewski-ctfp-pdf/releases"&gt;releases&lt;/a&gt; for additional formats and languages.)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/hmemcpy/milewski-ctfp-pdf" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8695bdb18f91fa7028908a9172f0b5d051879160/68747470733a2f2f7472617669732d63692e6f72672f686d656d6370792f6d696c6577736b692d637466702d7064662e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/hmemcpy/milewski-ctfp-pdf.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://s3.amazonaws.com/milewski-ctfp-pdf/category-theory-for-programmers.pdf" rel="nofollow"&gt;(latest CI build)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/601206/47271389-8eea0900-d581-11e8-8e81-5b932e336336.png"&gt;&lt;img src="https://user-images.githubusercontent.com/601206/47271389-8eea0900-d581-11e8-8e81-5b932e336336.png" alt="Buy Category Theory for Programmers" width="410" style="max-width:100%;"&gt;&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;&lt;a href="https://www.blurb.com/b/9621951-category-theory-for-programmers-new-edition-hardco" rel="nofollow"&gt;Available in full-color hardcover print&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
Publish date: 12 August, 2019. Based off release tag &lt;a href="https://github.com/hmemcpy/milewski-ctfp-pdf/releases/tag/v1.3.0"&gt;v1.3.0&lt;/a&gt;. See &lt;a href="errata-1.3.0.md"&gt;errata-1.3.0&lt;/a&gt; for changes and fixes since print.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.blurb.com/b/9603882-category-theory-for-programmers-scala-edition-pape" rel="nofollow"&gt;Scala Edition is now available in paperback&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;
Publish date: 12 August, 2019. Based off release tag &lt;a href="https://github.com/hmemcpy/milewski-ctfp-pdf/releases/tag/v1.3.0"&gt;v1.3.0&lt;/a&gt;. See &lt;a href="errata-scala.md"&gt;errata-scala&lt;/a&gt; for changes and fixes since print.&lt;/p&gt;
&lt;p&gt;This is an &lt;em&gt;unofficial&lt;/em&gt; PDF version of "Category Theory for Programmers" by Bartosz Milewski, converted from his &lt;a href="https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/" rel="nofollow"&gt;blogpost series&lt;/a&gt; (with permission!)&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-building" class="anchor" aria-hidden="true" href="#building"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building&lt;/h2&gt;
&lt;p&gt;The best way to build the book is using the &lt;a href="https://nixos.org/nix/" rel="nofollow"&gt;Nix&lt;/a&gt; package manager. After installing Nix, type &lt;code&gt;nix-shell&lt;/code&gt; in the root directory of the project. This will download all the needed dependencies and tools to build the book (TeXLive, required fonts and packages, Pygments theme for syntax highligting, etc.)&lt;/p&gt;
&lt;p&gt;When the download is complete, and you're prompted with a shell, use the instructions below to build the book.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;src&lt;/code&gt; directory contains the LaTeX sources. To recompile the book, go there and enter:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ make&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To build the Scala edition, type:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ make scala&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Upon successful compilation, the files will be placed in the &lt;code&gt;out&lt;/code&gt; directory next to &lt;code&gt;src&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The file &lt;code&gt;preamble.tex&lt;/code&gt; contains all the configuration and style declarations.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgements" class="anchor" aria-hidden="true" href="#acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;PDF LaTeX source and the tools to create it are based on the work by Andres Raba et al., available here: &lt;a href="https://github.com/sarabander/sicp-pdf"&gt;https://github.com/sarabander/sicp-pdf&lt;/a&gt;.&lt;br&gt;
The book content is taken, with permission, from Bartosz Milewski's blogpost series, and adapted to the LaTeX format.&lt;/p&gt;
&lt;p&gt;Thanks to the following people for contributing corrections/conversions and misc:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oleg Rakitskiy&lt;/li&gt;
&lt;li&gt;Jared Weakly&lt;/li&gt;
&lt;li&gt;Paolo G. Giarrusso&lt;/li&gt;
&lt;li&gt;Adi Shavit&lt;/li&gt;
&lt;li&gt;Mico Loretan&lt;/li&gt;
&lt;li&gt;Marcello Seri&lt;/li&gt;
&lt;li&gt;Erwin Maruli Tua Pakpahan&lt;/li&gt;
&lt;li&gt;Markus Hauck&lt;/li&gt;
&lt;li&gt;Yevheniy Zelenskyy&lt;/li&gt;
&lt;li&gt;Ross Kirsling&lt;/li&gt;
&lt;li&gt;...and many others!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note from Bartosz: I really appreciate all your contributions. You made this book much better than I could have imagined. Thank you!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;The PDF book, &lt;code&gt;.tex&lt;/code&gt; files, and associated images and figures in directories &lt;code&gt;src/fig&lt;/code&gt; and &lt;code&gt;src/content&lt;/code&gt; are licensed under Creative Commons Attribution-ShareAlike 4.0 International License (&lt;a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="nofollow"&gt;cc by-sa&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The script files &lt;code&gt;scraper.py&lt;/code&gt; and others are licensed under GNU General Public License version 3 (for details, see &lt;a href="https://github.com/hmemcpy/milewski-ctfp-pdf/blob/master/LICENSE"&gt;LICENSE&lt;/a&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>hmemcpy</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>dart-lang/language #10 in TeX, Today</title><link>https://github.com/dart-lang/language</link><description>&lt;p&gt;&lt;i&gt;Design of the Dart language&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-dart-language-evolution" class="anchor" aria-hidden="true" href="#dart-language-evolution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dart language evolution&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/dart-lang/language" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/603c879b44e3c78bdd33b11d894682ba28e5fc1f/68747470733a2f2f7472617669732d63692e6f72672f646172742d6c616e672f6c616e67756167652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/dart-lang/language.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository is a place for the Dart language team to work on
language changes and features, and to solicit and accept feedback and requests.&lt;/p&gt;
&lt;p&gt;Issues and feature requests relevant to the language and the specification may
be filed &lt;a href="https://github.com/dart-lang/language/issues"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-organization" class="anchor" aria-hidden="true" href="#organization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Organization&lt;/h1&gt;
&lt;p&gt;We follow &lt;a href="https://github.com/dart-lang/language/blob/master/doc/life_of_a_language_feature.md"&gt;this
process&lt;/a&gt;
for planning and rolling out language changes.&lt;/p&gt;
&lt;p&gt;Features currently being worked on are listed in the
&lt;a href="https://github.com/dart-lang/language/projects/1"&gt;language funnel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Notes from language design meetings can be
found &lt;a href="https://github.com/dart-lang/language/blob/master/minutes/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-dart-language" class="anchor" aria-hidden="true" href="#dart-language"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dart Language&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.dartlang.org" rel="nofollow"&gt;Dart&lt;/a&gt; is an open-source, scalable programming language, with robust
libraries and runtimes, for building web, server, and mobile apps.&lt;/p&gt;
&lt;p&gt;This repository tracks the Dart language specification
and changes to the Dart language.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Anyone can participate in the discussion about language changes
by participating on the dart language mailing list,
by replying to issues in this repository,
and by uploading documents, tests or other resources.&lt;/p&gt;
&lt;p&gt;When commenting on issues in this repository, keep in mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;g-emoji class="g-emoji" alias="+1" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44d.png"&gt;👍&lt;/g-emoji&gt; reactions are more useful than comments to show support.&lt;/li&gt;
&lt;li&gt;Motivating examples help us understand why you want new features more than
pointers to other languages which have them. We love hearing feedback about
your experiences with other languages, but we also want to know why they are
right for Dart in particular.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license--patents" class="anchor" aria-hidden="true" href="#license--patents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License &amp;amp; patents&lt;/h2&gt;
&lt;p&gt;See &lt;a href="https://github.com/dart-lang/language/blob/master/LICENSE"&gt;LICENSE&lt;/a&gt; and &lt;a href="https://github.com/dart-lang/language/blob/master/PATENTS"&gt;PATENTS&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>dart-lang</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>soulmachine/leetcode #11 in TeX, Today</title><link>https://github.com/soulmachine/leetcode</link><description>&lt;p&gt;&lt;i&gt;LeetCode题解，151道题完整版&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-leetcode题解" class="anchor" aria-hidden="true" href="#leetcode题解"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;#LeetCode题解&lt;/h2&gt;
&lt;h2&gt;&lt;a id="user-content-在线阅读" class="anchor" aria-hidden="true" href="#在线阅读"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;在线阅读&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.gitbook.com/book/soulmachine/algorithm-essentials/" rel="nofollow"&gt;https://www.gitbook.com/book/soulmachine/algorithm-essentials/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;##PDF下载
&lt;a href="https://github.com/soulmachine/leetcode/raw/master/C%2B%2B/leetcode-cpp.pdf"&gt;LeetCode题解(C++版).pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;C++ 文件夹下是C++版，内容一模一样，代码是用C++写的。&lt;/p&gt;
&lt;p&gt;Java 文件夹下是Java版，目前正在编写中，由于拖延症，不知道猴年马月能完成。&lt;/p&gt;
&lt;p&gt;##LaTeX模板
本书使用的是陈硕开源的&lt;a href="https://github.com/chenshuo/typeset"&gt;模板&lt;/a&gt;。这个模板制作精良，很有taste，感谢陈硕 :)&lt;/p&gt;
&lt;p&gt;##在Windows下编译&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装Tex Live 2015 &lt;a href="http://www.tug.org/texlive/" rel="nofollow"&gt;http://www.tug.org/texlive/&lt;/a&gt;。把bin目录例如&lt;code&gt;D:\texlive\2015\bin\win32&lt;/code&gt;加入PATH环境变量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装字体。这个LaTex模板总共使用了10个字体，下载地址 &lt;a href="https://pan.baidu.com/s/1eRFJXnW" rel="nofollow"&gt;https://pan.baidu.com/s/1eRFJXnW&lt;/a&gt; ，有的字体Windows自带了，有的字体Ubuntu自带了，但都不全，还是一次性安装完所有字体比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装TeXstudio &lt;a href="http://texstudio.sourceforge.net/" rel="nofollow"&gt;http://texstudio.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(可选)启动Tex Live Manager，更新所有已安装的软件包。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;配置TeXstudio。&lt;/p&gt;
&lt;p&gt;启动Texstudio，选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Commands&lt;/code&gt;，XeLaTex 设置为 &lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode %.tex&lt;/code&gt;；&lt;/p&gt;
&lt;p&gt;选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Build&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build &amp;amp; View 由默认的 PDF Chain 改为 Compile &amp;amp; View；&lt;/p&gt;
&lt;p&gt;Default Compiler 由默认的PdfLaTex 修改为 XeLaTex ；&lt;/p&gt;
&lt;p&gt;PDF Viewer 改为 “Internal PDF Viewer(windowed)”，这样预览时会弹出一个独立的窗口，这样比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编译。用TeXstudio打开&lt;code&gt;typeset.tex&lt;/code&gt;，点击界面上的绿色箭头就可以开始编译了。&lt;/p&gt;
&lt;p&gt;在下方的窗口可以看到TeXstudio正在使用的编译命令是&lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode "typeset".tex&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;##在Ubuntu下编译&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安装Tex Live 2015 &lt;a href="http://www.tug.org/texlive/" rel="nofollow"&gt;http://www.tug.org/texlive/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1.1. 下载TexLive 2015 的ISO 光盘，地址 &lt;a href="http://www.tug.org/texlive/acquire-iso.html" rel="nofollow"&gt;http://www.tug.org/texlive/acquire-iso.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1.2 mount 光盘，&lt;code&gt;sudo ./install-tl&lt;/code&gt; 开始安装&lt;/p&gt;
&lt;p&gt;1.3 加入环境变量&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; sudo vi /etc/profile
 export PATH=$PATH:/usr/local/texlive/2015/bin/x86_64-linux
 export MANPATH=$MANPATH:/usr/local/texlive/2015/texmf-dist/doc/man
 export INFPATH=$INFPATH:/usr/local/texlive/2015/texmf-dist/doc/info
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装字体。这个LaTex模板总共使用了10个字体，下载地址 &lt;a href="https://pan.baidu.com/s/1eRFJXnW" rel="nofollow"&gt;https://pan.baidu.com/s/1eRFJXnW&lt;/a&gt; ，有的字体Windows自带了，有的字体Ubuntu自带了，但都不全，还是一次性安装完所有字体比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装TeXstudio &lt;a href="http://texstudio.sourceforge.net/" rel="nofollow"&gt;http://texstudio.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;配置TeXstudio。&lt;/p&gt;
&lt;p&gt;启动Texstudio，选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Commands&lt;/code&gt;，XeLaTex 设置为 &lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode %.tex&lt;/code&gt;；&lt;/p&gt;
&lt;p&gt;选择 &lt;code&gt;Options--&amp;gt;Configure Texstudio--&amp;gt;Build&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Build &amp;amp; View 由默认的 PDF Chain 改为 Compile &amp;amp; View；&lt;/p&gt;
&lt;p&gt;Default Compiler 由默认的PdfLaTex 修改为 XeLaTex ；&lt;/p&gt;
&lt;p&gt;PDF Viewer 改为 “Internal PDF Viewer(windowed)”，这样预览时会弹出一个独立的窗口，这样比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;编译。用TeXstudio打开&lt;code&gt;typeset.tex&lt;/code&gt;，点击界面上的绿色箭头就可以开始编译了。&lt;/p&gt;
&lt;p&gt;在下方的窗口可以看到TeXstudio正在使用的编译命令是&lt;code&gt;xelatex -synctex=1 -interaction=nonstopmode "typeset".tex&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;懒人版镜像。如果不想进行上面繁琐的安装过程，我做好了一个Ubuntu VMware虚拟机镜像，已经装好了 TexLive 2015, TexStudio和字体(详细的安装日志见压缩包注释)，开箱即用，下载地址 &lt;a href="http://pan.baidu.com/s/1cLWkgA" rel="nofollow"&gt;http://pan.baidu.com/s/1cLWkgA&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;##如何贡献代码
编译通过后，就具备了完整的LaTeX编译环境了。&lt;/p&gt;
&lt;p&gt;本书模板已经写好了，基本上不需要很多LaTeX知识就可以动手了。&lt;/p&gt;
&lt;p&gt;欢迎给本书添加内容或纠正错误，在自己本地编译成PDF，预览没问题后，就可以发pull request过来了。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-qq群" class="anchor" aria-hidden="true" href="#qq群"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;QQ群&lt;/h2&gt;
&lt;p&gt;237669375&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-小密圈" class="anchor" aria-hidden="true" href="#小密圈"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;小密圈&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/silicon-job.jpeg"&gt;&lt;img src="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/silicon-job.jpeg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-algohub" class="anchor" aria-hidden="true" href="#algohub"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;AlgoHub&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.algohub.org" rel="nofollow"&gt;https://www.algohub.org&lt;/a&gt; 是我建立的一个刷题网站，即将上线，敬请期待&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-纸质书" class="anchor" aria-hidden="true" href="#纸质书"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;纸质书&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;本书即将由电子工业出版社出版，敬请期待&lt;/strong&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>soulmachine</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>pingcap/docs-cn #12 in TeX, Today</title><link>https://github.com/pingcap/docs-cn</link><description>&lt;p&gt;&lt;i&gt;TiDB/TiKV/PD documents in Chinese.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;table data-table-type="yaml-metadata"&gt;
  &lt;thead&gt;
  &lt;tr&gt;
  &lt;th&gt;draft&lt;/th&gt;
  &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
  &lt;tr&gt;
  &lt;td&gt;&lt;div&gt;true&lt;/div&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1&gt;&lt;a id="user-content-tidb-简介" class="anchor" aria-hidden="true" href="#tidb-简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TiDB 简介&lt;/h1&gt;
&lt;p&gt;TiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。&lt;/p&gt;
&lt;p&gt;TiDB 具备如下特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;高度兼容 MySQL&lt;/p&gt;
&lt;p&gt;&lt;a href="/v3.0/reference/mysql-compatibility.md"&gt;大多数情况下&lt;/a&gt;，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;水平弹性扩展&lt;/p&gt;
&lt;p&gt;通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分布式事务&lt;/p&gt;
&lt;p&gt;TiDB 100% 支持标准的 ACID 事务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;真正金融级高可用&lt;/p&gt;
&lt;p&gt;相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一站式 HTAP 解决方案&lt;/p&gt;
&lt;p&gt;TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP 解决方案，一份存储同时处理 OLTP &amp;amp; OLAP，无需传统繁琐的 ETL 过程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;云原生 SQL 数据库&lt;/p&gt;
&lt;p&gt;TiDB 是为云而设计的数据库，支持公有云、私有云和混合云，使部署、配置和维护变得十分简单。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TiDB 的设计目标是 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析可以通过 &lt;a href="/v3.0/reference/tispark.md"&gt;TiSpark 项目&lt;/a&gt;来完成。&lt;/p&gt;
&lt;p&gt;TiDB 对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力。&lt;/p&gt;
&lt;p&gt;三篇文章了解 TiDB 技术内幕：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://pingcap.com/blog-cn/tidb-internal-1/" rel="nofollow"&gt;说存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pingcap.com/blog-cn/tidb-internal-2/" rel="nofollow"&gt;说计算&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pingcap.com/blog-cn/tidb-internal-3/" rel="nofollow"&gt;谈调度&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>pingcap</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>jikexueyuanwiki/tensorflow-zh #13 in TeX, Today</title><link>https://github.com/jikexueyuanwiki/tensorflow-zh</link><description>&lt;p&gt;&lt;i&gt;谷歌全新开源人工智能系统TensorFlow官方文档中文版&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-tensorflow-官方文档中文版" class="anchor" aria-hidden="true" href="#tensorflow-官方文档中文版"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow 官方文档中文版&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="SOURCE/images/TensorFlow.jpg"&gt;&lt;img src="SOURCE/images/TensorFlow.jpg" alt="" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-你正在阅读的项目可能会比-android-系统更加深远地影响着世界" class="anchor" aria-hidden="true" href="#你正在阅读的项目可能会比-android-系统更加深远地影响着世界"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;你正在阅读的项目可能会比 Android 系统更加深远地影响着世界！&lt;/h3&gt;
&lt;h2&gt;&lt;a id="user-content-缘起" class="anchor" aria-hidden="true" href="#缘起"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;缘起&lt;/h2&gt;
&lt;p&gt;2015年11月9日，Google发布人工智能系统TensorFlow并宣布开源，同日，极客学院组织在线TensorFlow中文文档翻译。&lt;/p&gt;
&lt;p&gt;机器学习作为人工智能的一种类型，可以让软件根据大量的数据来对未来的情况进行阐述或预判。如今，领先的科技巨头无不在机器学习下予以极大投入。Facebook、苹果、微软，甚至国内的百度。Google 自然也在其中。「TensorFlow」是 Google 多年以来内部的机器学习系统。如今，Google 正在将此系统成为开源系统，并将此系统的参数公布给业界工程师、学者和拥有大量编程能力的技术人员，这意味着什么呢？&lt;/p&gt;
&lt;p&gt;打个不太恰当的比喻，如今 Google 对待 TensorFlow 系统，有点类似于该公司对待旗下移动操作系统 Android。如果更多的数据科学家开始使用 Google 的系统来从事机器学习方面的研究，那么这将有利于 Google 对日益发展的机器学习行业拥有更多的主导权。&lt;/p&gt;
&lt;p&gt;为了让国内的技术人员在最短的时间内迅速掌握这一世界领先的 AI 系统，极客学院 Wiki 团队发起对 TensorFlow 官方文档的中文协同翻译，一周之内，全部翻译认领完成，一个月后，全部30章节翻译校对完成，上线极客学院Wiki平台并提供下载。&lt;/p&gt;
&lt;p&gt;Google TensorFlow项目负责人Jeff Dean为该中文翻译项目回信称："&lt;em&gt;看到能够将TensorFlow翻译成中文我非常激动，我们将TensorFlow开源的主要原因之一是为了让全世界的人们能够从机器学习与人工智能中获益，类似这样的协作翻译能够让更多的人更容易地接触到TensorFlow项目，很期待接下来该项目在全球范围内的应用!&lt;/em&gt;"&lt;/p&gt;
&lt;p&gt;Jeff回信原文：&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="SOURCE/images/jeff.png"&gt;&lt;img src="SOURCE/images/jeff.png" alt="jeff" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;再次衷心感谢每一位为该翻译项目做出贡献的同学，我们会持续关注TensorFlow、AI领域以及其它最新技术的发展、持续维护该协作翻译、持续提供更多更优质的内容，为广大IT学习者们服务！&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-内容来源" class="anchor" aria-hidden="true" href="#内容来源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;内容来源&lt;/h2&gt;
&lt;p&gt;英文官方网站：&lt;br&gt;
&lt;a href="http://tensorflow.org/" rel="nofollow"&gt;http://tensorflow.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;官方GitHub仓库：&lt;br&gt;
&lt;a href="https://github.com/tensorflow/tensorflow"&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;中文版 GitHub 仓库：&lt;br&gt;
&lt;a href="https://github.com/jikexueyuanwiki/tensorflow-zh"&gt;https://github.com/jikexueyuanwiki/tensorflow-zh&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-参与者按认领章节排序" class="anchor" aria-hidden="true" href="#参与者按认领章节排序"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;参与者（按认领章节排序）&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-翻译" class="anchor" aria-hidden="true" href="#翻译"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;翻译&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/PFZheng"&gt;@PFZheng&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/linbojin"&gt;@Tony Jin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/chenweican"&gt;@chenweican&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bingjin"&gt;@bingjin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/oskycar"&gt;@oskycar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/btpeter"&gt;@btpeter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Warln"&gt;@Warln&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ericxk"&gt;@ericxk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/wangaicc"&gt;@wangaicc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TerenceCooper"&gt;@Terence Cooper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhyhooo"&gt;@zhyhooo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/thylaco1eo"&gt;@thylaco1eo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/volvet"&gt;@volvet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhangkom"&gt;@zhangkom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/derekshang"&gt;@derekshang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lianghyv"&gt;@lianghyv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nb312"&gt;@nb312&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Jim-Zenn"&gt;@Jim-Zenn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/andyiac"&gt;@andyiac&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TerenceCooper"&gt;@Terence Cooper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/leege100"&gt;@leege100&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-校对" class="anchor" aria-hidden="true" href="#校对"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;校对&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/sstruct"&gt;@yangtze&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ericxk"&gt;@ericxk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WangHong-yang"&gt;@HongyangWang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/LichAmnesia"&gt;@LichAmnesia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhyhooo"&gt;@zhyhooo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/waiwaizheng"&gt;@waiwaizheng&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/WangHong-yang"&gt;@HongyangWang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorfly"&gt;@tensorfly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lonlonago"&gt;@lonlonago&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jishaoming"&gt;@jishaoming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lucky521"&gt;@lucky521&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/allensummer"&gt;@allensummer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/volvet"&gt;@volvet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ZHNathanielLee"&gt;@ZHNathanielLee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PengFoo"&gt;@pengfoo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/qiaohaijun"&gt;@qiaohaijun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SeikaScarlet"&gt;@Seika&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-进度记录" class="anchor" aria-hidden="true" href="#进度记录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;进度记录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2015-11-10, 谷歌发布全新人工智能系统TensorFlow并宣布开源, 极客学院Wiki启动协同翻译，创建 GitHub 仓库，制定协同规范&lt;/li&gt;
&lt;li&gt;2015-11-18, 所有章节认领完毕，翻译完成18章，校对认领7章，Star数361，fork数100，协同翻译QQ群及技术交流群的TF爱好者将近300人，GitHub搜索TensorFlow排名第二&lt;/li&gt;
&lt;li&gt;2015-12-10, Star数超过500&lt;/li&gt;
&lt;li&gt;2015-12-15, 项目正式上线&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-花絮" class="anchor" aria-hidden="true" href="#花絮"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;花絮&lt;/h2&gt;
&lt;p&gt;在组织翻译的过程中，有些事情令人印象深刻，记录下来，希望以后来学习文档的同学能够明了到手中这份文档的由来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参加翻译的有学生，也有老师；有专门研究AI/ML的，也有对此感兴趣的；有国内的，也有远在纽约的；有工程技术人员也有博士、专家&lt;/li&gt;
&lt;li&gt;其中一位，&lt;a href="http://www.longmotto.com" rel="nofollow"&gt;恩泽&lt;/a&gt;同学，为了翻译一篇文档，在前一天没有睡觉的情况下坚持翻完，20个小时没有合眼&lt;/li&gt;
&lt;li&gt;还有一位老师，刚从讲台上讲完课，就立即给我们的翻译提修改意见&lt;/li&gt;
&lt;li&gt;很多同学自发的将搭建环境中遇到的问题总结到FAQ里帮助他人&lt;/li&gt;
&lt;li&gt;为了一个翻译细节，经常是来回几次，和其他人讨论完善&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-持续改进" class="anchor" aria-hidden="true" href="#持续改进"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;持续改进&lt;/h2&gt;
&lt;p&gt;这样的一个高技术领域的文档，我们在翻译的过程中，难免会有不完善的地方，希望请大家一起帮助我们持续改进文档的翻译质量，帮助更多的人，方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在GitHub上提Issue或Pull Request，地址为: &lt;a href="https://github.com/jikexueyuanwiki/tensorflow-zh"&gt;https://github.com/jikexueyuanwiki/tensorflow-zh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;加入TensorFlow技术交流群，与TensorFlower们一起研究交流技术干货--TensorFlow技术交流群：782484288&lt;/li&gt;
&lt;li&gt;对翻译感兴趣？加入协同翻译群：248320884，与翻译大神一道研究TensorFlow的本地化&lt;/li&gt;
&lt;li&gt;给我们写邮件： &lt;a href="mailto:wiki@jikexueyuan.com"&gt;wiki@jikexueyuan.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-感谢支持" class="anchor" aria-hidden="true" href="#感谢支持"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;感谢支持&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://wiki.jikexueyuan.com" rel="nofollow"&gt;极客学院 Wiki&lt;/a&gt; 提供图文教程托管服务&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-离线版本" class="anchor" aria-hidden="true" href="#离线版本"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;离线版本&lt;/h2&gt;
&lt;p&gt;目前，离线版本(PDF、ePub)可正常下载、使用&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tex-pdf-修订版" class="anchor" aria-hidden="true" href="#tex-pdf-修订版"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tex-PDF 修订版&lt;/h2&gt;
&lt;p&gt;&lt;a href="tex_pdf"&gt;Tex-PDF 修订版&lt;/a&gt; 目前正在编订中，欢迎加入进来一起修订。您可以在此查看&lt;a href="tex_pdf/tensorflow_manual_cn.pdf"&gt;预览版&lt;/a&gt;目前最新状态。&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jikexueyuanwiki</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item><item><title>Wandmalfarbe/pandoc-latex-template #14 in TeX, Today</title><link>https://github.com/Wandmalfarbe/pandoc-latex-template</link><description>&lt;p&gt;&lt;i&gt;A pandoc LaTeX template to convert markdown files to PDF or LaTeX.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;Last seen &lt;b&gt;2019-10-28&lt;/b&gt;; First seen &lt;b&gt;2019-10-28&lt;/b&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="icon.png"&gt;&lt;img src="icon.png" align="right" height="110" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-eisvogel" class="anchor" aria-hidden="true" href="#eisvogel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eisvogel&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/Wandmalfarbe/pandoc-latex-template" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b87755780c096b231f6f2e8a6192d30318d187a3/68747470733a2f2f7472617669732d63692e6f72672f57616e646d616c66617262652f70616e646f632d6c617465782d74656d706c6174652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/Wandmalfarbe/pandoc-latex-template.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A clean &lt;strong&gt;pandoc LaTeX template&lt;/strong&gt; to convert your markdown files to PDF or LaTeX. It is designed for lecture notes and exercises with a focus on computer science. The template is compatible with pandoc 2.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-preview" class="anchor" aria-hidden="true" href="#preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preview&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;A custom title page&lt;/th&gt;
&lt;th align="center"&gt;A basic example page&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/custom-titlepage/custom-titlepage.pdf"&gt;&lt;img src="examples/custom-titlepage/custom-titlepage.png" alt="A custom title page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/basic-example/basic-example.pdf"&gt;&lt;img src="examples/basic-example/basic-example.png" alt="A basic example page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install pandoc from &lt;a href="http://pandoc.org/" rel="nofollow"&gt;http://pandoc.org/&lt;/a&gt;. You also need to install &lt;a href="https://en.wikibooks.org/wiki/LaTeX/Installation#Distributions" rel="nofollow"&gt;LaTeX&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the latest version of the Eisvogel template from &lt;a href="https://github.com/Wandmalfarbe/pandoc-latex-template/releases/latest"&gt;the release page&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Extract the downloaded ZIP archive and open the folder.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Move the template &lt;code&gt;eisvogel.tex&lt;/code&gt; to your pandoc templates folder and rename the file to &lt;code&gt;eisvogel.latex&lt;/code&gt;. The location of the templates folder depends on your operating system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unix, Linux, macOS: &lt;code&gt;/Users/USERNAME/.local/share/pandoc/templates/&lt;/code&gt; or &lt;code&gt;/Users/USERNAME/.pandoc/templates/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Windows Vista or later: &lt;code&gt;C:\Users\USERNAME\AppData\Roaming\pandoc\templates\&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If there are no folders called &lt;code&gt;templates&lt;/code&gt; or &lt;code&gt;pandoc&lt;/code&gt; you need to create them and put the template &lt;code&gt;eisvogel.latex&lt;/code&gt; inside. You can find the default user data directory on your system by looking at the output of &lt;code&gt;pandoc --version&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Open the terminal and navigate to the folder where your markdown file is located.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Execute the following command&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --from markdown --template eisvogel --listings&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code&gt;example.md&lt;/code&gt; is the markdown file you want to convert to PDF.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to have nice headers and footers you need to supply metadata to your document. You can do that with a &lt;a href="http://pandoc.org/MANUAL.html#extension-yaml_metadata_block" rel="nofollow"&gt;YAML metadata block&lt;/a&gt; at the top of your markdown document (see the &lt;a href="examples/basic-example/basic-example.md"&gt;example markdown file&lt;/a&gt;). Your markdown document may look like the following:&lt;/p&gt;
&lt;div class="highlight highlight-source-gfm"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;---&lt;/span&gt;
&lt;span class="pl-ent"&gt;title&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;The Document Title&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-ent"&gt;author&lt;/span&gt;: &lt;span class="pl-s"&gt;[Example Author, Another Author]&lt;/span&gt;
&lt;span class="pl-ent"&gt;date&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;2017-02-20&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-ent"&gt;keywords&lt;/span&gt;: &lt;span class="pl-s"&gt;[Markdown, Example]&lt;/span&gt;
&lt;span class="pl-c"&gt;...&lt;/span&gt;

Here is the actual document text...&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-custom-template-variables" class="anchor" aria-hidden="true" href="#custom-template-variables"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Custom Template Variables&lt;/h3&gt;
&lt;p&gt;This template defines some new variables to control the appearance of the resulting PDF document. The existing template variables from pandoc are all supported and their documentation can be found in &lt;a href="https://pandoc.org/MANUAL.html#variables-for-latex" rel="nofollow"&gt;the pandoc manual&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;turns on the title page when &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-color&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the background color of the title page. The color value must be given as an HTML hex color like &lt;code&gt;D8DE2C&lt;/code&gt; without the leading number sign (&lt;code&gt;#&lt;/code&gt;). When specifying the color in YAML, it is advisable to enclose it in quotes like so &lt;code&gt;titlepage-color: "D8DE2C"&lt;/code&gt; to avoid the truncation of the color (e.g. &lt;code&gt;000000&lt;/code&gt; becoming &lt;code&gt;0&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-text-color&lt;/code&gt; (defaults to &lt;code&gt;5F5F5F&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the text color of the title page&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-rule-color&lt;/code&gt; (defaults to &lt;code&gt;435488&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the color of the rule on the top of the title page&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-rule-height&lt;/code&gt; (defaults to &lt;code&gt;4&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the height of the rule on the top of the title page (in points)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-background&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the path to a background image for the title page. The background image is scaled to cover the entire page. In the examples folder under &lt;code&gt;titlepage-background&lt;/code&gt; are a few example background images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;caption-justification&lt;/code&gt; (defaults to &lt;code&gt;raggedright&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;justification setting for captions (uses the &lt;code&gt;justification&lt;/code&gt; parameter of the &lt;a href="https://ctan.org/pkg/caption?lang=en" rel="nofollow"&gt;caption&lt;/a&gt; package)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;toc-own-page&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;begin new page after table of contents, when &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;listings-disable-line-numbers&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;disables line numbers for all listings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;listings-no-page-break&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;avoid page break inside listings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;disable-header-and-footer&lt;/code&gt; (default to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;disables the header and footer completely on all pages&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;header-left&lt;/code&gt; (defaults to the title)&lt;/p&gt;
&lt;p&gt;the text on the left side of the header&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;header-center&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the text in the center of the header&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;header-right&lt;/code&gt; (defaults to the date)&lt;/p&gt;
&lt;p&gt;the text on the right side of the header&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footer-left&lt;/code&gt; (defaults to the author)&lt;/p&gt;
&lt;p&gt;the text on the left side of the footer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footer-center&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the text in the center of the footer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footer-right&lt;/code&gt; (defaults to the page number)&lt;/p&gt;
&lt;p&gt;the text on the right side of the footer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footnotes-pretty&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;prettifies formatting of footnotes (requires package &lt;code&gt;footmisc&lt;/code&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footnotes-disable-backlinks&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;disables making the reference from the footnote at the bottom of the page into a link back to the occurence of the footnote in the main text.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;book&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;typeset as book&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;logo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;path to an image that will be displayed on the title page. The path is always relative to where pandoc is executed. The option &lt;code&gt;--resource-path&lt;/code&gt; has no effect.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;logo-width&lt;/code&gt; (defaults to &lt;code&gt;100&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the width of the logo (in points)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;first-chapter&lt;/code&gt; (defaults to &lt;code&gt;1&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;if typesetting a book with chapter numbers, specifies the number that will be assigned to the first chapter&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;float-placement-figure&lt;/code&gt; (defaults to &lt;code&gt;H&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;Reset the default placement specifier for figure environments to the supplied value e.g. &lt;code&gt;htbp&lt;/code&gt;. The available specifiers are listed below. The first four placement specifiers can be combined.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;h&lt;/code&gt;: Place the float &lt;em&gt;here&lt;/em&gt;, i.e., approximately at the same point it occurs in the source text.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;t&lt;/code&gt;: Place the float at the &lt;em&gt;top&lt;/em&gt; of the page.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Place the float at the &lt;em&gt;bottom&lt;/em&gt; of the page.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p&lt;/code&gt;: Place the float on the next &lt;em&gt;page&lt;/em&gt; that will contain only floats like figures and tables.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H&lt;/code&gt;: Place the float &lt;em&gt;HERE&lt;/em&gt; (exactly where it occurs in the source text). The &lt;code&gt;H&lt;/code&gt; specifier is provided by the &lt;a href="https://ctan.org/pkg/float" rel="nofollow"&gt;float package&lt;/a&gt; and may not be used in conjunction with any other placement specifiers.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;table-use-row-colors&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;enables row colors for tables. The default value is &lt;code&gt;false&lt;/code&gt; because the coloring extends beyond the edge of the table and there is currently no way to change that.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;code-block-font-size&lt;/code&gt; (defaults to &lt;code&gt;\small&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;LaTeX command to change the font size for code blocks. The available values are &lt;code&gt;\tiny&lt;/code&gt;, &lt;code&gt;\scriptsize&lt;/code&gt;, &lt;code&gt;\footnotesize&lt;/code&gt;, &lt;code&gt;\small&lt;/code&gt;, &lt;code&gt;\normalsize&lt;/code&gt;, &lt;code&gt;\large&lt;/code&gt;, &lt;code&gt;\Large&lt;/code&gt;, &lt;code&gt;\LARGE&lt;/code&gt;, &lt;code&gt;\huge&lt;/code&gt; and &lt;code&gt;\Huge&lt;/code&gt;. This option will change the font size for default code blocks using the verbatim environment and for code blocks generated with listings.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-numbered-sections" class="anchor" aria-hidden="true" href="#numbered-sections"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Numbered Sections&lt;/h3&gt;
&lt;p&gt;For PDFs with &lt;a href="http://pandoc.org/MANUAL.html#options-affecting-specific-writers" rel="nofollow"&gt;numbered sections&lt;/a&gt; use the &lt;code&gt;--number-sections&lt;/code&gt; or &lt;code&gt;-N&lt;/code&gt; option.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --number-sections&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-syntax-highlighting-with-listings" class="anchor" aria-hidden="true" href="#syntax-highlighting-with-listings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syntax Highlighting with Listings&lt;/h3&gt;
&lt;p&gt;You can get syntax highlighting of delimited code blocks by using the LaTeX package listings with the option &lt;code&gt;--listings&lt;/code&gt;. This example will produce the same syntax highlighting as in the example PDF.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --listings&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-syntax-highlighting-without-listings" class="anchor" aria-hidden="true" href="#syntax-highlighting-without-listings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syntax Highlighting Without Listings&lt;/h3&gt;
&lt;p&gt;The following examples show &lt;a href="http://pandoc.org/MANUAL.html#syntax-highlighting" rel="nofollow"&gt;syntax highlighting of delimited code blocks&lt;/a&gt; without using listings. To see a list of all the supported highlight styles, type &lt;code&gt;pandoc --list-highlight-styles&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style pygments&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style kate&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style espresso&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style tango&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-standalone-latex-document" class="anchor" aria-hidden="true" href="#standalone-latex-document"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Standalone LaTeX Document&lt;/h3&gt;
&lt;p&gt;To produce a standalone LaTeX document for compiling with any LaTeX editor use &lt;code&gt;.tex&lt;/code&gt; as an output file extension.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.tex --template eisvogel&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-changing-the-document-language" class="anchor" aria-hidden="true" href="#changing-the-document-language"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Changing the Document Language&lt;/h3&gt;
&lt;p&gt;The default language of this template is American English. The &lt;code&gt;lang&lt;/code&gt; variable identifies the main language of the document, using a code according to &lt;a href="https://tools.ietf.org/html/bcp47" rel="nofollow"&gt;BCP 47&lt;/a&gt; (e.g. &lt;code&gt;en&lt;/code&gt; or &lt;code&gt;en-GB&lt;/code&gt;). For an incomplete list of the supported language codes see &lt;a href="http://mirrors.ctan.org/language/hyph-utf8/doc/generic/hyph-utf8/hyph-utf8.pdf" rel="nofollow"&gt;the documentation for the hyph-utf8 package (Section 2)&lt;/a&gt;. The following example changes the language to British English:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel -V lang=en-GB&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The following example changes the language to German:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel -V lang=de&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-typesetting-a-book" class="anchor" aria-hidden="true" href="#typesetting-a-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Typesetting a Book&lt;/h3&gt;
&lt;p&gt;To typeset a book supply the template variable &lt;code&gt;-V book&lt;/code&gt; from the command line or via &lt;code&gt;book: true&lt;/code&gt; in the metadata.&lt;/p&gt;
&lt;p&gt;To get the correct chapter headings you need to tell pandoc that it should convert first level headings (indicated by one &lt;code&gt;#&lt;/code&gt; in markdown) to chapters with the command line option &lt;code&gt;--top-level-division=chapter&lt;/code&gt;. Chapter numbers start at 1. If you need to change that, specify &lt;code&gt;first-chapter&lt;/code&gt; in the template variables.&lt;/p&gt;
&lt;p&gt;There will be one blank page before each chapter because the template is two-sided per default. So if you plan to publish your book as a PDF and don’t need a blank page you should add the class option &lt;code&gt;onesided&lt;/code&gt; which can be done by supplying a template variable &lt;code&gt;-V classoption=oneside&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-example-images" class="anchor" aria-hidden="true" href="#example-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Images&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;A green title page&lt;/th&gt;
&lt;th align="center"&gt;A background image on the title page&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/green-titlepage/green-titlepage.pdf"&gt;&lt;img src="examples/green-titlepage/green-titlepage.png" alt="A green title page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/titlepage-background/titlepage-background.pdf"&gt;&lt;img src="examples/titlepage-background/titlepage-background.png" alt="A background image on the title page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;images and tables&lt;/th&gt;
&lt;th align="center"&gt;Code blocks styled without listings&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/images-and-tables/images-and-tables.pdf"&gt;&lt;img src="examples/images-and-tables/images-and-tables.png" alt="images and tables" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/without-listings/without-listings.pdf"&gt;&lt;img src="examples/without-listings/without-listings.png" alt="Code blocks styled without listings" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;A book&lt;/th&gt;
&lt;th align="center"&gt;Code blocks styled with listings&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/book/book.pdf"&gt;&lt;img src="examples/book/book.png" alt="A book" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/listings/listings.pdf"&gt;&lt;img src="examples/listings/listings.png" alt="Code blocks styled with listings" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This template includes code for styling block quotations from &lt;a href="https://github.com/aaronwolen/pandoc-letter"&gt;pandoc-letter&lt;/a&gt; by &lt;a href="https://github.com/aaronwolen"&gt;Aaron Wolen&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is open source licensed under the BSD 3-Clause License. Please see the &lt;a href="LICENSE"&gt;LICENSE file&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Wandmalfarbe</author><pubDate>Mon, 28 Oct 2019 00:00:00 GMT</pubDate></item></channel></rss>