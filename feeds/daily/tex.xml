<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: TeX, Today</title><link>https://github.com/trending/tex?since=daily</link><description>The top repositories on GitHub for tex, measured daily</description><pubDate>Mon, 02 Dec 2019 01:06:04 GMT</pubDate><lastBuildDate>Mon, 02 Dec 2019 01:06:04 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>abhat222/Data-Science--Cheat-Sheet #1 in TeX, Today</title><link>https://github.com/abhat222/Data-Science--Cheat-Sheet</link><description>&lt;p&gt;&lt;i&gt;Cheat Sheets&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;
Taken from &lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet"&gt;&lt;strong&gt;Link to original GitHub page&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-data-science-cheatsheets" class="anchor" aria-hidden="true" href="#data-science-cheatsheets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Science Cheatsheets&lt;/h1&gt;
&lt;p&gt;List of Data Science Cheatsheets :&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="Artificial%20Intelligence/README.md"&gt;Artificial Intelligence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Big%20Data/README.md"&gt;Big Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Data%20Engineering/README.md"&gt;Data Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Data%20Mining/README.md"&gt;Data Mining&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Data%20Science/README.md"&gt;Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Data%20Visualization/README.md"&gt;Data Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Data%20Warehouse/README.md"&gt;Data Warehouse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Deep%20Learning/README.md"&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="DevOps/README.md"&gt;DevOps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Docker%20&amp;amp;%20Kubernetes/README.md"&gt;Docker &amp;amp; Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Excel/README.md"&gt;Excel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Git/README.md"&gt;Git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Images//README.md"&gt;Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Interview%20Questions/README.md"&gt;Interview Questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Linux/README.md"&gt;Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet#machine-learning"&gt;Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Mathematics/README.md"&gt;Mathematics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Matlab/README.md"&gt;Matlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="NLP/README.md"&gt;NLP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Numpy/README.md"&gt;Numpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Ordinary%20Differential%20Equations/README.md"&gt;Ordinary Differential Equations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Pandas/README.md"&gt;Pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Probability/README.md"&gt;Probability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Python/README.md"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Scala/README.md"&gt;Scala&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="SQL/README.md"&gt;SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Statistics/README.md"&gt;Statistics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-python" class="anchor" aria-hidden="true" href="#python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Python/Python_cheatsheet.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/python_cheatsheet.PNG?" alt="Illustration" width="415px" style="max-width:100%;"&gt;      &lt;/a&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Python/spaCy.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/SpaCy.PNG?" alt="Illustration" width="415px" style="max-width:100%;"&gt;&lt;/a&gt;                                   &lt;b&gt;Python Cheat Sheet&lt;/b&gt;                                                                  &lt;b&gt;Spacy Cheat Sheet&lt;b&gt;&lt;br&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;b&gt;
&lt;p&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Pandas/pandas_cheat_sheet.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/DA_Pandas.PNG?" alt="Illustration" height="320px" width="415px" style="max-width:100%;"&gt;      &lt;/a&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Pandas/Reading%20and%20Writing%20data%20with%20PANDAS.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/RW_Panda.PNG?" alt="Illustration" width="415px" height="320px" style="max-width:100%;"&gt;&lt;/a&gt;                                   &lt;b&gt;Data Analysis with Pandas&lt;b&gt;                                              &lt;b&gt;Pandas (Reading and Writing Data)&lt;b&gt;&lt;br&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;b&gt;&lt;b&gt;
&lt;p&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Python/python-cheatsheets-ds.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/PythonForDS.PNG?" alt="Illustration" height="300px" width="415px" style="max-width:100%;"&gt;      &lt;/a&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Numpy/100_numpy_exercises.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/101_numpy_exercises.jpg?" alt="Illustration" width="415px" height="300px" style="max-width:100%;"&gt;&lt;/a&gt;                                   &lt;b&gt;Python for Data Science&lt;b&gt;                                                                  &lt;b&gt;100 Numpy Exercises&lt;b&gt;&lt;br&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;b&gt;&lt;b&gt;
&lt;p&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Python/Python%20for%20Data%20Analysis.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/pythonforDA.PNG?" alt="Illustration" height="300px" width="415px" style="max-width:100%;"&gt;      &lt;/a&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/Pandas/pandas-10min.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/Pandas_10mins.PNG?" alt="Illustration" width="415px" height="300px" style="max-width:100%;"&gt;&lt;/a&gt;                             &lt;b&gt;Python for Data Analysis&lt;b&gt;                                                              &lt;b&gt;10 Minutes to Pandas&lt;b&gt;&lt;br&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;b&gt;&lt;b&gt;
&lt;h1&gt;&lt;a id="user-content-r-language" class="anchor" aria-hidden="true" href="#r-language"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;R Language&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/R%20Cheat%20Sheet/R%20Cheat%20Sheets.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/R_cheatsheet.PNG?" alt="Illustration" height="300px" width="415px" style="max-width:100%;"&gt;      &lt;/a&gt;&lt;a href="https://github.com/abhat222/Data-Science--Cheat-Sheet/blob/master/R%20Cheat%20Sheet/R%20Programming%20Cheat%20Sheet.pdf"&gt;&lt;img src="https://github.com/abhat222/Data-Science--Cheat-Sheet/raw/master/Images/R.PNG?" alt="Illustration" width="415px" height="300px" style="max-width:100%;"&gt;&lt;/a&gt;                                    &lt;b&gt;R Cheat Sheet&lt;b&gt;                                                                     &lt;b&gt;R (Basics &amp;amp; Advanced)&lt;b&gt;&lt;br&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;b&gt;&lt;b&gt;
&lt;h1&gt;&lt;a id="user-content-machine-learning" class="anchor" aria-hidden="true" href="#machine-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Machine Learning&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/cyborg-girl/Data-Science--Cheat-Sheet/blob/master/Machine%20Learning/Applied%20Machine%20Learning%20Problem%20Solving%20Framework.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/abhat222/Data-Science--Cheat-Sheet/master/Machine%20Learning/Applied%20Machine%20Learning%20Problem%20Solving%20Framework.jpg" alt="Illustration" height="300px" width="415px" style="max-width:100%;"&gt;       &lt;/a&gt;&lt;a href="https://github.com/cyborg-girl/Data-Science--Cheat-Sheet/blob/master/Machine%20Learning/Cheat%20Sheet%20Algorithms%20for%20Supervised%20and%20Unsupervised%20Learning.pdf"&gt;&lt;img src="https://github.com/cyborg-girl/Data-Science--Cheat-Sheet/raw/master/Images/supervised-and-unsupervised-learning.PNG?" alt="Illustration" width="415px" height="300px" style="max-width:100%;"&gt;&lt;/a&gt;                                    &lt;b&gt;R Cheat Sheet&lt;b&gt;                                                                     &lt;b&gt;Machine Learning&lt;b&gt;&lt;br&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;b&gt;&lt;b&gt;
&lt;h1&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/cyborg-girl/Data-Science--Cheat-Sheet/blob/master/Deep%20Learning/Coursera%20Deep%20Learning%20course%20Notes.pdf"&gt;&lt;img src="https://github.com/cyborg-girl/Data-Science--Cheat-Sheet/raw/master/Images/coursera-deep-learning.PNG" alt="Illustration" height="300px" width="415px" style="max-width:100%;"&gt;       &lt;/a&gt;&lt;a href="https://github.com/cyborg-girl/Data-Science--Cheat-Sheet/blob/master/Deep%20Learning/super-cheatsheet-deep-learning.pdf"&gt;&lt;img src="https://github.com/cyborg-girl/Data-Science--Cheat-Sheet/raw/master/Images/super-cheatsheet-deep-learning.PNG" alt="Illustration" width="415px" height="300px" style="max-width:100%;"&gt;&lt;/a&gt;                                    &lt;b&gt;R Cheat Sheet&lt;b&gt;                                                                     &lt;b&gt;Machine Learning&lt;b&gt;&lt;br&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&lt;b&gt;&lt;b&gt;&lt;b&gt;
&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/article&gt;&lt;/div&gt;</description><author>abhat222</author><guid isPermaLink="false">https://github.com/abhat222/Data-Science--Cheat-Sheet</guid><pubDate>Mon, 02 Dec 2019 00:01:00 GMT</pubDate></item><item><title>billryan/resume #2 in TeX, Today</title><link>https://github.com/billryan/resume</link><description>&lt;p&gt;&lt;i&gt;An elegant \LaTeX\ résumé template&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-résumé" class="anchor" aria-hidden="true" href="#résumé"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Résumé&lt;/h1&gt;
&lt;p&gt;Hit branch &lt;a href="https://github.com/billryan/resume/tree/zh_CN"&gt;zh_CN&lt;/a&gt; if you want a Simplified Chinese résumé.&lt;/p&gt;
&lt;p&gt;中文用户请前往 &lt;a href="https://github.com/billryan/resume/tree/zh_CN"&gt;zh_CN&lt;/a&gt; 分支。&lt;/p&gt;
&lt;p&gt;An elegant \LaTeX\ résumé template, compiled with \XeLaTeX. Inspired by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zachscrivena/simple-resume-cv"&gt;zachscrivena/simple-resume-cv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ctan.org/pkg/res" rel="nofollow"&gt;res&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.jianxu.net/en/files/JianXu_CV.pdf" rel="nofollow"&gt;JianXu's CV&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.stat.berkeley.edu/~paciorek/computingTips/Latex_template_creating_CV_.html" rel="nofollow"&gt;paciorek's CV/Resume template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sharelatex.com/blog/2011/03/27/how-to-write-a-latex-class-file-and-design-your-own-cv.html" rel="nofollow"&gt;How to write a LaTeX class file and design your own CV (Part 1) - ShareLaTeX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Easy to further customize or extend&lt;/li&gt;
&lt;li&gt;Full support for unicode characters (e.g. CJK) with \XeLaTeX\&lt;/li&gt;
&lt;li&gt;Perfect Simplified Chinese fonts supported with Adobefonts&lt;/li&gt;
&lt;li&gt;FontAwesome 4.6.3 support&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fork this repository&lt;/li&gt;
&lt;li&gt;Add information about you directly in GitHub&lt;/li&gt;
&lt;li&gt;Compile TeX file to PDF with &lt;a href="https://latexonline.cc/" rel="nofollow"&gt;LaTeX.Online&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Can also use Overleaf for online compilation (&lt;a href="https://www.overleaf.com/" rel="nofollow"&gt;https://www.overleaf.com/&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-sample-output" class="anchor" aria-hidden="true" href="#sample-output"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sample Output&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1292567/62409353-3fecfc00-b608-11e9-8e83-84962912c956.png"&gt;&lt;img src="https://user-images.githubusercontent.com/1292567/62409353-3fecfc00-b608-11e9-8e83-84962912c956.png" alt="English" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1292567/62409351-3f546580-b608-11e9-9f6d-d232a68c5451.png"&gt;&lt;img src="https://user-images.githubusercontent.com/1292567/62409351-3f546580-b608-11e9-9f6d-d232a68c5451.png" alt="English with photo" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/1292567/62409352-3fecfc00-b608-11e9-8d9e-76243ca3052a.png"&gt;&lt;img src="https://user-images.githubusercontent.com/1292567/62409352-3fecfc00-b608-11e9-8d9e-76243ca3052a.png" alt="简体中文" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/billryan/resume/files/3463503/resume.pdf"&gt;English PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/billryan/resume/files/3463501/resume_photo.pdf"&gt;English with photo PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/billryan/resume/files/3463502/resume-zh_CN.pdf"&gt;简体中文 PDF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Edit in ShareLaTeX online - &lt;a href="https://www.sharelatex.com/templates/556b27cf0d23e5a8117053d9" rel="nofollow"&gt;https://www.sharelatex.com/templates/556b27cf0d23e5a8117053d9&lt;/a&gt;, &lt;strong&gt;no TeX software install!&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Compile tex on your Computer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you only need a résumé in English or have installed Adobe Simplified Chinese on your OS, &lt;strong&gt;It would be better to clone only the master branch,&lt;/strong&gt; since the Simplified Chinese fonts files are too large.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/billryan/resume.git --branch master --depth 1 --single-branch &amp;lt;folder&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://opensource.org/licenses/MIT" rel="nofollow"&gt;The MIT License (MIT)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Copyrighted fonts are not subjected to this License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>billryan</author><guid isPermaLink="false">https://github.com/billryan/resume</guid><pubDate>Mon, 02 Dec 2019 00:02:00 GMT</pubDate></item><item><title>posquit0/Awesome-CV #3 in TeX, Today</title><link>https://github.com/posquit0/Awesome-CV</link><description>&lt;p&gt;&lt;i&gt;:page_facing_up: Awesome CV is LaTeX template for your outstanding job application&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1 align="center"&gt;&lt;a id="user-content-------------awesome-cv" class="anchor" aria-hidden="true" href="#------------awesome-cv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;
  &lt;a href="https://github.com/posquit0/Awesome-CV" title="AwesomeCV Documentation"&gt;
    &lt;img alt="AwesomeCV" src="https://github.com/posquit0/Awesome-CV/raw/master/icon.png" width="200px" height="200px" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;br&gt;
  Awesome CV
&lt;/h1&gt;
&lt;p align="center"&gt;
  LaTeX template for your outstanding job application
&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;a href="https://www.paypal.me/posquit0" rel="nofollow"&gt;
    &lt;img alt="Donate" src="https://camo.githubusercontent.com/abbdd7bf97ae7919db5962b255f40aded5189c4f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d626c75652e737667" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-blue.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://circleci.com/gh/posquit0/Awesome-CV" rel="nofollow"&gt;
    &lt;img alt="CircleCI" src="https://camo.githubusercontent.com/d42593802854990d35ca42943e478dd35d6c64c9/68747470733a2f2f636972636c6563692e636f6d2f67682f706f7371756974302f417765736f6d652d43562e7376673f7374796c653d736869656c64" data-canonical-src="https://circleci.com/gh/posquit0/Awesome-CV.svg?style=shield" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;
    &lt;img alt="Example Resume" src="https://camo.githubusercontent.com/836d3a9f44da3462e5c47b6c58bf066bffbaf739/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f726573756d652d7064662d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/resume-pdf-green.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/cv.pdf" rel="nofollow"&gt;
    &lt;img alt="Example CV" src="https://camo.githubusercontent.com/8afab53a91bc30d0da18a9ea0cc70f2d0a1571df/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f63762d7064662d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/cv-pdf-green.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
  &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;
    &lt;img alt="Example Coverletter" src="https://camo.githubusercontent.com/ce88ed0c1af9e5611df67818460447b69572ae9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f7665726c65747465722d7064662d677265656e2e737667" data-canonical-src="https://img.shields.io/badge/coverletter-pdf-green.svg" style="max-width:100%;"&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-awesome-cv" class="anchor" aria-hidden="true" href="#what-is-awesome-cv"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is Awesome CV?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Awesome CV&lt;/strong&gt; is LaTeX template for a &lt;strong&gt;CV(Curriculum Vitae)&lt;/strong&gt;, &lt;strong&gt;Résumé&lt;/strong&gt; or &lt;strong&gt;Cover Letter&lt;/strong&gt; inspired by &lt;a href="https://www.sharelatex.com/templates/cv-or-resume/fancy-cv" rel="nofollow"&gt;Fancy CV&lt;/a&gt;. It is easy to customize your own template, especially since it is really written by a clean, semantic markup.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-donate" class="anchor" aria-hidden="true" href="#donate"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Donate&lt;/h2&gt;
&lt;p&gt;Please help keep this project alive! Donations are welcome and will go towards further development of this project.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PayPal: paypal.me/posquit0
BTC: 1Je3DxJVM2a9nTVPNo55SfQwpmxA6N2KKb
BCH: 1Mg1wG7PwHGrHYSWS67TsGSjo5GHEVbF16
ETH: 0x77ED9B4659F80205E9B9C9FB1E26EDB9904AFCC7
QTUM: QZT7D6m3QtTTqp7s4ZWAwLtGDsoHMMaM8E
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Thank you for your support!&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-preview" class="anchor" aria-hidden="true" href="#preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preview&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-résumé" class="anchor" aria-hidden="true" href="#résumé"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Résumé&lt;/h4&gt;
&lt;p&gt;You can see &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Page. 1&lt;/th&gt;
&lt;th align="center"&gt;Page. 2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-0.png" alt="Résumé" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/resume-1.png" alt="Résumé" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-cover-letter" class="anchor" aria-hidden="true" href="#cover-letter"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cover Letter&lt;/h4&gt;
&lt;p&gt;You can see &lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;Without Sections&lt;/th&gt;
&lt;th align="center"&gt;With Sections&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-0.png" alt="Cover Letter(Traditional)" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter.pdf" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/posquit0/Awesome-CV/master/examples/coverletter-1.png" alt="Cover Letter(Awesome)" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.overleaf.com/latex/templates/awesome-cv/tvmzpvdjfqxp" rel="nofollow"&gt;&lt;strong&gt;Edit Résumé on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.overleaf.com/latex/templates/awesome-cv-cover-letter/pfzzjspkthbk" rel="nofollow"&gt;&lt;strong&gt;Edit Cover Letter on OverLeaf.com&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note:&lt;/em&gt; Above services do not guarantee up-to-date source code of Awesome CV&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-use" class="anchor" aria-hidden="true" href="#how-to-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to Use&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h4&gt;
&lt;p&gt;A full TeX distribution is assumed.  &lt;a href="http://tex.stackexchange.com/q/55437" rel="nofollow"&gt;Various distributions for different operating systems (Windows, Mac, *nix) are available&lt;/a&gt; but TeX Live is recommended.
You can &lt;a href="http://tex.stackexchange.com/q/1092" rel="nofollow"&gt;install TeX from upstream&lt;/a&gt; (recommended; most up-to-date) or use &lt;code&gt;sudo apt-get install texlive-full&lt;/code&gt; if you really want that.  (It's generally a few years behind.)&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h4&gt;
&lt;p&gt;At a command prompt, run&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ xelatex {your-cv}.tex&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should result in the creation of &lt;code&gt;{your-cv}.pdf&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credit" class="anchor" aria-hidden="true" href="#credit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credit&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.latex-project.org" rel="nofollow"&gt;&lt;strong&gt;LaTeX&lt;/strong&gt;&lt;/a&gt; is a fantastic typesetting program that a lot of people use these days, especially the math and computer science people in academia.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/furl/latex-fontawesome"&gt;&lt;strong&gt;LaTeX FontAwesome&lt;/strong&gt;&lt;/a&gt; is bindings for FontAwesome icons to be used in XeLaTeX.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/google/roboto"&gt;&lt;strong&gt;Roboto&lt;/strong&gt;&lt;/a&gt; is the default font on Android and ChromeOS, and the recommended font for Google’s visual language, Material Design.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/adobe-fonts/source-sans-pro"&gt;&lt;strong&gt;Source Sans Pro&lt;/strong&gt;&lt;/a&gt; is a set of OpenType fonts that have been designed to work well in user interface (UI) environments.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;You are free to take my &lt;code&gt;.tex&lt;/code&gt; file and modify it to create your own resume. Please don't use my resume for anything else without my permission, though!&lt;/p&gt;
&lt;p&gt;If you have any questions, feel free to join me at &lt;code&gt;#posquit0&lt;/code&gt; on Freenode and ask away. Click &lt;a href="https://kiwiirc.com/client/irc.freenode.net/posquit0" rel="nofollow"&gt;here&lt;/a&gt; to connect.&lt;/p&gt;
&lt;p&gt;Good luck!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-see-also" class="anchor" aria-hidden="true" href="#see-also"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;See Also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/posquit0/hugo-awesome-identity"&gt;Awesome Identity&lt;/a&gt; - A single-page Hugo theme to introduce yourself.&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>posquit0</author><guid isPermaLink="false">https://github.com/posquit0/Awesome-CV</guid><pubDate>Mon, 02 Dec 2019 00:03:00 GMT</pubDate></item><item><title>rstudio/cheatsheets #4 in TeX, Today</title><link>https://github.com/rstudio/cheatsheets</link><description>&lt;p&gt;&lt;i&gt;RStudio Cheat Sheets&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-rstudio-cheat-sheets" class="anchor" aria-hidden="true" href="#rstudio-cheat-sheets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RStudio Cheat Sheets&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="pngs/rstudio-ide.png"&gt;&lt;img src="pngs/rstudio-ide.png" width="364" height="288" align="right" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The cheat sheets make it easy to learn about and use some of our favorite packages. They are published in their respective PDF versions here: &lt;a href="https://www.rstudio.com/resources/cheatsheets/" rel="nofollow"&gt;https://www.rstudio.com/resources/cheatsheets/&lt;/a&gt;, some are also available in the RStudio IDE under Help-Cheatsheets.&lt;/p&gt;
&lt;p&gt;This repository contains the source Apple Keynote files or the current, archived and translated versions.&lt;/p&gt;
&lt;p&gt;The cheat sheets use the creative commons copyright. Please see the LICENSE document for more details.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-translations" class="anchor" aria-hidden="true" href="#translations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Translations&lt;/h2&gt;
&lt;p&gt;If you wish to contribute to this effort by translating a cheat sheet, please feel free to use the source Keynote file. To submit a translation, please use a Pull Request via GitHub or email it to us at &lt;a href="mailto:info@rstudio.com"&gt;info@rstudio.com&lt;/a&gt; with the subject "Translated Cheatsheet".&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tips-for-making-a-new-cheat-sheet" class="anchor" aria-hidden="true" href="#tips-for-making-a-new-cheat-sheet"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tips for making a new cheat sheet&lt;/h2&gt;
&lt;p&gt;Keep these tips in mind when creating a new cheat sheet:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;RStudio cheat sheets are hosted at &lt;a href="https://github.com/rstudio/cheatsheets"&gt;https://github.com/rstudio/cheatsheets&lt;/a&gt;. You can submit new cheat sheets to the repository with a pull request.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The files &lt;code&gt;keynotes/0-template.key&lt;/code&gt; and &lt;code&gt;powerpoints/0-template.ppt&lt;/code&gt; are official templates that contain some helpful tips.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tip. You may find it easier to create a new cheat sheet by duplicating the most recent Keynote / Powerpoint cheat sheet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The cheat sheets are not meant to be text documents. Ideally, they are scannable visual aids that use layout and visual mnemonics to help people zoom into the functions they need. As an analogy, think of a cheat sheet as more like a well organized computer menu bar that leads you to a command than a manual that documents each command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The cheat sheets use a cohesive, black and white printer friendly theme (which is what you see in the sheets), so please stay close to the appearance of the existing sheets.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It's already baked into every cheat sheet and the template, but you should include a &lt;a href="https://creativecommons.org/" rel="nofollow"&gt;Creative Commons&lt;/a&gt; Copyright on each side of the sheet to make them easy to repurpose.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Budget more time than you expect to make the sheets. So far, I've found this process to be the least time consuming:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the package web page and any vignettes to identify which functions to include (I try to include anything that doesn't seem trivial.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Organize the functions into meaningful, self-explanatory groups.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Think about how to visualize the purpose of each function.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Think about what key mental models, definitions, or explanations the cheat sheet should contain in addition to the functions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sketch out several possible layouts for the sheet. Take care to put the more basic and/or pre-requisite content above and to the left of other content. Try to keep related content on the same side of the page.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Type out all of the explanations and function definitions. Lay them out. Verify that everything fits. White space is very important. Use it to make the sheet scannable, even if it means smaller text.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Making the visuals is the most time consuming part, so I usually save them for last.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tweak until happy.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pay attention to the details!&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Final tip: Edit the text to be very concise - rely on diagrams where possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rstudio</author><guid isPermaLink="false">https://github.com/rstudio/cheatsheets</guid><pubDate>Mon, 02 Dec 2019 00:04:00 GMT</pubDate></item><item><title>mohuangrui/ucasthesis #5 in TeX, Today</title><link>https://github.com/mohuangrui/ucasthesis</link><description>&lt;p&gt;&lt;i&gt; [最新样式] 中国科学院大学学位论文 LaTeX 模板  LaTeX Thesis Template for the University of Chinese Academy of Sciences &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-ucasthesis-国科大学位论文-latex-模板-最新样式" class="anchor" aria-hidden="true" href="#ucasthesis-国科大学位论文-latex-模板-最新样式"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;code&gt;ucasthesis&lt;/code&gt; 国科大学位论文 LaTeX 模板 [最新样式]&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-模板下载" class="anchor" aria-hidden="true" href="#模板下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模板下载&lt;/h2&gt;
&lt;p&gt;请在页面右边点击：&lt;strong&gt;Clone or download -&amp;gt; Download Zip&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-重要建议" class="anchor" aria-hidden="true" href="#重要建议"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;重要建议&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;关于 LaTeX 的知识性问题，请查阅 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki"&gt;LaTeX 知识小站&lt;/a&gt; 和 &lt;a href="https://en.wikibooks.org/wiki/LaTeX" rel="nofollow"&gt;LaTeX Wikibook&lt;/a&gt;，如发问需前往 &lt;a href="https://github.com/CTeX-org/forum"&gt;CTeX Forum&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;关于 ucasthesis 编译和设计的问题，请先读 &lt;strong&gt;模板使用说明.pdf&lt;/strong&gt;，如发问需遵从&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"&gt;提问流程&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;使用邮件传播 ucasthesis 时，请先删除 &lt;code&gt;artratex.bat&lt;/code&gt; 以防范 Dos 脚本的潜在风险。&lt;/li&gt;
&lt;li&gt;开题报告请见：&lt;a href="https://github.com/mohuangrui/ucasproposal"&gt;ucasproposal: 中国科学院大学开题报告 LaTeX 模板&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;书脊制作请见：&lt;a href="https://github.com/mohuangrui/latexspine"&gt;latexspine: LaTeX 书脊模板&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-模板简介" class="anchor" aria-hidden="true" href="#模板简介"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模板简介&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ucasthesis 为撰写中国科学院大学&lt;strong&gt;本&lt;/strong&gt;、&lt;strong&gt;硕&lt;/strong&gt;、&lt;strong&gt;博&lt;/strong&gt;学位论文和&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98#%E5%A6%82%E4%BD%95%E5%A1%AB%E5%86%99%E5%8D%9A%E5%A3%AB%E5%90%8E%E7%9A%84-frontinfotex-"&gt;&lt;strong&gt;博后&lt;/strong&gt;&lt;/a&gt;报告的 LaTeX 模版。ucasthesis 提供了简单明了的&lt;strong&gt;模板使用说明.pdf&lt;/strong&gt;。无论你是否具有 LaTeX 使用经验，都可较为轻松地使用以完成学位论文的撰写和排版。谢谢大家的测试、反馈和支持，我们一起的努力让 ucasthesis 非常荣幸地得到了国科大本科部陆晴老师、本科部学位办丁云云老师和中科院数学与系统科学研究院吴凌云研究员的支持，并得到吴凌云学长在 &lt;a href="http://www.ctex.org/HomePage" rel="nofollow"&gt;CTEX&lt;/a&gt; 的发布。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到许多同学可能缺乏 LaTeX 使用经验，ucasthesis 将 LaTeX 的复杂性高度封装，开放出简单的接口，以便轻易使用。同时，对用 LaTeX 撰写论文的一些主要难题，如制图、制表、文献索引等，进行了详细说明，并提供了相应的代码样本，理解了上述问题后，对于初学者而言，使用此模板撰写学位论文将不存在实质性的困难。所以，如果你是初学者，请不要直接放弃，因为同样为初学者的我，十分明白让 LaTeX 简单易用的重要性，而这正是 ucasthesis 所追求和体现的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;此中国科学院大学学位论文模板 ucasthesis 基于中科院数学与系统科学研究院吴凌云研究员的 CASthesis 模板发展而来。当前 ucasthesis 模板满足最新的中国科学院大学学位论文撰写要求和封面设定。兼顾操作系统：Windows，Linux，MacOS 和 LaTeX 编译引擎：pdflatex，xelatex，lualatex。支持中文书签、中文渲染、中文粗体显示、拷贝 PDF 中的文本到其他文本编辑器等特性（&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%AD%97%E4%BD%93%E9%85%8D%E7%BD%AE"&gt;Windows 系统 PDF 拷贝乱码的解决方案需见：字体配置&lt;/a&gt;）。此外，对模板的文档结构进行了精心设计，撰写了编译脚本提高模板的易用性和使用效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ucasthesis 的目标在于简化学位论文的撰写，利用 LaTeX 格式与内容分离的特征，模板将格式设计好后，作者可只需关注论文内容。 同时，ucasthesis 有着整洁一致的代码结构和扼要的注解，对文档的仔细阅读可为初学者提供一个学习 LaTeX 的窗口。此外，模板的架构十分注重通用性，事实上，ucasthesis 不仅是国科大学位论文模板，同时，通过少量修改即可成为使用 LaTeX 撰写中英文文章或书籍的通用模板，并为使用者的个性化设定提供了接口。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-重要通知" class="anchor" aria-hidden="true" href="#重要通知"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;重要通知&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;2019-10-21&lt;/code&gt; 模板样式进行了修改，请查看下面的修改描述，以决定是否需要更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-更新记录" class="anchor" aria-hidden="true" href="#更新记录"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新记录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-10-12&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/198"&gt;huiwenzhang, issue #198&lt;/a&gt; 修复&lt;code&gt;mainmatter&lt;/code&gt;下&lt;code&gt;\chapter*&lt;/code&gt;的页眉错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-10-12&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/195"&gt;Fancy0609, muzimuzhi, issue #195&lt;/a&gt; 调整由&lt;code&gt;AutoFakeBold&lt;/code&gt;控制的伪粗体加粗程度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-10-11&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/190"&gt;Pantrick, issue #190&lt;/a&gt; 采用 &lt;a href="https://github.com/muzimuzhi"&gt;muzimuzhi&lt;/a&gt; 提供的方法实现&lt;code&gt;\advisor{}&lt;/code&gt;和&lt;code&gt;\institute{}&lt;/code&gt;的自动换行功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-08-01&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/183"&gt;vectorliu, issue #183&lt;/a&gt; 修改英文模式下的&lt;code&gt;plain&lt;/code&gt;选项为&lt;code&gt;scheme=plain&lt;/code&gt;以消除对&lt;code&gt;Algorithm&lt;/code&gt;样式的修改。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-06-15&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/177"&gt;HaorenWang, issue #177&lt;/a&gt; 调整矢量、矩阵、张量字体样式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-06-09&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/170"&gt;DRjy, issue #170&lt;/a&gt; 轻微缩减目录中编号与标题的间距；根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/174"&gt;e71828, issue #174&lt;/a&gt; 轻微增加页眉中编号与标题的间距。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-05-25&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/169"&gt;CDMA2019, issue #169&lt;/a&gt; 提供横排图表环境下页眉页脚的横排，具体使用见 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E6%A8%AA%E6%8E%92%E5%9B%BE%E8%A1%A8"&gt;横排图表&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-24&lt;/code&gt; 拓展模版兼容 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98#%E5%A6%82%E4%BD%95%E5%A1%AB%E5%86%99%E5%8D%9A%E5%A3%AB%E5%90%8E%E7%9A%84-frontinfotex-"&gt;博后报告&lt;/a&gt;。修复 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/156"&gt;gsp2014, issue #156&lt;/a&gt; 文献引用中的连字符的间断显示和上标引用中逗号下沉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-19&lt;/code&gt; 修复 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/117"&gt;nihaomiao, issue #117&lt;/a&gt;&lt;code&gt;\mathbf&lt;/code&gt;失效问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-16&lt;/code&gt; 修复国际生需要的&lt;code&gt;plain&lt;/code&gt;模式下无法改变英文章标题字体大小的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-09&lt;/code&gt; 对部分宏命令进行调整，无功能及样式上的修改。若需更新，建议参考 &lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E6%9B%B4%E6%96%B0%E6%8C%87%E5%8D%97"&gt;更新指南&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-04-04&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/134"&gt;liuy334, songchunlin, issue #134&lt;/a&gt; ，调整行距使&lt;code&gt;LaTeX&lt;/code&gt;版与&lt;code&gt;Word&lt;/code&gt;版的行数和每行字数相一致。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-03-28&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/49"&gt;zssasa, allenwoods, issue #49&lt;/a&gt; ，修复&lt;code&gt;bicaption&lt;/code&gt;对&lt;code&gt;longtable&lt;/code&gt;的兼容性。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/133"&gt;BowenHou, issue #133&lt;/a&gt; ，使下划线能对长标题自动换行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-03-25&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/127"&gt;DRjy, muzimuzhi, issue #127&lt;/a&gt; ，为&lt;code&gt;摘要&lt;/code&gt;等无需在目录中显示的结构元素建立书签。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/130"&gt;muzimuzhi, issue #130&lt;/a&gt; ，修正对&lt;code&gt;\voffset&lt;/code&gt;的使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-03-14&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/121"&gt;opt-gaobin, issue #121&lt;/a&gt; ，修正中文标点使下划线断掉的问题。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/120"&gt;Guoqiang Zhang, email; weili-ict, issue #120&lt;/a&gt; ，修复&lt;code&gt;\proofname&lt;/code&gt;命令对2015年及更早&lt;code&gt;LaTeX&lt;/code&gt;编译器的兼容性问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-02-20&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/100"&gt;opt-gaobin, issue #100&lt;/a&gt; ，增加定理、定义、证明等数学环境。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/102"&gt;DRjy, issue #102&lt;/a&gt; ，调整&lt;code&gt;\mathcal&lt;/code&gt;字体样式。根据 [zike Liu, email] ，适当缩减目录列表的缩进。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/105"&gt;xiaoyaoE, issue #105&lt;/a&gt; ，使数字字体和英文字体一致。完善中文版和国际版之间的中英格式切换。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2019-01-10&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/57"&gt;mnpengjk, issue #57&lt;/a&gt; ， 将公式编号前加点纳入模版默认，更多讨论可见：&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E7%90%90%E5%B1%91%E7%BB%86%E8%8A%82"&gt;琐屑细节&lt;/a&gt; 。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/95"&gt;yunyun2019, issue #95&lt;/a&gt; ，采用 &lt;a href="https://github.com/zepinglee"&gt;zepinglee&lt;/a&gt; 基于国标样式为&lt;code&gt;ucas&lt;/code&gt;所定制文献样式：&lt;a href="https://github.com/CTeX-org/gbt7714-bibtex-style/tree/ucas"&gt;ucas 样式分支&lt;/a&gt; ，文献样式更多讨论可见：&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E6%96%87%E7%8C%AE%E6%A0%B7%E5%BC%8F"&gt;文献样式&lt;/a&gt;。根据 [邵岳林, email] ，将附录复原为常规的排版设置，若需将附录置于参考文献后，请见：&lt;a href="https://github.com/mohuangrui/ucasthesis/wiki/%E7%90%90%E5%B1%91%E7%BB%86%E8%8A%82"&gt;琐屑细节&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-04-03&lt;/code&gt; 根据国科大本科部陆晴老师和本科部学位办丁云云老师的复审审核建议再次修复一些样式细节问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-04-02&lt;/code&gt; 模板进行了重大更新，修复了样式、字体、格式等许多问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据国科大本科部陆晴老师的建议对模版样式进行了诸多拓展和修正，并完善对本科生论文元素的兼容性。&lt;/li&gt;
&lt;li&gt;在 &lt;a href="https://github.com/CTeX-org/ctex-kit"&gt;ctex&lt;/a&gt; 开发者的帮助下解决了如何多次调用&lt;code&gt;Times New Roman&lt;/code&gt;而不导致黑体调用错误的问题。根据 [twn1993, email]，修复默认黑体为微软雅黑而不是&lt;code&gt;SimHei&lt;/code&gt;的问题。&lt;/li&gt;
&lt;li&gt;繁复折腾测试后终于找出一个在&lt;code&gt;ctex&lt;/code&gt;默认黑体替换粗宋体设定环境内全局&lt;code&gt;AutoFakeBold&lt;/code&gt;失效状态下折衷特定字体库不全条件下生僻字显示和系统默认字重不全条件下粗宋体显示以及不同操作系统下如何平衡上述字库自重矛盾还有根据操作系统自动调用所带有的&lt;code&gt;Times&lt;/code&gt;字体的方案。&lt;/li&gt;
&lt;li&gt;设定论文封面据英文学位名如自动切换。密级据是否填写自动显示。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-03-22&lt;/code&gt; 演示表标题居表上，加粗图表标注，设置长图表标题悬挂缩进（由于&lt;code&gt;bicaption&lt;/code&gt;宏包无法正确接受&lt;code&gt;caption&lt;/code&gt;宏包的&lt;code&gt;margin&lt;/code&gt;选项，图表中英标题第一行无法正确同步缩进，从而放弃第一行的缩进），强调多图中子图标题的规范使用，通过摘要和符号列表演示标题不在目录中显示却仍在页眉中显示。根据 [赵永明, email]，设置双语图表标题和&lt;code&gt;bicaption&lt;/code&gt;不在图形列表和表格列表中显示英文标题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-03-21&lt;/code&gt; 根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/42"&gt;zhanglinbo, issue #42&lt;/a&gt; ，使用 &lt;a href="https://github.com/xiaoyao9933/UCASthesis"&gt;xiaoyao9933&lt;/a&gt; 制作的&lt;code&gt;ucas_logo.pdf&lt;/code&gt;使学校&lt;code&gt;logo&lt;/code&gt;放大不失真。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/41"&gt;Starsky Wong, issue #41&lt;/a&gt; ，设置标题英文设为&lt;code&gt;Times New Roman&lt;/code&gt;。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/29"&gt;will0n, issue #29&lt;/a&gt; ，&lt;a href="https://github.com/mohuangrui/ucasthesis/issues/26"&gt;Man-Ting-Fang, issue #26&lt;/a&gt; ，&lt;a href="https://github.com/mohuangrui/ucasthesis/issues/12"&gt;diyiliaoya, issue #12&lt;/a&gt; ，和 [赵永明, email] ，矫正一些格式细节问题。根据 &lt;a href="https://github.com/mohuangrui/ucasthesis/issues/30"&gt;tangjie1992, issue #30&lt;/a&gt; ，配置算法环境。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-02-04&lt;/code&gt; 在 &lt;a href="https://github.com/CTeX-org/ctex-kit"&gt;ctex&lt;/a&gt; 开发者的帮助下修复误用字体命令导致的粗宋体异常。然后，将模板兼容性进一步扩展为兼容操作系统&lt;code&gt;Windows&lt;/code&gt;，&lt;code&gt;Linux&lt;/code&gt;，&lt;code&gt;MacOS&lt;/code&gt;和&lt;code&gt;LaTeX &lt;/code&gt;编译引擎&lt;code&gt;pdflatex&lt;/code&gt;，&lt;code&gt;xelatex&lt;/code&gt;，&lt;code&gt;lualatex&lt;/code&gt;。移除&lt;code&gt;microtype&lt;/code&gt;宏包以提高编译效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2018-01-28&lt;/code&gt; 基于国科大&lt;code&gt;2018&lt;/code&gt;新版论文规范进行了重大修改，采用新的封面、声明、页眉页脚样式。展示标题中使用数学公式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;2017-05-14&lt;/code&gt; 根据 [赵永明, email] ，增加&lt;code&gt;\citepns{}&lt;/code&gt;和&lt;code&gt;\citetns{}&lt;/code&gt;命令提供上标引用下混合非上标引用的需求。根据 [臧光明, email] ，添加设定论文为&lt;code&gt;thesis&lt;/code&gt;或&lt;code&gt;dissertation&lt;/code&gt;的命令。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>mohuangrui</author><guid isPermaLink="false">https://github.com/mohuangrui/ucasthesis</guid><pubDate>Mon, 02 Dec 2019 00:05:00 GMT</pubDate></item><item><title>deedy/Deedy-Resume #6 in TeX, Today</title><link>https://github.com/deedy/Deedy-Resume</link><description>&lt;p&gt;&lt;i&gt;A one page , two asymmetric column resume template in XeTeX that caters to an undergraduate Computer Science student&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deedy-resume" class="anchor" aria-hidden="true" href="#deedy-resume"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deedy-Resume&lt;/h1&gt;
&lt;p&gt;A &lt;strong&gt;one-page&lt;/strong&gt;, &lt;strong&gt;two asymmetric column&lt;/strong&gt; resume template in &lt;strong&gt;XeTeX&lt;/strong&gt; that caters particularly to an &lt;strong&gt;undergraduate Computer Science&lt;/strong&gt; student.
As of &lt;strong&gt;v1.2&lt;/strong&gt;, there is an option to choose from two templates:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;MacFonts&lt;/strong&gt; - uses fonts native to OSX - &lt;em&gt;Helvetica&lt;/em&gt;, &lt;em&gt;Helvetica Neue&lt;/em&gt; (and it's Light and Ultralight versions) and the CJK fonts &lt;em&gt;Heiti SC&lt;/em&gt;, and &lt;em&gt;Heiti TC&lt;/em&gt;. The EULA of these fonts prevents distribution on Open Source.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenFonts&lt;/strong&gt; - uses free, open-source fonts that resemble the above - &lt;em&gt;Lato&lt;/em&gt; (and its various variants) and &lt;em&gt;Raleway&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It is licensed under the Apache License 2.0.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Common LaTeX resume-builders such as &lt;a href="http://www.latextemplates.com/template/moderncv-cv-and-cover-letter" rel="nofollow"&gt;&lt;strong&gt;moderncv&lt;/strong&gt;&lt;/a&gt;  and the &lt;a href="https://github.com/afriggeri/cv"&gt;&lt;strong&gt;friggeri-cv&lt;/strong&gt;&lt;/a&gt; look great if you're looking for a multi-page resume with numerous citations, but usually imperfect for making a thorough, single-page one. A lot of companies today search resumes based on &lt;a href="http://www.businessinsider.com/most-big-companies-have-a-tracking-system-that-scans-your-resume-for-keywords-2012-1" rel="nofollow"&gt;keywords&lt;/a&gt; but at the same time require/prefer a one-page resume, especially for undergraduates.&lt;/p&gt;
&lt;p&gt;This template attempts to &lt;strong&gt;look clean&lt;/strong&gt;, highlight &lt;strong&gt;details&lt;/strong&gt;, be a &lt;strong&gt;single page&lt;/strong&gt;, and allow useful &lt;strong&gt;LaTeX templating&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-preview" class="anchor" aria-hidden="true" href="#preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preview&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-openfonts" class="anchor" aria-hidden="true" href="#openfonts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenFonts&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/OpenFonts/sample-image.png"&gt;&lt;img src="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/OpenFonts/sample-image.png" alt="alt tag" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-macfonts" class="anchor" aria-hidden="true" href="#macfonts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;MacFonts&lt;/h3&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/MacFonts/sample-image.png"&gt;&lt;img src="https://raw.githubusercontent.com/deedydas/Deedy-Resume/master/MacFonts/sample-image.png" alt="alt tag" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dependencies" class="anchor" aria-hidden="true" href="#dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependencies&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Compiles only with &lt;strong&gt;XeTeX&lt;/strong&gt; and required &lt;strong&gt;BibTex&lt;/strong&gt; for compiling publications and the .bib filetype.&lt;/li&gt;
&lt;li&gt;Uses fonts that are usually only available to &lt;strong&gt;Mac&lt;/strong&gt; users such as Helvetica Neue Light.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-availability" class="anchor" aria-hidden="true" href="#availability"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Availability&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;MacFonts version - &lt;a href="http://debarghyadas.com/resume/debarghya-das-resume.pdf" rel="nofollow"&gt;as an online preview&lt;/a&gt; and &lt;a href="https://github.com/deedydas/Deedy-Resume/raw/master/MacFonts/deedy_resume.pdf"&gt;as a direct download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenFonts version - &lt;a href="https://github.com/deedydas/Deedy-Resume/raw/master/OpenFonts/deedy_resume-openfont.pdf"&gt;as a direct download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Overleaf&lt;/strong&gt;.com (formerly &lt;strong&gt;WriteLatex&lt;/strong&gt;.com) (v1 fonts/colors changed) - &lt;a href="https://www.writelatex.com/templates/deedy-resume/sqdbztjjghvz#.U2H9Kq1dV18" rel="nofollow"&gt;compilable online&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ShareLatex&lt;/strong&gt;.com (v1 fonts changes) - &lt;a href="https://www.sharelatex.com/templates/cv-or-resume/deedy-resume" rel="nofollow"&gt;compilable online&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-changelog" class="anchor" aria-hidden="true" href="#changelog"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Changelog&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-v12" class="anchor" aria-hidden="true" href="#v12"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v1.2&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Added publications in place of societies.&lt;/li&gt;
&lt;li&gt;Collapsed a portion of education.&lt;/li&gt;
&lt;li&gt;Fixed a bug with alignment of overflowing long last updated dates on the top right.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a id="user-content-v11" class="anchor" aria-hidden="true" href="#v11"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;v1.1&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Fixed several compilation bugs with \renewcommand&lt;/li&gt;
&lt;li&gt;Got Open-source fonts (Windows/Linux support)&lt;/li&gt;
&lt;li&gt;Added Last Updated&lt;/li&gt;
&lt;li&gt;Moved Title styling into .sty&lt;/li&gt;
&lt;li&gt;Commented .sty file.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODO&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Merge OpenFont and MacFonts as a single sty with options.&lt;/li&gt;
&lt;li&gt;Figure out a smoother way for the document to flow onto the next page.&lt;/li&gt;
&lt;li&gt;Add styling information for a "Projects/Hacks" section.&lt;/li&gt;
&lt;li&gt;Add location/address information&lt;/li&gt;
&lt;li&gt;Fix the hacky 'References' omission outside the .cls file in the MacFonts version.&lt;/li&gt;
&lt;li&gt;Add various styling and section options and allow for multiple pages smoothly.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-known-issues" class="anchor" aria-hidden="true" href="#known-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Known Issues:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Overflows onto second page if any column's contents are more than the vertical limit&lt;/li&gt;
&lt;li&gt;Hacky space on the first bullet point on the second column.&lt;/li&gt;
&lt;li&gt;Hacky redefinition of \refname to omit 'References' text for publications in the MacFonts version.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Copyright 2014 Debarghya Das

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>deedy</author><guid isPermaLink="false">https://github.com/deedy/Deedy-Resume</guid><pubDate>Mon, 02 Dec 2019 00:06:00 GMT</pubDate></item><item><title>Wandmalfarbe/pandoc-latex-template #7 in TeX, Today</title><link>https://github.com/Wandmalfarbe/pandoc-latex-template</link><description>&lt;p&gt;&lt;i&gt;A pandoc LaTeX template to convert markdown files to PDF or LaTeX.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="icon.png"&gt;&lt;img src="icon.png" align="right" height="110" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-eisvogel" class="anchor" aria-hidden="true" href="#eisvogel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Eisvogel&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/Wandmalfarbe/pandoc-latex-template" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b87755780c096b231f6f2e8a6192d30318d187a3/68747470733a2f2f7472617669732d63692e6f72672f57616e646d616c66617262652f70616e646f632d6c617465782d74656d706c6174652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/Wandmalfarbe/pandoc-latex-template.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A clean &lt;strong&gt;pandoc LaTeX template&lt;/strong&gt; to convert your markdown files to PDF or LaTeX. It is designed for lecture notes and exercises with a focus on computer science. The template is compatible with pandoc 2.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-preview" class="anchor" aria-hidden="true" href="#preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Preview&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;A custom title page&lt;/th&gt;
&lt;th align="center"&gt;A basic example page&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/custom-titlepage/custom-titlepage.pdf"&gt;&lt;img src="examples/custom-titlepage/custom-titlepage.png" alt="A custom title page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/basic-example/basic-example.pdf"&gt;&lt;img src="examples/basic-example/basic-example.png" alt="A basic example page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install pandoc from &lt;a href="http://pandoc.org/" rel="nofollow"&gt;http://pandoc.org/&lt;/a&gt;. You also need to install &lt;a href="https://en.wikibooks.org/wiki/LaTeX/Installation#Distributions" rel="nofollow"&gt;LaTeX&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the latest version of the Eisvogel template from &lt;a href="https://github.com/Wandmalfarbe/pandoc-latex-template/releases/latest"&gt;the release page&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Extract the downloaded ZIP archive and open the folder.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Move the template &lt;code&gt;eisvogel.tex&lt;/code&gt; to your pandoc templates folder and rename the file to &lt;code&gt;eisvogel.latex&lt;/code&gt;. The location of the templates folder depends on your operating system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unix, Linux, macOS: &lt;code&gt;/Users/USERNAME/.local/share/pandoc/templates/&lt;/code&gt; or &lt;code&gt;/Users/USERNAME/.pandoc/templates/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Windows Vista or later: &lt;code&gt;C:\Users\USERNAME\AppData\Roaming\pandoc\templates\&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If there are no folders called &lt;code&gt;templates&lt;/code&gt; or &lt;code&gt;pandoc&lt;/code&gt; you need to create them and put the template &lt;code&gt;eisvogel.latex&lt;/code&gt; inside. You can find the default user data directory on your system by looking at the output of &lt;code&gt;pandoc --version&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Open the terminal and navigate to the folder where your markdown file is located.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Execute the following command&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --from markdown --template eisvogel --listings&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code&gt;example.md&lt;/code&gt; is the markdown file you want to convert to PDF.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to have nice headers and footers you need to supply metadata to your document. You can do that with a &lt;a href="http://pandoc.org/MANUAL.html#extension-yaml_metadata_block" rel="nofollow"&gt;YAML metadata block&lt;/a&gt; at the top of your markdown document (see the &lt;a href="examples/basic-example/basic-example.md"&gt;example markdown file&lt;/a&gt;). Your markdown document may look like the following:&lt;/p&gt;
&lt;div class="highlight highlight-source-gfm"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;---&lt;/span&gt;
&lt;span class="pl-ent"&gt;title&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;The Document Title&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-ent"&gt;author&lt;/span&gt;: &lt;span class="pl-s"&gt;[Example Author, Another Author]&lt;/span&gt;
&lt;span class="pl-ent"&gt;date&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;2017-02-20&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-ent"&gt;keywords&lt;/span&gt;: &lt;span class="pl-s"&gt;[Markdown, Example]&lt;/span&gt;
&lt;span class="pl-c"&gt;...&lt;/span&gt;

Here is the actual document text...&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-custom-template-variables" class="anchor" aria-hidden="true" href="#custom-template-variables"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Custom Template Variables&lt;/h3&gt;
&lt;p&gt;This template defines some new variables to control the appearance of the resulting PDF document. The existing template variables from pandoc are all supported and their documentation can be found in &lt;a href="https://pandoc.org/MANUAL.html#variables-for-latex" rel="nofollow"&gt;the pandoc manual&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;turns on the title page when &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-color&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the background color of the title page. The color value must be given as an HTML hex color like &lt;code&gt;D8DE2C&lt;/code&gt; without the leading number sign (&lt;code&gt;#&lt;/code&gt;). When specifying the color in YAML, it is advisable to enclose it in quotes like so &lt;code&gt;titlepage-color: "D8DE2C"&lt;/code&gt; to avoid the truncation of the color (e.g. &lt;code&gt;000000&lt;/code&gt; becoming &lt;code&gt;0&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-text-color&lt;/code&gt; (defaults to &lt;code&gt;5F5F5F&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the text color of the title page&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-rule-color&lt;/code&gt; (defaults to &lt;code&gt;435488&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the color of the rule on the top of the title page&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-rule-height&lt;/code&gt; (defaults to &lt;code&gt;4&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the height of the rule on the top of the title page (in points)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;titlepage-background&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the path to a background image for the title page. The background image is scaled to cover the entire page. In the examples folder under &lt;code&gt;titlepage-background&lt;/code&gt; are a few example background images.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;caption-justification&lt;/code&gt; (defaults to &lt;code&gt;raggedright&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;justification setting for captions (uses the &lt;code&gt;justification&lt;/code&gt; parameter of the &lt;a href="https://ctan.org/pkg/caption?lang=en" rel="nofollow"&gt;caption&lt;/a&gt; package)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;toc-own-page&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;begin new page after table of contents, when &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;listings-disable-line-numbers&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;disables line numbers for all listings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;listings-no-page-break&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;avoid page break inside listings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;disable-header-and-footer&lt;/code&gt; (default to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;disables the header and footer completely on all pages&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;header-left&lt;/code&gt; (defaults to the title)&lt;/p&gt;
&lt;p&gt;the text on the left side of the header&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;header-center&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the text in the center of the header&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;header-right&lt;/code&gt; (defaults to the date)&lt;/p&gt;
&lt;p&gt;the text on the right side of the header&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footer-left&lt;/code&gt; (defaults to the author)&lt;/p&gt;
&lt;p&gt;the text on the left side of the footer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footer-center&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;the text in the center of the footer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footer-right&lt;/code&gt; (defaults to the page number)&lt;/p&gt;
&lt;p&gt;the text on the right side of the footer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footnotes-pretty&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;prettifies formatting of footnotes (requires package &lt;code&gt;footmisc&lt;/code&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;footnotes-disable-backlinks&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;disables making the reference from the footnote at the bottom of the page into a link back to the occurence of the footnote in the main text.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;book&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;typeset as book&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;logo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;path to an image that will be displayed on the title page. The path is always relative to where pandoc is executed. The option &lt;code&gt;--resource-path&lt;/code&gt; has no effect.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;logo-width&lt;/code&gt; (defaults to &lt;code&gt;100&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;the width of the logo (in points)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;first-chapter&lt;/code&gt; (defaults to &lt;code&gt;1&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;if typesetting a book with chapter numbers, specifies the number that will be assigned to the first chapter&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;float-placement-figure&lt;/code&gt; (defaults to &lt;code&gt;H&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;Reset the default placement specifier for figure environments to the supplied value e.g. &lt;code&gt;htbp&lt;/code&gt;. The available specifiers are listed below. The first four placement specifiers can be combined.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;h&lt;/code&gt;: Place the float &lt;em&gt;here&lt;/em&gt;, i.e., approximately at the same point it occurs in the source text.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;t&lt;/code&gt;: Place the float at the &lt;em&gt;top&lt;/em&gt; of the page.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt;: Place the float at the &lt;em&gt;bottom&lt;/em&gt; of the page.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p&lt;/code&gt;: Place the float on the next &lt;em&gt;page&lt;/em&gt; that will contain only floats like figures and tables.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H&lt;/code&gt;: Place the float &lt;em&gt;HERE&lt;/em&gt; (exactly where it occurs in the source text). The &lt;code&gt;H&lt;/code&gt; specifier is provided by the &lt;a href="https://ctan.org/pkg/float" rel="nofollow"&gt;float package&lt;/a&gt; and may not be used in conjunction with any other placement specifiers.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;table-use-row-colors&lt;/code&gt; (defaults to &lt;code&gt;false&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;enables row colors for tables. The default value is &lt;code&gt;false&lt;/code&gt; because the coloring extends beyond the edge of the table and there is currently no way to change that.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;code-block-font-size&lt;/code&gt; (defaults to &lt;code&gt;\small&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;LaTeX command to change the font size for code blocks. The available values are &lt;code&gt;\tiny&lt;/code&gt;, &lt;code&gt;\scriptsize&lt;/code&gt;, &lt;code&gt;\footnotesize&lt;/code&gt;, &lt;code&gt;\small&lt;/code&gt;, &lt;code&gt;\normalsize&lt;/code&gt;, &lt;code&gt;\large&lt;/code&gt;, &lt;code&gt;\Large&lt;/code&gt;, &lt;code&gt;\LARGE&lt;/code&gt;, &lt;code&gt;\huge&lt;/code&gt; and &lt;code&gt;\Huge&lt;/code&gt;. This option will change the font size for default code blocks using the verbatim environment and for code blocks generated with listings.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-numbered-sections" class="anchor" aria-hidden="true" href="#numbered-sections"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Numbered Sections&lt;/h3&gt;
&lt;p&gt;For PDFs with &lt;a href="http://pandoc.org/MANUAL.html#options-affecting-specific-writers" rel="nofollow"&gt;numbered sections&lt;/a&gt; use the &lt;code&gt;--number-sections&lt;/code&gt; or &lt;code&gt;-N&lt;/code&gt; option.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --number-sections&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-syntax-highlighting-with-listings" class="anchor" aria-hidden="true" href="#syntax-highlighting-with-listings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syntax Highlighting with Listings&lt;/h3&gt;
&lt;p&gt;You can get syntax highlighting of delimited code blocks by using the LaTeX package listings with the option &lt;code&gt;--listings&lt;/code&gt;. This example will produce the same syntax highlighting as in the example PDF.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --listings&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-syntax-highlighting-without-listings" class="anchor" aria-hidden="true" href="#syntax-highlighting-without-listings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syntax Highlighting Without Listings&lt;/h3&gt;
&lt;p&gt;The following examples show &lt;a href="http://pandoc.org/MANUAL.html#syntax-highlighting" rel="nofollow"&gt;syntax highlighting of delimited code blocks&lt;/a&gt; without using listings. To see a list of all the supported highlight styles, type &lt;code&gt;pandoc --list-highlight-styles&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style pygments&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style kate&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style espresso&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel --highlight-style tango&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-standalone-latex-document" class="anchor" aria-hidden="true" href="#standalone-latex-document"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Standalone LaTeX Document&lt;/h3&gt;
&lt;p&gt;To produce a standalone LaTeX document for compiling with any LaTeX editor use &lt;code&gt;.tex&lt;/code&gt; as an output file extension.&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.tex --template eisvogel&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-changing-the-document-language" class="anchor" aria-hidden="true" href="#changing-the-document-language"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Changing the Document Language&lt;/h3&gt;
&lt;p&gt;The default language of this template is American English. The &lt;code&gt;lang&lt;/code&gt; variable identifies the main language of the document, using a code according to &lt;a href="https://tools.ietf.org/html/bcp47" rel="nofollow"&gt;BCP 47&lt;/a&gt; (e.g. &lt;code&gt;en&lt;/code&gt; or &lt;code&gt;en-GB&lt;/code&gt;). For an incomplete list of the supported language codes see &lt;a href="http://mirrors.ctan.org/language/hyph-utf8/doc/generic/hyph-utf8/hyph-utf8.pdf" rel="nofollow"&gt;the documentation for the hyph-utf8 package (Section 2)&lt;/a&gt;. The following example changes the language to British English:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel -V lang=en-GB&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The following example changes the language to German:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;pandoc example.md -o example.pdf --template eisvogel -V lang=de&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-typesetting-a-book" class="anchor" aria-hidden="true" href="#typesetting-a-book"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Typesetting a Book&lt;/h3&gt;
&lt;p&gt;To typeset a book supply the template variable &lt;code&gt;-V book&lt;/code&gt; from the command line or via &lt;code&gt;book: true&lt;/code&gt; in the metadata.&lt;/p&gt;
&lt;p&gt;To get the correct chapter headings you need to tell pandoc that it should convert first level headings (indicated by one &lt;code&gt;#&lt;/code&gt; in markdown) to chapters with the command line option &lt;code&gt;--top-level-division=chapter&lt;/code&gt;. Chapter numbers start at 1. If you need to change that, specify &lt;code&gt;first-chapter&lt;/code&gt; in the template variables.&lt;/p&gt;
&lt;p&gt;There will be one blank page before each chapter because the template is two-sided per default. So if you plan to publish your book as a PDF and don’t need a blank page you should add the class option &lt;code&gt;onesided&lt;/code&gt; which can be done by supplying a template variable &lt;code&gt;-V classoption=oneside&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-example-images" class="anchor" aria-hidden="true" href="#example-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Images&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;A green title page&lt;/th&gt;
&lt;th align="center"&gt;A background image on the title page&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/green-titlepage/green-titlepage.pdf"&gt;&lt;img src="examples/green-titlepage/green-titlepage.png" alt="A green title page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/titlepage-background/titlepage-background.pdf"&gt;&lt;img src="examples/titlepage-background/titlepage-background.png" alt="A background image on the title page" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;images and tables&lt;/th&gt;
&lt;th align="center"&gt;Code blocks styled without listings&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/images-and-tables/images-and-tables.pdf"&gt;&lt;img src="examples/images-and-tables/images-and-tables.png" alt="images and tables" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/without-listings/without-listings.pdf"&gt;&lt;img src="examples/without-listings/without-listings.png" alt="Code blocks styled without listings" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;A book&lt;/th&gt;
&lt;th align="center"&gt;Code blocks styled with listings&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="examples/book/book.pdf"&gt;&lt;img src="examples/book/book.png" alt="A book" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="examples/listings/listings.pdf"&gt;&lt;img src="examples/listings/listings.png" alt="Code blocks styled with listings" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This template includes code for styling block quotations from &lt;a href="https://github.com/aaronwolen/pandoc-letter"&gt;pandoc-letter&lt;/a&gt; by &lt;a href="https://github.com/aaronwolen"&gt;Aaron Wolen&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This project is open source licensed under the BSD 3-Clause License. Please see the &lt;a href="LICENSE"&gt;LICENSE file&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Wandmalfarbe</author><guid isPermaLink="false">https://github.com/Wandmalfarbe/pandoc-latex-template</guid><pubDate>Mon, 02 Dec 2019 00:07:00 GMT</pubDate></item><item><title>xdanaux/moderncv #8 in TeX, Today</title><link>https://github.com/xdanaux/moderncv</link><description>&lt;p&gt;&lt;i&gt;A modern curriculum vitae class for LaTeX&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;#moderncv: a modern curriculum vitae class#&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Moderncv&lt;/strong&gt; provides a documentclass for typesetting curricula vitae in various
styles. Moderncv aims to be both straightforward to use and customizable,
providing five ready-made styles (classic, casual, banking, oldstyle and fancy)
and allowing one to define his own by modifying colors, fonts, icons, etc.&lt;/p&gt;
&lt;p&gt;Most commands are defined in such a way that arguments are optional.&lt;/p&gt;
&lt;p&gt;Until a decent manual is written, one can always look in the "examples"
directory for some examples. Documents can be compiled into dvi, ps or pdf.&lt;/p&gt;
&lt;p&gt;Author: Xavier Danaux &lt;a href="mailto:xdanaux@gmail.com"&gt;xdanaux@gmail.com&lt;/a&gt;&lt;br&gt;
Licence: The LaTeX Project Public Li­cense, version 1.3c&lt;br&gt;
URL: &lt;a href="https://github.com/xdanaux/moderncv"&gt;https://github.com/xdanaux/moderncv&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>xdanaux</author><guid isPermaLink="false">https://github.com/xdanaux/moderncv</guid><pubDate>Mon, 02 Dec 2019 00:08:00 GMT</pubDate></item><item><title>matze/mtheme #9 in TeX, Today</title><link>https://github.com/matze/mtheme</link><description>&lt;p&gt;&lt;i&gt;A modern LaTeX Beamer theme&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h2&gt;&lt;a id="user-content-metropolis" class="anchor" aria-hidden="true" href="#metropolis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Metropolis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;IMPORTANT NOTICES FOR VERSION 1.0&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The package and theme name changed from &lt;em&gt;m&lt;/em&gt; to &lt;em&gt;metropolis&lt;/em&gt;!&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;title format&lt;/code&gt; values have been restructured. Please refer to the
&lt;a href="http://mirrors.ctan.org/macros/latex/contrib/beamer-contrib/themes/metropolis/doc/metropolistheme.pdf" rel="nofollow"&gt;manual&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Metropolis is a simple, modern Beamer theme suitable for anyone to use. It tries
to minimize noise and maximize space for content; the only visual flourish it
offers is an (optional) progress bar added to each slide. The core design
principles of the theme were described in a blog post
&lt;a href="http://bloerg.net/2014/09/20/a-modern-beamer-theme.html" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Not convinced? Have a look at the &lt;a href="http://mirrors.ctan.org/macros/latex/contrib/beamer-contrib/themes/metropolis/demo/demo.pdf" rel="nofollow"&gt;demo slides&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/da754cd10b8a0c20144d0fa848a347698ff7a197/687474703a2f2f692e696d6775722e636f6d2f4278753532667a2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/da754cd10b8a0c20144d0fa848a347698ff7a197/687474703a2f2f692e696d6775722e636f6d2f4278753532667a2e706e67" alt="Sample" data-canonical-src="http://i.imgur.com/Bxu52fz.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;To install a stable version of this theme, please refer to update instructions
of your TeX distribution. Metropolis is on &lt;a href="http://ctan.org/pkg/beamertheme-metropolis" rel="nofollow"&gt;CTAN&lt;/a&gt; since December
2014 thus it is part of MikTeX and will be part of TeX Live 2016.&lt;/p&gt;
&lt;p&gt;Installing Metropolis from source, like any Beamer theme, involves four easy
steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Download the source&lt;/strong&gt; with a &lt;code&gt;git clone&lt;/code&gt; of the &lt;a href="https://github.com/matze/mtheme"&gt;Metropolis repository&lt;/a&gt;
or as a &lt;a href="https://github.com/matze/mtheme/archive/master.zip"&gt;zip archive&lt;/a&gt; of
the latest development version.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compile the style files&lt;/strong&gt; by running &lt;code&gt;make sty&lt;/code&gt; inside the downloaded
directory. (Or run LaTeX directly on &lt;code&gt;source/metropolistheme.ins&lt;/code&gt;.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Move the resulting &lt;code&gt;*.sty&lt;/code&gt; files&lt;/strong&gt; to the folder containing your
presentation. To use Metropolis with many presentations, run &lt;code&gt;make install&lt;/code&gt;
or move the &lt;code&gt;*.sty&lt;/code&gt; files to a folder in your TeX path instead (might require
&lt;code&gt;sudo&lt;/code&gt; rights).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use the theme for your presentation&lt;/strong&gt; by declaring &lt;code&gt;\usetheme{metropolis}&lt;/code&gt; in
the preamble of your Beamer document.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;For best results&lt;/strong&gt; install Mozilla's &lt;a href="https://github.com/bBoxType/FiraSans"&gt;Fira Sans&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;The following code shows a minimal example of a Beamer presentation using
Metropolis.&lt;/p&gt;
&lt;div class="highlight highlight-text-tex-latex"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;\documentclass&lt;/span&gt;{&lt;span class="pl-c1"&gt;beamer&lt;/span&gt;}
&lt;span class="pl-c1"&gt;\usetheme&lt;/span&gt;{metropolis}           &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;%&lt;/span&gt; Use metropolis theme&lt;/span&gt;
&lt;span class="pl-c1"&gt;\title&lt;/span&gt;{A minimal example}
&lt;span class="pl-c1"&gt;\date&lt;/span&gt;{&lt;span class="pl-c1"&gt;\today&lt;/span&gt;}
&lt;span class="pl-c1"&gt;\author&lt;/span&gt;{Matthias Vogelgesang}
&lt;span class="pl-c1"&gt;\institute&lt;/span&gt;{Centre for Modern Beamer Themes}
&lt;span class="pl-c1"&gt;\begin&lt;/span&gt;{&lt;span class="pl-smi"&gt;document&lt;/span&gt;}
  &lt;span class="pl-c1"&gt;\maketitle&lt;/span&gt;
  &lt;span class="pl-c1"&gt;\section&lt;/span&gt;{&lt;span class="pl-en"&gt;First Section&lt;/span&gt;}
  &lt;span class="pl-c1"&gt;\begin&lt;/span&gt;{&lt;span class="pl-smi"&gt;frame&lt;/span&gt;}{First Frame}
    Hello, world!
  &lt;span class="pl-c1"&gt;\end&lt;/span&gt;{&lt;span class="pl-smi"&gt;frame&lt;/span&gt;}
&lt;span class="pl-c1"&gt;\end&lt;/span&gt;{&lt;span class="pl-smi"&gt;document&lt;/span&gt;}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Detailed information on using Metropolis can be found in the &lt;a href="http://mirrors.ctan.org/macros/latex/contrib/beamer-contrib/themes/metropolis/doc/metropolistheme.pdf" rel="nofollow"&gt;manual&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For an alternative dark color theme, please have a look at Ross Churchley's
excellent &lt;a href="https://github.com/rchurchley/beamercolortheme-owl"&gt;owl&lt;/a&gt; theme.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;The theme itself is licensed under a &lt;a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="nofollow"&gt;Creative Commons Attribution-ShareAlike
4.0 International License&lt;/a&gt;. This
means that if you change the theme and re-distribute it, you &lt;em&gt;must&lt;/em&gt; retain the
copyright notice header and license it under the same CC-BY-SA license. This
does not affect the presentation that you create with the theme.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>matze</author><guid isPermaLink="false">https://github.com/matze/mtheme</guid><pubDate>Mon, 02 Dec 2019 00:09:00 GMT</pubDate></item><item><title>wklchris/Note-by-LaTeX #10 in TeX, Today</title><link>https://github.com/wklchris/Note-by-LaTeX</link><description>&lt;p&gt;&lt;i&gt;中文 LaTeX 手册 - 简单粗暴 LaTeX。A LaTeX manual written by me to help more Chinese LaTeX learners: A concise handbook of LaTeX. &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="Readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-欢迎来到-latex-cn-项目welcome" class="anchor" aria-hidden="true" href="#欢迎来到-latex-cn-项目welcome"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;欢迎来到 LaTeX-cn 项目！Welcome!&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;== 所有PDF内容如果定稿，下载会发布在release（&lt;a href="https://github.com/wklchris/Note-by-LaTeX/releases"&gt;https://github.com/wklchris/Note-by-LaTeX/releases&lt;/a&gt;）中。PDF files can be accessed in the release page of this repo.  ==&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#incoming-update"&gt;&lt;strong&gt;Incoming Update 即将更新&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sub-repos"&gt;Sub-repos 仓库内容&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#latex-cn-chinese"&gt;LaTeX-cn 中文项目&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latex-beamer-en-suspended"&gt;LaTeX-beamer 英文项目（挂起）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#outdate-projects-log"&gt;过往项目日志&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-incoming-update" class="anchor" aria-hidden="true" href="#incoming-update"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Incoming Update&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;本公告于2018年10月14日发送，当前版本 v1.6.3。This incoming announcement was leaked on Oct 14, 2018. Current version: v1.6.3.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;本手册所有内容基本确定，对于普通 LaTeX 使用者而言已足够使用。TikZ 部分缓慢更新，不排除断更可能。作者目前忙于其他事务，因此请不要继续等待本手册的后续版本&lt;/strong&gt;。&lt;em&gt;&lt;strong&gt;All contents of this handbook has been determined, which is enough for normal LaTeX users. Please don't wait following version of it because the author is busy in many other things. As for TikZ chapter, it is SLOWLY updating and might be suspended in the future&lt;/strong&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;本手册可能出版；即使出版，本人也保证本仓库仍然维护与开源．&lt;em&gt;This handbook will probably be published. I guarantee readers that I will still maintain this repo and keep it open-source even if the book is published.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-sub-repos" class="anchor" aria-hidden="true" href="#sub-repos"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sub-repos&lt;/h1&gt;
&lt;p&gt;本仓库用于存放我的个人学习笔记，全部使用 LaTeX 或者 Markdown 进行撰写。所有运行环境均为Windows系统。具体包括：&lt;em&gt;This repository is for the use of storing my learning notes (by LaTeX or Markdown). All running environments are &lt;strong&gt;Windows&lt;/strong&gt; system. Namely it  includes:&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-latex-cn-chinese" class="anchor" aria-hidden="true" href="#latex-cn-chinese"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LaTeX-cn (Chinese)&lt;/h2&gt;
&lt;p&gt;LaTeX是一种排版系统，比通常使用的Microsoft Word字处理软件在排版方面更有优势。该一站式手册讲述了如何高效使用LaTeX。&lt;em&gt;LaTeX is a typesetting system, which outperforms Microsoft Word on typesetting. I write this all-in-one manual to tell how to use LaTeX efficiently.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最新版本v1.6.3，于2018年3月发布。&lt;em&gt;Latest version is v1.6.3 releaesd in Mar, 2018.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;正考虑将 Tikz 作为附加章节，届时可能发布带 Tikz与不带 Tikz 两版手册。&lt;em&gt;Considering adding Tikz as an additional chapter. And I might upload two versions of the manual (with/without Tikz respectively) at the next release.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-latex-beamer-en-suspended" class="anchor" aria-hidden="true" href="#latex-beamer-en-suspended"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;LaTeX-beamer-en (suspended)&lt;/h2&gt;
&lt;p&gt;（挂起）关于beamer的基础使用，完全使用英文。&lt;em&gt;(Suspended) Basic beamer knowledge. Totally written in English.&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-outdate-projects-log" class="anchor" aria-hidden="true" href="#outdate-projects-log"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Outdate Projects Log&lt;/h1&gt;
&lt;p&gt;过往项目已于2017年10月初取消跟进。读者可以回退到当时的版本进行查找。&lt;/p&gt;
&lt;p&gt;p.s. 在 Release 页面，python-cn 的第一版仍保留了下来。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;LaTeX-cn&lt;/strong&gt;: ver 1.6 于2017年6月定稿。&lt;/p&gt;
&lt;p&gt;—— 正在思考如何改进至下一版。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;githubpush-cn&lt;/strong&gt;: 2016年8月24日定稿。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;python-cn&lt;/strong&gt;: 2016年7月22日定稿。&lt;/p&gt;
&lt;p&gt;—— 附：Python安装Lib的&lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs" rel="nofollow"&gt;非官方Whl文件下载点&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>wklchris</author><guid isPermaLink="false">https://github.com/wklchris/Note-by-LaTeX</guid><pubDate>Mon, 02 Dec 2019 00:10:00 GMT</pubDate></item><item><title>vdumoulin/conv_arithmetic #11 in TeX, Today</title><link>https://github.com/vdumoulin/conv_arithmetic</link><description>&lt;p&gt;&lt;i&gt;A technical report on convolution arithmetic in the context of deep learning&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-convolution-arithmetic" class="anchor" aria-hidden="true" href="#convolution-arithmetic"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolution arithmetic&lt;/h1&gt;
&lt;p&gt;A technical report on convolution arithmetic in the context of deep learning.&lt;/p&gt;
&lt;p&gt;The code and the images of this tutorial are free to use as regulated by the
licence and subject to proper attribution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[1] Vincent Dumoulin, Francesco Visin - &lt;a href="https://arxiv.org/abs/1603.07285" rel="nofollow"&gt;A guide to convolution arithmetic
for deep learning&lt;/a&gt;
(&lt;a href="https://gist.github.com/fvisin/165ca9935392fa9600a6c94664a01214"&gt;BibTeX&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-convolution-animations" class="anchor" aria-hidden="true" href="#convolution-animations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Convolution animations&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;N.B.: Blue maps are inputs, and cyan maps are outputs.&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/no_padding_no_strides.gif"&gt;&lt;img width="150px" src="gif/no_padding_no_strides.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/arbitrary_padding_no_strides.gif"&gt;&lt;img width="150px" src="gif/arbitrary_padding_no_strides.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/same_padding_no_strides.gif"&gt;&lt;img width="150px" src="gif/same_padding_no_strides.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/full_padding_no_strides.gif"&gt;&lt;img width="150px" src="gif/full_padding_no_strides.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;No padding, no strides&lt;/td&gt;
    &lt;td&gt;Arbitrary padding, no strides&lt;/td&gt;
    &lt;td&gt;Half padding, no strides&lt;/td&gt;
    &lt;td&gt;Full padding, no strides&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/no_padding_strides.gif"&gt;&lt;img width="150px" src="gif/no_padding_strides.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/padding_strides.gif"&gt;&lt;img width="150px" src="gif/padding_strides.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/padding_strides_odd.gif"&gt;&lt;img width="150px" src="gif/padding_strides_odd.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;No padding, strides&lt;/td&gt;
    &lt;td&gt;Padding, strides&lt;/td&gt;
    &lt;td&gt;Padding, strides (odd)&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-transposed-convolution-animations" class="anchor" aria-hidden="true" href="#transposed-convolution-animations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transposed convolution animations&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;N.B.: Blue maps are inputs, and cyan maps are outputs.&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/no_padding_no_strides_transposed.gif"&gt;&lt;img width="150px" src="gif/no_padding_no_strides_transposed.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/arbitrary_padding_no_strides_transposed.gif"&gt;&lt;img width="150px" src="gif/arbitrary_padding_no_strides_transposed.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/same_padding_no_strides_transposed.gif"&gt;&lt;img width="150px" src="gif/same_padding_no_strides_transposed.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/full_padding_no_strides_transposed.gif"&gt;&lt;img width="150px" src="gif/full_padding_no_strides_transposed.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;No padding, no strides, transposed&lt;/td&gt;
    &lt;td&gt;Arbitrary padding, no strides, transposed&lt;/td&gt;
    &lt;td&gt;Half padding, no strides, transposed&lt;/td&gt;
    &lt;td&gt;Full padding, no strides, transposed&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/no_padding_strides_transposed.gif"&gt;&lt;img width="150px" src="gif/no_padding_strides_transposed.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/padding_strides_transposed.gif"&gt;&lt;img width="150px" src="gif/padding_strides_transposed.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/padding_strides_odd_transposed.gif"&gt;&lt;img width="150px" src="gif/padding_strides_odd_transposed.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;No padding, strides, transposed&lt;/td&gt;
    &lt;td&gt;Padding, strides, transposed&lt;/td&gt;
    &lt;td&gt;Padding, strides, transposed (odd)&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-dilated-convolution-animations" class="anchor" aria-hidden="true" href="#dilated-convolution-animations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dilated convolution animations&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;N.B.: Blue maps are inputs, and cyan maps are outputs.&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;tbody&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="gif/dilation.gif"&gt;&lt;img width="150px" src="gif/dilation.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;No padding, no stride, dilation&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-generating-the-makefile" class="anchor" aria-hidden="true" href="#generating-the-makefile"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generating the Makefile&lt;/h2&gt;
&lt;p&gt;From the repository's root directory:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ ./bin/generate_makefile&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-generating-the-animations" class="anchor" aria-hidden="true" href="#generating-the-animations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generating the animations&lt;/h2&gt;
&lt;p&gt;From the repository's root directory:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ make all_animations&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The animations will be output to the &lt;code&gt;gif&lt;/code&gt; directory. Individual animation steps
will be output in PDF format to the &lt;code&gt;pdf&lt;/code&gt; directory and in PNG format to the
&lt;code&gt;png&lt;/code&gt; directory.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-compiling-the-document" class="anchor" aria-hidden="true" href="#compiling-the-document"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compiling the document&lt;/h2&gt;
&lt;p&gt;From the repository's root directory:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ make&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>vdumoulin</author><guid isPermaLink="false">https://github.com/vdumoulin/conv_arithmetic</guid><pubDate>Mon, 02 Dec 2019 00:11:00 GMT</pubDate></item><item><title>zhanwen/MathModel #12 in TeX, Today</title><link>https://github.com/zhanwen/MathModel</link><description>&lt;p&gt;&lt;i&gt;研究生数学建模，数学建模竞赛优秀论文，数学建模算法，LaTeX论文模板，算法思维导图，参考书籍，Matlab软件教程，PPT&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-数学建模资源" class="anchor" aria-hidden="true" href="#数学建模资源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学建模资源&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-2019-年研究生数模" class="anchor" aria-hidden="true" href="#2019-年研究生数模"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019 年研究生数模&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-20191111-又是双十一比赛结果经过一个半月的评审在这一天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo" class="anchor" aria-hidden="true" href="#20191111-又是双十一比赛结果经过一个半月的评审在这一天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019.11.11 又是双十一，比赛结果经过一个半月的评审，在这一天公布了&lt;a href="2019%E5%B9%B4%E6%9C%80%E7%BB%88%E8%8E%B7%E5%A5%96%E5%90%8D%E5%8D%95"&gt;获奖名单&lt;/a&gt;，大家的努力相信都会有所收获。余生还有很多有意义的事情需要我们去做，让我们一起努力。(o^o)&lt;/h4&gt;
&lt;h3&gt;&lt;a id="user-content-20199192019923-比赛已经结束大家耐心等待获奖吧oo" class="anchor" aria-hidden="true" href="#20199192019923-比赛已经结束大家耐心等待获奖吧oo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2019.9.19—2019.9.23 比赛已经结束，大家耐心等待获奖吧（(o^^o)）&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-论文提交md5使用方法" class="anchor" aria-hidden="true" href="#论文提交md5使用方法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;论文提交（MD5使用方法）&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;MD5文件校验和使用说明：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/blob/master/MD5%E6%96%87%E4%BB%B6%E6%A0%A1%E9%AA%8C%E5%92%8C%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E.md"&gt;&lt;strong&gt;MD5文件校验和使用说明&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-论文模版更新" class="anchor" aria-hidden="true" href="#论文模版更新"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;论文模版更新&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;LaTex 论文模版：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/blob/master/2019%E5%B9%B4%E8%AE%BA%E6%96%87%E6%A8%A1%E7%89%88/2019%E5%B9%B4Latex%E6%A8%A1%E7%89%88.zip"&gt;&lt;strong&gt;LaTex 论文模版&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Word 论文模版：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/blob/master/2019%E5%B9%B4%E8%AE%BA%E6%96%87%E6%A8%A1%E7%89%88/%E2%80%9C%E5%8D%8E%E4%B8%BA%E6%9D%AF%E2%80%9D%E7%AC%AC%E5%8D%81%E5%85%AD%E5%B1%8A%E4%B8%AD%E5%9B%BD%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AE%BA%E6%96%87%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83.doc"&gt;&lt;strong&gt;Word 论文模版（已更新最新）&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;LaTex 论文模版使用方式：&lt;/em&gt; &lt;a href="https://github.com/zhanwen/MathModel/tree/master/2019%E5%B9%B4%E8%AE%BA%E6%96%87%E6%A8%A1%E7%89%88/latex_note.md"&gt;&lt;strong&gt;如何编译 Latex 文件&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-下载方式仓库比较大建议单个文件下载" class="anchor" aria-hidden="true" href="#下载方式仓库比较大建议单个文件下载"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载方式(仓库比较大，建议单个文件下载)&lt;/h4&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/downloaddemo2.gif"&gt;&lt;img src="./images/downloaddemo2.gif" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt;  
&lt;p&gt;&lt;em&gt;主题：&lt;/em&gt; &lt;a href="https://cpipc.chinadegrees.cn/cw/hp/4" rel="nofollow"&gt;&lt;strong&gt;“华为杯”第十六届中国研究生数学建模竞赛&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;报名时间：&lt;/em&gt; &lt;strong&gt;2019年6月1日8:00——9月10日17:00&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;审核时间：&lt;/em&gt; &lt;strong&gt;2019年6月1日8:00——9月12日17:00&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;交费时间：&lt;/em&gt; &lt;strong&gt;2019年7月1日8:00——9月15日17:00&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;比赛时间：&lt;/em&gt; &lt;strong&gt;2019年9月19日8:00——9月23日12:00&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-官网报名地址官网地址" class="anchor" aria-hidden="true" href="#官网报名地址官网地址"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;官网报名地址：&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/4" rel="nofollow"&gt;官网地址&lt;/a&gt;&lt;/h4&gt;
&lt;hr&gt;  
&lt;h3&gt;&lt;a id="user-content-2018915-祝大家比赛开心-_" class="anchor" aria-hidden="true" href="#2018915-祝大家比赛开心-_"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2018.9.15 祝大家比赛开心 （^_^）&lt;/h3&gt;
&lt;h3&gt;&lt;a id="user-content-2018919-比赛已经结束大家耐心等待获奖吧o" class="anchor" aria-hidden="true" href="#2018919-比赛已经结束大家耐心等待获奖吧o"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2018.9.19 比赛已经结束，大家耐心等待获奖吧（^o^）&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-20181111-比赛结果经过一个半月的评审终于在昨天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo" class="anchor" aria-hidden="true" href="#20181111-比赛结果经过一个半月的评审终于在昨天公布了获奖名单大家的努力相信都会有所收获余生还有很多有意义的事情需要我们去做让我们一起努力oo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2018.11.11 比赛结果经过一个半月的评审，终于在昨天公布了&lt;a href="https://github.com/zhanwen/MathModel/tree/master/2018%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/2018%E5%B9%B4%E6%9C%80%E7%BB%88%E8%8E%B7%E5%A5%96%E5%90%8D%E5%8D%95"&gt;获奖名单&lt;/a&gt;，大家的努力相信都会有所收获。余生还有很多有意义的事情需要我们去做，让我们一起努力。(o^^o)&lt;/h4&gt;
&lt;hr&gt;  
&lt;h4&gt;&lt;a id="user-content-更新添加比赛官网地址戳这里" class="anchor" aria-hidden="true" href="#更新添加比赛官网地址戳这里"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;更新/添加比赛官网地址&lt;a href="https://cpipc.chinadegrees.cn/" rel="nofollow"&gt;戳这里&lt;/a&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/4" rel="nofollow"&gt;数学建模竞赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/6" rel="nofollow"&gt;电子设计竞赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/2c9088a5696cbf370169a3f8101510bd" rel="nofollow"&gt;人工智能创新大赛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cpipc.chinadegrees.cn/cw/hp/2c9088a5696cbf370169a3f8934810be" rel="nofollow"&gt;机器人创新设计大赛&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-下载与使用由于整个项目直接下载比较慢可以看方式四" class="anchor" aria-hidden="true" href="#下载与使用由于整个项目直接下载比较慢可以看方式四"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载与使用（由于整个项目直接下载比较慢，可以看方式四）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;方式一：使用 &lt;code&gt;git&lt;/code&gt; 下载。&lt;br&gt;
&lt;code&gt;git clone https://github.com/zhanwen/MathModel.git&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;方式二：直接下载压缩包。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/downloaddemo.gif"&gt;&lt;img src="./images/downloaddemo.gif" height="250" width="500" align="center" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方式三
&lt;ul&gt;
&lt;li&gt;可以单个文件下载，选择自己需要的某篇论文，直接在对应的页面点击下载即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./images/download3.gif"&gt;&lt;img src="./images/download3.gif" height="250" width="500" align="center" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方式四：百度云下载（推荐）
&lt;ul&gt;
&lt;li&gt;使用百度云下载，正常的客户端会出现限速，导致下载的很慢，这里给大家推荐一个绕过百度云下载限速的方式。具体怎么下载，请参照 &lt;a href="https://github.com/iikira/BaiduPCS-Go"&gt;绕过限速&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;该项目的百度云链接 &lt;a href="https://pan.baidu.com/s/1UnngHxNR0EVoyBpKlPxFAw" rel="nofollow"&gt;https://pan.baidu.com/s/1UnngHxNR0EVoyBpKlPxFAw&lt;/a&gt;，密码：&lt;code&gt;ea2n&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-国赛试题" class="anchor" aria-hidden="true" href="#国赛试题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;国赛试题&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2019%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2019年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2018%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2018年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2017%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2017年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2016%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2016年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2015%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2015年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2014%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2014年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2013%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2013年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2012%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2012年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2011%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2011年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2010%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2010年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2009%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2009年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2008%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2008年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2007%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2007年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2006%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2006年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2005%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2005年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AF%95%E9%A2%98/2004%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9B%E8%AF%95%E9%A2%98"&gt;2004年研究生数学建模竞赛试题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-国赛论文" class="anchor" aria-hidden="true" href="#国赛论文"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;国赛论文&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2018年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：关于跳台跳水体型系数设置的建模分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：光传送网建模与价值评估&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：对恐怖袭击事件记录数据的量化分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：基于卫星高度计海面高度异常资料获取潮汐调和常数方法及应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：多无人机对组网雷达的协同干扰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2018%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：航站楼扩增评估&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2017年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：无人机在抢险救灾中的优化运用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：面向下一代光通信的 VCSEL 激光器仿真模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：航班恢复问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：基于监控视频的前景目标提取&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：多波次导弹发射中的规划问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：地下物流系统网络&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2016年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：多无人机协同任务规划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：具有遗传性疾病和性状的遗传位点分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：基于无线通信基站的室内三维定位问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：军事行动避空侦察的时机和路线选择&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：粮食最低收购价政策问题研究&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2015年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：水面舰艇编队防空和信息化战争评估模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：数据的多流形结构分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：移动通信中的无线信道“指纹”特征建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：面向节能的单/多列车优化决策问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：数控加工刀具运动的优化控制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：旅游路线规划问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2014年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：小鼠视觉感受区电位信号(LFP)与视觉刺激之间的关系研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：机动目标的跟踪与反跟踪&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：无线通信中的快时变信道建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：人体营养健康角度的中国果蔬发展战略研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：乘用车物流运输计划问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2013年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：变循环发动机部件法建模及优化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：功率放大器非线性特性及预失真模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：微蜂窝环境中无线接收信号的特性分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：空气中PM2.5问题的研究 attachment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/E"&gt;E题：中等收入定位与人口度量模型研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/F"&gt;F题：可持续的中国城乡居民养老保险体系的数学模型研究&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2012年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：基因识别问题及其算法实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：基于卫星无源探测的空间飞行器主动段轨道估计与误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：有杆抽油系统的数学建模及诊断&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：基于卫星云图的风失场(云导风)度量模型与算法探讨&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2011年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：基于光的波粒二象性一种猜想的数学仿真&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：吸波材料与微波暗室问题的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：小麦发育后期茎杆抗倒性的数学模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：房地产行业的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2010年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：确定肿瘤的重要基因信息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：与封堵渍口有关的重物落水后运动过程的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：神经元的形态分类和识别&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：特殊工件磨削加工的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2009年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：我国就业人数或城镇登记失业率的数学建模&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：枪弹头痕迹，自动比对方法的研究&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：多传感器数据融合与航迹预测&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：110 警车配置及巡逻方案&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2008年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：汶川地震中唐家山堪塞湖泄洪问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：城市道路交通信号实时控制问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;C题：货运列车的编组调度问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;D题：中央空调系统节能设计问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2007年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：建立食品卫生安全保障体系数学模型及改进模型的若干理论问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：械臂运动路径设计问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：探讨提高高速公路路面质量的改进方案&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：邮政运输网络中的邮路规划和邮车调运&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2006年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：Ad Hoc 网络中的区域划分和资源分配问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：确定高精度参数问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：维修线性流量阀时的内筒设计问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：学生面试问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2005年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：Highway Traveling time Estimate and Optimal Routing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：空中加油&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：城市交通管理中的出租车规划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：仓库容量有限条件下的随机存贮管理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87"&gt;2004年优秀论文&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/A"&gt;A题：发现黄球并定位&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/B"&gt;B题：使用下料问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/C"&gt;C题：售后服务数据的运用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E5%9B%BD%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E5%B9%B4%E4%BC%98%E7%A7%80%E8%AE%BA%E6%96%87/D"&gt;D题：研究生录取问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-美赛论文" class="anchor" aria-hidden="true" href="#美赛论文"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;美赛论文&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2017%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2017年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2016%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2016年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2015%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2015年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2014%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2014年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2013%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2013年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2012%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2012年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2011%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2011年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2010%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2010年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2009%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2009年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2008%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2008年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2007%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2007年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2006%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2006年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2005%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2005年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%BE%8E%E8%B5%9B%E8%AE%BA%E6%96%87/2004%E7%BE%8E%E8%B5%9B%E7%89%B9%E7%AD%89%E5%A5%96%E5%8E%9F%E7%89%88%E8%AE%BA%E6%96%87%E9%9B%86"&gt;2004年特等奖论文&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-数学建模算法" class="anchor" aria-hidden="true" href="#数学建模算法"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学建模算法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95"&gt;经典算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95"&gt;现代算法&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BB%BF%E7%9C%9F"&gt;计算机仿真&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95"&gt;粒子群算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE"&gt;马尔可夫链&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%B3%95"&gt;蒙特卡洛法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E6%B3%95"&gt;模拟退火法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;神经网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E5%B0%8F%E6%B3%A2%E5%88%86%E6%9E%90"&gt;小波分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E7%8E%B0%E4%BB%A3%E7%AE%97%E6%B3%95/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95"&gt;遗传算法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-教材及课件" class="anchor" aria-hidden="true" href="#教材及课件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;教材及课件&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E6%95%99%E6%9D%90%E5%8F%8A%E8%AF%BE%E4%BB%B6/%E5%9B%BD%E9%98%B2%E7%A7%91%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6"&gt;国防科技术大学&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/%E6%95%99%E6%9D%90%E5%8F%8A%E8%AF%BE%E4%BB%B6/%E6%B5%99%E6%B1%9F%E5%A4%A7%E5%AD%A6%E8%AF%BE%E4%BB%B6/PPT%E8%AF%BE%E4%BB%B6"&gt;浙江大学课件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-数学建模算法思维导图" class="anchor" aria-hidden="true" href="#数学建模算法思维导图"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数学建模算法思维导图&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/Mind"&gt;思维导图&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-matlab-入门教程" class="anchor" aria-hidden="true" href="#matlab-入门教程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Matlab 入门教程&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/zhanwen/MathModel/tree/master/Matlab%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B"&gt;Matlab入门和在线性代数中的应用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt; 
&lt;h3&gt;&lt;a id="user-content-声明" class="anchor" aria-hidden="true" href="#声明"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;声明&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;其中有些内容整理自互联网，如有侵权，请联系，我将及时处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-个人微信公众号" class="anchor" aria-hidden="true" href="#个人微信公众号"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;个人微信公众号&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dotzhang&lt;/code&gt;：一名不羁的学僧，我的世界不只有学术。一条迷途的咸鱼，正在游向属于它的天地！&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/images/donate/common.jpg"&gt;&lt;img src="/images/donate/common.jpg" width="150" height="150" alt="weixin" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-赞助和支持" class="anchor" aria-hidden="true" href="#赞助和支持"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;赞助和支持&lt;/h3&gt;
&lt;p&gt;这些内容都是我花了不少时间整理出来的, 如果你觉得它对你很有帮助, 请你也分享给需要学习的朋友们。如果你看好我的内容分享, 也可以考虑适当的赞助打赏, 让我有更多的动力去继续分享更好的内容给大家。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;微信&lt;/th&gt;
&lt;th&gt;支付宝&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/donate/weixinpay.jpg"&gt;&lt;img src="images/donate/weixinpay.jpg" width="150" height="150" alt="pay check" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/donate/alipay.jpg"&gt;&lt;img src="images/donate/alipay.jpg" width="150" height="150" alt="pay check" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;&lt;a id="user-content-联系" class="anchor" aria-hidden="true" href="#联系"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;联系&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Email：&lt;a href="https://mail.google.com/" rel="nofollow"&gt;hanwenme@gmail.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;微  信（有任何问题都可以直接怼我）：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/donate/wechat.png"&gt;&lt;img src="images/donate/wechat.png" width="150" height="150" alt="pay check" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zhanwen</author><guid isPermaLink="false">https://github.com/zhanwen/MathModel</guid><pubDate>Mon, 02 Dec 2019 00:12:00 GMT</pubDate></item><item><title>ixy-languages/ixy-languages #13 in TeX, Today</title><link>https://github.com/ixy-languages/ixy-languages</link><description>&lt;p&gt;&lt;i&gt;A high-speed network driver written in C, Rust, Go, C#, Java, OCaml, Haskell, Swift, Javascript, and Python&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-overview" class="anchor" aria-hidden="true" href="#overview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overview&lt;/h1&gt;
&lt;p&gt;Ixy is an educational user space network driver for the Intel ixgbe family of 10 Gbit/s NICs (82599ES aka X520, X540, X550, X552, ...).
Its goal is to show that writing a super-fast network driver can be surprisingly simple, check out the &lt;a href="https://github.com/emmericp/ixy"&gt;full description in the main repository of the C implementation&lt;/a&gt; to learn about the basics of user space drivers.
Ixy was originally written in C as lowest common denominator of system programming languages, but it is possible to write user space drivers in any programming language.&lt;/p&gt;
&lt;p&gt;Check out our research paper &lt;a href="https://www.net.in.tum.de/fileadmin/bibtex/publications/papers/the-case-for-writing-network-drivers-in-high-level-languages.pdf" rel="nofollow"&gt;"The Case for Writing Network Drivers in High-Level Languages"&lt;/a&gt; [&lt;a href="https://www.net.in.tum.de/publications/bibtex/highleveldrivers.bib" rel="nofollow"&gt;BibTeX&lt;/a&gt;] or watch the recording of our &lt;a href="https://media.ccc.de/v/35c3-9670-safe_and_secure_drivers_in_high-level_languages" rel="nofollow"&gt;talk at 35C3&lt;/a&gt; to learn more.&lt;/p&gt;
&lt;p&gt;Yes, these drivers are really a full implementation of an actual PCIe driver in these languages; they handle everything from setting up DMA memory to receiving and transmitting packets in a high-level language. You don't need to write any kernel code to build drivers!
Some languages require a few lines of C stubs for features not offered by the language; usually related to getting the memory address of buffers or calling mmap in the right way. But all the core logic is in high-level languages; the implementations are about 1000 lines of code each.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;th&gt;Status&lt;/th&gt;
&lt;th&gt;Full evaluation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/emmericp/ixy"&gt;ixy.c&lt;/a&gt;*&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.net.in.tum.de/fileadmin/bibtex/publications/papers/ixy-writing-user-space-network-drivers.pdf" rel="nofollow"&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Rust&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.rs"&gt;ixy.rs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.net.in.tum.de/fileadmin/bibtex/publications/theses/2018-ixy-rust.pdf" rel="nofollow"&gt;Thesis&lt;/a&gt;, &lt;a href="Rust-vs-C-performance.md"&gt;Rust vs. C performance comparison&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.go"&gt;ixy.go&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.net.in.tum.de/fileadmin/bibtex/publications/theses/2018-ixy-go.pdf" rel="nofollow"&gt;Thesis&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;C#&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.cs"&gt;ixy.cs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.net.in.tum.de/fileadmin/bibtex/publications/theses/2018-ixy-c-sharp.pdf" rel="nofollow"&gt;Thesis&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Java&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.java"&gt;ixy.java&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;(WIP), &lt;a href="Java-garbage-collectors.md"&gt;GC comparison&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCaml&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.ml"&gt;ixy.ml&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.ml/blob/master/README.md"&gt;Documentation&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Haskell&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.hs"&gt;ixy.hs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.net.in.tum.de/fileadmin/bibtex/publications/theses/2019-ixy-haskell.pdf" rel="nofollow"&gt;Thesis&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Swift&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.swift"&gt;ixy.swift&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.swift/blob/master/README.md"&gt;Documentation&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Javascript&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.js"&gt;ixy.js&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;(WIP)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Python&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ixy-languages/ixy.py"&gt;ixy.py&lt;/a&gt;*&lt;/td&gt;
&lt;td&gt;Finished&lt;/td&gt;
&lt;td&gt;(WIP)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;*) also features a VirtIO driver for easy testing in VMs with Vagrant&lt;/p&gt;
&lt;p&gt;This repository here is only a short summary of the project, check out the repositories and full evaluations linked above for all the gory details.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-performance" class="anchor" aria-hidden="true" href="#performance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Performance&lt;/h1&gt;
&lt;p&gt;Our &lt;a href="https://github.com/ixy-languages/benchmark-scripts"&gt;benchmarking script&lt;/a&gt; for the &lt;a href="https://github.com/emmericp/MoonGen"&gt;MoonGen packet generator&lt;/a&gt; loads the forwarder example application with full bidirectional load at 20 Gbit/s with 64 byte packets (29.76 Mpps).
The forwarder then increments one byte in the packet to ensure that the packet is loaded all the way into the L1 cache.
Correct functionality of the forwarder is also tested by the script by validating sequence numbers.&lt;/p&gt;
&lt;p&gt;A main driver of performance for network drivers is sending/receiving packets in batches from/to the NIC.
Ixy can already achieve a high performance with relatively low batch sizes of 32-64 because it is a full user space driver.
Other user space packet processing frameworks like netmap that rely on a kernel driver need larger batch sizes of 512 and above to amortize the larger overhead of communicating with the driver in the kernel.
Running this on a single core of a Xeon E3-1230 v2 CPU yields these throughput results in million packets per second (Mpps) when varying the batch size.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/batches-3.3.png"&gt;&lt;img src="img/batches-3.3.png" alt="Performance with different batch sizes, CPU at 3.3 GHz" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/batches-1.6.png"&gt;&lt;img src="img/batches-1.6.png" alt="Performance with different batch sizes, CPU at 1.6 GHz" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Notes on multi-core:&lt;/em&gt; Some languages implement multi-threading for ixy, but some can't or are limited by the language's design (e.g., the GIL in Python and OCaml). However, this isn't a real problem because multi-threading within one process isn't really necessary.
Network cards can split the traffic at the hardware level (via a feature called RSS), the traffic can then be distributed to independent different processes.
For example, &lt;a href="https://github.com/snabbco/snabb"&gt;Snabb&lt;/a&gt; works like this and many DPDK applications use multiple threads that do not communicate (shared-nothing architecture).&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-latency" class="anchor" aria-hidden="true" href="#latency"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latency&lt;/h1&gt;
&lt;p&gt;Average and median latency is the same regardless of the programming language as latency is dominated by buffering times, the &lt;a href="https://github.com/ixy-languages/benchmark-scripts"&gt;evaluation script&lt;/a&gt; can sample the latency of up to 1000 packets per second with hardware timestamping (precision: 12.8 nanoseconds).
This yields somewhat interesting results depending on queue sizes and NUMA configuration, see the &lt;a href="https://www.net.in.tum.de/fileadmin/bibtex/publications/papers/ixy-writing-user-space-network-drivers.pdf" rel="nofollow"&gt;ixy paper&lt;/a&gt; for an evaluation.&lt;/p&gt;
&lt;p&gt;Latency spikes induced by languages featuring a garbage collector might not be caught by the test setup above.
We have a second test setup to catch this: we also capture &lt;em&gt;all&lt;/em&gt; packets before and after the device under test with fiber optic taps and use &lt;a href="https://github.com/AP-Frank/MoonGen/tree/moonsniff"&gt;MoonSniff&lt;/a&gt; to acquire hardware timestamps (25.6 nanosecond precision) for all packets.&lt;/p&gt;
&lt;p&gt;Running the forwarder on an Intel Xeon E5-2620 v3 at 2.4 GHz yields the following results for the forwarding latency.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/latency-hdr-hist-1.png"&gt;&lt;img src="img/latency-hdr-hist-1.png" alt="Latency" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/latency-hdr-hist-10.png"&gt;&lt;img src="img/latency-hdr-hist-10.png" alt="Latency" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="img/latency-hdr-hist-20.png"&gt;&lt;img src="img/latency-hdr-hist-20.png" alt="Latency" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;How to read this graph: the x axis refers to the percentage of packets that can be forwarded in this time. For example, if a language takes longer than 100µs for only one packet in 1000 packets, it shows a value of 100µs at x position 99.9.
This graph focuses on the tail latency, note the logarithmic scaling on the x axis.&lt;/p&gt;
&lt;p&gt;Graphs only include languages that can cope with the offered load.
Measuring an overloaded driver doesn't make sense as latency is dominated by the buffer size in this scenario.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ixy-languages</author><guid isPermaLink="false">https://github.com/ixy-languages/ixy-languages</guid><pubDate>Mon, 02 Dec 2019 00:13:00 GMT</pubDate></item><item><title>xu-cheng/latex-action #14 in TeX, Today</title><link>https://github.com/xu-cheng/latex-action</link><description>&lt;p&gt;&lt;i&gt;:octocat: GitHub Action to compile LaTeX documents&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-latex-action" class="anchor" aria-hidden="true" href="#latex-action"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;latex-action&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/xu-cheng/latex-action/actions"&gt;&lt;img src="https://github.com/xu-cheng/latex-action/workflows/Test%20Github%20Action/badge.svg" alt="GitHub Actions Status" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub Action to compile LaTeX documents.&lt;/p&gt;
&lt;p&gt;It runs in &lt;a href="https://github.com/xu-cheng/latex-docker"&gt;a docker image&lt;/a&gt; with a full &lt;a href="https://www.tug.org/texlive/" rel="nofollow"&gt;TeXLive&lt;/a&gt; environment installed.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-inputs" class="anchor" aria-hidden="true" href="#inputs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Inputs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;root_file&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The root LaTeX file to be compiled. This input is required.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;working_directory&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The working directory for the LaTeX engine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;compiler&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The LaTeX engine to be invoked. By default, &lt;a href="https://ctan.org/pkg/latexmk" rel="nofollow"&gt;&lt;code&gt;latexmk&lt;/code&gt;&lt;/a&gt; is used, which automates the process of generating LaTeX documents by issuing the appropriate sequence of commands to be run.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;args&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The extra arguments to be passed to the LaTeX engine. By default, it is &lt;code&gt;-pdf -file-line-error -interaction=nonstopmode&lt;/code&gt;. This tells &lt;code&gt;latexmk&lt;/code&gt; to use &lt;code&gt;pdflatex&lt;/code&gt;. Refer to &lt;a href="http://texdoc.net/texmf-dist/doc/support/latexmk/latexmk.pdf" rel="nofollow"&gt;&lt;code&gt;latexmk&lt;/code&gt; document&lt;/a&gt; for more information.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;extra_system_packages&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The extra packages to be installed by &lt;a href="https://pkgs.alpinelinux.org/packages" rel="nofollow"&gt;&lt;code&gt;apk&lt;/code&gt;&lt;/a&gt; separated by space. For example, &lt;code&gt;extra_system_packages: "py-pygments"&lt;/code&gt; will install the package &lt;code&gt;py-pygments&lt;/code&gt; to be used by the &lt;code&gt;minted&lt;/code&gt; for code highlights.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;div class="highlight highlight-source-yaml"&gt;&lt;pre&gt;&lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;Build LaTeX document&lt;/span&gt;
&lt;span class="pl-ent"&gt;on&lt;/span&gt;: &lt;span class="pl-s"&gt;[push]&lt;/span&gt;
&lt;span class="pl-ent"&gt;jobs&lt;/span&gt;:
  &lt;span class="pl-ent"&gt;build_latex&lt;/span&gt;:
    &lt;span class="pl-ent"&gt;runs-on&lt;/span&gt;: &lt;span class="pl-s"&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class="pl-ent"&gt;steps&lt;/span&gt;:
      - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;Set up Git repository&lt;/span&gt;
        &lt;span class="pl-ent"&gt;uses&lt;/span&gt;: &lt;span class="pl-s"&gt;actions/checkout@v1&lt;/span&gt;
      - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;Compile LaTeX document&lt;/span&gt;
        &lt;span class="pl-ent"&gt;uses&lt;/span&gt;: &lt;span class="pl-s"&gt;xu-cheng/latex-action@master&lt;/span&gt;
        &lt;span class="pl-ent"&gt;with&lt;/span&gt;:
          &lt;span class="pl-ent"&gt;root_file&lt;/span&gt;: &lt;span class="pl-s"&gt;main.tex&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-faqs" class="anchor" aria-hidden="true" href="#faqs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQs&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-use-xelatex-or-lualatex-instead-of-pdflatex" class="anchor" aria-hidden="true" href="#how-to-use-xelatex-or-lualatex-instead-of-pdflatex"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to use XeLaTeX or LuaLaTeX instead of pdfLaTeX?&lt;/h3&gt;
&lt;p&gt;By default, this action uses pdfLaTeX. If you want to use XeLaTeX or LuaLaTeX, you can set the &lt;code&gt;args&lt;/code&gt; to &lt;code&gt;-xelatex -file-line-error -interaction=nonstopmode&lt;/code&gt; or &lt;code&gt;-lualatex --file-line-error --interaction=nonstopmode&lt;/code&gt; respectively. Alternatively, you could create a &lt;code&gt;.latexmkrc&lt;/code&gt; file. Refer to the &lt;a href="http://texdoc.net/texmf-dist/doc/support/latexmk/latexmk.pdf" rel="nofollow"&gt;&lt;code&gt;latexmk&lt;/code&gt; document&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-how-to-enable---shell-escape" class="anchor" aria-hidden="true" href="#how-to-enable---shell-escape"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to enable &lt;code&gt;--shell-escape&lt;/code&gt;?&lt;/h3&gt;
&lt;p&gt;To enable &lt;code&gt;--shell-escape&lt;/code&gt;, you should add it to &lt;code&gt;args&lt;/code&gt;. For example, set &lt;code&gt;args&lt;/code&gt; to &lt;code&gt;-pdf -file-line-error -interaction=nonstopmode -shell-escape&lt;/code&gt; when using pdfLaTeX.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-where-is-the-pdf-file-how-to-upload-it" class="anchor" aria-hidden="true" href="#where-is-the-pdf-file-how-to-upload-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Where is the PDF file? How to upload it?&lt;/h3&gt;
&lt;p&gt;The PDF file will be in the same folder as that of the LaTeX source in the CI environment. It is up to you on whether to upload it to some places. Here are some example.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can use &lt;a href="https://github.com/actions/upload-artifact"&gt;&lt;code&gt;@actions/upload-artifact&lt;/code&gt;&lt;/a&gt; to upload PDF file to the workflow tab.&lt;/li&gt;
&lt;li&gt;You can use &lt;a href="https://github.com/actions/upload-release-asset"&gt;&lt;code&gt;@actions/upload-release-asset&lt;/code&gt;&lt;/a&gt; to upload PDF file to the Github Release.&lt;/li&gt;
&lt;li&gt;You can use normal shell tools such as &lt;code&gt;scp&lt;/code&gt;/&lt;code&gt;git&lt;/code&gt;/&lt;code&gt;rsync&lt;/code&gt; to upload PDF file anywhere. For example, you can git push to the &lt;code&gt;gh-pages&lt;/code&gt; branch in your repo, so you can view the document using Github Pages.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-it-fails-to-build-the-document-how-to-solve-it" class="anchor" aria-hidden="true" href="#it-fails-to-build-the-document-how-to-solve-it"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;It fails to build the document, how to solve it?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Try to solve the problem by examining the build log.&lt;/li&gt;
&lt;li&gt;Try to build the document locally.&lt;/li&gt;
&lt;li&gt;You can also try to narrow the problem by creating a minimal working example to reproduce the problem.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/xu-cheng/latex-action/issues/new"&gt;Open an issue&lt;/a&gt; if you need help.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;MIT&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>xu-cheng</author><guid isPermaLink="false">https://github.com/xu-cheng/latex-action</guid><pubDate>Mon, 02 Dec 2019 00:14:00 GMT</pubDate></item><item><title>sjtug/SJTUThesis #15 in TeX, Today</title><link>https://github.com/sjtug/SJTUThesis</link><description>&lt;p&gt;&lt;i&gt;上海交通大学 XeLaTeX 学位论文及课程论文模板&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-sjtuthesis-示例模板" class="anchor" aria-hidden="true" href="#sjtuthesis-示例模板"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SJTUThesis 示例模板&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/sjtug/SJTUThesis" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/02f2f1af0164f59600d60c5ab36d6d00cc7965e6/68747470733a2f2f7472617669732d63692e6f72672f736a7475672f534a54555468657369732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/sjtug/SJTUThesis.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/sjtug/SJTUTeX"&gt;&lt;img src="https://camo.githubusercontent.com/b20fd01bb8695a8ce736fbdc05e56e19c2720db4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f534a545554686569732d76312e302e307263342d677265656e2e737667" alt="SJTUTeX" data-canonical-src="https://img.shields.io/badge/SJTUTheis-v1.0.0rc4-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/sjtug/SJTUThesis?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ccbcccbbb07428a02cec5fcd31f878c0501ffa77/68747470733a2f2f6261646765732e6769747465722e696d2f736a7475672f534a54555468657369732e737667" alt="Join the chat at https://gitter.im/sjtug/SJTUThesis" data-canonical-src="https://badges.gitter.im/sjtug/SJTUThesis.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-欢迎使用上海交通大学论文模板" class="anchor" aria-hidden="true" href="#欢迎使用上海交通大学论文模板"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;欢迎使用上海交通大学论文模板&lt;/h2&gt;
&lt;p&gt;本示例模板是应用上海交通大学学位论文（非官方）LaTeX 文档类 SJTUThesis 的一个完整实现。演示了排版中常用的例子，包括公式、表格、算法、参考文献等。
用户可以参考或者直接基于此示例文档撰写论文。&lt;/p&gt;
&lt;p&gt;请注意 SJTUThesis 目前仅支持 XeTeX 引擎，字符编码仅支持 UTF-8。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-获取模板" class="anchor" aria-hidden="true" href="#获取模板"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;获取模板&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-下载模版" class="anchor" aria-hidden="true" href="#下载模版"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;下载模版&lt;/h3&gt;
&lt;p&gt;普通用户可以直接 &lt;code&gt;clone&lt;/code&gt; 或者在 &lt;a href="https://github.com/sjtug/SJTUThesis"&gt;Github&lt;/a&gt; 页面下载仓库代码。&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;git clone https://github.com/sjtug/SJTUThesis.git&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-overleaf" class="anchor" aria-hidden="true" href="#overleaf"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Overleaf&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.overleaf.com?r=b3b31f49&amp;amp;rm=d&amp;amp;rs=b" rel="nofollow"&gt;Overleaf&lt;/a&gt; 用户可以从下面的模版链接创建自己的项目。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.overleaf.com/latex/templates/sjtuthesis-latex-thesis-template-for-shanghai-jiao-tong-university/spmggcjfshrb?r=b3b31f49&amp;amp;rm=d&amp;amp;rs=b" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/af01a932005954b8d29f174678a0a34e876099ca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f7665726c6561662d736a74757468657369732d677265656e2e737667" alt="Overleaf" data-canonical-src="https://img.shields.io/badge/overleaf-sjtuthesis-green.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-模板使用" class="anchor" aria-hidden="true" href="#模板使用"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;模板使用&lt;/h2&gt;
&lt;p&gt;如果你不熟悉 LaTeX 的编译流程，请&lt;strong&gt;不要&lt;/strong&gt;直接使用编译器进行编译。针对不同的平台，模版提供了相应的编译脚本。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-linux-与-macos-用户" class="anchor" aria-hidden="true" href="#linux-与-macos-用户"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linux 与 macOS 用户&lt;/h3&gt;
&lt;p&gt;推荐使用模版提供的 &lt;code&gt;Makefile&lt;/code&gt; 进行编译，具体来说我们提供了如下几条可用的命令：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;make all                      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 编译生成 thesis.pdf&lt;/span&gt;
make clean                    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 删除编译所产生的中间文件&lt;/span&gt;
make cleanall                 &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 删除 thesis.pdf 和所有中间文件&lt;/span&gt;
make wordcount                &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 论文字数统计&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-windows-用户" class="anchor" aria-hidden="true" href="#windows-用户"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Windows 用户&lt;/h3&gt;
&lt;p&gt;对于 Windows 用户，我们也提供了编译脚本 &lt;code&gt;Compile.bat&lt;/code&gt;。可以双击直接编译，也可以在命令提示符窗口中使用脚本提供的额外功能：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;.&lt;span class="pl-cce"&gt;\C&lt;/span&gt;ompile.bat thesis          &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 编译生成 thesis.pdf&lt;/span&gt;
.&lt;span class="pl-cce"&gt;\C&lt;/span&gt;ompile.bat clean           &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 删除编译所产生的中间文件&lt;/span&gt;
.&lt;span class="pl-cce"&gt;\C&lt;/span&gt;ompile.bat cleanall        &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 删除 thesis.pdf 和所有中间文件&lt;/span&gt;
.&lt;span class="pl-cce"&gt;\C&lt;/span&gt;ompile.bat wordcount       &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; 论文字数统计&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;更多关于模板的实现细节以及使用信息，请查看使用文档 &lt;code&gt;sjtuthesis.pdf&lt;/code&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-反馈与贡献" class="anchor" aria-hidden="true" href="#反馈与贡献"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;反馈与贡献&lt;/h2&gt;
&lt;p&gt;本模版是由诸多感兴趣的同学一起维护的开源项目，我们非常欢迎问题反馈和新的贡献者！&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-反馈问题" class="anchor" aria-hidden="true" href="#反馈问题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;反馈问题&lt;/h3&gt;
&lt;p&gt;如果在使用上有任何问题，建议先查阅项目的 &lt;a href="https://github.com/sjtug/SJTUThesis/wiki"&gt;Wiki 文档&lt;/a&gt;。
如果这些不能解决你的问题，建议通过以下方式进行反馈（按推荐顺序排序）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/sjtug/SJTUThesis/issues"&gt;在 GitHub 项目主页开 issue&lt;/a&gt; (推荐)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bbs.sjtu.edu.cn/bbsdoc?board=TeX_LaTeX" rel="nofollow"&gt;在水源 BBS TeX_LaTeX 版发帖&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外也可以在我们的 &lt;a href="https://gitter.im/sjtug/SJTUThesis" rel="nofollow"&gt;Gitter&lt;/a&gt; 在线聊天频道讨论任何有关与模版的话题。&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-成为贡献者" class="anchor" aria-hidden="true" href="#成为贡献者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;成为贡献者&lt;/h3&gt;
&lt;p&gt;这个仓库是面向用户的&lt;strong&gt;示例模版&lt;/strong&gt;，如果你有很好的排版示例，可以提交到此仓库与大家分享。如果你想要为 SJTUThesis 文档类贡献代码，可移步 &lt;a href="https://github.com/sjtug/SJTUTeX"&gt;SJTUTeX&lt;/a&gt;。在贡献之前，你可以从&lt;a href="https://github.com/sjtug/SJTUThesis/issues?q=is%3Aissue+is%3Aopen+label%3Agood-first-issue"&gt;这些问题&lt;/a&gt;开始熟悉贡献代码的流程。除了提交 Pull Request 之外，还有以下方式可以进行贡献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;帮助我们解答同学们的&lt;a href="https://github.com/sjtug/SJTUThesis/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+is%3Aopen+label%3Atype%2Fquestion+"&gt;问题&lt;/a&gt;，这些问题你也可能遇到过并且知道如何解决；&lt;/li&gt;
&lt;li&gt;与我们一起维护项目的 &lt;a href="https://github.com/sjtug/SJTUThesis/wiki"&gt;Wiki 文档&lt;/a&gt;，Wiki 任何人都可以直接编辑；&lt;/li&gt;
&lt;li&gt;向周围同学安利 SJTUThesis，让更多的同学使用我们维护的模板；&lt;/li&gt;
&lt;li&gt;在我们的&lt;a href="https://gitter.im/sjtug/SJTUThesis" rel="nofollow"&gt;在线聊天频道&lt;/a&gt;上告诉我们你的使用体验，以及吐槽。如果你也想成为项目的长期维护者，也可以通过在线频道告诉我们。:-)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-致谢" class="anchor" aria-hidden="true" href="#致谢"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;致谢&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;感谢 &lt;a href="https://github.com/CTeX-org/ctex-kit"&gt;CTeX-kit&lt;/a&gt; 提供了 LaTeX 的中文支持；&lt;/li&gt;
&lt;li&gt;感谢那位最先制作出博士学位论文 LaTeX 模板的交大物理系同学；&lt;/li&gt;
&lt;li&gt;感谢 William Wang 同学对模板移植做出的巨大贡献；&lt;/li&gt;
&lt;li&gt;感谢 &lt;a href="https://github.com/weijianwen"&gt;@weijianwen&lt;/a&gt; 学长一直以来的开发和维护工作；&lt;/li&gt;
&lt;li&gt;感谢 &lt;a href="https://github.com/sjtug"&gt;@sjtug&lt;/a&gt; 以及 &lt;a href="https://github.com/dyweb"&gt;@dyweb&lt;/a&gt; 对 0.9.5 之后版本的开发和维护工作；&lt;/li&gt;
&lt;li&gt;感谢所有为模板贡献过代码的&lt;a href="https://github.com/sjtug/SJTUThesis/graphs/contributors"&gt;同学们&lt;/a&gt;，以及所有测试和使用模板的各位同学。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-软件许可证" class="anchor" aria-hidden="true" href="#软件许可证"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;软件许可证&lt;/h2&gt;
&lt;p&gt;上海交通大学校徽校名图片（&lt;code&gt;sjtu-logo.pdf&lt;/code&gt; 等）的版权归上海交通大学所有。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sjtuthesis.cls&lt;/code&gt; 文档类与相关附属文件，以及 &lt;code&gt;biblatex-gb7714-2015&lt;/code&gt; 样式文件使用 &lt;a href="https://www.latex-project.org/lppl.txt" rel="nofollow"&gt;LPPL&lt;/a&gt; 授权。&lt;/p&gt;
&lt;p&gt;其他部分使用 &lt;a href="LICENSE"&gt;Apache License 2.0&lt;/a&gt; 授权。&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>sjtug</author><guid isPermaLink="false">https://github.com/sjtug/SJTUThesis</guid><pubDate>Mon, 02 Dec 2019 00:15:00 GMT</pubDate></item><item><title>AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template #16 in TeX, Today</title><link>https://github.com/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template</link><description>&lt;p&gt;&lt;i&gt;LaTeX-template for russian Phd thesis&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;LaTeX-шаблон для русской кандидатской диссертации и её автореферата.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-особенности" class="anchor" aria-hidden="true" href="#особенности"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Особенности&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Кодировка: UTF-8.&lt;/li&gt;
&lt;li&gt;Стандарт: ГОСТ Р 7.0.11-2011.&lt;/li&gt;
&lt;li&gt;Поддерживаемые движки: pdfTeX, XeTeX, LuaTeX.&lt;/li&gt;
&lt;li&gt;Поддерживаемые реализации библиографии: встроенная на движке BibTeX, BibLaTeX
на движке Biber.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template/releases/latest"&gt;&lt;strong&gt;Примеры компиляции шаблона&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="Readme/Installation.md"&gt;&lt;strong&gt;Установка программного обеспечения и сборка диссертации в файлы PDF&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="Readme/github.md"&gt;&lt;strong&gt;Как писать диссертацию на GitHub?&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-обсуждение" class="anchor" aria-hidden="true" href="#обсуждение"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Обсуждение&lt;/h2&gt;
&lt;p&gt;Общие вопросы лучше всего писать в gitter-канал:
&lt;a href="https://gitter.im/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Для отчётов об ошибках и для конкретных пожеланий/предложений лучше всего использовать раздел &lt;a href="https://github.com/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template/issues"&gt;Issues&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-структура" class="anchor" aria-hidden="true" href="#структура"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Структура&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="dissertation.tex"&gt;dissertation.tex&lt;/a&gt;: главный файл диссертации.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="Dissertation/"&gt;папка Dissertation&lt;/a&gt;:&lt;/strong&gt; Структурированная система файлов с
шаблоном диссертации.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;папка images:&lt;/strong&gt; Папка для размещения файлов изображений, относящихся только
к диссертации.&lt;/li&gt;
&lt;li&gt;&lt;a href="Dissertation/setup.tex"&gt;setup.tex&lt;/a&gt;: Файл упрощённой настройки оформления
диссертации.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="synopsis.tex"&gt;synopsis.tex&lt;/a&gt;: главный файл автореферата диссертации.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="Synopsis/"&gt;папка Synopsis&lt;/a&gt;:&lt;/strong&gt; Структурированная система файлов с шаблоном
автореферата.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;папка images:&lt;/strong&gt; Папка для размещения файлов изображений, относящихся
только к автореферату диссертации.&lt;/li&gt;
&lt;li&gt;&lt;a href="Synopsis/setup.tex"&gt;setup.tex&lt;/a&gt;: Файл упрощённой настройки оформления
автореферата.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="presentation.tex"&gt;presentation.tex&lt;/a&gt;: главный файл презентации.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="Presentation/"&gt;папка Presentation&lt;/a&gt;:&lt;/strong&gt; Структурированная система файлов с
шаблоном презентации.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="Documents/"&gt;папка Documents&lt;/a&gt;:&lt;/strong&gt; Полезные документы (ГОСТ-ы и постановления).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="PSCyr/"&gt;папка PSCyr&lt;/a&gt;:&lt;/strong&gt; Пакет PSCyr + инструкции по установке.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="BibTeX-Styles/"&gt;папка BibTeX-Styles&lt;/a&gt;:&lt;/strong&gt; Подборка русских стилевых пакетов
BibTeX под UTF-8.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;папка common:&lt;/strong&gt; Общие файлы настроек и управления содержанием шаблонов.
&lt;ul&gt;
&lt;li&gt;&lt;a href="common/characteristic.tex"&gt;characteristic.tex&lt;/a&gt;: Часть общей характеристики
работы, повторяющаяся в диссертации и автореферате.&lt;/li&gt;
&lt;li&gt;&lt;a href="common/concl.tex"&gt;concl.tex&lt;/a&gt;: Заключение. Является общим для автореферата
и диссертации (согласно &lt;a href="Documents/GOST%20R%207.0.11-2011.pdf"&gt;ГОСТ Р 7.0.11-2011&lt;/a&gt;,
пункты 5.3.3 и 9.2.3).&lt;/li&gt;
&lt;li&gt;&lt;a href="common/data.tex"&gt;data.tex&lt;/a&gt;: Общие данные (название работы, руководитель,
оппоненты, ключевые слова и т. п.).&lt;/li&gt;
&lt;li&gt;&lt;a href="common/packages.tex"&gt;packages.tex&lt;/a&gt; и &lt;a href="common/styles.tex"&gt;styles.tex&lt;/a&gt;: Общие
пакеты и стили оформления автореферата и диссертации.&lt;/li&gt;
&lt;li&gt;&lt;a href="common/setup.tex"&gt;setup.tex&lt;/a&gt;: Общие настройки автореферата и диссертации.
В нём же настраивается выбор реализации библиографии.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;папка biblio:&lt;/strong&gt; Файлы с библиографией.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;папка images:&lt;/strong&gt; Общие файлы изображений шаблонов.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;папка listings:&lt;/strong&gt; Общие файлы листингов.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-дополнительная-полезная-информация" class="anchor" aria-hidden="true" href="#дополнительная-полезная-информация"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Дополнительная полезная информация&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="Readme/Bibliography.md"&gt;Оформление библиографии&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="CONTRIBUTING.md"&gt;Как вносить правки в проект&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="Readme/Links.md"&gt;Полезные ссылки&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sharelatex.com/templates/thesis/russian-phd-latex-dissertation-template" rel="nofollow"&gt;Шаблон в галерее шаблонов ShareLaTeX&lt;/a&gt; (очень старая версия).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-благодарности" class="anchor" aria-hidden="true" href="#благодарности"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Благодарности&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Большое спасибо Юлии Мартыновой за &lt;a href="http://alessia-lano.livejournal.com/4267.html" rel="nofollow"&gt;оригинальный вариант шаблона&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Большое спасибо &lt;a href="https://github.com/dustalov"&gt;dustalov&lt;/a&gt;,
&lt;a href="https://github.com/Lenchik"&gt;Lenchik&lt;/a&gt;, &lt;a href="https://github.com/tonkonogov"&gt;tonkonogov&lt;/a&gt;
за значительный вклад и обсуждения.&lt;/li&gt;
&lt;li&gt;Спасибо &lt;a href="https://github.com/storkvist"&gt;storkvist&lt;/a&gt;, &lt;a href="https://github.com/kshmirko"&gt;kshmirko&lt;/a&gt;,
&lt;a href="https://github.com/ZoomRmc"&gt;ZoomRmc&lt;/a&gt;, &lt;a href="https://github.com/tonytonov"&gt;tonytonov&lt;/a&gt;,
&lt;a href="https://github.com/Thibak"&gt;Thibak&lt;/a&gt;, &lt;a href="https://github.com/eximius8"&gt;eximius8&lt;/a&gt;,
&lt;a href="https://github.com/Nizky"&gt;Nizky&lt;/a&gt; за полезные правки и замечания.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-лицензия" class="anchor" aria-hidden="true" href="#лицензия"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Лицензия&lt;/h2&gt;
&lt;p&gt;CC BY 4.0&lt;/p&gt;
&lt;p&gt;Поэтому можно модифицировать и использовать шаблон любым образом, при
условии сохранения авторства на шаблон оформления диссертации в
формате LaTeX (в виде списка авторов в настоящем файле).  При этом не
накладывается никаких ограничений на текст диссертации, все права на
содержательную часть диссертации остаются за её автором.  В том числе,
если в тексте возникает раздел благодарностей (например, научному
руководителю за умелое руководство, коллегам за помощь в работе и
т.д.), то надо ли выносить авторам шаблона
&lt;em&gt;Russian-Phd-LaTeX-Dissertation-Template&lt;/em&gt; благодарность за помощь в
оформлении диссертации или нет - решает сам диссертант. Использвание
шаблона не накладывает никаких ограничений на использование итоговых
файлов (например, PDF с готовой диссертацией или авторефератом),
т.е. никак не регулирует то, как они распространяются, копируются,
модифицируются и т.д.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>AndreyAkinshin</author><guid isPermaLink="false">https://github.com/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template</guid><pubDate>Mon, 02 Dec 2019 00:16:00 GMT</pubDate></item><item><title>ybayle/awesome-deep-learning-music #17 in TeX, Today</title><link>https://github.com/ybayle/awesome-deep-learning-music</link><description>&lt;p&gt;&lt;i&gt;List of articles related to deep learning applied to music&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="fig/logo.png"&gt;&lt;img align="right" src="fig/logo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-deep-learning-for-music-dl4m-" class="anchor" aria-hidden="true" href="#deep-learning-for-music-dl4m-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep Learning for Music (DL4M) &lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;By &lt;a href="http://yannbayle.fr/english/index.php" rel="nofollow"&gt;Yann Bayle&lt;/a&gt; (&lt;a href="http://yannbayle.fr/english/index.php" rel="nofollow"&gt;Website&lt;/a&gt;, &lt;a href="https://github.com/ybayle"&gt;GitHub&lt;/a&gt;) from LaBRI (&lt;a href="http://www.labri.fr/" rel="nofollow"&gt;Website&lt;/a&gt;, &lt;a href="https://twitter.com/labriOfficial/" rel="nofollow"&gt;Twitter&lt;/a&gt;), Univ. Bordeaux (&lt;a href="https://www.u-bordeaux.fr/" rel="nofollow"&gt;Website&lt;/a&gt;, &lt;a href="https://twitter.com/univbordeaux" rel="nofollow"&gt;Twitter&lt;/a&gt;), CNRS (&lt;a href="http://www.cnrs.fr/" rel="nofollow"&gt;Website&lt;/a&gt;, &lt;a href="https://twitter.com/CNRS" rel="nofollow"&gt;Twitter&lt;/a&gt;) and SCRIME (&lt;a href="https://scrime.u-bordeaux.fr/" rel="nofollow"&gt;Website&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; Non-exhaustive list of scientific articles on deep learning for music: &lt;a href="#dl4m-summary"&gt;summary&lt;/a&gt; (Article title, pdf link and code), &lt;a href="dl4m.tsv"&gt;details&lt;/a&gt; (table - more info), &lt;a href="dl4m.bib"&gt;details&lt;/a&gt; (bib - all info)&lt;/p&gt;
&lt;p&gt;The role of this curated list is to gather scientific articles, thesis and reports that use deep learning approaches applied to music.
The list is currently under construction but feel free to contribute to the missing fields and to add other resources! To do so, please refer to the &lt;a href="#how-to-contribute"&gt;How To Contribute&lt;/a&gt; section.
The resources provided here come from my review of the state-of-the-art for my PhD Thesis for which an article is being written.
There are already surveys on deep learning for &lt;a href="https://arxiv.org/pdf/1709.01620.pdf" rel="nofollow"&gt;music generation&lt;/a&gt;, &lt;a href="https://arxiv.org/ftp/arxiv/papers/1708/1708.07524.pdf" rel="nofollow"&gt;speech separation&lt;/a&gt; and &lt;a href="https://www.researchgate.net/profile/Seyed_Reza_Shahamiri/publication/319158024_Speaker_Identification_Features_Extraction_Methods_A_Systematic_Review/links/599e2816aca272dff12fdef1/Speaker-Identification-Features-Extraction-Methods-A-Systematic-Review.pdf" rel="nofollow"&gt;speaker identification&lt;/a&gt;.
However, these surveys do not cover music information retrieval tasks that are included in this repository.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#dl4m-summary"&gt;DL4M summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dl4m-details"&gt;DL4M details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#code-without-articles"&gt;Code without articles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#statistics-and-visualisations"&gt;Statistics and visualisations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advices-for-reviewers-of-dl4m-articles"&gt;Advices for reviewers of dl4m articles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-contribute"&gt;How To Contribute&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#acronyms-used"&gt;Acronyms used&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sources"&gt;Sources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-useful-related-lists-and-resources"&gt;Other useful related lists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cited-by"&gt;Cited by&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-dl4m-summary" class="anchor" aria-hidden="true" href="#dl4m-summary"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DL4M summary&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Year&lt;/th&gt;
&lt;th&gt;Articles, Thesis and Reports&lt;/th&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1988&lt;/td&gt;
&lt;td&gt;Neural net modeling of music&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1988&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=23933" rel="nofollow"&gt;Creation by refinement: A creativity paradigm for gradient descent learning networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1988&lt;/td&gt;
&lt;td&gt;A sequential network design for musical applications&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1989&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.jstor.org/stable/3679550" rel="nofollow"&gt;The representation of pitch in a neural net model of chord classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1989&lt;/td&gt;
&lt;td&gt;&lt;a href="https://quod.lib.umich.edu/cgi/p/pod/dod-idx/algorithms-for-music-composition.pdf?c=icmc;idno=bbp2372.1989.044;format=pdf" rel="nofollow"&gt;Algorithms for music composition by neural nets: Improved CBR paradigms&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1989&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.jstor.org/stable/3679551" rel="nofollow"&gt;A connectionist approach to algorithmic composition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1994&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www-labs.iro.umontreal.ca/~pift6080/H09/documents/papers/mozer-music.pdf" rel="nofollow"&gt;Neural network music composition by prediction: Exploring the benefits of psychoacoustic constraints and multi-scale processing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1995&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/publication/3622871_Automatic_source_identification_of_monophonic_musical_instrument_sounds" rel="nofollow"&gt;Automatic source identification of monophonic musical instrument sounds&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1995&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/514161/" rel="nofollow"&gt;Neural network based model for classification of music type&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1997&lt;/td&gt;
&lt;td&gt;&lt;a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1496&amp;amp;context=compsci" rel="nofollow"&gt;A machine learning approach to musical style recognition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1998&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/pub1/soltau_hagen_1998_2/soltau_hagen_1998_2.pdf" rel="nofollow"&gt;Recognition of music types&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1999&lt;/td&gt;
&lt;td&gt;&lt;a href="https://s3.amazonaws.com/academia.edu.documents/3551783/10.1.1.39.6248.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&amp;amp;Expires=1507055806&amp;amp;Signature=5mGzQc7bvJgUZYfXOmCX8eeNQOs%3D&amp;amp;response-content-disposition=inline%3B%20filename%3DMusical_networks_Parallel_distributed_pe.pdf" rel="nofollow"&gt;Musical networks: Parallel distributed perception and performance&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2001&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.cs.smith.edu/~jfrankli/papers/CtColl01.pdf" rel="nofollow"&gt;Multi-phase learning for jazz improvisation and interaction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2002&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Giuseppe_Buzzanca/publication/228588086_A_supervised_learning_approach_to_musical_style_recognition/links/54b43ee90cf26833efd0109f.pdf" rel="nofollow"&gt;A supervised learning approach to musical style recognition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2002&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www-perso.iro.umontreal.ca/~eckdoug/papers/2002_ieee.pdf" rel="nofollow"&gt;Finding temporal structure in music: Blues improvisation with LSTM recurrent networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2002&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Matija_Marolt/publication/2473938_Neural_Networks_for_Note_Onset_Detection_in_Piano_Music/links/00b49525efccc79fed000000.pdf" rel="nofollow"&gt;Neural networks for note onset detection in piano music&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2004&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.murase.nuie.nagoya-u.ac.jp/~ide/res/paper/E04-conference-pablo-1.pdf" rel="nofollow"&gt;A convolutional-kernel based approach for note onset detection in piano-solo audio signals&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2009&lt;/td&gt;
&lt;td&gt;&lt;a href="http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for-audio-classification-using-convolutional-deep-belief-networks.pdf" rel="nofollow"&gt;Unsupervised feature learning for audio classification using convolutional deep belief networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2010&lt;/td&gt;
&lt;td&gt;&lt;a href="http://lbms03.cityu.edu.hk/theses/c_ftt/mphil-cs-b39478026f.pdf" rel="nofollow"&gt;Audio musical genre classification using convolutional neural networks and pitch and tempo transformations&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2010&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Antoni_Chan2/publication/44260643_Automatic_Musical_Pattern_Feature_Extraction_Using_Convolutional_Neural_Network/links/02e7e523dac6bb86b0000000.pdf" rel="nofollow"&gt;Automatic musical pattern feature extraction using convolutional neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2011&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.ismir2011.ismir.net/papers/PS6-3.pdf" rel="nofollow"&gt;Audio-based music classification with a pretrained convolutional network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2012&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/6406762/" rel="nofollow"&gt;Rethinking automatic chord recognition with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2012&lt;/td&gt;
&lt;td&gt;&lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.2304&amp;amp;rep=rep1&amp;amp;type=pdf" rel="nofollow"&gt;Moving beyond feature design: Deep architectures and automatic feature learning in music informatics&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2012&lt;/td&gt;
&lt;td&gt;&lt;a href="http://liris.cnrs.fr/Documents/Liris-5602.pdf" rel="nofollow"&gt;Local-feature-map integration using convolutional neural networks for music genre classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2012&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pdfs.semanticscholar.org/099d/85f25e9336f48ff64287a4b53ee5fb64ab51.pdf" rel="nofollow"&gt;Learning sparse feature representations for music annotation and retrieval&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2012&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.ismir2012.ismir.net/event/papers/139_ISMIR_2012.pdf" rel="nofollow"&gt;Unsupervised learning of local features for music classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2013&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ismir2013.ismir.net/wp-content/uploads/2013/09/69_Paper.pdf" rel="nofollow"&gt;Multiscale approaches to music audio feature learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2013&lt;/td&gt;
&lt;td&gt;&lt;a href="http://phenicx.upf.edu/system/files/publications/Schlueter_MML13.pdf" rel="nofollow"&gt;Musical onset detection with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2013&lt;/td&gt;
&lt;td&gt;&lt;a href="http://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf" rel="nofollow"&gt;Deep content-based music recommendation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="https://pdfs.semanticscholar.org/8a24/c5131d5a28165f719697028c34b00e6d3f60.pdf" rel="nofollow"&gt;The munich LSTM-RNN approach to the MediaEval 2014 Emotion In Music task&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/6854950/" rel="nofollow"&gt;End-to-end learning for music audio&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="https://courses.engr.illinois.edu/ece544na/fa2014/Tao_Feng.pdf" rel="nofollow"&gt;Deep learning for music genre classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cs.tut.fi/sgn/arg/music/tuomasv/dnn_eusipco2014.pdf" rel="nofollow"&gt;Recognition of acoustic events using deep neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.degruyter.com/downloadpdf/j/eletel.2014.60.issue-4/eletel-2014-0042/eletel-2014-0042.pdf" rel="nofollow"&gt;Deep image features in music information retrieval&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7024-humphrey.pdf" rel="nofollow"&gt;From music audio to chord tablature: Teaching deep convolutional networks to play guitar&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7029-schluter.pdf" rel="nofollow"&gt;Improved musical onset detection with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="https://dav.grrrr.org/public/pub/ullrich_schlueter_grill-2014-ismir.pdf" rel="nofollow"&gt;Boundary detection in music structure analysis using convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.smcnus.org/wp-content/uploads/2014/08/reco_MM14.pdf" rel="nofollow"&gt;Improving content-based and hybrid music recommendation using deep learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2014&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7034-zhang.pdf" rel="nofollow"&gt;A deep representation for invariance and music classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ismir2015.uma.es/LBD/LBD24.pdf" rel="nofollow"&gt;Auralisation of deep convolutional neural networks: Listening to learned features&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/keunwoochoi/Auralisation"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="http://perso.telecom-paristech.fr/~grichard/Publications/2015-durand-icassp.pdf" rel="nofollow"&gt;Downbeat tracking with multiple features and deep neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.ofai.at/~jan.schlueter/pubs/2015_eusipco.pdf" rel="nofollow"&gt;Music boundary detection using neural networks on spectrograms and self-similarity lag matrices&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Toni_Hirvonen/publication/276061831_Classification_of_Spatial_Audio_Location_and_Content_Using_Convolutional_Neural_Networks/links/5550665908ae12808b37fe5a/Classification-of-Spatial-Audio-Location-and-Content-Using-Convolutional-Neural-Networks.pdf" rel="nofollow"&gt;Classification of spatial audio location and content using convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6905/pdf/imm6905.pdf" rel="nofollow"&gt;Deep learning, audio adversaries, and music content analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1507.04761.pdf" rel="nofollow"&gt;Deep learning and music adversaries&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/coreyker/dnn-mgr"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://hal-imt.archives-ouvertes.fr/hal-01110035/" rel="nofollow"&gt;Singing voice detection with deep recurrent neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1511.05520.pdf" rel="nofollow"&gt;Automatic instrument recognition in polyphonic music using convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://bmcfee.github.io/papers/ismir2015_augmentation.pdf" rel="nofollow"&gt;A software framework for musical data augmentation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1508.04999v1.pdf" rel="nofollow"&gt;A deep bag-of-features model for music auto-tagging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ismir2015.uma.es/LBD/LBD27.pdf" rel="nofollow"&gt;Music-noise segmentation in spectrotemporal domain using convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/ftp/arxiv/papers/1512/1512.07370.pdf" rel="nofollow"&gt;Musical instrument sound classification with deep convolutional neural network using feature fusion approach&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="http://karol.piczak.com/papers/Piczak2015-ESC-ConvNet.pdf" rel="nofollow"&gt;Environmental sound classification with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://grrrr.org/pub/schlueter-2015-ismir.pdf" rel="nofollow"&gt;Exploring data augmentation for improved singing voice detection with neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/f0k/ismir2015"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://cs224d.stanford.edu/reports/SkiZhengshan.pdf" rel="nofollow"&gt;Singer traits identification using deep neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1411.1623.pdf" rel="nofollow"&gt;A hybrid recurrent neural network for music transcription&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1508.01774.pdf" rel="nofollow"&gt;An end-to-end neural network for polyphonic music transcription&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://link.springer.com/chapter/10.1007/978-3-319-22482-4_50" rel="nofollow"&gt;Deep karaoke: Extracting vocals from musical mixtures using a convolutional deep neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ismir2015.uma.es/LBD/LBD13.pdf" rel="nofollow"&gt;Folk music style modelling by recurrent neural networks with long short term memory units&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/IraKorshunova/folk-rnn"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Stefan_Uhlich/publication/282001406_Deep_neural_network_based_instrument_extraction_from_music/links/5600eeda08ae07629e52b397/Deep-neural-network-based-instrument-extraction-from-music.pdf" rel="nofollow"&gt;Deep neural network based instrument extraction from music&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2015&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Xiaoqing_Zheng3/publication/275347034_A_Deep_Neural_Network_for_Modeling_Music/links/5539d2060cf2239f4e7dad0d/A-Deep-Neural-Network-for-Modeling-Music.pdf" rel="nofollow"&gt;A deep neural network for modeling music&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://file.scirp.org/pdf/CS_2016042615054817.pdf" rel="nofollow"&gt;An efficient approach for segmentation, feature extraction and classification of audio signals&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/0B1OooSxEtl0FcG9MYnY2Ylh5c0U/view" rel="nofollow"&gt;Text-based LSTM networks for automatic music composition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1606.02096.pdf" rel="nofollow"&gt;Towards playlist generation algorithms using RNNs trained on within-track transitions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1606.00298.pdf" rel="nofollow"&gt;Automatic tagging using deep convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/7471677/" rel="nofollow"&gt;Automatic chord estimation on seventhsbass chord vocabulary using deep neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1612.01010.pdf" rel="nofollow"&gt;DeepBach: A steerable model for Bach chorales generation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Ghadjeres/DeepBach"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.rhythmos.org/MMILab-Andre_files/ISMIR2016_CNNDBNbeats_camready.pdf" rel="nofollow"&gt;Bayesian meter tracking on learned signal representations&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1606.04930.pdf" rel="nofollow"&gt;Deep learning for music&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Il_Young_Jeong/publication/305683876_Learning_temporal_features_using_a_deep_neural_network_and_its_application_to_music_genre_classification/links/5799a27c08aec89db7bb9f92.pdf" rel="nofollow"&gt;Learning temporal features using a deep neural network and its application to music genre classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1612.05153.pdf" rel="nofollow"&gt;On the potential of simple framewise approaches to piano transcription&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1612.05065.pdf" rel="nofollow"&gt;Feature learning for chord recognition: The deep chroma extractor&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/fdlm/chordrec/tree/master/experiments/ismir2016"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Filip_Korzeniowski/publication/305590295_A_Fully_Convolutional_Deep_Auditory_Model_for_Musical_Chord_Recognition/links/579486ba08aed51475cc6958/A-Fully-Convolutional-Deep-Auditory-Model-for-Musical-Chord-Recognition.pdf?_iepl%5BhomeFeedViewId%5D=HTzFFmKPia2YminQ4psHT5at&amp;amp;_iepl%5Bcontexts%5D%5B0%5D=pcfhf&amp;amp;_iepl%5BinteractionType%5D=publicationDownload&amp;amp;origin=publication_detail&amp;amp;ev=pub_int_prw_xdl&amp;amp;msrp=Dz_6LKHzYcPyP-LmgZPF-m63ayZ6k0entFEntooiu_e32zfETNQXKPQSTFOI87NONIIQuUQdnUtwORdomTXfteTrb09KiAIdDtBJnw_02P6JeRr5zu2eyaCG.2Uxsi_eENxtbYL39lvorIK8LofRYhkgpUHzpzmVzkIEiyHc0wUY87rEa4PH1qbXi4k4RyagHUsA2IsZtewnprglORjx2v9Cwbk9ZfQ.cd67BaqtHul_hE6SX6vUFKuldz81aH6dWq-cYMkq5vQKCHcvB8l9zgeM694Efb_r2wBB5GT9idt3OLeME0UxVHI6ROxamgK3LMNlSw.JtZXAo9HhR9t-8Wl3gxJgnoM4--rtmDEUDbXSWezbFyU-CoB_nyfxbRQ4kdoN4-5aJ3Tgx4YHdikicqAhc_cezB2ZntjxkB4rEDx1A" rel="nofollow"&gt;A fully convolutional deep auditory model for musical chord recognition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/document/7471734/" rel="nofollow"&gt;A deep bidirectional long short-term memory based multi-scale approach for music dynamic emotion prediction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://mac.citi.sinica.edu.tw/~yang/pub/liu16mm.pdf" rel="nofollow"&gt;Event localization in music auto-tagging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ciaua/clip2frame"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lostanlen/ismir2016/blob/master/paper/lostanlen_ismir2016.pdf"&gt;Deep convolutional networks on the pitch spiral for musical instrument recognition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lostanlen/ismir2016"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://openreview.net/pdf?id=SkxKPDv5xl" rel="nofollow"&gt;SampleRNN: An unconditional end-to-end neural audio generation model&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/soroushmehr/sampleRNN_ICLR2017"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1604.06338.pdf" rel="nofollow"&gt;Robust audio event recognition with 1-max pooling convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://jordipons.me/media/CBMI16.pdf" rel="nofollow"&gt;Experimenting with musically motivated convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/jordipons/"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/07/163_Paper.pdf" rel="nofollow"&gt;Singing voice melody transcription using deep neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.music-ir.org/mirex/abstracts/2016/RSGP1.pdf" rel="nofollow"&gt;Singing voice separation using deep neural networks and F0 estimation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://cvssp.org/projects/maruss/mirex2016/" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.ofai.at/~jan.schlueter/pubs/2016_ismir.pdf" rel="nofollow"&gt;Learning to pinpoint singing voice from weakly labeled examples&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/7733228/" rel="nofollow"&gt;Analysis of time-frequency representations for musical onset detection with convolutional neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.degruyter.com/downloadpdf/j/amcs.2016.26.issue-1/amcs-2016-0014/amcs-2016-0014.pdf" rel="nofollow"&gt;Note onset detection in musical signals via neural-network-based multi-ODF fusion&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://drive.google.com/file/d/0B1OooSxEtl0FcTBiOGdvSTBmWnc/view" rel="nofollow"&gt;Music transcription modelling and composition using deep learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/IraKorshunova/folk-rnn"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202016/pdfs/0000579.pdf" rel="nofollow"&gt;Convolutional neural network for robust pitch determination&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2016&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1604.07160.pdf" rel="nofollow"&gt;Deep convolutional neural networks and data augmentation for acoustic event detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://bitbucket.org/naoya1/aenet_release" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1706.08818.pdf" rel="nofollow"&gt;Gabor frames and deep scattering networks in audio processing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/bazzica2017clarinet.pdf" rel="nofollow"&gt;Vision-based detection of acoustic timed events: A case study on clarinet note onsets&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.01620.pdf" rel="nofollow"&gt;Deep learning techniques for music generation - A survey&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1711.07682.pdf" rel="nofollow"&gt;JamBot: Music theory aware chord based generation of polyphonic music with LSTMs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/brunnergino/JamBot"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.00572.pdf" rel="nofollow"&gt;XFlow: 1D &amp;lt;-&amp;gt; 2D cross-modal deep neural networks for audiovisual classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/cella2017mli.pdf" rel="nofollow"&gt;Machine listening intelligence&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://mtg.upf.edu/system/files/publications/monoaural-audio-source_0.pdf" rel="nofollow"&gt;Monoaural audio source separation using deep convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/MTG/DeepConvSep"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/8019322/" rel="nofollow"&gt;Deep multimodal network for multi-label classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.04396.pdf" rel="nofollow"&gt;A tutorial on deep learning for music information retrieval&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/keunwoochoi/dl4mir"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.01922.pdf" rel="nofollow"&gt;A comparison on audio signal preprocessing methods for deep neural networks on music tagging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/keunwoochoi/transfer_learning_music"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1703.09179v3.pdf" rel="nofollow"&gt;Transfer learning for music classification and regression tasks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/keunwoochoi/transfer_learning_music"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/7952585/" rel="nofollow"&gt;Convolutional recurrent neural networks for music classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/keunwoochoi/icassp_2017"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.inf.ufpr.br/lesoliveira/download/ASOC2017.pdf" rel="nofollow"&gt;An evaluation of convolutional neural networks for music classification using spectrograms&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.07153.pdf" rel="nofollow"&gt;Large vocabulary automatic chord estimation using deep neural nets: Design framework, system variations and limitations&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.02291.pdf" rel="nofollow"&gt;Basic filters for convolutional neural networks: Training or design?&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1708.05826.pdf" rel="nofollow"&gt;Ensemble Of Deep Neural Networks For Acoustic Scene Classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/7728057/" rel="nofollow"&gt;Robust downbeat tracking using an ensemble of convolutional networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/fan2017vector.pdf" rel="nofollow"&gt;Music signal processing using vector product neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/geng2017genre.pdf" rel="nofollow"&gt;Transforming musical signals through a genre classifying convolutional neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1707.03547.pdf" rel="nofollow"&gt;Audio to score matching by combining phonetic and duration information&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ronggong/jingjuSingingPhraseMatching/tree/v0.1.0"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.06404.pdf" rel="nofollow"&gt;Interactive music generation with positional constraints using anticipation-RNNs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.00740.pdf" rel="nofollow"&gt;Deep rank-based transposition-invariant distances on musical sequences&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1707.04588.pdf" rel="nofollow"&gt;GLSR-VAE: Geodesic latent space regularization for variational autoencoder architectures&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dl.acm.org/citation.cfm?id=3068697" rel="nofollow"&gt;Deep convolutional neural networks for predominant instrument recognition in polyphonic music&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1609.09430v2.pdf" rel="nofollow"&gt;CNN architectures for large-scale audio classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/8026272/" rel="nofollow"&gt;DeepSheet: A sheet music generator based on deep learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/hutchings2017drums.pdf" rel="nofollow"&gt;Talking Drums: Generating drum grooves with neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/171_Paper.pdf" rel="nofollow"&gt;Singing voice separation with deep U-Net convolutional networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Xiao-Ming/UNet-VocalSeparation-Chainer"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ceur-ws.org/Vol-1905/recsys2017_poster18.pdf" rel="nofollow"&gt;Music emotion recognition via end-to-end multimodal neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/koops2017pers.pdf" rel="nofollow"&gt;Chord label personalization through deep learning of integrated harmonic interval-based representations&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1706.02921.pdf" rel="nofollow"&gt;End-to-end musical key estimation using a convolutional neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.cp.jku.at/research/papers/Koutini_2017_mediaeval-acousticbrainz.pdf" rel="nofollow"&gt;MediaEval 2017 AcousticBrainz genre task: Multilayer perceptron approach&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.preprints.org/manuscript/201711.0027/v1" rel="nofollow"&gt;Classification-based singing melody extraction using deep convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1703.01793v2.pdf" rel="nofollow"&gt;Multi-level and multi-scale feature aggregation using pre-trained convolutional neural networks for music auto-tagging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1706.06810.pdf" rel="nofollow"&gt;Multi-level and multi-scale feature aggregation using sample-level deep convolutional neural networks for music classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/jongpillee/musicTagging_MSD"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1703.01789v2.pdf" rel="nofollow"&gt;Sample-level deep convolutional neural networks for music auto-tagging using raw waveforms&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1710.11418.pdf" rel="nofollow"&gt;A SeqGAN for Polyphonic Music Generation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/L0SG/seqgan-music"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.eurasip.org/Proceedings/Eusipco/Eusipco2017/papers/1570346835.pdf" rel="nofollow"&gt;Harmonic and percussive source separation using a convolutional auto encoder&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1706.02292.pdf" rel="nofollow"&gt;Stacked convolutional and recurrent neural networks for music emotion recognition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://repositori.upf.edu/bitstream/handle/10230/32919/Martel_2017.pdf?sequence=1&amp;amp;isAllowed=y" rel="nofollow"&gt;A deep learning approach to source separation and remixing of hiphop music&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://link.springer.com/chapter/10.1007%2F978-3-319-70096-0_49" rel="nofollow"&gt;Music Genre Classification Using Masked Conditional Neural Networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1711.01437.pdf" rel="nofollow"&gt;Monaural Singing Voice Separation with Skip-Filtering Connections and Recurrent Inference of Time-Frequency Mask&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Js-Mim/mss_pytorch"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Marius_Miron/publication/318322107_Generating_data_to_train_convolutional_neural_networks_for_classical_music_source_separation/links/59637cc3458515a3575b93c6/Generating-data-to-train-convolutional-neural-networks-for-classical-music-source-separation.pdf?_iepl%5BhomeFeedViewId%5D=WchoMnlUL1Hk9hBLVTeR8Amh&amp;amp;_iepl%5Bcontexts%5D%5B0%5D=pcfhf&amp;amp;_iepl%5BinteractionType%5D=publicationDownload&amp;amp;origin=publication_detail&amp;amp;ev=pub_int_prw_xdl&amp;amp;msrp=p3lQ8M4uZlb4TF5Hv9a2U3P2y4wW7ant5KWj4E5-OcD1Mg53p1ykTKHMG9_zVTB9n6mI8fvZOCL2Xhpru186pCEY-2ZxiYR-CB8_QvwHc1kUG-QE4SHdProR.LoJb2BDOiiQth3iR9xgZUxxCWEJgtTBF4whFrFa01OD49-3YYRxA0WQVN--zhtQU_7C2Pt0rKdwoFxT1pfxFvnKXSXmy2eT1Jpz-pw.U1QLoFO_Uc6aQVr2Nm2FcAi6BqAUfngH2Or5__6wegbCgVvTYoIGt22tmCkYbGTOQ_4PxBgt1LrvsFQiL0oMyogP8Yk8myTj0gs9jw.fGpkufGqAI4R2v8Hfe0ThcXL7M7yN2PuAlx974BGVn50SdUWvNhhIPWBD-zWTn8NKtVJx3XrjKXFrMgi9Cx7qGrNP8tBWpha6Srf6g" rel="nofollow"&gt;Generating data to train convolutional neural networks for classical music source separation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/MTG/DeepConvSep"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Marius_Miron/publication/318637038_Monaural_score-informed_source_separation_for_classical_music_using_convolutional_neural_networks/links/597327c6458515e26dfdb007/Monaural-score-informed-source-separation-for-classical-music-using-convolutional-neural-networks.pdf?_iepl%5BhomeFeedViewId%5D=WchoMnlUL1Hk9hBLVTeR8Amh&amp;amp;_iepl%5Bcontexts%5D%5B0%5D=pcfhf&amp;amp;_iepl%5BinteractionType%5D=publicationDownload&amp;amp;origin=publication_detail&amp;amp;ev=pub_int_prw_xdl&amp;amp;msrp=Hp6dDqMepEiRZ5E6WkreaqyjFkFkwMxPFoJvr14etVJsoKZBc5qb99fBnJjVUZrRHLFRhaXvNY9k1sMvYPOouuGbQP0YhEGm28zLw_55Zewu86WGnHck1Tqi.93HH2WqXfTedn6IaZRjjhQGYZVDHBz1X6nr4ABBgMAVv584gvGN3sW5IyBAY-4MBWf5DJFPBGm8zsaC2dKz8G-odZPfosWoXY0afAQ.KoCP2mO9l31lCER0oMZMZBrbuRGvb6ZzeBwHb88pL8AhMfJk03Hj1eLrohQIjPDETBj4hhqb0gniDGJgtZ9GnW64ZNjh9GbQDrIl5A.egNQTyC7t8P26zCQWrbEhf51Pxy2JRBZoTkH6SpRHHhRhFl1_AT_AT481lMcFI34-JbeRq-5oTQR7DpvAuw7iUIivd78ltuxpI9syg" rel="nofollow"&gt;Monaural score-informed source separation for classical music using convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/MTG/DeepConvSep"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/126_Paper.pdf" rel="nofollow"&gt;Multi-label music genre classification from audio, text, and images using deep features&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/sergiooramas/tartarus"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1706.09739.pdf" rel="nofollow"&gt;A deep multimodal approach for cold-start music recommendation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/sergiooramas/tartarus"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/7952660/" rel="nofollow"&gt;Melody extraction and detection through LSTM-RNN with harmonic sum loss&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1710.06648.pdf" rel="nofollow"&gt;Representation learning of music using artist labels&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/pfalz2017synthesis.pdf" rel="nofollow"&gt;Toward inverse control of physics-based sound synthesis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cct.lsu.edu/~apfalz/inverse_control.html" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1708.03211.pdf" rel="nofollow"&gt;DNN and CNN with weighted and multi-task loss functions for audio event detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/46_Paper.pdf" rel="nofollow"&gt;Score-informed syllable segmentation for a cappella singing voice with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ronggong/jingjuSyllabicSegmentaion/tree/v0.1.0"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1711.02520.pdf" rel="nofollow"&gt;End-to-end learning for music audio tagging at scale&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/jordipons/music-audio-tagging-at-scale-models"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/document/7952601/" rel="nofollow"&gt;Designing efficient architectures for modeling temporal features with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/jordipons/ICASSP2017"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/ronggong/EUSIPCO2017"&gt;Timbre analysis of music audio signals with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/jordipons/EUSIPCO2017"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.semanticaudio.co.uk/wp-content/uploads/2017/09/WIMP2017_Martinez-RamirezReiss.pdf" rel="nofollow"&gt;Deep learning and intelligent audio mixing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ofai.at/~jan.schlueter/pubs/phd/phd.pdf" rel="nofollow"&gt;Deep learning for event detection, sequence labelling and similarity estimation in music signals&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.researchgate.net/profile/Thomas_Pellegrini/publication/319326354_Music_Feature_Maps_with_Convolutional_Neural_Networks_for_Music_Genre_Classification/links/59ba5ae3458515bb9c4c6724/Music-Feature-Maps-with-Convolutional-Neural-Networks-for-Music-Genre-Classification.pdf?origin=publication_detail&amp;amp;ev=pub_int_prw_xdl&amp;amp;msrp=wzXuHZAa5zAnqEmErYyZwIRr2H0q01LnNEd4Wd7A15CQfdVLwdy98pmE-AdnrDvoc3-bVENSFrHt0yhaOiE2mQrYllVS9CJZOk-c9R0j_R1rbgcZugS6RtQ_.AUjPuJSF5P_DMngf-woH7W-7jdnQlbNQziR4_h6NnCHfR_zGcEa8vOyyOz5gx5nc4azqKTPQ5ZgGGLUxkLj1qCQLEQ5ThkhGlWHLyA.s6MBZE20-EO_RjRGCOCV4wk0WSFdN56Aloiraxz9hKCbJwRM2Et27RHVUA8jj9H8qvXIB6f7zSIrQgjXGrL2yCpyQlLffuf57rzSwg.KMMXbZrHsihV8DJM53xkHAWf3VebCJESi4KU4btNv9nQsyK2KnkhSQaTILKv0DSZY3c70a61LzywCBuoHtIhVOFhW5hVZN2n5O9uKQ" rel="nofollow"&gt;Music feature maps with convolutional neural networks for music genre classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://carlsouthall.files.wordpress.com/2017/12/ismir2017adt.pdf" rel="nofollow"&gt;Automatic drum transcription for polyphonic recordings using soft attention mechanisms and convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/CarlSouthall/ADTLib"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1711.00048.pdf" rel="nofollow"&gt;Adversarial semi-supervised audio source separation applied to singing voice extraction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://jcms.org.uk/issues/Vol2Issue1/taking-models-back-to-music-practice/Taking%20the%20Models%20back%20to%20Music%20Practice:%20Evaluating%20Generative%20Transcription%20Models%20built%20using%20Deep%20Learning.pdf" rel="nofollow"&gt;Taking the models back to music practice: Evaluating generative transcription models built using deep learning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/IraKorshunova/folk-rnn"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/178_Paper.pdf" rel="nofollow"&gt;Generating nontrivial melodies for music as a service&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1711.04845.pdf" rel="nofollow"&gt;Invariances and data augmentation for supervised music transcription&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/jthickstun/thickstun2018invariances/"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/43_Paper.pdf" rel="nofollow"&gt;Lyrics-based music genre classification using a hierarchical attention network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/alexTsaptsinos/lyricsHAN"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.08243.pdf" rel="nofollow"&gt;A hybrid DSP/deep learning approach to real-time full-band speech enhancement&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/xiph/rnnoise/"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://vbn.aau.dk/files/260308151/PHD_Gissel_Velarde_E_pdf.pdf" rel="nofollow"&gt;Convolutional methods for music analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.aes.org/e-lib/browse.cfm?elib=18682" rel="nofollow"&gt;Extending temporal feature integration for semantic audio analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://ieeexplore.ieee.org/abstract/document/8019552/" rel="nofollow"&gt;Recognition and retrieval of sound events using sparse coding convolutional neural network&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.mdpi.com/2076-3417/7/9/901/htm" rel="nofollow"&gt;A two-stage approach to note-level transcription of a specific piano&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1711.00229.pdf" rel="nofollow"&gt;Reducing model complexity for DNN based large-scale audio classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="http://dorienherremans.com/dlm2017/papers/wyse2017spect.pdf" rel="nofollow"&gt;Audio spectrogram representations for processing with convolutional neural networks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://lonce.org/research/audioST/" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1607.03681.pdf" rel="nofollow"&gt;Unsupervised feature learning based on deep models for environmental audio tagging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1703.06052.pdf" rel="nofollow"&gt;Attention and localization based on a deep convolutional recurrent model for weakly supervised audio tagging&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/yongxuUSTC/att_loc_cgrnn"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://www.cs.tut.fi/sgn/arg/dcase2017/documents/challenge_technical_reports/DCASE2017_Xu_146.pdf" rel="nofollow"&gt;Surrey-CVSSP system for DCASE2017 challenge task4&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/yongxuUSTC/dcase2017_task4_cvssp"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017&lt;/td&gt;
&lt;td&gt;&lt;a href="https://qmro.qmul.ac.uk/xmlui/handle/123456789/24946" rel="nofollow"&gt;A study on LSTM networks for polyphonic music sequence modelling&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://www.eecs.qmul.ac.uk/~ay304/code/ismir17" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1709.06298.pdf" rel="nofollow"&gt;MuseGAN: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/salu133445/musegan"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1809.04281.pdf" rel="nofollow"&gt;Music transformer: Generating music with long-term structure&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2018&lt;/td&gt;
&lt;td&gt;&lt;a href="https://nips2018creativity.github.io/doc/music_theory_inspired_policy_gradient.pdf" rel="nofollow"&gt;Music theory inspired policy gradient method for piano music transcription&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/abs/1810.12247" rel="nofollow"&gt;Enabling factorized piano music modeling and generation with the MAESTRO dataset&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019&lt;/td&gt;
&lt;td&gt;&lt;a href="https://arxiv.org/pdf/1904.10509.pdf" rel="nofollow"&gt;Generating Long Sequences with Sparse Transformers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/openai/sparse_attention"&gt;GitHub&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-dl4m-details" class="anchor" aria-hidden="true" href="#dl4m-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DL4M details&lt;/h2&gt;
&lt;p&gt;A human-readable table summarized version if displayed in the file &lt;a href="dl4m.tsv"&gt;dl4m.tsv&lt;/a&gt;. All details for each article are stored in the corresponding bib entry in &lt;a href="dl4m.bib"&gt;dl4m.bib&lt;/a&gt;. Each entry has the regular bib field:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;author&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;year&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;title&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;journal&lt;/code&gt; or &lt;code&gt;booktitle&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each entry in &lt;a href="dl4m.bib"&gt;dl4m.bib&lt;/a&gt; also displays additional information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;link&lt;/code&gt; - HTML link to the PDF file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;code&lt;/code&gt; - Link to the source code if available&lt;/li&gt;
&lt;li&gt;&lt;code&gt;archi&lt;/code&gt; - Neural network architecture&lt;/li&gt;
&lt;li&gt;&lt;code&gt;layer&lt;/code&gt; - Number of layers&lt;/li&gt;
&lt;li&gt;&lt;code&gt;task&lt;/code&gt; - The proposed tasks studied in the article&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataset&lt;/code&gt; - The names of the dataset used&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataaugmentation&lt;/code&gt; - The type of data augmentation technique used&lt;/li&gt;
&lt;li&gt;&lt;code&gt;time&lt;/code&gt; - The computation time&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hardware&lt;/code&gt; - The hardware used&lt;/li&gt;
&lt;li&gt;&lt;code&gt;note&lt;/code&gt; - Additional notes and information&lt;/li&gt;
&lt;li&gt;&lt;code&gt;repro&lt;/code&gt; - Indication to what extent the experiments are reproducible&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-code-without-articles" class="anchor" aria-hidden="true" href="#code-without-articles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code without articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/drscotthawley/audio-classifier-keras-cnn"&gt;Audio Classifier in Keras using Convolutional Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jisungk/deepjazz"&gt;Deep learning driven jazz generation using Keras &amp;amp; Theano&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jordipons/music-audio-tagging-at-scale-models"&gt;End-to-end learning for music audio tagging at scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Hguimaraes/gtzan.keras"&gt;Music Genre classification on GTZAN dataset using CNNs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/helenacuesta/choir-pitch-estimation"&gt;Pitch Estimation of Choir Music using Deep Learning Strategies: from Solo to Unison Recordings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ruohoruotsi/LSTM-Music-Genre-Classification"&gt;Music Genre Classification with LSTMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/rickiepark/cnn_mer"&gt;CNN based Music Emotion Classification using TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/andabi/music-source-separation"&gt;Separating singing voice from music based on deep neural networks in Tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kristijanbartol/Deep-Music-Tagger"&gt;Music tag classification model using CRNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/despoisj/DeepAudioClassification"&gt;Finding the genre of a song with Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fephsun/neuralnetmusic"&gt;Composing music using neural nets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/djosix/Performance-RNN-PyTorch"&gt;Performance-RNN-PyTorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-statistics-and-visualisations" class="anchor" aria-hidden="true" href="#statistics-and-visualisations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Statistics and visualisations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;165 papers referenced. See the details in &lt;a href="dl4m.bib"&gt;dl4m.bib&lt;/a&gt;.
There are more papers from 2017 than any other years combined.
Number of articles per year:
&lt;a target="_blank" rel="noopener noreferrer" href="fig/articles_per_year.png"&gt;&lt;img src="fig/articles_per_year.png" alt="Number of articles per year" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If you are applying DL to music, there are &lt;a href="authors.md"&gt;356 other researchers&lt;/a&gt; in your field.&lt;/li&gt;
&lt;li&gt;34 tasks investigated. See the list of &lt;a href="tasks.md"&gt;tasks&lt;/a&gt;.
Tasks pie chart:
&lt;a target="_blank" rel="noopener noreferrer" href="fig/pie_chart_task.png"&gt;&lt;img src="fig/pie_chart_task.png" alt="Tasks pie chart" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;53 datasets used. See the list of &lt;a href="datasets.md"&gt;datasets&lt;/a&gt;.
Datasets pie chart:
&lt;a target="_blank" rel="noopener noreferrer" href="fig/pie_chart_dataset.png"&gt;&lt;img src="fig/pie_chart_dataset.png" alt="Datasets pie chart" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;30 architectures used. See the list of &lt;a href="architectures.md"&gt;architectures&lt;/a&gt;.
Architectures pie chart:
&lt;a target="_blank" rel="noopener noreferrer" href="fig/pie_chart_architecture.png"&gt;&lt;img src="fig/pie_chart_architecture.png" alt="Architectures pie chart" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9 frameworks used. See the list of &lt;a href="frameworks.md"&gt;frameworks&lt;/a&gt;.
Frameworks pie chart:
&lt;a target="_blank" rel="noopener noreferrer" href="fig/pie_chart_framework.png"&gt;&lt;img src="fig/pie_chart_framework.png" alt="Frameworks pie chart" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Only 44 articles (26%) provide their source code.
Repeatability is the key to good science, so check out the &lt;a href="reproducibility.md"&gt;list of useful resources on reproducibility for MIR and ML&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-advices-for-reviewers-of-dl4m-articles" class="anchor" aria-hidden="true" href="#advices-for-reviewers-of-dl4m-articles"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Advices for reviewers of dl4m articles&lt;/h2&gt;
&lt;p&gt;Please refer to the &lt;a href="advice_review.md"&gt;advice_review.md&lt;/a&gt; file.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-to-contribute" class="anchor" aria-hidden="true" href="#how-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How To Contribute&lt;/h2&gt;
&lt;p&gt;Contributions are welcome!
Please refer to the &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-faq" class="anchor" aria-hidden="true" href="#faq"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;FAQ&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;How are the articles sorted?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The articles are first sorted by decreasing year (to keep up with the latest news) and then alphabetically by the main author's family name.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why are preprint from arXiv included in the list?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I want to have exhaustive research and the latest news on DL4M. However, one should take care of the information provided in the articles currently in review. If possible you should wait for the final accepted and peer-reviewed version before citing an arXiv paper. I regularly update the arXiv links to the corresponding published papers when available.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How much can I trust the results published in an article?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The list provided here does not guarantee the quality of the articles. You should either try to reproduce the experiments described or submit a request to &lt;a href="https://github.com/ReScience/ReScience"&gt;ReScience&lt;/a&gt;. Use one article's conclusion at your own risks.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-acronyms-used" class="anchor" aria-hidden="true" href="#acronyms-used"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acronyms used&lt;/h2&gt;
&lt;p&gt;A list of useful acronyms used in deep learning and music is stored in &lt;a href="acronyms.md"&gt;acronyms.md&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-sources" class="anchor" aria-hidden="true" href="#sources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sources&lt;/h2&gt;
&lt;p&gt;The list of conferences, journals and aggregators used to gather the proposed materials is stored in &lt;a href="sources.md"&gt;sources.md&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributors" class="anchor" aria-hidden="true" href="#contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://yannbayle.fr/english/index.php" rel="nofollow"&gt;Yann Bayle&lt;/a&gt; (&lt;a href="https://github.com/ybayle"&gt;GitHub&lt;/a&gt;) - Instigator and principal maintainer&lt;/li&gt;
&lt;li&gt;Vincent Lostanlen (&lt;a href="https://github.com/lostanlen"&gt;GitHub&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://keunwoochoi.wordpress.com/" rel="nofollow"&gt;Keunwoo Choi&lt;/a&gt; (&lt;a href="https://github.com/keunwoochoi"&gt;GitHub&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.eecs.qmul.ac.uk/~sturm/" rel="nofollow"&gt;Bob L. Sturm&lt;/a&gt; (&lt;a href="https://github.com/boblsturm"&gt;GitHub&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.audiolabs-erlangen.de/fau/assistant/balke" rel="nofollow"&gt;Stefan Balke&lt;/a&gt; (&lt;a href="https://github.com/stefan-balke"&gt;GitHub&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.jordipons.me/" rel="nofollow"&gt;Jordi Pons&lt;/a&gt; (&lt;a href="https://github.com/jordipons"&gt;GitHub&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Mirza Zulfan (&lt;a href="https://github.com/mirzazulfan"&gt;GitHub&lt;/a&gt;) for the logo&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/devn"&gt;Devin Walters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/LegendJ"&gt;https://github.com/LegendJ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-other-useful-related-lists-and-resources" class="anchor" aria-hidden="true" href="#other-useful-related-lists-and-resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other useful related lists and resources&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-audio" class="anchor" aria-hidden="true" href="#audio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Audio&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tuwien-musicir/DL_MIR_Tutorial"&gt;DL4MIR tutorial with keras&lt;/a&gt; - Tutorial for Deep Learning on Music Information Retrieval by &lt;a href="http://ifs.tuwien.ac.at/~lidy/" rel="nofollow"&gt;Thomas Lidy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=sI_8EA0_ha8" rel="nofollow"&gt;Video talk from Ron Weiss&lt;/a&gt; - Ron Weiss (Google) Talk on Training neural network acoustic models on waveforms&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.jordipons.me/media/DL4Music_Pons.pdf" rel="nofollow"&gt;Slides on DL4M&lt;/a&gt; - A personal (re)view of the state-of-the-art by &lt;a href="http://www.jordipons.me/" rel="nofollow"&gt;Jordi Pons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marl/dl4mir-tutorial"&gt;DL4MIR tutorial&lt;/a&gt; - Python tutorials for learning to solve MIR tasks with DL&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/faroit/awesome-python-scientific-audio"&gt;Awesome Python Scientific Audio&lt;/a&gt; - Python resources for Audio and Machine Learning&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ismir.net/resources.php" rel="nofollow"&gt;ISMIR resources&lt;/a&gt; - Community maintained list&lt;/li&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/a/ismir.net/forum/#!forum/community" rel="nofollow"&gt;ISMIR Google group&lt;/a&gt; - Daily dose of general MIR&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/vinta/awesome-python#audio"&gt;Awesome Python&lt;/a&gt; - Audio section of Python resources&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/notthetup/awesome-webaudio"&gt;Awesome Web Audio&lt;/a&gt; - WebAudio packages and resources&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ciconia/awesome-music"&gt;Awesome Music&lt;/a&gt; - Music softwares&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/adius/awesome-music-production"&gt;Awesome Music Production&lt;/a&gt; - Music creation&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.asimovinstitute.org/analyzing-deep-learning-tools-music/" rel="nofollow"&gt;The Asimov Institute&lt;/a&gt; - 6 deep learning tools for music generation&lt;/li&gt;
&lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/icdlm" rel="nofollow"&gt;DLM Google group&lt;/a&gt; - Deep Learning in Music group&lt;/li&gt;
&lt;li&gt;&lt;a href="https://slackpass.io/mircommunity" rel="nofollow"&gt;MIR community on Slack&lt;/a&gt; - Link to subscribe to the MIR community's Slack&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.music.mcgill.ca/~cmckay/links_academic.html" rel="nofollow"&gt;Unclassified list of MIR-related links&lt;/a&gt; - &lt;a href="http://www.music.mcgill.ca/~cmckay/" rel="nofollow"&gt;Cory McKay&lt;/a&gt;'s list of various links on DL, MIR, ...&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jordipons.me/wiki/index.php/MIRDL" rel="nofollow"&gt;MIRDL&lt;/a&gt; - Unmaintained list of DL articles for MIR from &lt;a href="http://www.jordipons.me/" rel="nofollow"&gt;Jordi Pons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.crowdai.org/challenges/www-2018-challenge-learning-to-recognize-musical-genre" rel="nofollow"&gt;WWW 2018 Challenge&lt;/a&gt; - Learning to Recognize Musical Genre on the &lt;a href="https://github.com/mdeff/fma"&gt;FMA&lt;/a&gt; dataset&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/umbrellabeach/music-generation-with-DL"&gt;Music generation with DL&lt;/a&gt; - List of resources on music generation with deep learning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mitpress.mit.edu/books/auditory-scene-analysis" rel="nofollow"&gt;Auditory Scene Analysis&lt;/a&gt; - Book about the perceptual organization of sound by &lt;a href="https://en.wikipedia.org/wiki/Albert_Bregman" rel="nofollow"&gt;Albert Bregman&lt;/a&gt;, the "father of &lt;a href="https://en.wikipedia.org/wiki/Auditory_scene_analysis" rel="nofollow"&gt;Auditory Scene Analysis&lt;/a&gt;".
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://webpages.mcgill.ca/staff/Group2/abregm1/web/downloadstoc.htm" rel="nofollow"&gt;Demonstrations of Auditory Scene Analysis&lt;/a&gt; - Audio demonstrations, which illustrate examples of auditory perceptual organization.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-music-datasets" class="anchor" aria-hidden="true" href="#music-datasets"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Music datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.audiocontentanalysis.org/data-sets/" rel="nofollow"&gt;AudioContentAnalysis nearly exhaustive list of music-related datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://teachingmir.wikispaces.com/Datasets" rel="nofollow"&gt;Teaching MIR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#cite_ref-215" rel="nofollow"&gt;Wikipedia's list of datasets for machine learning research&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://deeplearning.net/datasets/" rel="nofollow"&gt;Datasets for deep learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/caesar0301/awesome-public-datasets"&gt;Awesome public datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ybayle/awesome-music-listening"&gt;Awesome music listening&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-deep-learning" class="anchor" aria-hidden="true" href="#deep-learning"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deep learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1711.03543" rel="nofollow"&gt;DLPaper2Code: Auto-generation of Code from Deep Learning Research Papers&lt;/a&gt; -&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ysh329/deep-learning-model-convertor"&gt;Model Convertors&lt;/a&gt; - Convertors for DL frameworks and backend&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hunkim/deep_architecture_genealogy"&gt;Deep architecture genealogy&lt;/a&gt; - Genealogy of DL architectures&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.univie.ac.at/nuhag-php/dateien/talks/3358_schlueter.pdf" rel="nofollow"&gt;Deep Learning as an Engineer&lt;/a&gt; - Slides from Jan Schlüter&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ChristosChristofidis/awesome-deep-learning"&gt;Awesome Deep Learning&lt;/a&gt; - General deep learning resources&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/endymecy/awesome-deeplearning-resources"&gt;Awesome Deep Learning Resources&lt;/a&gt; - Papers regarding deep learning and deep reinforcement learning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kjw0612/awesome-rnn"&gt;Awesome RNNs&lt;/a&gt; - RNNs code, theory and applications&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kailashahirwar/cheatsheets-ai"&gt;Cheatsheets AI&lt;/a&gt; - Cheat Sheets for Keras, neural networks, scikit-learn,...&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dennybritz/deeplearning-papernotes"&gt;DL PaperNotes&lt;/a&gt; - Summaries and notes on general deep learning research papers&lt;/li&gt;
&lt;li&gt;General &lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; lists&lt;/li&gt;
&lt;li&gt;&lt;a href="http://minds.jacobs-university.de/sites/default/files/uploads/papers/PracticalESN.pdf" rel="nofollow"&gt;Echo State Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ruder.io/deep-learning-nlp-best-practices/index.html#introduction" rel="nofollow"&gt;DL in NLP&lt;/a&gt; - Best practices for using neural networks by &lt;a href="http://ruder.io/" rel="nofollow"&gt;Sebastian Ruder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs231n.github.io/convolutional-networks/" rel="nofollow"&gt;CNN overview&lt;/a&gt; - Stanford Course&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1710.02224.pdf" rel="nofollow"&gt;Dilated Recurrent Neural Networks&lt;/a&gt; - How to improve RNNs?&lt;/li&gt;
&lt;li&gt;&lt;a href="https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/?utm_content=buffer0d2a7&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=bufferhttps://blog.recast.ai/ml-spotlight-rnn/?utm_content=bufferf19d3&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer" rel="nofollow"&gt;Encoder-Decoder in RNNs&lt;/a&gt; - How Does Attention Work in Encoder-Decoder Recurrent Neural Networks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/randal_olson/status/927157485240311808/photo/1" rel="nofollow"&gt;On the use of DL&lt;/a&gt; - Misc fun around DL&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/eriklindernoren/ML-From-Scratch"&gt;ML from scratch&lt;/a&gt; - Python implementations of ML models and algorithms from scratch from Data Mining to DL&lt;/li&gt;
&lt;li&gt;&lt;a href="https://project.inria.fr/deeplearning/files/2016/05/DLFrameworks.pdf" rel="nofollow"&gt;Comparison of DL frameworks&lt;/a&gt; - Presentation describing the different existing frameworks for DL&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1511.07289.pdf" rel="nofollow"&gt;ELU &amp;gt; ReLU&lt;/a&gt; - Article describing the differences between ELU and ReLU&lt;/li&gt;
&lt;li&gt;&lt;a href="http://incompleteideas.net/sutton/book/bookdraft2017nov5.pdf" rel="nofollow"&gt;Reinforcement Learning: An Introduction&lt;/a&gt; - Book about reinforcement learning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0" rel="nofollow"&gt;Estimating Optimal Learning Rate&lt;/a&gt; - Blog post on the learning rate optimisation&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/scikit-learn-contrib/imbalanced-learn"&gt;GitHub repo for sklearn add-on for imbalanced learning&lt;/a&gt; - ML in uneven datasets&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=YJnddoa8sHk" rel="nofollow"&gt;Video on DL from Nando de Freitas, Scott Reed and Oriol Vinyals&lt;/a&gt; - Deep Learning: Practice and Trends (NIPS 2017 Tutorial, parts I &amp;amp; II)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1711.10337" rel="nofollow"&gt;Article "Are GANs Created Equal? A Large-Scale Study"&lt;/a&gt; - Actually comparing DL algorithms&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750" rel="nofollow"&gt;Battle of the Deep Learning frameworks&lt;/a&gt; - DL frameworks comparison and evolution&lt;/li&gt;
&lt;li&gt;&lt;a href="http://timvieira.github.io/blog/post/2018/03/16/black-box-optimization/" rel="nofollow"&gt;Black-box optimization&lt;/a&gt; - There are other optimization algorithms than just gradient descent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-cited-by" class="anchor" aria-hidden="true" href="#cited-by"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cited by&lt;/h2&gt;
&lt;p&gt;If you use the information contained in this repository, please let us know! This repository is cited by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://twitter.com/Slychief/status/915218386421997568" rel="nofollow"&gt;Alexander Schindler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.audiolabs-erlangen.de/resources/MIR/2017-GI-Tutorial-Musik/2017_MuellerWeissBalke_GI_DeepLearningMIR.pdf" rel="nofollow"&gt;Meinard Müller, Christof Weiss, Stefan Balke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.crowdai.org/challenges/www-2018-challenge-learning-to-recognize-musical-genre" rel="nofollow"&gt;WWW 2018 Challenge: Learning to Recognize Musical Genre&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ChristosChristofidis/awesome-deep-learning"&gt;Awesome Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/AINewsFeed/status/897832912351105025" rel="nofollow"&gt;AINewsFeed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;You are free to copy, modify, and distribute &lt;em&gt;&lt;strong&gt;Deep Learning for Music (DL4M)&lt;/strong&gt;&lt;/em&gt; with attribution under the terms of the MIT license. See the LICENSE file for details.
This project use another projects and you may refer to them for appropriate license information :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ddbeck/readme-checklist"&gt;Readme checklist&lt;/a&gt; - To build an universal Readme.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.pylint.org/" rel="nofollow"&gt;Pylint&lt;/a&gt; - To clean the python code.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.numpy.org/" rel="nofollow"&gt;Numpy&lt;/a&gt; - To manage python structure.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://matplotlib.org/" rel="nofollow"&gt;Matplotlib&lt;/a&gt; - To plot nice figures.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sciunto-org/python-bibtexparser"&gt;Bibtexparser&lt;/a&gt; - To deal with the bib entries.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ybayle/awesome-deep-learning-music#deep-learning-for-music-dl4m-"&gt;Go back to top&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ybayle</author><guid isPermaLink="false">https://github.com/ybayle/awesome-deep-learning-music</guid><pubDate>Mon, 02 Dec 2019 00:17:00 GMT</pubDate></item></channel></rss>