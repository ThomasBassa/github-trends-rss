<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Lua, Today</title><link>https://github.com/trending/lua?since=daily</link><description>The top repositories on GitHub for lua, measured daily</description><pubDate>Mon, 03 Feb 2020 01:12:15 GMT</pubDate><lastBuildDate>Mon, 03 Feb 2020 01:12:15 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>neovim/nvim-lsp #1 in Lua, Today</title><link>https://github.com/neovim/nvim-lsp</link><description>&lt;p&gt;&lt;i&gt;Nvim LSP client configurations&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-nvim-lsp" class="anchor" aria-hidden="true" href="#nvim-lsp"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;nvim-lsp&lt;/h1&gt;
&lt;p&gt;Collection of common configurations for the &lt;a href="https://neovim.io/doc/user/lsp.html" rel="nofollow"&gt;Nvim LSP client&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is hoped that these configurations serve as a "source of truth", but they
are strictly &lt;em&gt;best effort&lt;/em&gt;. If something doesn't work, these configs are useful
as a starting point, which you can adjust to fit your environment.&lt;/p&gt;
&lt;p&gt;This is work-in-progress and &lt;strong&gt;requires &lt;a href="https://github.com/neovim/neovim/releases/tag/nightly"&gt;Nvim HEAD/nightly&lt;/a&gt;&lt;/strong&gt;.
Update Nvim and nvim-lsp before reporting an issue.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributions-are-welcome" class="anchor" aria-hidden="true" href="#contributions-are-welcome"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributions are welcome!&lt;/h2&gt;
&lt;p&gt;There are many language servers in the world, and not enough time.
Help us create configs for &lt;em&gt;all the LSPs!&lt;/em&gt;&lt;/p&gt;
&lt;ol start="0"&gt;
&lt;li&gt;Read &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions.
Ask questions in &lt;a href="https://gitter.im/neovim/neovim" rel="nofollow"&gt;Neovim Gitter&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Choose a language from &lt;a href="https://github.com/neoclide/coc.nvim/wiki/Language-servers"&gt;the coc.nvim wiki&lt;/a&gt; or
&lt;a href="https://github.com/emacs-lsp/lsp-mode#supported-languages"&gt;the emacs-lsp project&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Create a new file at &lt;code&gt;lua/nvim_lsp/SERVER_NAME.lua&lt;/code&gt;. See
&lt;a href="https://github.com/neovim/nvim-lsp/blob/master/lua/nvim_lsp/"&gt;existing configs&lt;/a&gt; for
examples (&lt;code&gt;lua/nvim_lsp/texlab.lua&lt;/code&gt; is an extensive example).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Requires &lt;a href="https://github.com/neovim/neovim/releases/tag/nightly"&gt;Nvim HEAD/nightly&lt;/a&gt; (v0.5 prerelease).&lt;/li&gt;
&lt;li&gt;nvim-lsp is just a plugin. Install it like any other Vim plugin.
&lt;pre&gt;&lt;code&gt;:Plug 'neovim/nvim-lsp'
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Call &lt;code&gt;:packadd nvim-lsp&lt;/code&gt; in your vimrc if you installed nvim-lsp to
&lt;code&gt;'packpath'&lt;/code&gt; or if you use a package manager such as minpac.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;Each config provides a &lt;code&gt;setup()&lt;/code&gt; function, to initialize the server with
reasonable defaults and some server-specific things like commands or different
diagnostics.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim.cmd('packadd nvim-lsp')
require'nvim_lsp'.&amp;lt;config&amp;gt;.setup{name=…, settings = {…}, …}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Find the &lt;a href="#configurations"&gt;config&lt;/a&gt; for your language, then paste the example
given there to your &lt;code&gt;init.vim&lt;/code&gt;. &lt;strong&gt;All examples are given in Lua,&lt;/strong&gt; see &lt;code&gt;:help :lua-heredoc&lt;/code&gt; to use Lua from your init.vim.&lt;/p&gt;
&lt;p&gt;Some configs may define additional server-specific functions, e.g. the &lt;code&gt;texlab&lt;/code&gt;
config provides &lt;code&gt;nvim_lsp.texlab.buf_build({bufnr})&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-example-using-the-defaults" class="anchor" aria-hidden="true" href="#example-using-the-defaults"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: using the defaults&lt;/h3&gt;
&lt;p&gt;To use the defaults, just call &lt;code&gt;setup()&lt;/code&gt; with an empty &lt;code&gt;config&lt;/code&gt; parameter.
For the &lt;code&gt;gopls&lt;/code&gt; config, that would be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim.cmd('packadd nvim-lsp')
require'nvim_lsp'.gopls.setup{}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-example-override-some-defaults" class="anchor" aria-hidden="true" href="#example-override-some-defaults"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: override some defaults&lt;/h3&gt;
&lt;p&gt;To set some config properties at &lt;code&gt;setup()&lt;/code&gt;, specify their keys. For example to
change how the "project root" is found, set the &lt;code&gt;root_dir&lt;/code&gt; key:&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; nvim_lsp &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;require&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;nvim_lsp&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
nvim_lsp.&lt;span class="pl-smi"&gt;gopls&lt;/span&gt;.&lt;span class="pl-c1"&gt;setup&lt;/span&gt;{
  root_dir &lt;span class="pl-k"&gt;=&lt;/span&gt; nvim_lsp.&lt;span class="pl-smi"&gt;util&lt;/span&gt;.&lt;span class="pl-c1"&gt;root_pattern&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;.git&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;);
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;a href="#configurations"&gt;documentation&lt;/a&gt; for each config lists default values and
additional optional properties.&lt;/p&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; nvim_lsp &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;require&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;nvim_lsp&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
nvim_lsp.&lt;span class="pl-smi"&gt;texlab&lt;/span&gt;.&lt;span class="pl-c1"&gt;setup&lt;/span&gt;{
  name &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;texlab_fancy&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;;
  log_level &lt;span class="pl-k"&gt;=&lt;/span&gt; vim.&lt;span class="pl-smi"&gt;lsp&lt;/span&gt;.&lt;span class="pl-smi"&gt;protocol&lt;/span&gt;.&lt;span class="pl-smi"&gt;MessageType&lt;/span&gt;.&lt;span class="pl-smi"&gt;Log&lt;/span&gt;;
  settings &lt;span class="pl-k"&gt;=&lt;/span&gt; {
    latex &lt;span class="pl-k"&gt;=&lt;/span&gt; {
      build &lt;span class="pl-k"&gt;=&lt;/span&gt; {
        onSave &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;true&lt;/span&gt;;
      }
    }
  }
}&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-example-custom-config" class="anchor" aria-hidden="true" href="#example-custom-config"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example: custom config&lt;/h3&gt;
&lt;p&gt;To configure a custom/private server, just require &lt;code&gt;nvim_lsp/configs&lt;/code&gt; and do
the same as we do if we were adding it to the repository itself.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define the config: &lt;code&gt;configs.foo_lsp = { … }&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Call &lt;code&gt;setup()&lt;/code&gt;: &lt;code&gt;require'nvim_lsp'.foo_lsp.setup{}&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight highlight-source-lua"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;local&lt;/span&gt; nvim_lsp &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;require&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;nvim_lsp&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-k"&gt;local&lt;/span&gt; configs &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;require&lt;/span&gt;&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;nvim_lsp/configs&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;--&lt;/span&gt; Check if it's already defined for when I reload this file.&lt;/span&gt;
&lt;span class="pl-k"&gt;if&lt;/span&gt; &lt;span class="pl-k"&gt;not&lt;/span&gt; nvim_lsp.&lt;span class="pl-smi"&gt;foo_lsp&lt;/span&gt; &lt;span class="pl-k"&gt;then&lt;/span&gt;
  configs.&lt;span class="pl-smi"&gt;foo_lsp&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
    default_config &lt;span class="pl-k"&gt;=&lt;/span&gt; {
      cmd &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;/home/ashkan/works/3rd/lua-language-server/run.sh&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;};
      filetypes &lt;span class="pl-k"&gt;=&lt;/span&gt; {&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;lua&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;};
      root_dir &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;function&lt;/span&gt;(&lt;span class="pl-smi"&gt;fname&lt;/span&gt;)
        &lt;span class="pl-k"&gt;return&lt;/span&gt; nvim_lsp.&lt;span class="pl-smi"&gt;util&lt;/span&gt;.&lt;span class="pl-c1"&gt;find_git_ancestor&lt;/span&gt;(fname) &lt;span class="pl-k"&gt;or&lt;/span&gt; vim.&lt;span class="pl-smi"&gt;loop&lt;/span&gt;.&lt;span class="pl-c1"&gt;os_homedir&lt;/span&gt;()
      &lt;span class="pl-k"&gt;end&lt;/span&gt;;
      log_level &lt;span class="pl-k"&gt;=&lt;/span&gt; vim.&lt;span class="pl-smi"&gt;lsp&lt;/span&gt;.&lt;span class="pl-smi"&gt;protocol&lt;/span&gt;.&lt;span class="pl-smi"&gt;MessageType&lt;/span&gt;.&lt;span class="pl-smi"&gt;Warning&lt;/span&gt;;
      settings &lt;span class="pl-k"&gt;=&lt;/span&gt; {};
    };
  }
&lt;span class="pl-k"&gt;end&lt;/span&gt;
nvim_lsp.&lt;span class="pl-smi"&gt;foo_lsp&lt;/span&gt;.&lt;span class="pl-c1"&gt;setup&lt;/span&gt;{}&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-installing-a-language-server" class="anchor" aria-hidden="true" href="#installing-a-language-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing a language server&lt;/h3&gt;
&lt;p&gt;Configs may provide an &lt;code&gt;install()&lt;/code&gt; function. Then you can use
&lt;code&gt;:LspInstall {name}&lt;/code&gt; to install the required language server.
For example, to install the Elm language server:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:LspInstall elmls
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use &lt;code&gt;:LspInstallInfo&lt;/code&gt; to see install info.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:LspInstallInfo
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-setup-function" class="anchor" aria-hidden="true" href="#setup-function"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;setup() function&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;setup()&lt;/code&gt; interface:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvim_lsp.SERVER.setup{config}

  The `config` parameter has the same shape as that of
  |vim.lsp.start_client()|, with these additions and changes:

  {root_dir}
    Required for some servers, optional for others.
    Function of the form `function(filename, bufnr)`.
    Called on new candidate buffers being attached-to.
    Returns either a root_dir or nil.

    If a root_dir is returned, then this file will also be attached. You
    can optionally use {filetype} to help pre-filter by filetype.

    If a root_dir is returned which is unique from any previously returned
    root_dir, a new server will be spawned with that root_dir.

    If nil is returned, the buffer is skipped.

    See |nvim_lsp.util.search_ancestors()| and the functions which use it:
    - |nvim_lsp.util.root_pattern(patterns...)| finds an ancestor which
    - contains one of the files in `patterns...`. This is equivalent
      to coc.nvim's "rootPatterns"
    - Related utilities for common tools:
      - |nvim_lsp.util.find_git_root()|
      - |nvim_lsp.util.find_node_modules_root()|
      - |nvim_lsp.util.find_package_json_root()|

  {name}
    Defaults to the server's name.

  {filetypes}
    Set of filetypes to filter for consideration by {root_dir}.
    May be empty.
    Server may specify a default value.

  {log_level}
    controls the level of logs to show from build processes and other
    window/logMessage events. Defaults to
    vim.lsp.protocol.MessageType.Warning instead of
    vim.lsp.protocol.MessageType.Log.

  {settings}
    Map with case-sensitive keys corresponding to `workspace/configuration`
    event responses.
    We also notify the server *once* on `initialize` with
    `workspace/didChangeConfiguration`.
    If you change the settings later on, you must emit the notification
    with `client.workspace_did_change_configuration({settings})`
    Example: `settings = { keyName = { subKey = 1 } }`

  {on_attach}
    `function(client)` executed with the current buffer as the one the {client}
    is being attached-to. This is different from
    |vim.lsp.start_client()|'s on_attach parameter, which passes the {bufnr} as
    the second parameter instead. Useful for doing buffer-local setup.

  {on_new_config}
    `function(new_config)` will be executed after a new configuration has been
    created as a result of {root_dir} returning a unique value. You can use this
    as an opportunity to further modify the new_config or use it before it is
    sent to |vim.lsp.start_client()|.
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-configurations" class="anchor" aria-hidden="true" href="#configurations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configurations&lt;/h1&gt;
&lt;p&gt;The following LSP configs are included. Follow a link to find documentation for
that config.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>neovim</author><guid isPermaLink="false">https://github.com/neovim/nvim-lsp</guid><pubDate>Mon, 03 Feb 2020 00:01:00 GMT</pubDate></item><item><title>openwrt/luci #2 in Lua, Today</title><link>https://github.com/openwrt/luci</link><description>&lt;p&gt;&lt;i&gt;LuCI - OpenWrt Configuration Interface&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-openwrt-luci-feed" class="anchor" aria-hidden="true" href="#openwrt-luci-feed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenWrt luci feed&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://hosted.weblate.org/engage/openwrt/?utm_source=widget" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/47d411daca21e7a3a1e812d4f30c9c5a41a23cb3/68747470733a2f2f686f737465642e7765626c6174652e6f72672f776964676574732f6f70656e7772742f2d2f7376672d62616467652e737667" alt="Translation status" data-canonical-src="https://hosted.weblate.org/widgets/openwrt/-/svg-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-description" class="anchor" aria-hidden="true" href="#description"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;This is the OpenWrt "luci"-feed containing LuCI - OpenWrt Configuration Interface.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;This feed is enabled by default. Your feeds.conf.default (or feeds.conf) should contain a line like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;src-git luci https://github.com/openwrt/luci.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To install all its package definitions, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./scripts/feeds update luci
./scripts/feeds install -a -p luci
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-api-reference" class="anchor" aria-hidden="true" href="#api-reference"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API Reference&lt;/h2&gt;
&lt;p&gt;You can browse the generated API documentation directly on Github.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://openwrt.github.io/luci/api/index.html" rel="nofollow"&gt;Server side Lua APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://openwrt.github.io/luci/jsapi/index.html" rel="nofollow"&gt;Client side JavaScript APIs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-development" class="anchor" aria-hidden="true" href="#development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development&lt;/h2&gt;
&lt;p&gt;Documentation for developing and extending LuCI can be found &lt;a href="https://github.com/openwrt/luci/wiki"&gt;in the Wiki&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;See &lt;a href="LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-package-guidelines" class="anchor" aria-hidden="true" href="#package-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Package Guidelines&lt;/h2&gt;
&lt;p&gt;See &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-translation-status" class="anchor" aria-hidden="true" href="#translation-status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Translation status&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://hosted.weblate.org/engage/openwrt/?utm_source=widget" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f855e22709cc0ccc6f6e012a71d57c0a9297838e/68747470733a2f2f686f737465642e7765626c6174652e6f72672f776964676574732f6f70656e7772742f2d2f6d756c74692d6175746f2e737667" alt="Translation status" data-canonical-src="https://hosted.weblate.org/widgets/openwrt/-/multi-auto.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>openwrt</author><guid isPermaLink="false">https://github.com/openwrt/luci</guid><pubDate>Mon, 03 Feb 2020 00:02:00 GMT</pubDate></item><item><title>karpathy/char-rnn #3 in Lua, Today</title><link>https://github.com/karpathy/char-rnn</link><description>&lt;p&gt;&lt;i&gt;Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="Readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-char-rnn" class="anchor" aria-hidden="true" href="#char-rnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;char-rnn&lt;/h1&gt;
&lt;p&gt;This code implements &lt;strong&gt;multi-layer Recurrent Neural Network&lt;/strong&gt; (RNN, LSTM, and GRU) for training/sampling from character-level language models. In other words the model takes one text file as input and trains a Recurrent Neural Network that learns to predict the next character in a sequence. The RNN can then be used to generate text character by character that will look like the original training data. The context of this code base is described in detail in my &lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="nofollow"&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are new to Torch/Lua/Neural Nets, it might be helpful to know that this code is really just a slightly more fancy version of this &lt;a href="https://gist.github.com/karpathy/d4dee566867f8291f086"&gt;100-line gist&lt;/a&gt; that I wrote in Python/numpy. The code in this repo additionally: allows for multiple layers, uses an LSTM instead of a vanilla RNN, has more supporting code for model checkpointing, and is of course much more efficient since it uses mini-batches and can run on a GPU.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-update-torch-rnn" class="anchor" aria-hidden="true" href="#update-torch-rnn"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Update: torch-rnn&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://cs.stanford.edu/people/jcjohns/" rel="nofollow"&gt;Justin Johnson&lt;/a&gt; (@jcjohnson) recently re-implemented char-rnn from scratch with a much nicer/smaller/cleaner/faster Torch code base. It's under the name &lt;a href="https://github.com/jcjohnson/torch-rnn"&gt;torch-rnn&lt;/a&gt;. It uses Adam for optimization and hard-codes the RNN/LSTM forward/backward passes for space/time efficiency. This also avoids headaches with cloning models in this repo. In other words, torch-rnn should be the default char-rnn implemention to use now instead of the one in this code base.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;p&gt;This code is written in Lua and requires &lt;a href="http://torch.ch/" rel="nofollow"&gt;Torch&lt;/a&gt;. If you're on Ubuntu, installing Torch in your home directory may look something like:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps &lt;span class="pl-k"&gt;|&lt;/span&gt; bash
$ git clone https://github.com/torch/distro.git &lt;span class="pl-k"&gt;~&lt;/span&gt;/torch --recursive
$ &lt;span class="pl-c1"&gt;cd&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/torch&lt;span class="pl-k"&gt;;&lt;/span&gt; 
$ ./install.sh      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; and enter "yes" at the end to modify your bashrc&lt;/span&gt;
$ &lt;span class="pl-c1"&gt;source&lt;/span&gt; &lt;span class="pl-k"&gt;~&lt;/span&gt;/.bashrc&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See the Torch installation documentation for more details. After Torch is installed we need to get a few more packages using &lt;a href="https://luarocks.org/" rel="nofollow"&gt;LuaRocks&lt;/a&gt; (which already came with the Torch install). In particular:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ luarocks install nngraph 
$ luarocks install optim
$ luarocks install nn&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you'd like to train on an NVIDIA GPU using CUDA (this can be to about 15x faster), you'll of course need the GPU, and you will have to install the &lt;a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow"&gt;CUDA Toolkit&lt;/a&gt;. Then get the &lt;code&gt;cutorch&lt;/code&gt; and &lt;code&gt;cunn&lt;/code&gt; packages:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ luarocks install cutorch
$ luarocks install cunn&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you'd like to use OpenCL GPU instead (e.g. ATI cards), you will instead need to install the &lt;code&gt;cltorch&lt;/code&gt; and &lt;code&gt;clnn&lt;/code&gt; packages, and then use the option &lt;code&gt;-opencl 1&lt;/code&gt; during training (&lt;a href="https://github.com/hughperkins/cltorch/issues"&gt;cltorch issues&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;$ luarocks install cltorch
$ luarocks install clnn&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-data" class="anchor" aria-hidden="true" href="#data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data&lt;/h3&gt;
&lt;p&gt;All input data is stored inside the &lt;code&gt;data/&lt;/code&gt; directory. You'll notice that there is an example dataset included in the repo (in folder &lt;code&gt;data/tinyshakespeare&lt;/code&gt;) which consists of a subset of works of Shakespeare. I'm providing a few more datasets on &lt;a href="http://cs.stanford.edu/people/karpathy/char-rnn/" rel="nofollow"&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Your own data&lt;/strong&gt;: If you'd like to use your own data then create a single file &lt;code&gt;input.txt&lt;/code&gt; and place it into a folder in the &lt;code&gt;data/&lt;/code&gt; directory. For example, &lt;code&gt;data/some_folder/input.txt&lt;/code&gt;. The first time you run the training script it will do some preprocessing and write two more convenience cache files into &lt;code&gt;data/some_folder&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dataset sizes&lt;/strong&gt;: Note that if your data is too small (1MB is already considered very small) the RNN won't learn very effectively. Remember that it has to learn everything completely from scratch. Conversely if your data is large (more than about 2MB), feel confident to increase &lt;code&gt;rnn_size&lt;/code&gt; and train a bigger model (see details of training below). It will work &lt;em&gt;significantly better&lt;/em&gt;. For example with 6MB you can easily go up to &lt;code&gt;rnn_size&lt;/code&gt; 300 or even more. The biggest that fits on my GPU and that I've trained with this code is &lt;code&gt;rnn_size&lt;/code&gt; 700 with &lt;code&gt;num_layers&lt;/code&gt; 3 (2 is default).&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-training" class="anchor" aria-hidden="true" href="#training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Training&lt;/h3&gt;
&lt;p&gt;Start training the model using &lt;code&gt;train.lua&lt;/code&gt;. As a sanity check, to run on the included example dataset simply try:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th train.lua -gpuid -1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that here we are setting the flag &lt;code&gt;gpuid&lt;/code&gt; to -1, which tells the code to train using CPU, otherwise it defaults to GPU 0.  There are many other flags for various options. Consult &lt;code&gt;$ th train.lua -help&lt;/code&gt; for comprehensive settings. Here's another example that trains a bigger network and also shows how you can run on your own custom dataset (this already assumes that &lt;code&gt;data/some_folder/input.txt&lt;/code&gt; exists):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th train.lua -data_dir data/some_folder -rnn_size 512 -num_layers 2 -dropout 0.5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Checkpoints.&lt;/strong&gt; While the model is training it will periodically write checkpoint files to the &lt;code&gt;cv&lt;/code&gt; folder. The frequency with which these checkpoints are written is controlled with number of iterations, as specified with the &lt;code&gt;eval_val_every&lt;/code&gt; option (e.g. if this is 1 then a checkpoint is written every iteration). The filename of these checkpoints contains a very important number: the &lt;strong&gt;loss&lt;/strong&gt;. For example, a checkpoint with filename &lt;code&gt;lm_lstm_epoch0.95_2.0681.t7&lt;/code&gt; indicates that at this point the model was on epoch 0.95 (i.e. it has almost done one full pass over the training data), and the loss on validation data was 2.0681. This number is very important because the lower it is, the better the checkpoint works. Once you start to generate data (discussed below), you will want to use the model checkpoint that reports the lowest validation loss. Notice that this might not necessarily be the last checkpoint at the end of training (due to possible overfitting).&lt;/p&gt;
&lt;p&gt;Another important quantities to be aware of are &lt;code&gt;batch_size&lt;/code&gt; (call it B), &lt;code&gt;seq_length&lt;/code&gt; (call it S), and the &lt;code&gt;train_frac&lt;/code&gt; and &lt;code&gt;val_frac&lt;/code&gt; settings. The batch size specifies how many streams of data are processed in parallel at one time. The sequence length specifies the length of each stream, which is also the limit at which the gradients can propagate backwards in time. For example, if &lt;code&gt;seq_length&lt;/code&gt; is 20, then the gradient signal will never backpropagate more than 20 time steps, and the model might not &lt;em&gt;find&lt;/em&gt; dependencies longer than this length in number of characters. Thus, if you have a very difficult dataset where there are a lot of long-term dependencies you will want to increase this setting. Now, if at runtime your input text file has N characters, these first all get split into chunks of size &lt;code&gt;BxS&lt;/code&gt;. These chunks then get allocated across three splits: train/val/test according to the &lt;code&gt;frac&lt;/code&gt; settings. By default &lt;code&gt;train_frac&lt;/code&gt; is 0.95 and &lt;code&gt;val_frac&lt;/code&gt; is 0.05, which means that 95% of our data chunks will be trained on and 5% of the chunks will be used to estimate the validation loss (and hence the generalization). If your data is small, it's possible that with the default settings you'll only have very few chunks in total (for example 100). This is bad: In these cases you may want to decrease batch size or sequence length.&lt;/p&gt;
&lt;p&gt;Note that you can also initialize parameters from a previously saved checkpoint using &lt;code&gt;init_from&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-sampling" class="anchor" aria-hidden="true" href="#sampling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sampling&lt;/h3&gt;
&lt;p&gt;Given a checkpoint file (such as those written to &lt;code&gt;cv&lt;/code&gt;) we can generate new text. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th sample.lua cv/some_checkpoint.t7 -gpuid -1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make sure that if your checkpoint was trained with GPU it is also sampled from with GPU, or vice versa. Otherwise the code will (currently) complain. As with the train script, see &lt;code&gt;$ th sample.lua -help&lt;/code&gt; for full options. One important one is (for example) &lt;code&gt;-length 10000&lt;/code&gt; which would generate 10,000 characters (default = 2000).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Temperature&lt;/strong&gt;. An important parameter you may want to play with is &lt;code&gt;-temperature&lt;/code&gt;, which takes a number in range (0, 1] (0 not included), default = 1. The temperature is dividing the predicted log probabilities before the Softmax, so lower temperature will cause the model to make more likely, but also more boring and conservative predictions. Higher temperatures cause the model to take more chances and increase diversity of results, but at a cost of more mistakes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Priming&lt;/strong&gt;. It's also possible to prime the model with some starting text using &lt;code&gt;-primetext&lt;/code&gt;. This starts out the RNN with some hardcoded characters to &lt;em&gt;warm&lt;/em&gt; it up with some context before it starts generating text. E.g. a fun primetext might be &lt;code&gt;-primetext "the meaning of life is "&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Training with GPU but sampling on CPU&lt;/strong&gt;. Right now the solution is to use the &lt;code&gt;convert_gpu_cpu_checkpoint.lua&lt;/code&gt; script to convert your GPU checkpoint to a CPU checkpoint. In near future you will not have to do this explicitly. E.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ th convert_gpu_cpu_checkpoint.lua cv/lm_lstm_epoch30.00_1.3950.t7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will create a new file &lt;code&gt;cv/lm_lstm_epoch30.00_1.3950.t7_cpu.t7&lt;/code&gt; that you can use with the sample script and with &lt;code&gt;-gpuid -1&lt;/code&gt; for CPU mode.&lt;/p&gt;
&lt;p&gt;Happy sampling!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tips-and-tricks" class="anchor" aria-hidden="true" href="#tips-and-tricks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tips and Tricks&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-monitoring-validation-loss-vs-training-loss" class="anchor" aria-hidden="true" href="#monitoring-validation-loss-vs-training-loss"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Monitoring Validation Loss vs. Training Loss&lt;/h3&gt;
&lt;p&gt;If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If your training loss is much lower than validation loss then this means the network might be &lt;strong&gt;overfitting&lt;/strong&gt;. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.&lt;/li&gt;
&lt;li&gt;If your training/validation loss are about equal then your model is &lt;strong&gt;underfitting&lt;/strong&gt;. Increase the size of your model (either number of layers or the raw number of neurons per layer)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-approximate-number-of-parameters" class="anchor" aria-hidden="true" href="#approximate-number-of-parameters"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Approximate number of parameters&lt;/h3&gt;
&lt;p&gt;The two most important parameters that control the model are &lt;code&gt;rnn_size&lt;/code&gt; and &lt;code&gt;num_layers&lt;/code&gt;. I would advise that you always use &lt;code&gt;num_layers&lt;/code&gt; of either 2/3. The &lt;code&gt;rnn_size&lt;/code&gt; can be adjusted based on how much data you have. The two important quantities to keep track of here are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The number of parameters in your model. This is printed when you start training.&lt;/li&gt;
&lt;li&gt;The size of your dataset. 1MB file is approximately 1 million characters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil &amp;gt;&amp;gt; 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make &lt;code&gt;rnn_size&lt;/code&gt; larger.&lt;/li&gt;
&lt;li&gt;I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that heps the validation loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-best-models-strategy" class="anchor" aria-hidden="true" href="#best-models-strategy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Best models strategy&lt;/h3&gt;
&lt;p&gt;The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.&lt;/p&gt;
&lt;p&gt;It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.&lt;/p&gt;
&lt;p&gt;By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-additional-pointers-and-acknowledgements" class="anchor" aria-hidden="true" href="#additional-pointers-and-acknowledgements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Additional Pointers and Acknowledgements&lt;/h2&gt;
&lt;p&gt;This code was originally based on Oxford University Machine Learning class &lt;a href="https://github.com/oxford-cs-ml-2015/practical6"&gt;practical 6&lt;/a&gt;, which is in turn based on &lt;a href="https://github.com/wojciechz/learning_to_execute"&gt;learning to execute&lt;/a&gt; code from Wojciech Zaremba. Chunks of it were also developed in collaboration with my labmate &lt;a href="http://cs.stanford.edu/people/jcjohns/" rel="nofollow"&gt;Justin Johnson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To learn more about RNN language models I recommend looking at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks" rel="nofollow"&gt;My recent talk&lt;/a&gt; on char-rnn&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1308.0850" rel="nofollow"&gt;Generating Sequences With Recurrent Neural Networks&lt;/a&gt; by Alex Graves&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf" rel="nofollow"&gt;Generating Text with Recurrent Neural Networks&lt;/a&gt; by Ilya Sutskever&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf" rel="nofollow"&gt;Tomas Mikolov's Thesis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;MIT&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>karpathy</author><guid isPermaLink="false">https://github.com/karpathy/char-rnn</guid><pubDate>Mon, 03 Feb 2020 00:03:00 GMT</pubDate></item><item><title>titan-lang/titan #4 in Lua, Today</title><link>https://github.com/titan-lang/titan</link><description>&lt;p&gt;&lt;i&gt;The Titan programming language&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-titan" class="anchor" aria-hidden="true" href="#titan"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Titan&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/titan-lang/titan" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/45abbbd78de0d9016fc8f751feb589880b2a5753/68747470733a2f2f7472617669732d63692e6f72672f746974616e2d6c616e672f746974616e2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/titan-lang/titan.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/titan-lang/titan/branch/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4e057c319df6797a63962b93ff2d98935ee26af1/68747470733a2f2f636f6465636f762e696f2f67682f746974616e2d6c616e672f746974616e2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://codecov.io/gh/titan-lang/titan/coverage.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Titan is a new programming language, designed to be a statically-typed,
ahead-of-time compiled sister language to &lt;a href="http://www.lua.org" rel="nofollow"&gt;Lua&lt;/a&gt;. It is an
application programming language with a focus on performance.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-install" class="anchor" aria-hidden="true" href="#install"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install&lt;/h1&gt;
&lt;p&gt;First you need to download, extract and build the &lt;a href="http://www.lua.org/ftp/lua-5.3.5.tar.gz" rel="nofollow"&gt;sources to Lua 5.3.5&lt;/a&gt;
inside the folder where you cloned this repository. The Lua tarball will extract
to a &lt;code&gt;lua-5.3.5&lt;/code&gt; folder. Enter it and build Lua with &lt;code&gt;make linux MYCFLAGS=-fPIC&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can install the Titan compiler itself using  &lt;a href="http://luarocks.org" rel="nofollow"&gt;LuaRocks&lt;/a&gt;
this will also install all dependencies automatically.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    $ [install luarocks]
    $ luarocks make titan-scm-1.rockspec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To install without &lt;code&gt;sudo&lt;/code&gt; permissions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    $ [cd into titan folder]
    $ luarocks build --local
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also run the Titan compiler directly from the folder where you
cloned this repository if you install all the dependencies for the compiler.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-requirements-for-running-the-compiler" class="anchor" aria-hidden="true" href="#requirements-for-running-the-compiler"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements for running the compiler&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/sqmedeiros/lpeglabel"&gt;LPegLabel&lt;/a&gt; &amp;gt;= 1.5.0&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kikito/inspect.lua"&gt;inspect&lt;/a&gt; &amp;gt;= 3.1.0&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mpeterv/argparse"&gt;argparse&lt;/a&gt; &amp;gt;= 0.5.0&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/keplerproject/luafilesystem"&gt;luafilesystem&lt;/a&gt; &amp;gt;= 1.7.0&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;    $ titanc [--print-ast] [--lua &amp;lt;path&amp;gt;] [--tree &amp;lt;path&amp;gt;] &amp;lt;module&amp;gt; [&amp;lt;module&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The compiler takes a list of module names that you want to compile. Modules
are looked up in the source tree (defaults to the current working directory,
but you can override this with the &lt;code&gt;--tree&lt;/code&gt; option), as well as in the Titan
binary path, a semicolon-separated list of paths
(defaults to &lt;code&gt;.;/usr/local/lib/titan/0.5&lt;/code&gt;, you can override with a &lt;code&gt;TITAN_PATH_0_5&lt;/code&gt;
or &lt;code&gt;TITAN_PATH&lt;/code&gt; environment variable).&lt;/p&gt;
&lt;p&gt;If everything is all right with your modules, you will get the result of
your compilation as a native binary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if one of your Titan modules has a &lt;code&gt;main&lt;/code&gt; function, with signature
&lt;code&gt;function({string}):integer&lt;/code&gt;, then &lt;code&gt;titanc&lt;/code&gt; will bundle all modules
given in the command-line, along with all their dependencies where
source code was available, as a stand-alone executable program.&lt;/li&gt;
&lt;li&gt;Otherwise, it will compile each module into a shared library
(in the same path as the module source) that you can &lt;code&gt;import&lt;/code&gt; from
Titan as well as &lt;code&gt;require&lt;/code&gt; from Lua, and call any exported
functions/access exported variables. For each generated module, any
of its transitive imports is statically linked if source code was
found; dependencies that were only available as a shared library
will be dynamically loaded.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-running-the-test-suite" class="anchor" aria-hidden="true" href="#running-the-test-suite"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running the test suite&lt;/h1&gt;
&lt;p&gt;The test suite es written using Busted, which can be installed using LuaRocks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    $ luarocks install busted
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, you need to bulid the local copy of Lua, and run &lt;code&gt;busted&lt;/code&gt; from the root directory
of this repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    $ cd lua
    $ make linux
    $ cd ..
    $ busted
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may need to adapt the invocation of &lt;code&gt;make&lt;/code&gt; above to your platform.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-compiler-options" class="anchor" aria-hidden="true" href="#compiler-options"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compiler options&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;    --print-ast                     Print the AST.
    --lua &amp;lt;path&amp;gt;                    Path to the Lua sources (default 'lua-5.3.5/src')
    --tree &amp;lt;path&amp;gt;                   Path to the source tree for your Titan modules (default '.')
    -h, --help                      Show this help message and exit.
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-tentative-roadmap" class="anchor" aria-hidden="true" href="#tentative-roadmap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tentative roadmap&lt;/h1&gt;
&lt;p&gt;This is a &lt;em&gt;very&lt;/em&gt; preliminary roadmap towards Titan 1.0, where everything is
subject to change, with things more likely to change the further
they are in the roadmap:&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-supported" class="anchor" aria-hidden="true" href="#supported"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;control structures&lt;/li&gt;
&lt;li&gt;integers&lt;/li&gt;
&lt;li&gt;floats&lt;/li&gt;
&lt;li&gt;booleans&lt;/li&gt;
&lt;li&gt;strings&lt;/li&gt;
&lt;li&gt;arrays&lt;/li&gt;
&lt;li&gt;top-level functions&lt;/li&gt;
&lt;li&gt;early-bound modules&lt;/li&gt;
&lt;li&gt;multiple assignment/multiple returns&lt;/li&gt;
&lt;li&gt;FFI with C (C pointers, call C functions)&lt;/li&gt;
&lt;li&gt;records (structs) with methods&lt;/li&gt;
&lt;li&gt;maps&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-in-progress" class="anchor" aria-hidden="true" href="#in-progress"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;In progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;first-class functions (still only in the top-level)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-next" class="anchor" aria-hidden="true" href="#next"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;FFI with C, continued (C arrays, C structs)&lt;/li&gt;
&lt;li&gt;standard library that is a subset of Lua's standard library, built using the C FFI&lt;/li&gt;
&lt;li&gt;tagged variants (unions of structs with some syntax for switch/case on the tag)&lt;/li&gt;
&lt;li&gt;polymorphic functions&lt;/li&gt;
&lt;li&gt;for-in&lt;/li&gt;
&lt;li&gt;self-hosted compiler&lt;/li&gt;
&lt;li&gt;nested and anonymous first-class functions with proper lexical scoping (closures)&lt;/li&gt;
&lt;li&gt;":" syntax sugar for records of functions&lt;/li&gt;
&lt;li&gt;classes with single inheritance, either Go/Java/C#/Swift-like interfaces/protocols or Haskell/Rust-like typeclasses/traits&lt;/li&gt;
&lt;li&gt;":" method calls (not syntax sugar)&lt;/li&gt;
&lt;li&gt;operator overloading&lt;/li&gt;
&lt;li&gt;...Titan 1.0!&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>titan-lang</author><guid isPermaLink="false">https://github.com/titan-lang/titan</guid><pubDate>Mon, 03 Feb 2020 00:04:00 GMT</pubDate></item><item><title>jcjohnson/neural-style #5 in Lua, Today</title><link>https://github.com/jcjohnson/neural-style</link><description>&lt;p&gt;&lt;i&gt;Torch implementation of neural style algorithm&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-neural-style" class="anchor" aria-hidden="true" href="#neural-style"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;neural-style&lt;/h1&gt;
&lt;p&gt;This is a torch implementation of the paper &lt;a href="http://arxiv.org/abs/1508.06576" rel="nofollow"&gt;A Neural Algorithm of Artistic Style&lt;/a&gt;
by Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge.&lt;/p&gt;
&lt;p&gt;The paper presents an algorithm for combining the content of one image with the style of another image using
convolutional neural networks. Here's an example that maps the artistic style of
&lt;a href="https://en.wikipedia.org/wiki/The_Starry_Night" rel="nofollow"&gt;The Starry Night&lt;/a&gt;
onto a night-time photograph of the Stanford campus:&lt;/p&gt;
&lt;div align="center"&gt;
 &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_google.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_google.jpg" height="223px" style="max-width:100%;"&gt;&lt;/a&gt;
 &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/hoovertowernight.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/hoovertowernight.jpg" height="223px" style="max-width:100%;"&gt;&lt;/a&gt;
 &lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png" width="710px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Applying the style of different images to the same content image gives interesting results.
Here we reproduce Figure 2 from the paper, which renders a photograph of the Tubingen in Germany in a
variety of styles:&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/tubingen.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/tubingen.jpg" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_shipwreck.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_shipwreck.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Here are the results of applying the style of various pieces of artwork to this photograph of the
golden gate bridge:&lt;/p&gt;
&lt;div align="center" height="200px"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/frida_kahlo.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/frida_kahlo.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_kahlo.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_kahlo.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/escher_sphere.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/escher_sphere.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_escher.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_escher.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/woman-with-hat-matisse.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/woman-with-hat-matisse.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_matisse.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_matisse.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/the_scream.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/the_scream.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_scream.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_crop.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/starry_night_crop.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/seated-nude.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/seated-nude.jpg" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_seated.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_seated.png" height="160px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-content--style-tradeoff" class="anchor" aria-hidden="true" href="#content--style-tradeoff"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content / Style Tradeoff&lt;/h3&gt;
&lt;p&gt;The algorithm allows the user to trade-off the relative weight of the style and content reconstruction terms,
as shown in this example where we port the style of &lt;a href="http://www.wikiart.org/en/pablo-picasso/self-portrait-1907" rel="nofollow"&gt;Picasso's 1907 self-portrait&lt;/a&gt; onto Brad Pitt:&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/picasso_selfport1907.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/picasso_selfport1907.jpg" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/brad_pitt.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/inputs/brad_pitt.jpg" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_5_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_5_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_1_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_1_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_01_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_01_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_0025_style_10.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/pitt_picasso_content_0025_style_10.png" height="220px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-style-scale" class="anchor" aria-hidden="true" href="#style-scale"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Style Scale&lt;/h3&gt;
&lt;p&gt;By resizing the style image before extracting style features, we can control the types of artistic
features that are transfered from the style image; you can control this behavior with the &lt;code&gt;-style_scale&lt;/code&gt; flag.
Below we see three examples of rendering the Golden Gate Bridge in the style of The Starry Night.
From left to right, &lt;code&gt;-style_scale&lt;/code&gt; is 2.0, 1.0, and 0.5.&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale2.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale2.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale1.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale1.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale05.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scale05.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-multiple-style-images" class="anchor" aria-hidden="true" href="#multiple-style-images"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multiple Style Images&lt;/h3&gt;
&lt;p&gt;You can use more than one style image to blend multiple artistic styles.&lt;/p&gt;
&lt;p&gt;Clockwise from upper left: "The Starry Night" + "The Scream", "The Scream" + "Composition VII",
"Seated Nude" + "Composition VII", and "Seated Nude" + "The Starry Night"&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_scream.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream_composition_vii.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_seated.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry_seated.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_seated_nude_composition_vii.png" height="250px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-style-interpolation" class="anchor" aria-hidden="true" href="#style-interpolation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Style Interpolation&lt;/h3&gt;
&lt;p&gt;When using multiple style images, you can control the degree to which they are blended:&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_3_7.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_3_7.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_5_5.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_5_5.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_7_3.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/golden_gate_starry_scream_7_3.png" height="175px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-transfer-style-but-not-color" class="anchor" aria-hidden="true" href="#transfer-style-but-not-color"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transfer style but not color&lt;/h3&gt;
&lt;p&gt;If you add the flag &lt;code&gt;-original_colors 1&lt;/code&gt; then the output image will retain the colors of the original image;
this is similar to &lt;a href="http://blog.deepart.io/2016/06/04/color-independent-style-transfer/" rel="nofollow"&gt;the recent blog post by deepart.io&lt;/a&gt;.&lt;/p&gt;
&lt;div align="center"&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_starry.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_scream.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/tubingen_composition_vii.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_starry.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_starry.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_scream.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_scream.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_composition_vii.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/original_color/tubingen_composition_vii.png" height="185px" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-setup" class="anchor" aria-hidden="true" href="#setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup:&lt;/h2&gt;
&lt;p&gt;Dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/torch7"&gt;torch7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/szagoruyko/loadcaffe"&gt;loadcaffe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Optional dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For CUDA backend:
&lt;ul&gt;
&lt;li&gt;CUDA 6.5+&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/torch/cunn"&gt;cunn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For cuDNN backend:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/soumith/cudnn.torch"&gt;cudnn.torch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For OpenCL backend:
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/hughperkins/cltorch"&gt;cltorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hughperkins/clnn"&gt;clnn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After installing dependencies, you'll need to run the following script to download the VGG model:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sh models/download_models.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will download the original &lt;a href="https://gist.github.com/ksimonyan/3785162f95cd2d5fee77#file-readme-md"&gt;VGG-19 model&lt;/a&gt;.
Leon Gatys has graciously provided the modified version of the VGG-19 model that was used in their paper;
this will also be downloaded. By default the original VGG-19 model is used.&lt;/p&gt;
&lt;p&gt;If you have a smaller memory GPU then using NIN Imagenet model will be better and gives slightly worse yet comparable results. You can get the details on the model from &lt;a href="https://github.com/BVLC/caffe/wiki/Model-Zoo"&gt;BVLC Caffe ModelZoo&lt;/a&gt; and can download the files from &lt;a href="https://drive.google.com/folderview?id=0B0IedYUunOQINEFtUi1QNWVhVVU&amp;amp;usp=drive_web" rel="nofollow"&gt;NIN-Imagenet Download Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can find detailed installation instructions for Ubuntu in the &lt;a href="INSTALL.md"&gt;installation guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h2&gt;
&lt;p&gt;Basic usage:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;th neural_style.lua -style_image &amp;lt;image.jpg&amp;gt; -content_image &amp;lt;image.jpg&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OpenCL usage with NIN Model (This requires you download the NIN Imagenet model files as described above):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;th neural_style.lua -style_image examples/inputs/picasso_selfport1907.jpg -content_image examples/inputs/brad_pitt.jpg -output_image profile.png -model_file models/nin_imagenet_conv.caffemodel -proto_file models/train_val.prototxt -gpu 0 -backend clnn -num_iterations 1000 -seed 123 -content_layers relu0,relu3,relu7,relu12 -style_layers relu0,relu3,relu7,relu12 -content_weight 10 -style_weight 1000 -image_size 512 -optimizer adam
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/examples/outputs/pitt_picasso_nin_opencl.png"&gt;&lt;img src="/examples/outputs/pitt_picasso_nin_opencl.png" alt="OpenCL NIN Model Picasso Brad Pitt" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To use multiple style images, pass a comma-separated list like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-style_image starry_night.jpg,the_scream.jpg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note that paths to images should not contain the &lt;code&gt;~&lt;/code&gt; character to represent your home directory; you should instead use a relative
path or a full absolute path.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-image_size&lt;/code&gt;: Maximum side length (in pixels) of of the generated image. Default is 512.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-style_blend_weights&lt;/code&gt;: The weight for blending the style of multiple style images, as a
comma-separated list, such as &lt;code&gt;-style_blend_weights 3,7&lt;/code&gt;. By default all style images
are equally weighted.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-gpu&lt;/code&gt;: Zero-indexed ID of the GPU to use; for CPU mode set &lt;code&gt;-gpu&lt;/code&gt; to -1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Optimization options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-content_weight&lt;/code&gt;: How much to weight the content reconstruction term. Default is 5e0.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-style_weight&lt;/code&gt;: How much to weight the style reconstruction term. Default is 1e2.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-tv_weight&lt;/code&gt;: Weight of total-variation (TV) regularization; this helps to smooth the image.
Default is 1e-3. Set to 0 to disable TV regularization.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-num_iterations&lt;/code&gt;: Default is 1000.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-init&lt;/code&gt;: Method for generating the generated image; one of &lt;code&gt;random&lt;/code&gt; or &lt;code&gt;image&lt;/code&gt;.
Default is &lt;code&gt;random&lt;/code&gt; which uses a noise initialization as in the paper; &lt;code&gt;image&lt;/code&gt;
initializes with the content image.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-optimizer&lt;/code&gt;: The optimization algorithm to use; either &lt;code&gt;lbfgs&lt;/code&gt; or &lt;code&gt;adam&lt;/code&gt;; default is &lt;code&gt;lbfgs&lt;/code&gt;.
L-BFGS tends to give better results, but uses more memory. Switching to ADAM will reduce memory usage;
when using ADAM you will probably need to play with other parameters to get good results, especially
the style weight, content weight, and learning rate; you may also want to normalize gradients when
using ADAM.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-learning_rate&lt;/code&gt;: Learning rate to use with the ADAM optimizer. Default is 1e1.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-normalize_gradients&lt;/code&gt;: If this flag is present, style and content gradients from each layer will be
L1 normalized. Idea from &lt;a href="https://github.com/andersbll/neural_artistic_style"&gt;andersbll/neural_artistic_style&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Output options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-output_image&lt;/code&gt;: Name of the output image. Default is &lt;code&gt;out.png&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-print_iter&lt;/code&gt;: Print progress every &lt;code&gt;print_iter&lt;/code&gt; iterations. Set to 0 to disable printing.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-save_iter&lt;/code&gt;: Save the image every &lt;code&gt;save_iter&lt;/code&gt; iterations. Set to 0 to disable saving intermediate results.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Layer options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-content_layers&lt;/code&gt;: Comma-separated list of layer names to use for content reconstruction.
Default is &lt;code&gt;relu4_2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-style_layers&lt;/code&gt;: Comma-separated list of layer names to use for style reconstruction.
Default is &lt;code&gt;relu1_1,relu2_1,relu3_1,relu4_1,relu5_1&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Other options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-style_scale&lt;/code&gt;: Scale at which to extract features from the style image. Default is 1.0.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-original_colors&lt;/code&gt;: If you set this to 1, then the output image will keep the colors of the content image.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-proto_file&lt;/code&gt;: Path to the &lt;code&gt;deploy.txt&lt;/code&gt; file for the VGG Caffe model.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-model_file&lt;/code&gt;: Path to the &lt;code&gt;.caffemodel&lt;/code&gt; file for the VGG Caffe model.
Default is the original VGG-19 model; you can also try the normalized VGG-19 model used in the paper.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pooling&lt;/code&gt;: The type of pooling layers to use; one of &lt;code&gt;max&lt;/code&gt; or &lt;code&gt;avg&lt;/code&gt;. Default is &lt;code&gt;max&lt;/code&gt;.
The VGG-19 models uses max pooling layers, but the paper mentions that replacing these layers with average
pooling layers can improve the results. I haven't been able to get good results using average pooling, but
the option is here.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend&lt;/code&gt;: &lt;code&gt;nn&lt;/code&gt;, &lt;code&gt;cudnn&lt;/code&gt;, or &lt;code&gt;clnn&lt;/code&gt;. Default is &lt;code&gt;nn&lt;/code&gt;. &lt;code&gt;cudnn&lt;/code&gt; requires
&lt;a href="https://github.com/soumith/cudnn.torch"&gt;cudnn.torch&lt;/a&gt; and may reduce memory usage.
&lt;code&gt;clnn&lt;/code&gt; requires &lt;a href="https://github.com/hughperkins/cltorch"&gt;cltorch&lt;/a&gt; and &lt;a href="https://github.com/hughperkins/clnn"&gt;clnn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-cudnn_autotune&lt;/code&gt;: When using the cuDNN backend, pass this flag to use the built-in cuDNN autotuner to select
the best convolution algorithms for your architecture. This will make the first iteration a bit slower and can
take a bit more memory, but may significantly speed up the cuDNN backend.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-frequently-asked-questions" class="anchor" aria-hidden="true" href="#frequently-asked-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Frequently Asked Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Generated image has saturation artifacts:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/1310570/9694690/fa8e8782-5328-11e5-9c91-11f7b215ad19.png"&gt;&lt;img src="https://cloud.githubusercontent.com/assets/1310570/9694690/fa8e8782-5328-11e5-9c91-11f7b215ad19.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Update the &lt;code&gt;image&lt;/code&gt; packge to the latest version: &lt;code&gt;luarocks install image&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Running without a GPU gives an error message complaining about &lt;code&gt;cutorch&lt;/code&gt; not found&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;
Pass the flag &lt;code&gt;-gpu -1&lt;/code&gt; when running in CPU-only mode&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; The program runs out of memory and dies&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Try reducing the image size: &lt;code&gt;-image_size 256&lt;/code&gt; (or lower). Note that different image sizes will likely
require non-default values for &lt;code&gt;-style_weight&lt;/code&gt; and &lt;code&gt;-content_weight&lt;/code&gt; for optimal results.
If you are running on a GPU, you can also try running with &lt;code&gt;-backend cudnn&lt;/code&gt; to reduce memory usage.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Get the following error message:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;models/VGG_ILSVRC_19_layers_deploy.prototxt.cpu.lua:7: attempt to call method 'ceil' (a nil value)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Update &lt;code&gt;nn&lt;/code&gt; package to the latest version: &lt;code&gt;luarocks install nn&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Get an error message complaining about &lt;code&gt;paths.extname&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Update &lt;code&gt;torch.paths&lt;/code&gt; package to the latest version: &lt;code&gt;luarocks install paths&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; NIN Imagenet model is not giving good results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Make sure the correct &lt;code&gt;-proto_file&lt;/code&gt; is selected. Also make sure the correct parameters for &lt;code&gt;-content_layers&lt;/code&gt; and &lt;code&gt;-style_layers&lt;/code&gt; are set. (See OpenCL usage example above.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; &lt;code&gt;-backend cudnn&lt;/code&gt; is slower than default NN backend&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Add the flag &lt;code&gt;-cudnn_autotune&lt;/code&gt;; this will use the built-in cuDNN autotuner to select the best convolution algorithms.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-memory-usage" class="anchor" aria-hidden="true" href="#memory-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Memory Usage&lt;/h2&gt;
&lt;p&gt;By default, &lt;code&gt;neural-style&lt;/code&gt; uses the &lt;code&gt;nn&lt;/code&gt; backend for convolutions and L-BFGS for optimization.
These give good results, but can both use a lot of memory. You can reduce memory usage with the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use cuDNN&lt;/strong&gt;: Add the flag &lt;code&gt;-backend cudnn&lt;/code&gt; to use the cuDNN backend. This will only work in GPU mode.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use ADAM&lt;/strong&gt;: Add the flag &lt;code&gt;-optimizer adam&lt;/code&gt; to use ADAM instead of L-BFGS. This should significantly
reduce memory usage, but may require tuning of other parameters for good results; in particular you should
play with the learning rate, content weight, style weight, and also consider using gradient normalization.
This should work in both CPU and GPU modes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduce image size&lt;/strong&gt;: If the above tricks are not enough, you can reduce the size of the generated image;
pass the flag &lt;code&gt;-image_size 256&lt;/code&gt; to generate an image at half the default size.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the default settings, &lt;code&gt;neural-style&lt;/code&gt; uses about 3.5GB of GPU memory on my system;
switching to ADAM and cuDNN reduces the GPU memory footprint to about 1GB.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-speed" class="anchor" aria-hidden="true" href="#speed"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Speed&lt;/h2&gt;
&lt;p&gt;Speed can vary a lot depending on the backend and the optimizer.
Here are some times for running 500 iterations with &lt;code&gt;-image_size=512&lt;/code&gt; on a Maxwell Titan X with different settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer lbfgs&lt;/code&gt;: 62 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer adam&lt;/code&gt;: 49 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -optimizer lbfgs&lt;/code&gt;: 79 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer lbfgs&lt;/code&gt;: 58 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer adam&lt;/code&gt;: 44 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend clnn -optimizer lbfgs&lt;/code&gt;: 169 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend clnn -optimizer adam&lt;/code&gt;: 106 seconds&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are the same benchmarks on a Pascal Titan X with cuDNN 5.0 on CUDA 8.0 RC:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer lbfgs&lt;/code&gt;: 43 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend nn -optimizer adam&lt;/code&gt;: 36 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -optimizer lbfgs&lt;/code&gt;: 45 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer lbfgs&lt;/code&gt;: 30 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-backend cudnn -cudnn_autotune -optimizer adam&lt;/code&gt;: 22 seconds&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-multi-gpu-scaling" class="anchor" aria-hidden="true" href="#multi-gpu-scaling"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Multi-GPU scaling&lt;/h2&gt;
&lt;p&gt;You can use multiple GPUs to process images at higher resolutions; different layers of the network will be
computed on different GPUs. You can control which GPUs are used with the &lt;code&gt;-gpu&lt;/code&gt; flag, and you can control
how to split layers across GPUs using the &lt;code&gt;-multigpu_strategy&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;For example in a server with four GPUs, you can give the flag &lt;code&gt;-gpu 0,1,2,3&lt;/code&gt; to process on GPUs 0, 1, 2, and
3 in that order; by also giving the flag &lt;code&gt;-multigpu_strategy 3,6,12&lt;/code&gt; you indicate that the first two layers
should be computed on GPU 0, layers 3 to 5 should be computed on GPU 1, layers 6 to 11 should be computed on
GPU 2, and the remaining layers should be computed on GPU 3. You will need to tune the &lt;code&gt;-multigpu_strategy&lt;/code&gt;
for your setup in order to achieve maximal resolution.&lt;/p&gt;
&lt;p&gt;We can achieve very high quality results at high resolution by combining multi-GPU processing with multiscale
generation as described in the paper
&lt;a href="https://arxiv.org/abs/1611.07865" rel="nofollow"&gt;&lt;strong&gt;Controlling Perceptual Factors in Neural Style Transfer&lt;/strong&gt;&lt;/a&gt; by Leon A. Gatys,
Alexander S. Ecker, Matthias Bethge, Aaron Hertzmann and Eli Shechtman.&lt;/p&gt;
&lt;p&gt;Here is a 3620 x 1905 image generated on a server with four Pascal Titan X GPUs:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png"&gt;&lt;img src="https://raw.githubusercontent.com/jcjohnson/neural-style/master/examples/outputs/starry_stanford_bigger.png" height="400px" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The script used to generate this image &lt;a href="examples/multigpu_scripts/starry_stanford.sh"&gt;can be found here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-implementation-details" class="anchor" aria-hidden="true" href="#implementation-details"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Implementation details&lt;/h2&gt;
&lt;p&gt;Images are initialized with white noise and optimized using L-BFGS.&lt;/p&gt;
&lt;p&gt;We perform style reconstructions using the &lt;code&gt;conv1_1&lt;/code&gt;, &lt;code&gt;conv2_1&lt;/code&gt;, &lt;code&gt;conv3_1&lt;/code&gt;, &lt;code&gt;conv4_1&lt;/code&gt;, and &lt;code&gt;conv5_1&lt;/code&gt; layers
and content reconstructions using the &lt;code&gt;conv4_2&lt;/code&gt; layer. As in the paper, the five style reconstruction losses have
equal weights.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this code useful for your research, please cite:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{Johnson2015,
  author = {Johnson, Justin},
  title = {neural-style},
  year = {2015},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jcjohnson/neural-style}},
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>jcjohnson</author><guid isPermaLink="false">https://github.com/jcjohnson/neural-style</guid><pubDate>Mon, 03 Feb 2020 00:05:00 GMT</pubDate></item><item><title>awesomeWM/awesome #6 in Lua, Today</title><link>https://github.com/awesomeWM/awesome</link><description>&lt;p&gt;&lt;i&gt;awesome window manager&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-readme" class="anchor" aria-hidden="true" href="#readme"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Readme&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-about-awesome" class="anchor" aria-hidden="true" href="#about-awesome"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;About Awesome&lt;/h2&gt;
&lt;p&gt;Awesome is a highly configurable, next generation framework window manager for X.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-building-and-installation" class="anchor" aria-hidden="true" href="#building-and-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building and installation&lt;/h2&gt;
&lt;p&gt;After extracting the dist tarball, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create a build directory, run &lt;code&gt;cmake&lt;/code&gt; in it and build Awesome.&lt;/p&gt;
&lt;p&gt;After building is finished, you can either install via &lt;code&gt;make install&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make install  # you might need root permissions
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or by auto-generating a .deb or .rpm package, for easy removal later on:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make package

sudo dpkg -i awesome-x.y.z.deb
# or
sudo rpm -Uvh awesome-x.y.z.rpm
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: Awesome uses &lt;a href="https://cmake.org" rel="nofollow"&gt;&lt;code&gt;cmake&lt;/code&gt;&lt;/a&gt; to build. In case you want to
pass arguments to &lt;code&gt;cmake&lt;/code&gt;, please use the &lt;code&gt;CMAKE_ARGS&lt;/code&gt; environment variable. For
instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CMAKE_ARGS="-DCMAKE_INSTALL_PREFIX=/opt/awesome" make
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-installing-current-git-master-as-a-package-receipts" class="anchor" aria-hidden="true" href="#installing-current-git-master-as-a-package-receipts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing current git master as a package receipts&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-arch-linux-aur" class="anchor" aria-hidden="true" href="#arch-linux-aur"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Arch Linux AUR&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S --needed base-devel git
git clone https://aur.archlinux.org/awesome-git.git
cd awesome-git
makepkg -fsri
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-debian-based" class="anchor" aria-hidden="true" href="#debian-based"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Debian-based&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;sudo apt build-dep awesome
git clone https://github.com/awesomewm/awesome
cd awesome
make package
sudo apt install *.deb
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-build-dependencies" class="anchor" aria-hidden="true" href="#build-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build dependencies&lt;/h3&gt;
&lt;p&gt;Awesome has the following dependencies (besides a more-or-less standard POSIX
environment):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cmake.org" rel="nofollow"&gt;CMake &amp;gt;= 3.0.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lua.org" rel="nofollow"&gt;Lua &amp;gt;= 5.1.0&lt;/a&gt; or &lt;a href="http://luajit.org" rel="nofollow"&gt;LuaJIT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pavouk/lgi"&gt;LGI &amp;gt;= 0.8.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.x.org/archive//individual/proto/" rel="nofollow"&gt;xproto &amp;gt;= 7.0.15&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xcb.freedesktop.org/" rel="nofollow"&gt;libxcb &amp;gt;= 1.6&lt;/a&gt; with support for the RandR, XTest, Xinerama, SHAPE and
XKB extensions&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xcb.freedesktop.org/" rel="nofollow"&gt;libxcb-cursor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xcb.freedesktop.org/" rel="nofollow"&gt;libxcb-util &amp;gt;= 0.3.8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xcb.freedesktop.org/" rel="nofollow"&gt;libxcb-keysyms &amp;gt;= 0.3.4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xcb.freedesktop.org/" rel="nofollow"&gt;libxcb-icccm &amp;gt;= 0.3.8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://xcb.freedesktop.org/" rel="nofollow"&gt;libxcb-xfixes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Airblader/xcb-util-xrm"&gt;xcb-util-xrm &amp;gt;= 1.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://xkbcommon.org/" rel="nofollow"&gt;libxkbcommon&lt;/a&gt; with X11 support enabled&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.freedesktop.org/wiki/Software/startup-notification/" rel="nofollow"&gt;libstartup-notification &amp;gt;=
0.10&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cairographics.org/" rel="nofollow"&gt;cairo&lt;/a&gt; with support for XCB and GObject
introspection&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pango.org/" rel="nofollow"&gt;Pango&lt;/a&gt; with support for Cairo and GObject
introspection&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.gnome.org/Projects/GLib" rel="nofollow"&gt;GLib &amp;gt;= 2.40&lt;/a&gt; with support for GObject
introspection&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.gnome.org/gio/stable/" rel="nofollow"&gt;GIO&lt;/a&gt; with support for GObject
introspection&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.gnome.org/Projects/GdkPixbuf" rel="nofollow"&gt;GdkPixbuf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;libX11 with xcb support&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.imagemagick.org/script/index.php" rel="nofollow"&gt;Imagemagick's convert utility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/devnev/libxdg-basedir"&gt;libxdg-basedir &amp;gt;= 1.0.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally, the following optional dependencies exist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.freedesktop.org/wiki/Software/dbus/" rel="nofollow"&gt;DBus&lt;/a&gt; for DBus integration
and the &lt;code&gt;awesome-client&lt;/code&gt; utility&lt;/li&gt;
&lt;li&gt;&lt;a href="https://asciidoctor.org/" rel="nofollow"&gt;asciidoctor&lt;/a&gt; for generating man pages&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.gzip.org/" rel="nofollow"&gt;gzip&lt;/a&gt; for compressing man pages&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stevedonovan.github.io/ldoc/" rel="nofollow"&gt;ldoc &amp;gt;= 1.4.5&lt;/a&gt; for generating the
documentation&lt;/li&gt;
&lt;li&gt;&lt;a href="https://olivinelabs.com/busted/" rel="nofollow"&gt;busted&lt;/a&gt; for running unit tests&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mpeterv/luacheck"&gt;luacheck&lt;/a&gt; for static code analysis&lt;/li&gt;
&lt;li&gt;&lt;a href="https://keplerproject.github.io/luacov/" rel="nofollow"&gt;LuaCov&lt;/a&gt; for collecting code coverage
information&lt;/li&gt;
&lt;li&gt;libexecinfo on systems where libc does not provide &lt;code&gt;backtrace_symbols()&lt;/code&gt; to
generate slightly better backtraces on crashes&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Xephyr&lt;/code&gt; or &lt;code&gt;Xvfb&lt;/code&gt; for running integration tests&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.gtk.org/" rel="nofollow"&gt;GTK+ &amp;gt;= 3.10&lt;/a&gt; for &lt;code&gt;./themes/gtk/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gitlab.freedesktop.org/xorg/lib/libxcb-errors" rel="nofollow"&gt;xcb-errors&lt;/a&gt; for
pretty-printing of X11 errors&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.gnome.org/action/show/Projects/LibRsvg" rel="nofollow"&gt;libRSVG&lt;/a&gt; for displaying
SVG files without scaling artifacts&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tripie.sweb.cz/utils/wmctrl" rel="nofollow"&gt;wmctrl&lt;/a&gt; for testing WM interactions
with external actions&lt;/li&gt;
&lt;li&gt;&lt;a href="https://invisible-island.net/xterm/" rel="nofollow"&gt;xterm&lt;/a&gt; for various test cases&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-running-awesome" class="anchor" aria-hidden="true" href="#running-awesome"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running Awesome&lt;/h2&gt;
&lt;p&gt;You can directly select Awesome from your display manager. If not, you can
add the following line to your &lt;code&gt;.xinitrc&lt;/code&gt; to start Awesome using &lt;code&gt;startx&lt;/code&gt;
or to &lt;code&gt;.xsession&lt;/code&gt; to start Awesome using your display manager:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;exec awesome
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to connect Awesome to a specific display, make sure that
the &lt;code&gt;DISPLAY&lt;/code&gt; environment variable is set correctly, e.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DISPLAY=foo.bar:1 exec awesome
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(This will start Awesome on display &lt;code&gt;:1&lt;/code&gt; of the host foo.bar.)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h2&gt;
&lt;p&gt;The configuration of Awesome is done by creating a
&lt;code&gt;$XDG_CONFIG_HOME/awesome/rc.lua&lt;/code&gt; file, typically &lt;code&gt;~/.config/awesome/rc.lua&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;An example configuration named &lt;code&gt;awesomerc.lua&lt;/code&gt; is provided in the source.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-troubleshooting" class="anchor" aria-hidden="true" href="#troubleshooting"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Troubleshooting&lt;/h2&gt;
&lt;p&gt;On most systems any message printed by Awesome (including warnings and errors)
is written to &lt;code&gt;~/.xsession-errors&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If Awesome does not start or the configuration file is not producing the
desired results the user should examine this file to gain insight into the
problem.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-debugging-tips" class="anchor" aria-hidden="true" href="#debugging-tips"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Debugging tips&lt;/h3&gt;
&lt;p&gt;You can call &lt;code&gt;awesome&lt;/code&gt; with &lt;code&gt;gdb&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DISPLAY=:2 gdb awesome
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then in &lt;code&gt;gdb&lt;/code&gt; set any arguments and run it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(gdb) set args --replace
(gdb) run
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-asking-questions" class="anchor" aria-hidden="true" href="#asking-questions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Asking questions&lt;/h2&gt;
&lt;h4&gt;&lt;a id="user-content-irc" class="anchor" aria-hidden="true" href="#irc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;IRC&lt;/h4&gt;
&lt;p&gt;You can join us in the &lt;code&gt;#awesome&lt;/code&gt; channel on the &lt;a href="http://www.oftc.net/" rel="nofollow"&gt;OFTC&lt;/a&gt; IRC network.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://webchat.oftc.net/?channels=awesome" rel="nofollow"&gt;IRC Webchat&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-stack-overflow" class="anchor" aria-hidden="true" href="#stack-overflow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stack Overflow&lt;/h4&gt;
&lt;p&gt;You can ask questions on &lt;a href="http://stackoverflow.com/questions/tagged/awesome-wm" rel="nofollow"&gt;Stack Overflow&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-reddit" class="anchor" aria-hidden="true" href="#reddit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reddit&lt;/h4&gt;
&lt;p&gt;We also have a &lt;a href="https://www.reddit.com/r/awesomewm/" rel="nofollow"&gt;awesome subreddit&lt;/a&gt; where you can share your work and ask questions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-reporting-issues" class="anchor" aria-hidden="true" href="#reporting-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reporting issues&lt;/h2&gt;
&lt;p&gt;Please report any issues you may find on &lt;a href="https://github.com/awesomeWM/awesome/issues"&gt;our bugtracker&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing-code" class="anchor" aria-hidden="true" href="#contributing-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing code&lt;/h2&gt;
&lt;p&gt;You can submit pull requests on the &lt;a href="https://github.com/awesomeWM/awesome"&gt;github repository&lt;/a&gt;.
Please read the &lt;a href="https://github.com/awesomeWM/awesome/blob/master/docs/02-contributing.md"&gt;contributing guide&lt;/a&gt; for any coding, documentation or patch guidelines.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-status" class="anchor" aria-hidden="true" href="#status"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Status&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://travis-ci.com/awesomeWM/awesome" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/51ab7d666f310b66a0ba854c58c26fcbe9e140c1/68747470733a2f2f7472617669732d63692e636f6d2f617765736f6d65574d2f617765736f6d652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/awesomeWM/awesome.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;Online documentation is available &lt;a href="https://awesomewm.org/apidoc/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;The project is licensed under GNU General Public License v2 or later.
You can read it online at (&lt;a href="http://www.gnu.org/licenses/gpl-2.0.html" rel="nofollow"&gt;v2&lt;/a&gt;
or &lt;a href="http://www.gnu.org/licenses/gpl.html" rel="nofollow"&gt;v3&lt;/a&gt;).&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>awesomeWM</author><guid isPermaLink="false">https://github.com/awesomeWM/awesome</guid><pubDate>Mon, 03 Feb 2020 00:06:00 GMT</pubDate></item><item><title>DiscworldZA/gta-resources #7 in Lua, Today</title><link>https://github.com/DiscworldZA/gta-resources</link><description>&lt;p&gt;&lt;i&gt;All the DiscworldZA GTA Resources&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="readme.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Hi, my name is &lt;a href="https://twitter.com/DiscworldZA" rel="nofollow"&gt;DiscworldZA&lt;/a&gt;. I create GTA V mods for FiveM.&lt;/p&gt;
&lt;p&gt;I create mods while streaming. Give me a follow here for notifications &lt;a href="https://www.twitch.tv/DiscworldZA" rel="nofollow"&gt;Twitch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is my repo for all the mods I create.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-feedback" class="anchor" aria-hidden="true" href="#feedback"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feedback.&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Highly recommended&lt;/li&gt;
&lt;li&gt;Report Issues &lt;a href="https://github.com/DiscworldZA/gta-resources/issues"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Want a Mod or Feature? Request &lt;a href="https://github.com/DiscworldZA/gta-resources/issues"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Changelog &lt;a href="https://github.com/DiscworldZA/gta-resources/blob/master/changelog.md"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will create almost anything you can think of. Feel free to request it and I will see about creating it.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h1&gt;
&lt;p&gt;Most server owners are not developers but understand the basics. My mods are created highly configurable. Every location or price for the mods will be able to be configured. If you want more configuration options create an &lt;a href="https://github.com/DiscworldZA/gta-resources/issues"&gt;issue&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All ReadMe contains Configuration sections&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-explanation" class="anchor" aria-hidden="true" href="#explanation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Explanation&lt;/h1&gt;
&lt;p&gt;Most of my mods work with the &lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-base"&gt;Base&lt;/a&gt; mod and &lt;a href="https://github.com/ESX-Org/es_extended"&gt;ESX&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The reasoning behind this is to simplify my process and have all my mods up to the same standard and address bug fixing over the whole platform rather individual broken sections.
It is the same concept that &lt;a href="https://github.com/ESX-Org/es_extended"&gt;ESX&lt;/a&gt; works on but for all my needs.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-requirements-for-all-mods" class="anchor" aria-hidden="true" href="#requirements-for-all-mods"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements for all mods&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ESX-Org/es_extended"&gt;ESX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mythicrp/mythic_notify"&gt;Mythic Notify&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ESX-Org/esx_addonaccount"&gt;ESX Add on Account&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-mod-list" class="anchor" aria-hidden="true" href="#mod-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mod List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-base"&gt;Disc-Base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-ammo"&gt;Disc-Ammo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-armory"&gt;Disc-Armory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-autorepair"&gt;Disc-AutoRepair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-billing"&gt;Disc-Billing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-boot"&gt;Disc-Boot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-compensation"&gt;Disc-Compensation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-carthief"&gt;Disc-CarThief&lt;/a&gt; (my version of &lt;a href="https://github.com/KlibrDM/esx_carthief"&gt;esx_carthief&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-dragme"&gt;Disc-DragMe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-drugruns"&gt;Disc-DrugRuns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-drugsales"&gt;Disc-DrugSales&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-gcphone"&gt;Disc-GcPhone&lt;/a&gt; (add-on to &lt;a href="https://github.com/N3MTV/gcphone"&gt;gcphone&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-hotwire"&gt;Disc-HotWire&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-hud"&gt;Disc-HUD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-identification"&gt;Disc-Identification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-import"&gt;Disc-Import&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-inventoryhud"&gt;Disc-InventoryHUD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-jobcars"&gt;Disc-JobCars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-panic"&gt;Disc-Panic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-property"&gt;Disc-Property&lt;/a&gt; (BETA)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-showid"&gt;Disc-ShowId&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-social"&gt;Disc-Social&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-tax"&gt;Disc-Tax&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-teleport"&gt;Disc-Teleport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-vehiclepick"&gt;Disc-VehiclePick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-vehiclesales"&gt;Disc-VehicleSales&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-warrant"&gt;Disc-Warrant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-ideas" class="anchor" aria-hidden="true" href="#ideas"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ideas&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;NPC Jobs (These are all mods to add depth to the ESX versions)
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-cops"&gt;Disc-Cops&lt;/a&gt; (WIP)&lt;/li&gt;
&lt;li&gt;Disc-EMS&lt;/li&gt;
&lt;li&gt;Disc-Mechanic&lt;/li&gt;
&lt;li&gt;Disc-CarSales&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unique Garages&lt;/li&gt;
&lt;li&gt;Server Wide Robbery Mechanic&lt;/li&gt;
&lt;li&gt;Search Warrants for Disc-Properties via Disc-Warrants&lt;/li&gt;
&lt;li&gt;Automatic BOLO/Facial Detection&lt;/li&gt;
&lt;li&gt;Handheld Police and EMS devices&lt;/li&gt;
&lt;li&gt;Variable Drug Import and Selling (Allow Drug importing via ship or truck) (Allow Large shipments of drugs)&lt;/li&gt;
&lt;li&gt;Expanding EMS and Cop Procedure (Require documentation to be filed)&lt;/li&gt;
&lt;li&gt;Mechanic Repair Expansion&lt;/li&gt;
&lt;li&gt;Vehicle Shop Documentation (License and Registration)&lt;/li&gt;
&lt;li&gt;Cop Evidence Mechanic&lt;/li&gt;
&lt;li&gt;Judge Job (Allow search warrant authorization, Allow cases to be handled)&lt;/li&gt;
&lt;li&gt;Daily Login Reward System&lt;/li&gt;
&lt;li&gt;Vehicle Keys (Compatible With Hotwire)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Usage&lt;/h1&gt;
&lt;p&gt;Feel free to use my &lt;a href="https://github.com/DiscworldZA/gta-resources/tree/master/disc-base"&gt;Base&lt;/a&gt; mod to create your own! Just credit me in some way. Share your mods you created with my base mod with me!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-credit" class="anchor" aria-hidden="true" href="#credit"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credit&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Did I forget to credit you for your code?&lt;/li&gt;
&lt;li&gt;Am I using your code without permission?&lt;/li&gt;
&lt;li&gt;Do you want to use my code?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Message me on Discord. I will help you out.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-discord" class="anchor" aria-hidden="true" href="#discord"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Discord&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://discord.gg/S2SckF6" rel="nofollow"&gt;https://discord.gg/S2SckF6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>DiscworldZA</author><guid isPermaLink="false">https://github.com/DiscworldZA/gta-resources</guid><pubDate>Mon, 03 Feb 2020 00:07:00 GMT</pubDate></item></channel></rss>