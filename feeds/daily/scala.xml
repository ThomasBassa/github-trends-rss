<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Scala, Today</title><link>https://github.com/trending/scala?since=daily</link><description>The top repositories on GitHub for scala, measured daily</description><pubDate>Fri, 01 Nov 2019 00:05:42 GMT</pubDate><lastBuildDate>Fri, 01 Nov 2019 00:05:42 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>1400</ttl><item><title>fpinscala/fpinscala #1 in Scala, Today</title><link>https://github.com/fpinscala/fpinscala</link><description>&lt;p&gt;&lt;i&gt;Code, exercises, answers, and hints to go along with the book "Functional Programming in Scala"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://travis-ci.org/fpinscala/fpinscala" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/eda1ba73f57af016a5c2cdcd746f67cef92c0b41/68747470733a2f2f7472617669732d63692e6f72672f6670696e7363616c612f6670696e7363616c612e7376673f6272616e63683d6d6173746572" alt="Build status" data-canonical-src="https://travis-ci.org/fpinscala/fpinscala.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/fpinscala/fpinscala?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/fpinscala/fpinscala" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains exercises, hints, and answers for the book
&lt;a href="http://manning.com/bjarnason/" rel="nofollow"&gt;Functional Programming in Scala&lt;/a&gt;. Along
with the book itself, it's the closest you'll get to having your own
private functional programming tutor without actually having one.&lt;/p&gt;
&lt;p&gt;Here's how to use this repository:&lt;/p&gt;
&lt;p&gt;Each chapter in the book develops a fully working library of functions
and data types, built up through a series of exercises and example code
given in the book text. The shell of this working library and exercise
stubs live in
&lt;code&gt;exercises/src/main/scala/fpinscala/&amp;lt;chapter-description&amp;gt;&lt;/code&gt;, where
&lt;code&gt;&amp;lt;chapter-description&amp;gt;&lt;/code&gt; is a package name that corresponds to the
chapter title (see below). When you begin working on a chapter, we
recommend you open the exercise file(s) for that chapter, and when you
encounter exercises, implement them in the exercises file and make sure
they work.&lt;/p&gt;
&lt;p&gt;If you get stuck on an exercise, let's say exercise 4 in the chapter,
you can find hints in &lt;code&gt;answerkey/&amp;lt;chapter-description&amp;gt;/04.hint.txt&lt;/code&gt; (if
no hints are available for a problem, the file will just have a single
'-' as its contents) and the answer along with an explanation of the
answer and any variations in
&lt;code&gt;answerkey/&amp;lt;chapter-description&amp;gt;/04.answer.scala&lt;/code&gt; or
&lt;code&gt;04.answer.markdown&lt;/code&gt;. The finished Scala modules, with all answers for
each chapter live in
&lt;code&gt;answers/src/main/scala/fpinscala/&amp;lt;chapter-description&amp;gt;&lt;/code&gt;. Please feel
free to submit pull requests for alternate answers, improved hints, and
so on, so we can make this repo the very best resource for people
working through the book.&lt;/p&gt;
&lt;p&gt;Chapter descriptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chapter 2: gettingstarted&lt;/li&gt;
&lt;li&gt;Chapter 3: datastructures&lt;/li&gt;
&lt;li&gt;Chapter 4: errorhandling&lt;/li&gt;
&lt;li&gt;Chapter 5: laziness&lt;/li&gt;
&lt;li&gt;Chapter 6: state&lt;/li&gt;
&lt;li&gt;Chapter 7: parallelism&lt;/li&gt;
&lt;li&gt;Chapter 8: testing&lt;/li&gt;
&lt;li&gt;Chapter 9: parsing&lt;/li&gt;
&lt;li&gt;Chapter 10: monoids&lt;/li&gt;
&lt;li&gt;Chapter 11: monads&lt;/li&gt;
&lt;li&gt;Chapter 12: applicative&lt;/li&gt;
&lt;li&gt;Chapter 13: iomonad&lt;/li&gt;
&lt;li&gt;Chapter 14: localeffects&lt;/li&gt;
&lt;li&gt;Chapter 15: streamingio&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To build the code for the first time, if on windows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ .\sbt.cmd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If on mac/linux, first make sure you have not checked out the code onto
an encrypted file system, otherwise you will get compile errors
regarding too long file names (one solution is to put the fpinscala repo
on a unencrypted usb key, and symlink it into your preferred code
location).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ chmod a+x ./sbt
$ ./sbt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will download and launch &lt;a href="http://scala-sbt.org" rel="nofollow"&gt;sbt&lt;/a&gt;, a build tool
for Scala. Once it is finished downloading, you'll get a prompt from
which you can issue commands to build and interact with your code. Try
the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; project exercises
&amp;gt; compile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This switches to the exercises project, where your code lives, and
compiles the code. You can also do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; console
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to get a Scala REPL with access to your exercises, and&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; run
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get a menu of possible main methods to execute.&lt;/p&gt;
&lt;p&gt;To create project files for the eclipse IDE you can install the
&lt;a href="https://github.com/typesafehub/sbteclipse"&gt;sbteclipse&lt;/a&gt;
&lt;a href="http://scala-sbt.org" rel="nofollow"&gt;sbt&lt;/a&gt; plugin. This makes a new command available
in &lt;a href="http://scala-sbt.org" rel="nofollow"&gt;sbt&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; eclipse
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All code in this repository is
&lt;a href="http://opensource.org/licenses/mit-license.php" rel="nofollow"&gt;MIT-licensed&lt;/a&gt;. See the
LICENSE file for details.&lt;/p&gt;
&lt;p&gt;Have fun, and good luck! Also be sure to check out &lt;a href="https://github.com/fpinscala/fpinscala/wiki"&gt;the community
wiki&lt;/a&gt; for the &lt;strong&gt;chapter
notes&lt;/strong&gt;, links to more reading, and more.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Paul and Rúnar&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fpinscala</author><guid isPermaLink="false">https://github.com/fpinscala/fpinscala</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>apache/spark #2 in Scala, Today</title><link>https://github.com/apache/spark</link><description>&lt;p&gt;&lt;i&gt;Apache Spark&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-apache-spark" class="anchor" aria-hidden="true" href="#apache-spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apache Spark&lt;/h1&gt;
&lt;p&gt;Spark is a unified analytics engine for large-scale data processing. It provides
high-level APIs in Scala, Java, Python, and R, and an optimized engine that
supports general computation graphs for data analysis. It also supports a
rich set of higher-level tools including Spark SQL for SQL and DataFrames,
MLlib for machine learning, GraphX for graph processing,
and Structured Streaming for stream processing.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://spark.apache.org/" rel="nofollow"&gt;https://spark.apache.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cd70373593f382473fbf1fb17a08856e918039d4/68747470733a2f2f616d706c61622e63732e6265726b656c65792e6564752f6a656e6b696e732f6a6f622f737061726b2d6d61737465722d746573742d7362742d6861646f6f702d322e372f62616467652f69636f6e" alt="Jenkins Build" data-canonical-src="https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7/badge/icon" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d3336700f9c89f8132189f928e567a2c104503af/68747470733a2f2f696d672e736869656c64732e696f2f6170707665796f722f63692f417061636865536f667477617265466f756e646174696f6e2f737061726b2f6d61737465722e7376673f7374796c653d706c6173746963266c6f676f3d6170707665796f72" alt="AppVeyor Build" data-canonical-src="https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&amp;amp;logo=appveyor" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://spark-test.github.io/pyspark-coverage-site" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2aa88140c358afddfa651b98a462bd69c4af7eb8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f786d6c2e7376673f6c6162656c3d7079737061726b253230636f7665726167652675726c3d6874747073253341253246253246737061726b2d746573742e6769746875622e696f2532467079737061726b2d636f7665726167652d736974652671756572793d25324668746d6c253246626f64792532466469762535423125354425324664697625324668312532467370616e26636f6c6f72423d627269676874677265656e267374796c653d706c6173746963" alt="PySpark Coverage" data-canonical-src="https://img.shields.io/badge/dynamic/xml.svg?label=pyspark%20coverage&amp;amp;url=https%3A%2F%2Fspark-test.github.io%2Fpyspark-coverage-site&amp;amp;query=%2Fhtml%2Fbody%2Fdiv%5B1%5D%2Fdiv%2Fh1%2Fspan&amp;amp;colorB=brightgreen&amp;amp;style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-online-documentation" class="anchor" aria-hidden="true" href="#online-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online Documentation&lt;/h2&gt;
&lt;p&gt;You can find the latest Spark documentation, including a programming
guide, on the &lt;a href="https://spark.apache.org/documentation.html" rel="nofollow"&gt;project web page&lt;/a&gt;.
This README file only contains basic setup instructions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-building-spark" class="anchor" aria-hidden="true" href="#building-spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building Spark&lt;/h2&gt;
&lt;p&gt;Spark is built using &lt;a href="https://maven.apache.org/" rel="nofollow"&gt;Apache Maven&lt;/a&gt;.
To build Spark and its example programs, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./build/mvn -DskipTests clean package
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(You do not need to do this if you downloaded a pre-built package.)&lt;/p&gt;
&lt;p&gt;You can build Spark using more than one thread by using the -T option with Maven, see &lt;a href="https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3" rel="nofollow"&gt;"Parallel builds in Maven 3"&lt;/a&gt;.
More detailed documentation is available from the project site, at
&lt;a href="https://spark.apache.org/docs/latest/building-spark.html" rel="nofollow"&gt;"Building Spark"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For general development tips, including info on developing Spark using an IDE, see &lt;a href="https://spark.apache.org/developer-tools.html" rel="nofollow"&gt;"Useful Developer Tools"&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-scala-shell" class="anchor" aria-hidden="true" href="#interactive-scala-shell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Scala Shell&lt;/h2&gt;
&lt;p&gt;The easiest way to start using Spark is through the Scala shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/spark-shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try the following command, which should return 1,000,000,000:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scala&amp;gt; spark.range(1000 * 1000 * 1000).count()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-python-shell" class="anchor" aria-hidden="true" href="#interactive-python-shell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Python Shell&lt;/h2&gt;
&lt;p&gt;Alternatively, if you prefer Python, you can use the Python shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/pyspark
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And run the following command, which should also return 1,000,000,000:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; spark.range(1000 * 1000 * 1000).count()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-example-programs" class="anchor" aria-hidden="true" href="#example-programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Programs&lt;/h2&gt;
&lt;p&gt;Spark also comes with several sample programs in the &lt;code&gt;examples&lt;/code&gt; directory.
To run one of them, use &lt;code&gt;./bin/run-example &amp;lt;class&amp;gt; [params]&lt;/code&gt;. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/run-example SparkPi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will run the Pi example locally.&lt;/p&gt;
&lt;p&gt;You can set the MASTER environment variable when running examples to submit
examples to a cluster. This can be a mesos:// or spark:// URL,
"yarn" to run on YARN, and "local" to run
locally with one thread, or "local[N]" to run locally with N threads. You
can also use an abbreviated class name if the class is in the &lt;code&gt;examples&lt;/code&gt;
package. For instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MASTER=spark://host:7077 ./bin/run-example SparkPi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many of the example programs print usage help if no params are given.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-running-tests" class="anchor" aria-hidden="true" href="#running-tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running Tests&lt;/h2&gt;
&lt;p&gt;Testing first requires &lt;a href="#building-spark"&gt;building Spark&lt;/a&gt;. Once Spark is built, tests
can be run using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./dev/run-tests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please see the guidance on how to
&lt;a href="https://spark.apache.org/developer-tools.html#individual-tests" rel="nofollow"&gt;run tests for a module, or individual tests&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-a-note-about-hadoop-versions" class="anchor" aria-hidden="true" href="#a-note-about-hadoop-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Note About Hadoop Versions&lt;/h2&gt;
&lt;p&gt;Spark uses the Hadoop core library to talk to HDFS and other Hadoop-supported
storage systems. Because the protocols have changed in different versions of
Hadoop, you must build Spark against the same version that your cluster runs.&lt;/p&gt;
&lt;p&gt;Please refer to the build documentation at
&lt;a href="https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn" rel="nofollow"&gt;"Specifying the Hadoop Version and Enabling YARN"&lt;/a&gt;
for detailed guidance on building for a particular distribution of Hadoop, including
building for particular Hive and Hive Thriftserver distributions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Please refer to the &lt;a href="https://spark.apache.org/docs/latest/configuration.html" rel="nofollow"&gt;Configuration Guide&lt;/a&gt;
in the online documentation for an overview on how to configure Spark.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Please review the &lt;a href="https://spark.apache.org/contributing.html" rel="nofollow"&gt;Contribution to Spark guide&lt;/a&gt;
for information on how to get started contributing to the project.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/spark</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>yahoo/kafka-manager #3 in Scala, Today</title><link>https://github.com/yahoo/kafka-manager</link><description>&lt;p&gt;&lt;i&gt;A tool for managing Apache Kafka.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-kafka-manager" class="anchor" aria-hidden="true" href="#kafka-manager"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Kafka Manager&lt;/h1&gt;
&lt;p&gt;A tool for managing &lt;a href="http://kafka.apache.org" rel="nofollow"&gt;Apache Kafka&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It supports the following :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Manage multiple clusters&lt;/li&gt;
&lt;li&gt;Easy inspection of cluster state (topics, consumers, offsets, brokers, replica distribution, partition distribution)&lt;/li&gt;
&lt;li&gt;Run preferred replica election&lt;/li&gt;
&lt;li&gt;Generate partition assignments with option to select brokers to use&lt;/li&gt;
&lt;li&gt;Run reassignment of partition (based on generated assignments)&lt;/li&gt;
&lt;li&gt;Create a topic with optional topic configs (0.8.1.1 has different configs than 0.8.2+)&lt;/li&gt;
&lt;li&gt;Delete topic (only supported on 0.8.2+ and remember set delete.topic.enable=true in broker config)&lt;/li&gt;
&lt;li&gt;Topic list now indicates topics marked for deletion (only supported on 0.8.2+)&lt;/li&gt;
&lt;li&gt;Batch generate partition assignments for multiple topics with option to select brokers to use&lt;/li&gt;
&lt;li&gt;Batch run reassignment of partition for multiple topics&lt;/li&gt;
&lt;li&gt;Add partitions to existing topic&lt;/li&gt;
&lt;li&gt;Update config for existing topic&lt;/li&gt;
&lt;li&gt;Optionally enable JMX polling for broker level and topic level metrics.&lt;/li&gt;
&lt;li&gt;Optionally filter out consumers that do not have ids/ owners/ &amp;amp; offsets/ directories in zookeeper.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cluster Management&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/cluster.png"&gt;&lt;img src="/img/cluster.png" alt="cluster" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Topic List&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/topic-list.png"&gt;&lt;img src="/img/topic-list.png" alt="topic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Topic View&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/topic.png"&gt;&lt;img src="/img/topic.png" alt="topic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Consumer List View&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/consumer-list.png"&gt;&lt;img src="/img/consumer-list.png" alt="consumer" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Consumed Topic View&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/consumed-topic.png"&gt;&lt;img src="/img/consumed-topic.png" alt="consumer" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Broker List&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/broker-list.png"&gt;&lt;img src="/img/broker-list.png" alt="broker" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Broker View&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="/img/broker.png"&gt;&lt;img src="/img/broker.png" alt="broker" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://kafka.apache.org/downloads.html" rel="nofollow"&gt;Kafka 0.8.&lt;em&gt;.&lt;/em&gt; or 0.9.&lt;em&gt;.&lt;/em&gt; or 0.10.&lt;em&gt;.&lt;/em&gt; or 0.11.&lt;em&gt;.&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Java 8+&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h2&gt;
&lt;p&gt;The minimum configuration is the zookeeper hosts which are to be used for kafka manager state.
This can be found in the application.conf file in conf directory.  The same file will be packaged
in the distribution zip file; you may modify settings after unzipping the file on the desired server.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-manager.zkhosts="my.zookeeper.host.com:2181"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can specify multiple zookeeper hosts by comma delimiting them, like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-manager.zkhosts="my.zookeeper.host.com:2181,other.zookeeper.host.com:2181"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, use the environment variable &lt;code&gt;ZK_HOSTS&lt;/code&gt; if you don't want to hardcode any values.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ZK_HOSTS="my.zookeeper.host.com:2181"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can optionally enable/disable the following functionality by modifying the default list in application.conf :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;application.features=["KMClusterManagerFeature","KMTopicManagerFeature","KMPreferredReplicaElectionFeature","KMReassignPartitionsFeature"]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;KMClusterManagerFeature - allows adding, updating, deleting cluster from Kafka Manager&lt;/li&gt;
&lt;li&gt;KMTopicManagerFeature - allows adding, updating, deleting topic from a Kafka cluster&lt;/li&gt;
&lt;li&gt;KMPreferredReplicaElectionFeature - allows running of preferred replica election for a Kafka cluster&lt;/li&gt;
&lt;li&gt;KMReassignPartitionsFeature - allows generating partition assignments and reassigning partitions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Consider setting these parameters for larger clusters with jmx enabled :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kafka-manager.broker-view-thread-pool-size=&amp;lt; 3 * number_of_brokers&amp;gt;&lt;/li&gt;
&lt;li&gt;kafka-manager.broker-view-max-queue-size=&amp;lt; 3 * total # of partitions across all topics&amp;gt;&lt;/li&gt;
&lt;li&gt;kafka-manager.broker-view-update-seconds=&amp;lt; kafka-manager.broker-view-max-queue-size / (10 * number_of_brokers) &amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an example for a kafka cluster with 10 brokers, 100 topics, with each topic having 10 partitions giving 1000 total partitions with JMX enabled :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kafka-manager.broker-view-thread-pool-size=30&lt;/li&gt;
&lt;li&gt;kafka-manager.broker-view-max-queue-size=3000&lt;/li&gt;
&lt;li&gt;kafka-manager.broker-view-update-seconds=30&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The follow control consumer offset cache's thread pool and queue :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kafka-manager.offset-cache-thread-pool-size=&amp;lt; default is # of processors&amp;gt;&lt;/li&gt;
&lt;li&gt;kafka-manager.offset-cache-max-queue-size=&amp;lt; default is 1000&amp;gt;&lt;/li&gt;
&lt;li&gt;kafka-manager.kafka-admin-client-thread-pool-size=&amp;lt; default is # of processors&amp;gt;&lt;/li&gt;
&lt;li&gt;kafka-manager.kafka-admin-client-max-queue-size=&amp;lt; default is 1000&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You should increase the above for large # of consumers with consumer polling enabled.  Though it mainly affects ZK based consumer polling.&lt;/p&gt;
&lt;p&gt;Kafka managed consumer offset is now consumed by KafkaManagedOffsetCache from the "__consumer_offsets" topic.  Note, this has not been tested with large number of offsets being tracked.  There is a single thread per cluster consuming this topic so it may not be able to keep up on large # of offsets being pushed to the topic.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-authenticating-a-user-with-ldap" class="anchor" aria-hidden="true" href="#authenticating-a-user-with-ldap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Authenticating a User with LDAP&lt;/h3&gt;
&lt;p&gt;Warning, you need to have SSL configured with Kafka Manager to ensure your credentials aren't passed unencrypted.
Authenticating a User with LDAP is possible by passing the user credentials with the Authorization header.
LDAP authentication is done on first visit, if successful, a cookie is set.
On next request, the cookie value is compared with credentials from Authorization header.
LDAP support is through the basic authentication filter.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Configure basic authentication&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;basicAuthentication.enabled=true&lt;/li&gt;
&lt;li&gt;basicAuthentication.realm=&amp;lt; basic authentication realm&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Encryption parameters (optional, otherwise randomly generated on startup) :&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;basicAuthentication.salt="some-hex-string-representing-byte-array"&lt;/li&gt;
&lt;li&gt;basicAuthentication.iv="some-hex-string-representing-byte-array"&lt;/li&gt;
&lt;li&gt;basicAuthentication.secret="my-secret-string"&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Configure LDAP/LDAPS authentication&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;basicAuthentication.ldap.enabled=&amp;lt; Boolean flag to enable/disable ldap authentication &amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.server=&amp;lt; fqdn of LDAP server&amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.port=&amp;lt; port of LDAP server&amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.username=&amp;lt; LDAP search username&amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.password=&amp;lt; LDAP search password&amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.search-base-dn=&amp;lt; LDAP search base&amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.search-filter=&amp;lt; LDAP search filter&amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.connection-pool-size=&amp;lt; number of connection to LDAP server&amp;gt;&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.ssl=&amp;lt; Boolean flag to enable/disable LDAPS&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="4"&gt;
&lt;li&gt;(Optional) Limit access to a specific LDAP Group&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;basicAuthentication.ldap.group-filter=&amp;lt; LDAP group filter&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-example-online-ldap-test-server" class="anchor" aria-hidden="true" href="#example-online-ldap-test-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example (Online LDAP Test Server):&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;basicAuthentication.ldap.enabled=true&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.server="ldap.forumsys.com"&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.port=389&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.username="cn=read-only-admin,dc=example,dc=com"&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.password="password"&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.search-base-dn="dc=example,dc=com"&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.search-filter="(uid=$capturedLogin$)"&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.group-filter="cn=allowed-group,ou=groups,dc=example,dc=com"&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.connection-pool-size=10&lt;/li&gt;
&lt;li&gt;basicAuthentication.ldap.ssl=false&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-deployment" class="anchor" aria-hidden="true" href="#deployment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deployment&lt;/h2&gt;
&lt;p&gt;The command below will create a zip file which can be used to deploy the application.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./sbt clean dist
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please refer to play framework documentation on &lt;a href="https://www.playframework.com/documentation/2.4.x/ProductionConfiguration" rel="nofollow"&gt;production deployment/configuration&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If java is not in your path, or you need to build against a specific java version,
please use the following (the example assumes oracle java8):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ PATH=/usr/local/oracle-java-8/bin:$PATH \
  JAVA_HOME=/usr/local/oracle-java-8 \
  /path/to/sbt -java-home /usr/local/oracle-java-8 clean dist
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This ensures that the 'java' and 'javac' binaries in your path are first looked up in the
oracle java8 release. Next, for all downstream tools that only listen to JAVA_HOME, it points
them to the oracle java8 location. Lastly, it tells sbt to use the oracle java8 location as
well.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-starting-the-service" class="anchor" aria-hidden="true" href="#starting-the-service"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Starting the service&lt;/h2&gt;
&lt;p&gt;After extracting the produced zipfile, and changing the working directory to it, you can
run the service like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-manager
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, it will choose port 9000. This is overridable, as is the location of the
configuration file. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-manager -Dconfig.file=/path/to/application.conf -Dhttp.port=8080
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, if java is not in your path, or you need to run against a different version of java,
add the -java-home option as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-manager -java-home /usr/local/oracle-java-8
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-starting-the-service-with-security" class="anchor" aria-hidden="true" href="#starting-the-service-with-security"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Starting the service with Security&lt;/h2&gt;
&lt;p&gt;To add JAAS configuration for SASL, add the config file location at start:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-manager -Djava.security.auth.login.config=/path/to/my-jaas.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: Make sure the user running kafka manager has read permissions on the jaas config file&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-packaging" class="anchor" aria-hidden="true" href="#packaging"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Packaging&lt;/h2&gt;
&lt;p&gt;If you'd like to create a Debian or RPM package instead, you can run one of:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sbt debian:packageBin

sbt rpm:packageBin
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;Logo/favicon used is from &lt;a href="http://kafka.apache.org" rel="nofollow"&gt;Apache Kafka&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most of the utils code has been adapted to work with &lt;a href="http://curator.apache.org" rel="nofollow"&gt;Apache Curator&lt;/a&gt; from &lt;a href="http://kafka.apache.org" rel="nofollow"&gt;Apache Kafka&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Apache Licensed. See accompanying LICENSE file.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>yahoo</author><guid isPermaLink="false">https://github.com/yahoo/kafka-manager</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>InterestingLab/waterdrop #4 in Scala, Today</title><link>https://github.com/InterestingLab/waterdrop</link><description>&lt;p&gt;&lt;i&gt;生产环境的海量数据计算产品，文档地址：&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-waterdrop-" class="anchor" aria-hidden="true" href="#waterdrop-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Waterdrop &lt;a href="https://travis-ci.org/InterestingLab/waterdrop" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/93fc4795f2c7db407470e4e5c23a21e311390d03/68747470733a2f2f7472617669732d63692e6f72672f496e746572657374696e674c61622f776174657264726f702e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/InterestingLab/waterdrop.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://gitter.im/interestinglab_waterdrop/Lobby?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d9adb3c2e789c3e5bd526922bfd62ba73189c102/68747470733a2f2f6261646765732e6769747465722e696d2f696e746572657374696e676c61625f776174657264726f702f4c6f6262792e737667" alt="Join the chat at https://gitter.im/interestinglab_waterdrop/Lobby" data-canonical-src="https://badges.gitter.im/interestinglab_waterdrop/Lobby.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Waterdrop 是一个&lt;code&gt;非常易用&lt;/code&gt;，&lt;code&gt;高性能&lt;/code&gt;、支持&lt;code&gt;实时流式&lt;/code&gt;和&lt;code&gt;离线批处理&lt;/code&gt;的&lt;code&gt;海量数据&lt;/code&gt;处理产品，架构于&lt;code&gt;Apache Spark&lt;/code&gt; 和 &lt;code&gt;Apache Flink&lt;/code&gt;之上。&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-如果您没时间看下面内容请直接进入正题" class="anchor" aria-hidden="true" href="#如果您没时间看下面内容请直接进入正题"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;如果您没时间看下面内容，请直接进入正题:&lt;/h3&gt;
&lt;p&gt;请点击进入快速入门：&lt;a href="https://interestinglab.github.io/waterdrop/#/zh-cn/quick-start" rel="nofollow"&gt;https://interestinglab.github.io/waterdrop/#/zh-cn/quick-start&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Waterdrop 提供可直接执行的软件包，没有必要自行编译源代码，下载地址：&lt;a href="https://github.com/InterestingLab/waterdrop/releases"&gt;https://github.com/InterestingLab/waterdrop/releases&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;文档地址：&lt;a href="https://interestinglab.github.io/waterdrop/" rel="nofollow"&gt;https://interestinglab.github.io/waterdrop/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;各种线上应用案例，请见: &lt;a href="https://interestinglab.github.io/waterdrop/#/zh-cn/case_study/base" rel="nofollow"&gt;https://interestinglab.github.io/waterdrop/#/zh-cn/case_study/base&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果你遇到任何问题，请联系项目负责人 Gary(微信: &lt;code&gt;garyelephant&lt;/code&gt;) , RickyHuo(微信: &lt;code&gt;chodomatte1994&lt;/code&gt;)，加微信备注"waterdrop"，我们把你拉到&lt;code&gt;Waterdrop &amp;amp; Spark &amp;amp; Flink 交流群&lt;/code&gt;里，并为你提供全程免费服务，你也可以与其他伙伴交流大数据技术。扫码加我，拉你入群：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/wechat-qrcode/garyelephant.jpeg"&gt;&lt;img src="./docs/images/wechat-qrcode/garyelephant.jpeg" height="240" width="240" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-为什么我们需要-waterdrop" class="anchor" aria-hidden="true" href="#为什么我们需要-waterdrop"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;为什么我们需要 Waterdrop&lt;/h2&gt;
&lt;p&gt;Databricks 开源的 Apache Spark 对于分布式数据处理来说是一个伟大的进步。我们在使用 Spark 时发现了很多可圈可点之处，同时我们也发现了我们的机会 —— 通过我们的努力让Spark的使用更简单，更高效，并将业界和我们使用Spark的优质经验固化到Waterdrop这个产品中，明显减少学习成本，加快分布式数据处理能力在生产环境落地。&lt;/p&gt;
&lt;p&gt;除了大大简化分布式数据处理难度外，Waterdrop尽所能为您解决可能遇到的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据丢失与重复&lt;/li&gt;
&lt;li&gt;任务堆积与延迟&lt;/li&gt;
&lt;li&gt;吞吐量低&lt;/li&gt;
&lt;li&gt;应用到生产环境周期长&lt;/li&gt;
&lt;li&gt;缺少应用运行状态监控&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;"Waterdrop" 的中文是“水滴”，来自中国当代科幻小说作家刘慈欣的《三体》系列，它是三体人制造的宇宙探测器，会反射几乎全部的电磁波，表面绝对光滑，温度处于绝对零度，全部由被强互作用力紧密锁死的质子与中子构成，无坚不摧。在末日之战中，仅一个水滴就摧毁了人类太空武装力量近2千艘战舰。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-waterdrop-使用场景" class="anchor" aria-hidden="true" href="#waterdrop-使用场景"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Waterdrop 使用场景&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;海量数据ETL&lt;/li&gt;
&lt;li&gt;海量数据聚合&lt;/li&gt;
&lt;li&gt;多源数据处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-waterdrop-的特性" class="anchor" aria-hidden="true" href="#waterdrop-的特性"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Waterdrop 的特性&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;简单易用，灵活配置，无需开发&lt;/li&gt;
&lt;li&gt;实时流式处理&lt;/li&gt;
&lt;li&gt;离线多源数据分析&lt;/li&gt;
&lt;li&gt;高性能&lt;/li&gt;
&lt;li&gt;海量数据处理能力&lt;/li&gt;
&lt;li&gt;模块化和插件化，易于扩展&lt;/li&gt;
&lt;li&gt;支持利用SQL做数据处理和聚合&lt;/li&gt;
&lt;li&gt;支持Spark Structured Streaming&lt;/li&gt;
&lt;li&gt;支持Spark 2.x&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-waterdrop-的工作流程" class="anchor" aria-hidden="true" href="#waterdrop-的工作流程"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Waterdrop 的工作流程&lt;/h2&gt;
&lt;p align="center"&gt;
    &lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/wd-workflow.png"&gt;&lt;img src="./docs/images/wd-workflow.png" height="460" width="280" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                         Input[数据源输入] -&amp;gt; Filter[数据处理] -&amp;gt; Output[结果输出]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;多个Filter构建了数据处理的Pipeline，满足各种各样的数据处理需求，如果您熟悉SQL，也可以直接通过SQL构建数据处理的Pipeline，简单高效。目前Waterdrop支持的&lt;a href="zh-cn/configuration/filter-plugin"&gt;Filter列表&lt;/a&gt;, 仍然在不断扩充中。您也可以开发自己的数据处理插件，整个系统是易于扩展的。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-waterdrop-支持的插件" class="anchor" aria-hidden="true" href="#waterdrop-支持的插件"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Waterdrop 支持的插件&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Input plugin&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fake, File, Hdfs, Kafka, S3, Socket, 自行开发的Input plugin&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filter plugin&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Add, Checksum, Convert, Date, Drop, Grok, Json, Kv, Lowercase, Remove, Rename, Repartition, Replace, Sample, Split, Sql, Table, Truncate, Uppercase, Uuid, 自行开发的Filter plugin&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Output plugin&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Elasticsearch, File, Hdfs, Jdbc, Kafka, Mysql, S3, Stdout, 自行开发的Output plugin&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-环境依赖" class="anchor" aria-hidden="true" href="#环境依赖"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;环境依赖&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;java运行环境，java &amp;gt;= 8&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果您要在集群环境中运行Waterdrop，那么需要以下Spark集群环境的任意一种：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Spark on Yarn&lt;/li&gt;
&lt;li&gt;Spark Standalone&lt;/li&gt;
&lt;li&gt;Spark on Mesos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果您的数据量较小或者只是做功能验证，也可以仅使用&lt;code&gt;local&lt;/code&gt;模式启动，无需集群环境，Waterdrop支持单机运行。&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-文档" class="anchor" aria-hidden="true" href="#文档"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;文档&lt;/h2&gt;
&lt;p&gt;关于Waterdrop的&lt;a href="https://interestinglab.github.io/waterdrop/" rel="nofollow"&gt;详细文档&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-社区分享" class="anchor" aria-hidden="true" href="#社区分享"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;社区分享&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;2018-09-08 Elasticsearch 社区分享 &lt;a href="https://elasticsearch.cn/slides/127#page=1" rel="nofollow"&gt;Waterdrop：构建在Spark之上的简单高效数据处理系统&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2017-09-22 InterestingLab 内部分享 &lt;a href="http://slides.com/garyelephant/waterdrop/fullscreen?token=GKrQoxJi" rel="nofollow"&gt;Waterdrop介绍PPT&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-应用案例" class="anchor" aria-hidden="true" href="#应用案例"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;应用案例&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://weibo.com" rel="nofollow"&gt;微博&lt;/a&gt;, 增值业务部数据平台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/98b1cd501d80b2989aedbab733c36123f874357b/68747470733a2f2f696d672e742e73696e616a732e636e2f74352f7374796c652f696d616765732f7374617469636c6f676f2f67726f757073332e706e673f76657273696f6e3d66333632613163356265353230613135"&gt;&lt;img src="https://camo.githubusercontent.com/98b1cd501d80b2989aedbab733c36123f874357b/68747470733a2f2f696d672e742e73696e616a732e636e2f74352f7374796c652f696d616765732f7374617469636c6f676f2f67726f757073332e706e673f76657273696f6e3d66333632613163356265353230613135" height="120" width="160" data-canonical-src="https://img.t.sinajs.cn/t5/style/images/staticlogo/groups3.png?version=f362a1c5be520a15" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;微博某业务有数百个实时流式计算任务使用内部定制版Waterdrop，以及其子项目&lt;a href="https://github.com/InterestingLab/guardian"&gt;Guardian&lt;/a&gt;做Waterdrop On Yarn的任务监控。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.sina.com.cn/" rel="nofollow"&gt;新浪&lt;/a&gt;, 大数据运维分析平台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/sina-logo.png"&gt;&lt;img src="./docs/images/sina-logo.png" height="60" width="120" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;新浪运维数据分析平台使用waterdrop为新浪新闻，CDN等服务做运维大数据的实时和离线分析，并写入Clickhouse。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bytedance.com/zh" rel="nofollow"&gt;字节跳动&lt;/a&gt;，广告数据平台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/bytedance-logo.jpeg"&gt;&lt;img src="./docs/images/bytedance-logo.jpeg" height="90" width="150" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;字节跳动使用Waterdrop实现了多源数据的关联分析(如Hive和ES的数据源关联查询分析)，大大简化了不同数据源之间的分析对比工作，并且节省了大量的Spark程序的学习和开发时间。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.yixia.com/" rel="nofollow"&gt;一下科技&lt;/a&gt;, 一直播数据平台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/3528d6f6cfb58f2a046bd0b85291a17596aa5199/68747470733a2f2f696d67616c6979756e63646e2e6d69616f7061692e636f6d2f73746174696332303133313033312f6d69616f70616932303134303732392f6e65775f79697869612f7374617469632f696d67732f6c6f676f2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/3528d6f6cfb58f2a046bd0b85291a17596aa5199/68747470733a2f2f696d67616c6979756e63646e2e6d69616f7061692e636f6d2f73746174696332303133313033312f6d69616f70616932303134303732392f6e65775f79697869612f7374617469632f696d67732f6c6f676f2e706e67" height="60" width="120" data-canonical-src="https://imgaliyuncdn.miaopai.com/static20131031/miaopai20140729/new_yixia/static/imgs/logo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;永辉超市子公司-永辉云创，会员电商数据分析平台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/yonghuiyunchuang-logo.png"&gt;&lt;img src="./docs/images/yonghuiyunchuang-logo.png" height="60" width="120" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Waterdrop 为永辉云创旗下新零售品牌永辉生活提供电商用户行为数据实时流式与离线SQL计算。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;水滴筹, 数据平台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/shuidichou-logo.jpg"&gt;&lt;img src="./docs/images/shuidichou-logo.jpg" height="60" width="120" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;水滴筹在Yarn上使用Waterdrop做实时流式以及定时的离线批处理，每天处理3～4T的数据量，最终将数据写入Clickhouse。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;浙江乐控信息科技有限公司&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/zhejiang_lekong_xinxi_keji-logo.jpg"&gt;&lt;img src="./docs/images/zhejiang_lekong_xinxi_keji-logo.jpg" height="60" width="120" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Watedrop 为浙江乐控信息科技有限公司旗下乐控智能提供物联网交互数据实时流sql分析(Structured Streaming 引擎)和离线数据分析。每天处理的数据量8千万到一亿条数据 最终数据落地到kafka和mysql数据库。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://91fd.com" rel="nofollow"&gt;上海分蛋信息科技&lt;/a&gt;，大数据数据分析平台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/images/fendan-keji-logo.jpeg"&gt;&lt;img src="./docs/images/fendan-keji-logo.jpeg" height="60" width="120" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;分蛋科技使用Waterdrop做数据仓库实时同步，近百个Pipeline同步处理；数据流实时统计，数据平台指标离线计算。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其他公司 ... 期待您的加入，请联系微信: garyelephant&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-项目star增长趋势" class="anchor" aria-hidden="true" href="#项目star增长趋势"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;项目Star增长趋势&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Waterdrop已进入高速成长期，如果你支持此项目，请点Star.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://starchart.cc/InterestingLab/waterdrop" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e9d4c116c36525c7c2652dd3a27e2f29c0718c6b/68747470733a2f2f7374617263686172742e63632f496e746572657374696e674c61622f776174657264726f702e737667" alt="Stargazers over time" data-canonical-src="https://starchart.cc/InterestingLab/waterdrop.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-贡献观点和代码" class="anchor" aria-hidden="true" href="#贡献观点和代码"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;贡献观点和代码&lt;/h2&gt;
&lt;p&gt;提交问题和建议：&lt;a href="https://github.com/InterestingLab/waterdrop/issues"&gt;https://github.com/InterestingLab/waterdrop/issues&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;贡献代码：&lt;a href="https://github.com/InterestingLab/waterdrop/pulls"&gt;https://github.com/InterestingLab/waterdrop/pulls&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-开发者" class="anchor" aria-hidden="true" href="#开发者"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;开发者&lt;/h2&gt;
&lt;p&gt;感谢&lt;a href="https://github.com/InterestingLab/waterdrop/graphs/contributors"&gt;所有开发者&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-联系项目负责人" class="anchor" aria-hidden="true" href="#联系项目负责人"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;联系项目负责人&lt;/h2&gt;
&lt;p&gt;Garyelephant : &lt;a href="mailto:garygaowork@gmail.com"&gt;garygaowork@gmail.com&lt;/a&gt;, 微信: garyelephant&lt;/p&gt;
&lt;p&gt;RickyHuo : &lt;a href="mailto:huochen1994@163.com"&gt;huochen1994@163.com&lt;/a&gt;, 微信: chodomatte1994&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>InterestingLab</author><guid isPermaLink="false">https://github.com/InterestingLab/waterdrop</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>http4s/http4s #5 in Scala, Today</title><link>https://github.com/http4s/http4s</link><description>&lt;p&gt;&lt;i&gt;A minimal, idiomatic Scala interface for HTTP&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-http4s-----" class="anchor" aria-hidden="true" href="#http4s-----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Http4s &lt;a href="https://travis-ci.org/http4s/http4s" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a9022c01e1ad1eb4cbfaa85468c1c1587173c19e/68747470733a2f2f7472617669732d63692e6f72672f6874747034732f6874747034732e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/http4s/http4s.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/http4s/http4s" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/be1902f93402d993f93bfc2e666ddb0cb5b4dd6a/68747470733a2f2f6261646765732e6769747465722e696d2f6874747034732f6874747034732e706e67" alt="Gitter chat" data-canonical-src="https://badges.gitter.im/http4s/http4s.png" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://maven-badges.herokuapp.com/maven-central/org.http4s/http4s-core_2.12" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/01334c24d98856a8c00dbc8d82e549d2cdc31f29/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f6f72672e6874747034732f6874747034732d636f72655f322e31322f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/org.http4s/http4s-core_2.12/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://typelevel.org/projects/#http4s" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3b0e74dc481efe47f57b9f293fc57cf49637119a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f747970656c6576656c2d6c6962726172792d677265656e2e737667" alt="Typelevel library" data-canonical-src="https://img.shields.io/badge/typelevel-library-green.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://typelevel.org/cats/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2940747bf90ab8763b220669379d3a5190bde2fa/68747470733a2f2f747970656c6576656c2e6f72672f636174732f696d672f636174732d62616467652e737667" height="40px" align="right" alt="Cats friendly" data-canonical-src="https://typelevel.org/cats/img/cats-badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Http4s is a minimal, idiomatic Scala interface for HTTP services.  Http4s is
Scala's answer to Ruby's Rack, Python's WSGI, Haskell's WAI, and Java's
Servlets.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;http&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;HttpRoutes&lt;/span&gt;.of {
  &lt;span class="pl-k"&gt;case&lt;/span&gt; &lt;span class="pl-en"&gt;GET&lt;/span&gt; &lt;span class="pl-k"&gt;-&lt;/span&gt;&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Root&lt;/span&gt; &lt;span class="pl-k"&gt;/&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;hello&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class="pl-en"&gt;Ok&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello, better world.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Learn more at &lt;a href="https://http4s.org/" rel="nofollow"&gt;http4s.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you run into any difficulties please enable partial unification in your &lt;code&gt;build.sbt&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;scalacOptions &lt;span class="pl-k"&gt;++&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Seq&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;-Ypartial-unification&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-code-of-conduct" class="anchor" aria-hidden="true" href="#code-of-conduct"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code of Conduct&lt;/h2&gt;
&lt;p&gt;http4s is proud to be a &lt;a href="https://typelevel.org/" rel="nofollow"&gt;Typelevel&lt;/a&gt; incubator
project.  We are committed to providing a friendly, safe and welcoming
environment for all, and ask that the community adhere to the &lt;a href="https://http4s.org/code-of-conduct/" rel="nofollow"&gt;Scala
Code of Conduct&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This software is licensed under the Apache 2 license, quoted below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Copyright 2013-2019 http4s [&lt;a href="https://http4s.org/" rel="nofollow"&gt;https://http4s.org&lt;/a&gt;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;[&lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgments" class="anchor" aria-hidden="true" href="#acknowledgments"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.yourkit.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/97fa03cac759a772255b93c64ab1c9f76a103681/68747470733a2f2f7777772e796f75726b69742e636f6d2f696d616765732f796b6c6f676f2e706e67" alt="YourKit" data-canonical-src="https://www.yourkit.com/images/yklogo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Special thanks to &lt;a href="https://www.yourkit.com/" rel="nofollow"&gt;YourKit&lt;/a&gt; for supporting this project's ongoing performance tuning efforts with licenses to their excellent product.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>http4s</author><guid isPermaLink="false">https://github.com/http4s/http4s</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>Azure/mmlspark #6 in Scala, Today</title><link>https://github.com/Azure/mmlspark</link><description>&lt;p&gt;&lt;i&gt;Microsoft Machine Learning for Apache Spark&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0f31d64469b1c4f3dbe5e854f52bb3eb349e0ba8/68747470733a2f2f6d6d6c737061726b2e617a757265656467652e6e65742f69636f6e732f6d6d6c737061726b2e737667"&gt;&lt;img src="https://camo.githubusercontent.com/0f31d64469b1c4f3dbe5e854f52bb3eb349e0ba8/68747470733a2f2f6d6d6c737061726b2e617a757265656467652e6e65742f69636f6e732f6d6d6c737061726b2e737667" alt="MMLSpark" data-canonical-src="https://mmlspark.azureedge.net/icons/mmlspark.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-microsoft-machine-learning-for-apache-spark" class="anchor" aria-hidden="true" href="#microsoft-machine-learning-for-apache-spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Microsoft Machine Learning for Apache Spark&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://msazure.visualstudio.com/Cognitive%20Services/_build/latest?definitionId=83120&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c6013b9f6e8d726998981acea8cf0c6afa87dc8d/68747470733a2f2f6d73617a7572652e76697375616c73747564696f2e636f6d2f436f676e697469766525323053657276696365732f5f617069732f6275696c642f7374617475732f417a7572652e6d6d6c737061726b3f6272616e63684e616d653d6d6173746572" alt="Build Status" data-canonical-src="https://msazure.visualstudio.com/Cognitive%20Services/_apis/build/status/Azure.mmlspark?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/Azure/mmlspark" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3d33b1f413ba945dce11c42625c751b6e13acca3/68747470733a2f2f636f6465636f762e696f2f67682f417a7572652f6d6d6c737061726b2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/Azure/mmlspark/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/MMLSpark?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2177ea7fddaac7ecb8a0d5ebda9e0550ec2f79fa/68747470733a2f2f6261646765732e6769747465722e696d2f4d6963726f736f66742f4d4d4c537061726b2e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/Microsoft/MMLSpark.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Azure/mmlspark/releases"&gt;&lt;img src="https://camo.githubusercontent.com/2b95bde9e35735d085f2a64e334564fddb1e792b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d6e6f7465732d626c7565" alt="Release Notes" data-canonical-src="https://img.shields.io/badge/release-notes-blue" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/scala/index.html#package" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9541c1e00ab17b5c0f31ab880f7da0d1dd06cff0/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d617069253230646f6373266d6573736167653d7363616c6126636f6c6f723d626c7565266c6f676f3d7363616c61" alt="Scala Docs" data-canonical-src="https://img.shields.io/static/v1?label=api%20docs&amp;amp;message=scala&amp;amp;color=blue&amp;amp;logo=scala" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/pyspark/index.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a5ac918a682fe9c6992a7f1ab12e204964a53997/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d617069253230646f6373266d6573736167653d707974686f6e26636f6c6f723d626c7565266c6f676f3d707974686f6e" alt="PySpark Docs" data-canonical-src="https://img.shields.io/static/v1?label=api%20docs&amp;amp;message=python&amp;amp;color=blue&amp;amp;logo=python" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/1810.08744" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/efa888257e8261153f5ff4f426ad4893fb84badc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61636164656d69632d70617065722d376664636637" alt="Academic Paper" data-canonical-src="https://img.shields.io/badge/academic-paper-7fdcf7" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Azure/mmlspark/releases"&gt;&lt;img src="https://camo.githubusercontent.com/14e16b347646015d0f380e887d184c59e4640b4e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d312e302e302d2d7263312d626c7565" alt="Version" data-canonical-src="https://img.shields.io/badge/version-1.0.0--rc1-blue" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="#sbt"&gt;&lt;img src="https://camo.githubusercontent.com/f2134790d60abaea58ea73bbeed0e0853de9e0f5/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f69636f6e732f6261646765732f6d61737465725f76657273696f6e332e737667" alt="Snapshot Version" data-canonical-src="https://mmlspark.blob.core.windows.net/icons/badges/master_version3.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MMLSpark is an ecosystem of tools aimed towards expanding the distributed computing framework
&lt;a href="https://github.com/apache/spark"&gt;Apache Spark&lt;/a&gt; in several new directions.
MMLSpark adds many deep learning and data science tools to the Spark ecosystem,
including seamless integration of Spark Machine Learning pipelines with &lt;a href="https://github.com/Microsoft/CNTK"&gt;Microsoft Cognitive Toolkit
(CNTK)&lt;/a&gt;, &lt;a href="https://github.com/Microsoft/LightGBM"&gt;LightGBM&lt;/a&gt; and
&lt;a href="http://www.opencv.org/" rel="nofollow"&gt;OpenCV&lt;/a&gt;. These tools enable powerful and highly-scalable predictive and analytical models
for a variety of datasources.&lt;/p&gt;
&lt;p&gt;MMLSpark also brings new networking capabilities to the Spark Ecosystem. With the HTTP on Spark project, users
can embed &lt;strong&gt;any&lt;/strong&gt; web service into their SparkML models. In this vein, MMLSpark provides easy to use
SparkML transformers for a wide variety of &lt;a href="https://azure.microsoft.com/en-us/services/cognitive-services/" rel="nofollow"&gt;Microsoft Cognitive Services&lt;/a&gt;. For production grade deployment, the Spark Serving project enables high throughput,
sub-millisecond latency web services, backed by your Spark cluster.&lt;/p&gt;
&lt;p&gt;MMLSpark requires Scala 2.11, Spark 2.3+, and either Python 2.7 or Python 3.5+.
See the API documentation &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/scala/index.html#package" rel="nofollow"&gt;for
Scala&lt;/a&gt; and &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/pyspark/index.html" rel="nofollow"&gt;for
PySpark&lt;/a&gt;.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;&lt;em&gt;Table of Contents&lt;/em&gt;&lt;/strong&gt;&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#notable-features"&gt;Notable features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#a-short-example"&gt;A short example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#setup-and-installation"&gt;Setup and installation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gpu-vm-setup"&gt;GPU VM Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#spark-package"&gt;Spark package&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-cloud"&gt;Databricks cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sbt"&gt;SBT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#building-from-source"&gt;Building from source&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#blogs-and-publications"&gt;Blogs and Publications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing--feedback"&gt;Contributing &amp;amp; feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-relevant-projects"&gt;Other relevant projects&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;h2&gt;&lt;a id="user-content-projects" class="anchor" aria-hidden="true" href="#projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/93b3b7e4dfc1a58a5a6bdbbe67177307c9a47359/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f76772d626c75652d6461726b2d6f72616e67652e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/93b3b7e4dfc1a58a5a6bdbbe67177307c9a47359/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f76772d626c75652d6461726b2d6f72616e67652e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/vw-blue-dark-orange.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bfbef7ae756b550d3bd2648aed3bff7a7ceb03eb/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f636f675f73657276696365735f6f6e5f737061726b5f322e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/bfbef7ae756b550d3bd2648aed3bff7a7ceb03eb/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f636f675f73657276696365735f6f6e5f737061726b5f322e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/cog_services_on_spark_2.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ae54b5e5042ab39028bdf52f6fe7b42c7a475f55/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6465636973696f6e5f747265655f7265636f6c6f722e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/ae54b5e5042ab39028bdf52f6fe7b42c7a475f55/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6465636973696f6e5f747265655f7265636f6c6f722e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/decision_tree_recolor.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2a836683e4c037d1c65a09cebf680b991f3cd07e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6d6c737061726b5f73657276696e675f7265636f6c6f722e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/2a836683e4c037d1c65a09cebf680b991f3cd07e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6d6c737061726b5f73657276696e675f7265636f6c6f722e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/mmlspark_serving_recolor.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Vowpal Wabbit on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;The Cognitive Services on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;LightGBM on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;Spark Serving&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Fast, Sparse, and Effective Text Analytics&lt;/td&gt;
&lt;td align="center"&gt;Leverage the Microsoft Cognitive Services at Unprecedented Scales in your existing SparkML pipelines&lt;/td&gt;
&lt;td align="center"&gt;Train Gradient Boosted Machines with LightGBM&lt;/td&gt;
&lt;td align="center"&gt;Serve any Spark Computation as a Web Service with Sub-Millisecond Latency&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/9ea135c7b4beaee0365bf05e2f35977c4f1b148e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6963726f736572766963655f7265636f6c6f722e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/9ea135c7b4beaee0365bf05e2f35977c4f1b148e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6963726f736572766963655f7265636f6c6f722e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/microservice_recolor.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e706b7bfec0b1030f979a12a938b99dad9c329ce/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f64697374726962757465645f646565705f7265636f6c6f722e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/e706b7bfec0b1030f979a12a938b99dad9c329ce/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f64697374726962757465645f646565705f7265636f6c6f722e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/distributed_deep_recolor.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a27a8de5e9aede55d8565c7109b2becd20bbd5ed/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f4c494d452e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/a27a8de5e9aede55d8565c7109b2becd20bbd5ed/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f4c494d452e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/LIME.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1b81d8cc571ba4b0e21fb975542089374ce3a72c/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f62696e64696e67732e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/1b81d8cc571ba4b0e21fb975542089374ce3a72c/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f62696e64696e67732e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/bindings.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;HTTP on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;CNTK on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;Lime on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;Spark Binding Autogeneration&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;An Integration Between Spark and the HTTP Protocol, enabling Distributed Microservice Orchestration&lt;/td&gt;
&lt;td align="center"&gt;Distributed Deep Learning with the Microsoft Cognitive Toolkit&lt;/td&gt;
&lt;td align="center"&gt;Distributed, Model Agnostic, Interpretations for Classifiers&lt;/td&gt;
&lt;td align="center"&gt;Automatically Generate Spark bindings for PySpark and SparklyR&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Create a deep image classifier with transfer learning (&lt;a href="notebooks/samples/DeepLearning%20-%20Flower%20Image%20Classification.ipynb" title="Deep Flower Classification"&gt;example 9&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Fit a LightGBM classification or regression model on a biochemical dataset
(&lt;a href="notebooks/samples/LightGBM%20-%20Quantile%20Regression%20for%20Drug%20Discovery.ipynb" title="Quantile Regression with LightGBM"&gt;example 3&lt;/a&gt;), to learn more check out the &lt;a href="docs/lightgbm.md"&gt;LightGBM documentation
page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Deploy a deep network as a distributed web service with &lt;a href="docs/mmlspark-serving.md"&gt;MMLSpark
Serving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Use web services in Spark with &lt;a href="docs/http.md"&gt;HTTP on Apache Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Use Bi-directional LSTMs from Keras for medical entity extraction
(&lt;a href="notebooks/samples/DeepLearning%20-%20BiLSTM%20Medical%20Entity%20Extraction.ipynb" title="Medical Entity Extraction"&gt;example 8&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Create a text analytics system on Amazon book reviews (&lt;a href="notebooks/samples/TextAnalytics%20-%20Amazon%20Book%20Reviews.ipynb" title="Amazon Book Reviews - TextFeaturizer"&gt;example 4&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Perform distributed hyperparameter tuning to identify Breast Cancer
(&lt;a href="notebooks/samples/HyperParameterTuning%20-%20Fighting%20Breast%20Cancer.ipynb" title="Hyperparameter Tuning with MMLSpark"&gt;example 5&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Easily ingest images from HDFS into Spark &lt;code&gt;DataFrame&lt;/code&gt; (&lt;a href="notebooks/samples/DeepLearning%20-%20CIFAR10%20Convolutional%20Network.ipynb" title="CIFAR10 CNTK CNN Evaluation"&gt;example 6&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Use OpenCV on Spark to manipulate images (&lt;a href="notebooks/samples/OpenCV%20-%20Pipeline%20Image%20Transformations.ipynb" title="Pipeline Image Transformations"&gt;example 7&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Train classification and regression models easily via implicit featurization
of data (&lt;a href="notebooks/samples/Classification%20-%20Adult%20Census.ipynb" title="Adult Census Income Training"&gt;example 1&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Train and evaluate a flight delay prediction system (&lt;a href="notebooks/samples/Regression%20-%20Flight%20Delays.ipynb" title="Regression Example with Flight Delay Dataset"&gt;example 2&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See our &lt;a href="notebooks/samples/"&gt;notebooks&lt;/a&gt; for all examples.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-a-short-example" class="anchor" aria-hidden="true" href="#a-short-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A short example&lt;/h2&gt;
&lt;p&gt;Below is an excerpt from a simple example of using a pre-trained CNN to
classify images in the CIFAR-10 dataset.  View the whole source code in notebook &lt;a href="notebooks/samples/DeepLearning%20-%20Flower%20Image%20Classification.ipynb" title="Deep Flower Classification"&gt;example 9&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;...&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; mmlspark
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Initialize CNTKModel and define input and output columns&lt;/span&gt;
cntkModel &lt;span class="pl-k"&gt;=&lt;/span&gt; mmlspark.cntk.CNTKModel() \
  .setInputCol(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;images&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).setOutputCol(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;output&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) \
  .setModelLocation(modelFile)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train on dataset with internal spark pipeline&lt;/span&gt;
scoredImages &lt;span class="pl-k"&gt;=&lt;/span&gt; cntkModel.transform(imagesWithLabels)
&lt;span class="pl-c1"&gt;...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="notebooks/samples/"&gt;other sample notebooks&lt;/a&gt; as well as the MMLSpark
documentation for &lt;a href="http://mmlspark.azureedge.net/docs/scala/" rel="nofollow"&gt;Scala&lt;/a&gt; and
&lt;a href="http://mmlspark.azureedge.net/docs/pyspark/" rel="nofollow"&gt;PySpark&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup-and-installation" class="anchor" aria-hidden="true" href="#setup-and-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup and installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-spark-package" class="anchor" aria-hidden="true" href="#spark-package"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spark package&lt;/h3&gt;
&lt;p&gt;MMLSpark can be conveniently installed on existing Spark clusters via the
&lt;code&gt;--packages&lt;/code&gt; option, examples:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;spark-shell --packages com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1
pyspark --packages com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1
spark-submit --packages com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1 MyApp.jar&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This can be used in other Spark contexts too. For example, you can use MMLSpark
in &lt;a href="https://github.com/Azure/aztk/"&gt;AZTK&lt;/a&gt; by &lt;a href="https://github.com/Azure/aztk/wiki/PySpark-on-Azure-with-AZTK#optional-set-up-mmlspark"&gt;adding it to the
&lt;code&gt;.aztk/spark-defaults.conf&lt;/code&gt;
file&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-databricks" class="anchor" aria-hidden="true" href="#databricks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Databricks&lt;/h3&gt;
&lt;p&gt;To install MMLSpark on the &lt;a href="http://community.cloud.databricks.com" rel="nofollow"&gt;Databricks
cloud&lt;/a&gt;, create a new &lt;a href="https://docs.databricks.com/user-guide/libraries.html#libraries-from-maven-pypi-or-spark-packages" rel="nofollow"&gt;library from Maven
coordinates&lt;/a&gt;
in your workspace.&lt;/p&gt;
&lt;p&gt;For the coordinates use: &lt;code&gt;com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1&lt;/code&gt;.  Ensure this library is
attached to all clusters you create.&lt;/p&gt;
&lt;p&gt;Finally, ensure that your Spark cluster has at least Spark 2.1 and Scala 2.11.&lt;/p&gt;
&lt;p&gt;You can use MMLSpark in both your Scala and PySpark notebooks. To get started with our example notebooks import the following databricks archive:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://mmlspark.blob.core.windows.net/dbcs/MMLSpark%20Examples%20v1.0.0-rc1.dbc&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h3&gt;
&lt;p&gt;The easiest way to evaluate MMLSpark is via our pre-built Docker container.  To
do so, run the following command:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;docker run -it -p 8888:8888 -e ACCEPT_EULA=yes mcr.microsoft.com/mmlspark/release&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Navigate to &lt;a href="http://localhost:8888/" rel="nofollow"&gt;http://localhost:8888/&lt;/a&gt; in your web browser to run the sample
notebooks.  See the &lt;a href="docs/docker.md"&gt;documentation&lt;/a&gt; for more on Docker use.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To read the EULA for using the docker image, run \
&lt;code&gt;docker run -it -p 8888:8888 mcr.microsoft.com/mmlspark/release eula&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-gpu-vm-setup" class="anchor" aria-hidden="true" href="#gpu-vm-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GPU VM Setup&lt;/h3&gt;
&lt;p&gt;MMLSpark can be used to train deep learning models on GPU nodes from a Spark
application.  See the instructions for &lt;a href="docs/gpu-setup.md"&gt;setting up an Azure GPU
VM&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-python" class="anchor" aria-hidden="true" href="#python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python&lt;/h3&gt;
&lt;p&gt;To try out MMLSpark on a Python (or Conda) installation you can get Spark
installed via pip with &lt;code&gt;pip install pyspark&lt;/code&gt;.  You can then use &lt;code&gt;pyspark&lt;/code&gt; as in
the above example, or from python:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; pyspark
spark &lt;span class="pl-k"&gt;=&lt;/span&gt; pyspark.sql.SparkSession.builder.appName(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MyApp&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) \
            .config(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;spark.jars.packages&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) \
            .getOrCreate()
&lt;span class="pl-k"&gt;import&lt;/span&gt; mmlspark&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-sbt" class="anchor" aria-hidden="true" href="#sbt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SBT&lt;/h3&gt;
&lt;p&gt;If you are building a Spark application in Scala, add the following lines to
your &lt;code&gt;build.sbt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;libraryDependencies &lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;com.microsoft.ml.spark&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;mmlspark&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1.0.0-rc1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-building-from-source" class="anchor" aria-hidden="true" href="#building-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building from source&lt;/h3&gt;
&lt;p&gt;MMLSpark has recently transitioned to a new build infrastructure.
For detailed developer docs please see the &lt;a href="docs/developer-readme.md"&gt;Developer Readme&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are an existing mmlspark developer, you will need to reconfigure your
development setup. We now support platform independent development and
better integrate with intellij and SBT.
If you encounter issues please reach out to our support email!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-r-beta" class="anchor" aria-hidden="true" href="#r-beta"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;R (Beta)&lt;/h3&gt;
&lt;p&gt;To try out MMLSpark using the R autogenerated wrappers &lt;a href="docs/R-setup.md"&gt;see our
instructions&lt;/a&gt;.  Note: This feature is still under development
and some necessary custom wrappers may be missing.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-learn-more" class="anchor" aria-hidden="true" href="#learn-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Visit our &lt;a href="https://mmlspark.blob.core.windows.net/website/index.html" title="aka.ms/spark" rel="nofollow"&gt;new website&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Watch our keynote demos at &lt;a href="https://youtu.be/T_fs4C0aqD0?t=425" rel="nofollow"&gt;the Spark+AI Summit 2019&lt;/a&gt;, &lt;a href="https://youtu.be/N3ozCZXeOeU?t=472" rel="nofollow"&gt;the Spark+AI European Summit 2018&lt;/a&gt;, and &lt;a href="https://databricks.com/sparkaisummit/north-america/spark-summit-2018-keynotes#Intelligent-cloud" title="Developing for the Intelligent Cloud and Intelligent Edge" rel="nofollow"&gt;the Spark+AI Summit 2018&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Read &lt;a href="https://arxiv.org/abs/1804.04031" title="Flexible and Scalable Deep Learning with MMLSpark" rel="nofollow"&gt;our paper&lt;/a&gt; for a deep dive on MMLSpark.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;See how MMLSpark is used to &lt;a href="https://www.microsoft.com/en-us/ai/ai-lab-stories?activetab=pivot1:primaryr3" title="Identifying snow leopards with AI" rel="nofollow"&gt;help endangered species&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Explore generative adversarial artwork in &lt;a href="https://www.microsoft.com/en-us/ai/ai-lab-stories?activetab=pivot1:primaryr4" title="Generative art at the MET" rel="nofollow"&gt;our collaboration with The MET and MIT&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Explore &lt;a href="https://blogs.technet.microsoft.com/machinelearning/2018/03/05/image-data-support-in-apache-spark/" title="Image Data Support in Apache Spark" rel="nofollow"&gt;our collaboration with Apache Spark&lt;/a&gt; on image analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/how-to-use-mmlspark" title="How to Use Microsoft Machine Learning Library for Apache Spark" rel="nofollow"&gt;MMLSpark in Azure Machine Learning&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing--feedback" class="anchor" aria-hidden="true" href="#contributing--feedback"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing &amp;amp; feedback&lt;/h2&gt;
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;.  For more
information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow"&gt;Code of Conduct FAQ&lt;/a&gt; or contact
&lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional
questions or comments.&lt;/p&gt;
&lt;p&gt;See &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for contribution guidelines.&lt;/p&gt;
&lt;p&gt;To give feedback and/or report an issue, open a &lt;a href="https://help.github.com/articles/creating-an-issue/"&gt;GitHub
Issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-other-relevant-projects" class="anchor" aria-hidden="true" href="#other-relevant-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other relevant projects&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/VowpalWabbit/vowpal_wabbit"&gt;Vowpal Wabbit&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/LightGBM"&gt;LightGBM&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/DMTK"&gt;DMTK: Microsoft Distributed Machine Learning Toolkit&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/Recommenders"&gt;Recommenders&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/alipay/jpmml-sparkml-lightgbm"&gt;JPMML-SparkML plugin for converting MMLSpark LightGBM models to
PMML&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/CNTK"&gt;Microsoft Cognitive Toolkit&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview" rel="nofollow"&gt;Azure Machine Learning
preview features&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Apache®, Apache Spark, and Spark® are either registered trademarks or
trademarks of the Apache Software Foundation in the United States and/or other
countries.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Azure</author><guid isPermaLink="false">https://github.com/Azure/mmlspark</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>awslabs/deequ #7 in Scala, Today</title><link>https://github.com/awslabs/deequ</link><description>&lt;p&gt;&lt;i&gt;Deequ is a library built on top of Apache Spark for defining "unit tests for data", which measure data quality in large datasets.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-deequ---unit-tests-for-data" class="anchor" aria-hidden="true" href="#deequ---unit-tests-for-data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deequ - Unit Tests for Data&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/awslabs/deequ/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/1045b5de6fdcc0a3c7877cb95e7f8fd81cef5f3e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6177736c6162732f64656571752e737667" alt="GitHub license" data-canonical-src="https://img.shields.io/github/license/awslabs/deequ.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/awslabs/deequ/issues"&gt;&lt;img src="https://camo.githubusercontent.com/fbec63ee353e2e60df7d4285b648497c4ad4cdf7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6177736c6162732f64656571752e737667" alt="GitHub issues" data-canonical-src="https://img.shields.io/github/issues/awslabs/deequ.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.org/awslabs/deequ" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/36231689f6444a98e8eae9a71a1190d5872a191c/68747470733a2f2f7472617669732d63692e6f72672f6177736c6162732f64656571752e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/awslabs/deequ.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://maven-badges.herokuapp.com/maven-central/com.amazon.deequ/deequ" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cfbf30d4e1b682e75b888314efc8250cf2412ea2/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f636f6d2e616d617a6f6e2e64656571752f64656571752f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/com.amazon.deequ/deequ/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Deequ is a library built on top of Apache Spark for defining "unit tests for data", which measure data quality in large datasets. We are happy to receive feedback and &lt;a href="CONTRIBUTING.md"&gt;contributions&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements-and-installation" class="anchor" aria-hidden="true" href="#requirements-and-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements and Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Deequ&lt;/strong&gt; depends on Java 8 and is known to work with Apache Spark versions 2.2.x to 2.4.x.&lt;/p&gt;
&lt;p&gt;Available via &lt;a href="http://mvnrepository.com/artifact/com.amazon.deequ/deequ" rel="nofollow"&gt;maven central&lt;/a&gt;.
Add the latest release as a dependency to your project:
&lt;strong&gt;Maven&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.amazon.deequ&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;deequ&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;1.0.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;sbt&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;libraryDependencies += "com.amazon.deequ" % "deequ" % "1.0.2"
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-example" class="anchor" aria-hidden="true" href="#example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Deequ&lt;/strong&gt;'s purpose is to "unit-test" data to find errors early, before the data gets fed to consuming systems or machine learning algorithms. In the following, we will walk you through a toy example to showcase the most basic usage of our library. An executable version of the example is available &lt;a href="/src/main/scala/com/amazon/deequ/examples/BasicExample.scala"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Deequ&lt;/strong&gt; works on tabular data, e.g., CSV files, database tables, logs, flattened json files, basically anything that you can fit into a Spark dataframe. For this example, we assume that we work on some kind of &lt;code&gt;Item&lt;/code&gt; data, where every item has an id, a productName, a description, a priority and a count of how often it has been viewed.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;case&lt;/span&gt; &lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;Item&lt;/span&gt;(
  &lt;span class="pl-v"&gt;id&lt;/span&gt;: &lt;span class="pl-k"&gt;Long&lt;/span&gt;,
  &lt;span class="pl-v"&gt;productName&lt;/span&gt;: &lt;span class="pl-k"&gt;String&lt;/span&gt;,
  &lt;span class="pl-v"&gt;description&lt;/span&gt;: &lt;span class="pl-k"&gt;String&lt;/span&gt;,
  &lt;span class="pl-v"&gt;priority&lt;/span&gt;: &lt;span class="pl-k"&gt;String&lt;/span&gt;,
  &lt;span class="pl-v"&gt;numViews&lt;/span&gt;: &lt;span class="pl-k"&gt;Long&lt;/span&gt;
)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our library is built on &lt;a href="https://spark.apache.org/" rel="nofollow"&gt;Apache Spark&lt;/a&gt; and is designed to work with very large datasets (think billions of rows) that typically live in a distributed filesystem or a data warehouse. For the sake of simplicity in this example, we just generate a few toy records though.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;rdd&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; spark.sparkContext.parallelize(&lt;span class="pl-en"&gt;Seq&lt;/span&gt;(
  &lt;span class="pl-en"&gt;Item&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Thingy A&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;awesome thing.&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;high&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;0&lt;/span&gt;),
  &lt;span class="pl-en"&gt;Item&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Thingy B&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;available at http://thingb.com&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;null&lt;/span&gt;, &lt;span class="pl-c1"&gt;0&lt;/span&gt;),
  &lt;span class="pl-en"&gt;Item&lt;/span&gt;(&lt;span class="pl-c1"&gt;3&lt;/span&gt;, &lt;span class="pl-c1"&gt;null&lt;/span&gt;, &lt;span class="pl-c1"&gt;null&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;low&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;5&lt;/span&gt;),
  &lt;span class="pl-en"&gt;Item&lt;/span&gt;(&lt;span class="pl-c1"&gt;4&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Thingy D&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;checkout https://thingd.ca&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;low&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;10&lt;/span&gt;),
  &lt;span class="pl-en"&gt;Item&lt;/span&gt;(&lt;span class="pl-c1"&gt;5&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Thingy E&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;null&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;high&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;12&lt;/span&gt;)))

&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;data&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; spark.createDataFrame(rdd)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Most applications that work with data have implicit assumptions about that data, e.g., that attributes have certain types, do not contain NULL values, and so on. If these assumptions are violated, your application might crash or produce wrong outputs. The idea behind &lt;strong&gt;deequ&lt;/strong&gt; is to explicitly state these assumptions in the form of a "unit-test" for data, which can be verified on a piece of data at hand. If the data has errors, we can "quarantine" and fix it, before we feed to an application.&lt;/p&gt;
&lt;p&gt;The main entry point for defining how you expect your data to look is the &lt;a href="src/main/scala/com/amazon/deequ/VerificationSuite.scala"&gt;VerificationSuite&lt;/a&gt; from which you can add &lt;a href="src/main/scala/com/amazon/deequ/checks/Check.scala"&gt;Checks&lt;/a&gt; that define constraints on attributes of the data. In this example, we test for the following properties of our data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there are 5 rows in total&lt;/li&gt;
&lt;li&gt;values of the &lt;code&gt;id&lt;/code&gt; attribute are never NULL and unique&lt;/li&gt;
&lt;li&gt;values of the &lt;code&gt;productName&lt;/code&gt; attribute are never NULL&lt;/li&gt;
&lt;li&gt;the &lt;code&gt;priority&lt;/code&gt; attribute can only contain "high" or "low" as value&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numViews&lt;/code&gt; should not contain negative values&lt;/li&gt;
&lt;li&gt;at least half of the values in &lt;code&gt;description&lt;/code&gt; should contain a url&lt;/li&gt;
&lt;li&gt;the median of &lt;code&gt;numViews&lt;/code&gt; should be less than or equal to 10&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In code this looks as follows:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;com&lt;/span&gt;.&lt;span class="pl-en"&gt;amazon&lt;/span&gt;.&lt;span class="pl-en"&gt;deequ&lt;/span&gt;.&lt;span class="pl-en"&gt;VerificationSuite&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;com&lt;/span&gt;.&lt;span class="pl-en"&gt;amazon&lt;/span&gt;.&lt;span class="pl-en"&gt;deequ&lt;/span&gt;.&lt;span class="pl-en"&gt;checks&lt;/span&gt;.{&lt;span class="pl-en"&gt;Check&lt;/span&gt;, &lt;span class="pl-en"&gt;CheckLevel&lt;/span&gt;, &lt;span class="pl-en"&gt;CheckStatus&lt;/span&gt;}


&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;verificationResult&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;VerificationSuite&lt;/span&gt;()
  .onData(data)
  .addCheck(
    &lt;span class="pl-en"&gt;Check&lt;/span&gt;(&lt;span class="pl-en"&gt;CheckLevel&lt;/span&gt;.&lt;span class="pl-en"&gt;Error&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;unit testing my data&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
      .hasSize(_ &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-c1"&gt;5&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; we expect 5 rows&lt;/span&gt;
      .isComplete(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; should never be NULL&lt;/span&gt;
      .isUnique(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;id&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; should not contain duplicates&lt;/span&gt;
      .isComplete(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;productName&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; should never be NULL&lt;/span&gt;
      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; should only contain the values "high" and "low"&lt;/span&gt;
      .isContainedIn(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;priority&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-en"&gt;Array&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;high&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;low&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))
      .isNonNegative(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;numViews&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; should not contain negative values&lt;/span&gt;
      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; at least half of the descriptions should contain a url&lt;/span&gt;
      .containsURL(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;description&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, _ &lt;span class="pl-k"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;0.5&lt;/span&gt;)
      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; half of the items should have less than 10 views&lt;/span&gt;
      .hasApproxQuantile(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;numViews&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-c1"&gt;0.5&lt;/span&gt;, _ &lt;span class="pl-k"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;10&lt;/span&gt;))
    .run()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After calling &lt;code&gt;run&lt;/code&gt;, &lt;strong&gt;deequ&lt;/strong&gt; translates your test to a series of Spark jobs, which it executes to compute metrics on the data. Afterwards it invokes your assertion functions (e.g., &lt;code&gt;_ == 5&lt;/code&gt; for the size check) on these metrics to see if the constraints hold on the data. We can inspect the &lt;a href="src/main/scala/com/amazon/deequ/VerificationResult.scala"&gt;VerificationResult&lt;/a&gt; to see if the test found errors:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;com&lt;/span&gt;.&lt;span class="pl-en"&gt;amazon&lt;/span&gt;.&lt;span class="pl-en"&gt;deequ&lt;/span&gt;.&lt;span class="pl-en"&gt;constraints&lt;/span&gt;.&lt;span class="pl-en"&gt;ConstraintStatus&lt;/span&gt;


&lt;span class="pl-k"&gt;if&lt;/span&gt; (verificationResult.status &lt;span class="pl-k"&gt;==&lt;/span&gt; &lt;span class="pl-en"&gt;CheckStatus&lt;/span&gt;.&lt;span class="pl-en"&gt;Success&lt;/span&gt;) {
  println(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;The data passed the test, everything is fine!&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
} &lt;span class="pl-k"&gt;else&lt;/span&gt; {
  println(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;We found errors in the data:&lt;span class="pl-cce"&gt;\n&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)

  &lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;resultsForAllConstraints&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; verificationResult.checkResults
    .flatMap { &lt;span class="pl-k"&gt;case&lt;/span&gt; (_, checkResult) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; checkResult.constraintResults }

  resultsForAllConstraints
    .filter { _.status &lt;span class="pl-k"&gt;!=&lt;/span&gt; &lt;span class="pl-en"&gt;ConstraintStatus&lt;/span&gt;.&lt;span class="pl-en"&gt;Success&lt;/span&gt; }
    .foreach { result &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; println(&lt;span class="pl-k"&gt;s&lt;/span&gt;&lt;span class="pl-s"&gt;"&lt;/span&gt;${result.constraint}&lt;span class="pl-s"&gt;: &lt;/span&gt;${result.message.get}&lt;span class="pl-s"&gt;"&lt;/span&gt;) }
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we run the example, we get the following output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;We found errors in the data:

CompletenessConstraint(Completeness(productName)): Value: 0.8 does not meet the requirement!
PatternConstraint(containsURL(description)): Value: 0.4 does not meet the requirement!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The test found that our assumptions are violated! Only 4 out of 5 (80%) of the values of the &lt;code&gt;productName&lt;/code&gt; attribute are non-null and only 2 out of 5 (40%) values of the &lt;code&gt;description&lt;/code&gt; attribute contained a url. Fortunately, we ran a test and found the errors, somebody should immediately fix the data :)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-more-examples" class="anchor" aria-hidden="true" href="#more-examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More examples&lt;/h2&gt;
&lt;p&gt;Our library contains much more functionaliy than what we showed in the basic example. We are in the process of adding &lt;a href="src/main/scala/com/amazon/deequ/examples/"&gt;more examples&lt;/a&gt; for its advanced features. So far, we showcase the following functionality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/metrics_repository_example.md"&gt;Persistence and querying of computed metrics of the data with a MetricsRepository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/data_profiling_example.md"&gt;Data profiling&lt;/a&gt; of large data sets&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/anomaly_detection_example.md"&gt;Anomaly detection&lt;/a&gt; on data quality metrics over time&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/constraint_suggestion_example.md"&gt;Automatic suggestion of constraints&lt;/a&gt; for large datasets&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/algebraic_states_example.md"&gt;Incremental metrics computation on growing data and metric updates on partitioned data&lt;/a&gt; (advanced)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-citation" class="anchor" aria-hidden="true" href="#citation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you would like to reference this package in a research paper, please cite:&lt;/p&gt;
&lt;p&gt;Sebastian Schelter, Dustin Lange, Philipp Schmidt, Meltem Celikel, Felix Biessmann, and Andreas Grafberger. 2018. &lt;a href="http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf" rel="nofollow"&gt;Automating large-scale data quality verification&lt;/a&gt;. Proc. VLDB Endow. 11, 12 (August 2018), 1781-1794.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;This library is licensed under the Apache 2.0 License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>awslabs</author><guid isPermaLink="false">https://github.com/awslabs/deequ</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>delta-io/delta #8 in Scala, Today</title><link>https://github.com/delta-io/delta</link><description>&lt;p&gt;&lt;i&gt;An open-source storage layer that brings scalable, ACID transactions to Apache Spark™ and big data workloads.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/4aa10978589db1cffdd8a31bec9e4d052ddc66f1/68747470733a2f2f646f63732e64656c74612e696f2f6c61746573742f5f7374617469632f64656c74612d6c616b652d77686974652e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/4aa10978589db1cffdd8a31bec9e4d052ddc66f1/68747470733a2f2f646f63732e64656c74612e696f2f6c61746573742f5f7374617469632f64656c74612d6c616b652d77686974652e706e67" width="400" alt="Delta Lake Logo" data-canonical-src="https://docs.delta.io/latest/_static/delta-lake-white.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/delta-io/delta/tree/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/be74f3c65b07652b211eff6ee1469f3809e92c0a/68747470733a2f2f636972636c6563692e636f6d2f67682f64656c74612d696f2f64656c74612f747265652f6d61737465722e7376673f7374796c653d737667" alt="CircleCI" data-canonical-src="https://circleci.com/gh/delta-io/delta/tree/master.svg?style=svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Delta Lake is a storage layer that brings scalable, ACID transactions to &lt;a href="https://spark.apache.org" rel="nofollow"&gt;Apache Spark&lt;/a&gt; and other big-data engines.&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://docs.delta.io" rel="nofollow"&gt;Delta Lake Documentation&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://docs.delta.io/latest/quick-start.html" rel="nofollow"&gt;Quick Start Guide&lt;/a&gt; to get started with Scala, Java and Python.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-latest-binaries" class="anchor" aria-hidden="true" href="#latest-binaries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Latest Binaries&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-maven" class="anchor" aria-hidden="true" href="#maven"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Maven&lt;/h3&gt;
&lt;p&gt;You include Delta Lake in your Maven project by adding it as a dependency in your POM file. Delta Lake is cross compiled with Scala versions 2.11 and 2.12; choose the version that matches your project. If you are writing a Java project, you can use either version.&lt;/p&gt;
&lt;div class="highlight highlight-text-xml"&gt;&lt;pre&gt;&amp;lt;&lt;span class="pl-ent"&gt;dependency&lt;/span&gt;&amp;gt;
  &amp;lt;&lt;span class="pl-ent"&gt;groupId&lt;/span&gt;&amp;gt;io.delta&amp;lt;/&lt;span class="pl-ent"&gt;groupId&lt;/span&gt;&amp;gt;
  &amp;lt;&lt;span class="pl-ent"&gt;artifactId&lt;/span&gt;&amp;gt;delta-core_2.11&amp;lt;/&lt;span class="pl-ent"&gt;artifactId&lt;/span&gt;&amp;gt;
  &amp;lt;&lt;span class="pl-ent"&gt;version&lt;/span&gt;&amp;gt;0.4.0&amp;lt;/&lt;span class="pl-ent"&gt;version&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span class="pl-ent"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-sbt" class="anchor" aria-hidden="true" href="#sbt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SBT&lt;/h3&gt;
&lt;p&gt;You include Delta Lake in your SBT project by adding the following line to your build.sbt file:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;libraryDependencies &lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;io.delta&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;delta-core&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;0.4.0&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-api-documentation" class="anchor" aria-hidden="true" href="#api-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.delta.io/latest/delta-apidoc.html" rel="nofollow"&gt;Scala API docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.delta.io/latest/api/java/index.html" rel="nofollow"&gt;Java API docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.delta.io/latest/api/python/index.html" rel="nofollow"&gt;Python API docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-compatibility" class="anchor" aria-hidden="true" href="#compatibility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compatibility&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-compatibility-with-apache-spark-versions" class="anchor" aria-hidden="true" href="#compatibility-with-apache-spark-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Compatibility with Apache Spark Versions&lt;/h3&gt;
&lt;p&gt;Delta Lake currently requires Apache Spark 2.4.2. Earlier versions are missing &lt;a href="https://issues.apache.org/jira/browse/SPARK-27453" rel="nofollow"&gt;SPARK-27453&lt;/a&gt;, which breaks the &lt;code&gt;partitionBy&lt;/code&gt; clause of the &lt;code&gt;DataFrameWriter&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-api-compatibility" class="anchor" aria-hidden="true" href="#api-compatibility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API Compatibility&lt;/h3&gt;
&lt;p&gt;The only stable, public APIs currently provided by Delta Lake are through the &lt;code&gt;DataFrameReader&lt;/code&gt;/&lt;code&gt;Writer&lt;/code&gt; (i.e. &lt;code&gt;spark.read&lt;/code&gt;, &lt;code&gt;df.write&lt;/code&gt;, &lt;code&gt;spark.readStream&lt;/code&gt; and &lt;code&gt;df.writeStream&lt;/code&gt;). Options to these APIs will remain stable within a major release of Delta Lake (e.g., 1.x.x).&lt;/p&gt;
&lt;p&gt;All other interfaces in the this library are considered internal, and they are subject to change across minor / patch releases.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-data-storage-compatibility" class="anchor" aria-hidden="true" href="#data-storage-compatibility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data Storage Compatibility&lt;/h3&gt;
&lt;p&gt;Delta Lake guarantees backward compatibility for all Delta Lake tables (i.e., newer versions of Delta Lake will always be able to read tables written by older versions of Delta Lake). However, we reserve the right to break forwards compatibility as new features are introduced to the transaction protocol (i.e., an older version of Delta Lake may not be able to read a table produced by a newer version).&lt;/p&gt;
&lt;p&gt;Breaking changes in the protocol are indicated by incrementing the minimum reader/writer version in the &lt;code&gt;Protocol&lt;/code&gt; &lt;a href="https://github.com/delta-io/delta/blob/master/src/main/scala/org/apache/spark/sql/delta/actions/actions.scala"&gt;action&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-roadmap" class="anchor" aria-hidden="true" href="#roadmap"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Roadmap&lt;/h2&gt;
&lt;p&gt;Delta Lake is a recent open source project based on technology developed at Databricks. We plan to open-source all APIs that are required to correctly run Spark programs that read and write Delta tables. For a detailed timeline on this effort see the &lt;a href="https://github.com/delta-io/delta/milestones"&gt;project roadmap&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-building" class="anchor" aria-hidden="true" href="#building"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building&lt;/h1&gt;
&lt;p&gt;Delta Lake Core is compiled using &lt;a href="https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html" rel="nofollow"&gt;SBT&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To compile, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;build/sbt compile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate artifacts, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;build/sbt package
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To execute tests, run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;build/sbt test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Refer to &lt;a href="https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html" rel="nofollow"&gt;SBT docs&lt;/a&gt; for more commands.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-transaction-protocol" class="anchor" aria-hidden="true" href="#transaction-protocol"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transaction Protocol&lt;/h1&gt;
&lt;p&gt;&lt;a href="PROTOCOL.md"&gt;Delta Transaction Log Protocol&lt;/a&gt; document provides a specification of the transaction protocol.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-requirements-for-underlying-storage-systems" class="anchor" aria-hidden="true" href="#requirements-for-underlying-storage-systems"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements for Underlying Storage Systems&lt;/h2&gt;
&lt;p&gt;Delta Lake ACID guarantees are predicated on the atomicity and durability guarantees of the storage system. Specifically, we require the storage system to provide the following.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Atomic visibility&lt;/strong&gt;: There must be a way for a file to be visible in its entirety or not visible at all.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mutual exclusion&lt;/strong&gt;: Only one writer must be able to create (or rename) a file at the final destination.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistent listing&lt;/strong&gt;: Once a file has been written in a directory, all future listings for that directory must return that file.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Given that storage systems do not necessarily provide all of these guarantees out-of-the-box, Delta Lake transactional operations typically go through the &lt;a href="https://github.com/delta-io/delta/blob/master/src/main/scala/org/apache/spark/sql/delta/storage/LogStore.scala"&gt;LogStore API&lt;/a&gt; instead of accessing the storage system directly. We can plug in custom &lt;code&gt;LogStore&lt;/code&gt; implementations in order to provide the above guarantees for different storage systems. Delta Lake has built-in &lt;code&gt;LogStore&lt;/code&gt; implementations for HDFS, Amazon S3 and Azure storage services. Please see &lt;a href="https://docs.delta.io/latest/delta-storage.html" rel="nofollow"&gt;Delta Lake Storage Configuration&lt;/a&gt; for more details. If you are interested in adding a custom &lt;code&gt;LogStore&lt;/code&gt; implementation for your storage system, you can start discussions in the community mailing group.&lt;/p&gt;
&lt;p&gt;As an optimization, storage systems can also allow &lt;em&gt;partial listing of a directory, given a start marker&lt;/em&gt;. Delta Lake can use this ability to efficiently discover the latest version of a table, without listing all of the files in the transaction log.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-concurrency-control" class="anchor" aria-hidden="true" href="#concurrency-control"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Concurrency Control&lt;/h2&gt;
&lt;p&gt;Delta Lake ensures &lt;em&gt;serializability&lt;/em&gt; for concurrent reads and writes. Please see &lt;a href="https://docs.delta.io/latest/delta-concurrency.html" rel="nofollow"&gt;Delta Lake Concurrency Control&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-reporting-issues" class="anchor" aria-hidden="true" href="#reporting-issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reporting issues&lt;/h1&gt;
&lt;p&gt;We use &lt;a href="https://github.com/delta-io/delta/issues"&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href="#community"&gt;contact&lt;/a&gt; the community for getting answers.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h1&gt;
&lt;p&gt;We welcome contributions to Delta Lake. We use &lt;a href="https://github.com/delta-io/delta/pulls"&gt;GitHub Pull Requests &lt;/a&gt; for accepting changes. You will be prompted to sign a contributor license agreement before your change can be accepted.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h1&gt;
&lt;p&gt;There are two mediums of communication within the Delta Lake community.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Public Slack Channel&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://join.slack.com/t/delta-users/shared_invite/enQtNTY1NDg0ODcxOTI1LWJkZGU3ZmQ3MjkzNmY2ZDM0NjNlYjE4MWIzYjg2OWM1OTBmMWIxZTllMjg3ZmJkNjIwZmE1ZTZkMmQ0OTk5ZjA" rel="nofollow"&gt;Register here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://delta-users.slack.com/" rel="nofollow"&gt;Login here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Public &lt;a href="https://groups.google.com/forum/#!forum/delta-users" rel="nofollow"&gt;Mailing list&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>delta-io</author><guid isPermaLink="false">https://github.com/delta-io/delta</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>akka/akka #9 in Scala, Today</title><link>https://github.com/akka/akka</link><description>&lt;p&gt;&lt;i&gt;Build highly concurrent, distributed, and resilient message-driven applications on the JVM&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-akka-" class="anchor" aria-hidden="true" href="#akka-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Akka &lt;a href="https://index.scala-lang.org/akka/akka/akka-actor" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/daa5c167ea3ca8f58e68ed88dff62778a82842e0/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f616b6b612f616b6b612f616b6b612d6163746f722f6c61746573742e737667" alt="Latest version" data-canonical-src="https://index.scala-lang.org/akka/akka/akka-actor/latest.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;a href="https://travis-ci.org/akka/akka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/dc52832ba0357978d2f5d50a7ea216ead427290b/68747470733a2f2f7472617669732d63692e6f72672f616b6b612f616b6b612e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/akka/akka.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We believe that writing correct concurrent &amp;amp; distributed, resilient and elastic applications is too hard.
Most of the time it's because we are using the wrong tools and the wrong level of abstraction.&lt;/p&gt;
&lt;p&gt;Akka is here to change that.&lt;/p&gt;
&lt;p&gt;Using the Actor Model we raise the abstraction level and provide a better platform to build correct concurrent and scalable applications. This model is a perfect match for the principles laid out in the &lt;a href="http://www.reactivemanifesto.org/" rel="nofollow"&gt;Reactive Manifesto&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For resilience, we adopt the "Let it crash" model which the telecom industry has used with great success to build applications that self-heal and systems that never stop.&lt;/p&gt;
&lt;p&gt;Actors also provide the abstraction for transparent distribution and the basis for truly scalable and fault-tolerant applications.&lt;/p&gt;
&lt;p&gt;Learn more at &lt;a href="http://akka.io/" rel="nofollow"&gt;akka.io&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-reference-documentation" class="anchor" aria-hidden="true" href="#reference-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reference Documentation&lt;/h2&gt;
&lt;p&gt;The reference documentation is available at &lt;a href="http://doc.akka.io" rel="nofollow"&gt;doc.akka.io&lt;/a&gt;,
for &lt;a href="http://doc.akka.io/docs/akka/current/scala.html" rel="nofollow"&gt;Scala&lt;/a&gt; and &lt;a href="http://doc.akka.io/docs/akka/current/java.html" rel="nofollow"&gt;Java&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;You can join these groups and chats to discuss and ask Akka related questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forums: &lt;a href="https://discuss.akka.io" rel="nofollow"&gt;discuss.akka.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Chat room about &lt;em&gt;using&lt;/em&gt; Akka: &lt;a href="https://gitter.im/akka/akka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f9e40f1fe5bdc832a177e1a241915b4521db7272/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769747465722533412d616b6b61253246616b6b612d626c75652e7376673f7374796c653d666c61742d737175617265" alt="gitter: akka/akka" data-canonical-src="https://img.shields.io/badge/gitter%3A-akka%2Fakka-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Issue tracker: &lt;a href="https://github.com/akka/akka/issues"&gt;&lt;img src="https://camo.githubusercontent.com/b278eef1d47203c00101c53e739670458e8252b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769746875622533412d6973737565732d626c75652e7376673f7374796c653d666c61742d737175617265" alt="github: akka/akka" data-canonical-src="https://img.shields.io/badge/github%3A-issues-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to that, you may enjoy following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href="http://akka.io/news" rel="nofollow"&gt;news&lt;/a&gt; section of the page, which is updated whenever a new version is released&lt;/li&gt;
&lt;li&gt;The &lt;a href="http://blog.akka.io" rel="nofollow"&gt;Akka Team Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/akkateam" rel="nofollow"&gt;@akkateam&lt;/a&gt; on Twitter&lt;/li&gt;
&lt;li&gt;Questions tagged &lt;a href="http://stackoverflow.com/questions/tagged/akka" rel="nofollow"&gt;#akka on StackOverflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Projects built with Akka: &lt;a href="https://index.scala-lang.org/search?q=dependencies:akka/*" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a308ec8472732fc10c01d6004aaf761eea2a7080/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f636f756e742e7376673f713d646570656e64656e636965733a616b6b612f2a267375626a6563743d7363616c616465783a26636f6c6f723d626c7565267374796c653d666c61742d737175617265" alt="akka-dependency-badge" title="Built with Akka" data-canonical-src="https://index.scala-lang.org/count.svg?q=dependencies:akka/*&amp;amp;subject=scaladex:&amp;amp;color=blue&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Contributions are &lt;em&gt;very&lt;/em&gt; welcome!&lt;/p&gt;
&lt;p&gt;If you see an issue that you'd like to see fixed, the best way to make it happen is to help out by submitting a pull request implementing it.&lt;/p&gt;
&lt;p&gt;Refer to the &lt;a href="https://github.com/akka/akka/blob/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file for more details about the workflow,
and general hints on how to prepare your pull request. You can also ask for clarifications or guidance in GitHub issues directly,
or in the akka/dev chat if a more real time communication would be of benefit.&lt;/p&gt;
&lt;p&gt;A chat room is available for all questions related to &lt;em&gt;developing and contributing&lt;/em&gt; to Akka:
&lt;a href="https://gitter.im/akka/dev" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0a6c1891578680ac0418fb1b4e8beb0bbb1e00a8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769747465722533412d616b6b612532466465762d626c75652e7376673f7374796c653d666c61742d737175617265" alt="gitter: akka/dev" data-canonical-src="https://img.shields.io/badge/gitter%3A-akka%2Fdev-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Akka is Open Source and available under the Apache 2 License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>akka</author><guid isPermaLink="false">https://github.com/akka/akka</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>scalameta/metals #10 in Scala, Today</title><link>https://github.com/scalameta/metals</link><description>&lt;p&gt;&lt;i&gt;Scala language server with rich IDE features 🚀 &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-metals" class="anchor" aria-hidden="true" href="#metals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Metals&lt;/h1&gt;
&lt;a href="https://travis-ci.org/scalameta/metals" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/a2524f52634adb07fd59d018693f072f552a90d0/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f7363616c616d6574612f6d6574616c732f6d61737465722e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/travis/scalameta/metals/master.svg?style=flat-square" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://gitter.im/scalameta/metals" rel="nofollow"&gt;
&lt;img alt="Join the chat on Gitter" src="https://camo.githubusercontent.com/f7f01ae811427cbf536fb8047f67b2578a4cbe67/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f7363616c616d6574612f6d6574616c732e7376673f6c6f676f3d676974746572267374796c653d666c61742d73717561726526636f6c6f723d463731323633" data-canonical-src="https://img.shields.io/gitter/room/scalameta/metals.svg?logo=gitter&amp;amp;style=flat-square&amp;amp;color=F71263" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://twitter.com/scalameta" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/1079a3a4332d6c0fc38218766326dd730d3b2db4/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7363616c616d6574612e7376673f6c6f676f3d74776974746572267374796c653d666c61742d73717561726526636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/twitter/follow/scalameta.svg?logo=twitter&amp;amp;style=flat-square&amp;amp;color=blue" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://index.scala-lang.org/scalameta/metals/metals" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/809e4a056728ca7f7ab406a3308a2e35e708a4fb/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f7363616c616d6574612f6d6574616c732f6d6574616c732f6c61746573742e737667" data-canonical-src="https://index.scala-lang.org/scalameta/metals/metals/latest.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;See the website: &lt;a href="https://scalameta.org/metals/" rel="nofollow"&gt;https://scalameta.org/metals/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;See the contributing guide:
&lt;a href="https://scalameta.org/metals/docs/contributors/getting-started.html" rel="nofollow"&gt;https://scalameta.org/metals/docs/contributors/getting-started.html&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-team" class="anchor" aria-hidden="true" href="#team"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Team&lt;/h3&gt;
&lt;p&gt;The current maintainers (people who can merge pull requests) are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alexey Alekhin - &lt;a href="https://github.com/laughedelic"&gt;&lt;code&gt;@laughedelic&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gabriele Petronella - &lt;a href="https://github.com/gabro"&gt;&lt;code&gt;@gabro&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Johan Mudsam - &lt;a href="https://github.com/mudsam"&gt;&lt;code&gt;@mudsam&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jorge Vicente Cantero - &lt;a href="https://github.com/jvican"&gt;&lt;code&gt;@jvican&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Marek Żarnowski - &lt;a href="https://github.com/marek1840"&gt;&lt;code&gt;@marek1840&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ólafur Páll Geirsson - &lt;a href="https://github.com/olafurpg"&gt;&lt;code&gt;@olafurpg&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Shane Delmore - &lt;a href="https://github.com/ShaneDelmore"&gt;&lt;code&gt;@ShaneDelmore&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tomasz Godzik - &lt;a href="https://github.com/tgodzik"&gt;&lt;code&gt;@tgodzik&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;Huge thanks to &lt;a href="https://github.com/dragos"&gt;&lt;code&gt;@dragos&lt;/code&gt;&lt;/a&gt; for his work on a Scala
implementation of the LSP (see: &lt;a href="https://github.com/dragos/dragos-vscode-scala"&gt;https://github.com/dragos/dragos-vscode-scala&lt;/a&gt;).
This project helped us get quickly started with LSP. Since then, we have
refactored the project's original sources to the point where only a few simple
case classes remain.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-alternatives" class="anchor" aria-hidden="true" href="#alternatives"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternatives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jetbrains.com/help/idea/discover-intellij-idea-for-scala.html" rel="nofollow"&gt;IntelliJ IDEA&lt;/a&gt;:
the most widely used IDE for Scala using a re-implementation of the Scala
typechecker.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scala-ide.org/" rel="nofollow"&gt;Scala IDE&lt;/a&gt;: Eclipse-based IDE using the Scala
Presentation Compiler.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-why-metals" class="anchor" aria-hidden="true" href="#why-metals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Metals?&lt;/h2&gt;
&lt;p&gt;Metals = Meta (from Scalameta) + LS (from Language Server)&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>scalameta</author><guid isPermaLink="false">https://github.com/scalameta/metals</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>lagom/lagom #11 in Scala, Today</title><link>https://github.com/lagom/lagom</link><description>&lt;p&gt;&lt;i&gt;Reactive Microservices for the JVM&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://gitter.im/lagom/lagom?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6874dcd51a1c45579efb9156c2697f58c697b32c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e2532306769747465722d707572706c652e737667" alt="Gitter" data-canonical-src="https://img.shields.io/badge/chat-on%20gitter-purple.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/lagom/contributors?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d50e5f2c1668e62610d341583bd25709ab1bcdcf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d636f6e7472696275746f72732532306368616e6e656c2d707572706c652e737667" alt="Join the contributors chat at https://gitter.im/lagom/contributors" data-canonical-src="https://img.shields.io/badge/chat-contributors%20channel-purple.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://travis-ci.com/lagom/lagom" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0cd310cce25adba156cf841e87ad69632d31946f/68747470733a2f2f7472617669732d63692e636f6d2f6c61676f6d2f6c61676f6d2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/lagom/lagom.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.codetriage.com/lagom/lagom" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/1a03e1dca339ee3dbe961a771bddda61f99b302e/68747470733a2f2f7777772e636f64657472696167652e636f6d2f6c61676f6d2f6c61676f6d2f6261646765732f75736572732e737667" alt="Open Source Helpers" data-canonical-src="https://www.codetriage.com/lagom/lagom/badges/users.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-lagom---the-reactive-microservices-framework" class="anchor" aria-hidden="true" href="#lagom---the-reactive-microservices-framework"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lagom - The Reactive Microservices Framework&lt;/h1&gt;
&lt;p&gt;Lagom is a Swedish word meaning &lt;em&gt;just right, sufficient&lt;/em&gt;. Microservices are about creating services that are just the right size, that is, they have just the right level of functionality and isolation to be able to adequately implement a scalable and resilient system.&lt;/p&gt;
&lt;p&gt;Lagom focuses on ensuring that your application realizes the full potential of the &lt;a href="http://reactivemanifesto.org" rel="nofollow"&gt;Reactive Manifesto&lt;/a&gt; while delivering a high productivity development environment, and seamless production deployment experience.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-learn-more" class="anchor" aria-hidden="true" href="#learn-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.lagomframework.com" rel="nofollow"&gt;Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lagomframework.com/download.html" rel="nofollow"&gt;Download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.lagomframework.com/documentation" rel="nofollow"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://discuss.lagomframework.com" rel="nofollow"&gt;Discuss Lagom Forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/questions/ask?tags=lagom" rel="nofollow"&gt;Get help on Stack Overflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gitter.im/lagom/lagom" rel="nofollow"&gt;Community Gitter Chat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gitter.im/lagom/contributors" rel="nofollow"&gt;Contributors Gitter Chat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright (C) 2016-2019 Lightbend Inc. (&lt;a href="https://www.lightbend.com" rel="nofollow"&gt;https://www.lightbend.com&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this project except in compliance with the License. You may obtain a copy of the License at &lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lagom</author><guid isPermaLink="false">https://github.com/lagom/lagom</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>broadinstitute/cromwell #12 in Scala, Today</title><link>https://github.com/broadinstitute/cromwell</link><description>&lt;p&gt;&lt;i&gt;Scientific workflow engine designed for simplicity &amp; scalability. Trivially transition between one off use cases to massive scale production environments&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://travis-ci.com/broadinstitute/cromwell?branch=develop" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a528511f36f16df967c45eaeb126329a1d3b8fb2/68747470733a2f2f7472617669732d63692e636f6d2f62726f6164696e737469747574652f63726f6d77656c6c2e7376673f6272616e63683d646576656c6f70" alt="Build Status" data-canonical-src="https://travis-ci.com/broadinstitute/cromwell.svg?branch=develop" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/broadinstitute/cromwell" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a094e3047407af256b170cf2eed35f2e9886cc47/68747470733a2f2f636f6465636f762e696f2f67682f62726f6164696e737469747574652f63726f6d77656c6c2f6272616e63682f646576656c6f702f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/broadinstitute/cromwell/branch/develop/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-welcome-to-cromwell" class="anchor" aria-hidden="true" href="#welcome-to-cromwell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to Cromwell&lt;/h2&gt;
&lt;p&gt;Cromwell is a Workflow Management System geared towards scientific workflows. Cromwell is open sourced under the &lt;a href="LICENSE.txt"&gt;BSD 3-Clause license&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Cromwell documentation has a new home, &lt;a href="http://cromwell.readthedocs.io/en/develop" rel="nofollow"&gt;click here to check it out&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;First time to Cromwell? Get started with &lt;a href="http://cromwell.readthedocs.io/en/develop/tutorials/FiveMinuteIntro/" rel="nofollow"&gt;Tutorials&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Thinking about contributing to Cromwell? Get started by reading our &lt;a href="CONTRIBUTING.md"&gt;Contributor Guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-issue-tracking-is-now-on-jira" class="anchor" aria-hidden="true" href="#issue-tracking-is-now-on-jira"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Issue tracking is now on JIRA&lt;/h3&gt;
&lt;p&gt;Need to file an issue? Head over to &lt;a href="https://broadworkbench.atlassian.net/projects/BA/issues" rel="nofollow"&gt;our JIRA&lt;/a&gt;. You can sign in with any Google account.&lt;/p&gt;
&lt;p&gt;As of May 2019, we are in the process of migrating all issues from Github to JIRA. At a later date to be announced, submitting new Github issues will be disabled.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/jamie_the_cromwell_pig.png"&gt;&lt;img src="docs/jamie_the_cromwell_pig.png" alt="Jamie, the Cromwell pig" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>broadinstitute</author><guid isPermaLink="false">https://github.com/broadinstitute/cromwell</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>rtyley/bfg-repo-cleaner #13 in Scala, Today</title><link>https://github.com/rtyley/bfg-repo-cleaner</link><description>&lt;p&gt;&lt;i&gt;Removes large or troublesome blobs like git-filter-branch does, but faster. And written in Scala&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bfg-repo-cleaner-" class="anchor" aria-hidden="true" href="#bfg-repo-cleaner-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BFG Repo-Cleaner &lt;a href="https://travis-ci.org/rtyley/bfg-repo-cleaner" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/763e7a896452f78e6d46e90e89b48dfe1580cf83/68747470733a2f2f7472617669732d63692e6f72672f7274796c65792f6266672d7265706f2d636c65616e65722e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/rtyley/bfg-repo-cleaner.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Removes large or troublesome blobs like git-filter-branch does, but faster - and written in Scala&lt;/em&gt; - &lt;a href="https://j.mp/fund-bfg" rel="nofollow"&gt;Fund the BFG&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bfg --strip-blobs-bigger-than 1M --replace-text banned.txt repo.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The BFG is a simpler, faster (&lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AsR1d5Zpes8HdER3VGU1a3dOcmVHMmtzT2dsS2xNenc" rel="nofollow"&gt;10 - 720x&lt;/a&gt; faster)
alternative to &lt;code&gt;git-filter-branch&lt;/code&gt; for cleansing bad data out of your Git repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Removing &lt;strong&gt;Crazy Big Files&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Removing &lt;strong&gt;Passwords, Credentials&lt;/strong&gt; &amp;amp; other &lt;strong&gt;Private data&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Main documentation for The BFG is here : &lt;strong&gt;&lt;a href="https://rtyley.github.io/bfg-repo-cleaner/" rel="nofollow"&gt;https://rtyley.github.io/bfg-repo-cleaner/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rtyley</author><guid isPermaLink="false">https://github.com/rtyley/bfg-repo-cleaner</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>WeBankFinTech/Linkis #14 in Scala, Today</title><link>https://github.com/WeBankFinTech/Linkis</link><description>&lt;p&gt;&lt;i&gt;Linkis helps easily connect to various back-end computation/storage engines(Spark, Python, TiDB...), exposes various interfaces(REST, JDBC, Java ...), with multi-tenancy, high performance, and resource control.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-linkis" class="anchor" aria-hidden="true" href="#linkis"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Linkis&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8cb994f6c4a156c623fe057fccd7fb7d7d2e8c9b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322d3445423142412e737667" alt="License" data-canonical-src="https://img.shields.io/badge/license-Apache%202-4EB1BA.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;English | &lt;a href="docs/zh_CN/README.md"&gt;中文&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-introduction" class="anchor" aria-hidden="true" href="#introduction"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Linkis helps easily connect to various back-end computation/storage engines(Spark, Python, TiDB...), exposes various interfaces(REST, JDBC, Java ...), with multi-tenancy, high performance, and resource control.&lt;/p&gt;
&lt;p&gt;Linkis connects with computation/storage engines(Spark, Hive, Python and HBase), exposes REST/WS interface, and executes multi-language jobs(SQL, Pyspark, HiveQL and Scala), as a computation middleware.&lt;/p&gt;
&lt;p&gt;Based on the microservices architecture, Linkis provides enterprise-level features of multi-tenant isolation, resource management and access control. It also offers convenient support to manage unified variables, UDFs, functions and resource files. it is also guaranteed with sophisticated task/job lifecycle management capabilities under high-concurrency, high-performance and high-availability scenarios.&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/WeBankFinTech/Linkis/blob/master/images/linkis-intro-01.png?raw=true"&gt;&lt;img src="https://github.com/WeBankFinTech/Linkis/raw/master/images/linkis-intro-01.png?raw=true" alt="linkis-intro-01" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://github.com/WeBankFinTech/Linkis/blob/master/images/linkis-intro-03.png?raw=true"&gt;&lt;img src="https://github.com/WeBankFinTech/Linkis/raw/master/images/linkis-intro-03.png?raw=true" alt="linkis-intro-03" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Based on the concept of the computation middleware architecture of Linkis, we have built a large amount of applications and systems on top of it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Currently available open-source project: &lt;a href="https://github.com/WeBankFinTech/Scriptis"&gt;&lt;strong&gt;Scriptis - Data Development IDE Tool&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upcoming open-source projects：&lt;strong&gt;Data Visualization Tool&lt;/strong&gt;, &lt;strong&gt;Graphic Workflow Tool&lt;/strong&gt; and &lt;strong&gt;Data Quality Tool&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There will be more tools released as open-source projects, please stay tuned!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Unified Job Execution Services: A distributed REST/WebSocket service for processing scripts execution requests from user.&lt;/p&gt;
&lt;p&gt;Available computation engines so far: Spark, Python, TiSpark, Hive and Shell.&lt;/p&gt;
&lt;p&gt;Available languages so far: SparkSQL, Spark Scala, PySpark, R, Python, HQL and Shell.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Resource Management Services: Available for real-time control/limit of resource usage from both perspectives of amount and load for both systems and users. With dynamic charts of resource statistics, it is convenient to monitor and manage resource usage for systems and users.&lt;/p&gt;
&lt;p&gt;Available resource types so far: Yarn queue resources, server(CPU and memory), number of concurrent instances per user.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Application Management Services: Manages global user applications, including offline batch applications, interactive query applications and real-time streaming applications. Also provides powerful reusability especially for offline and interactive applications, with complete lifecycle management which automatically releases idle applications for users.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unified Storage Services: The generic IO architecture can quickly integrate with various storage systems and provide a unified invokable entrance. It is also highly integrated with most common data formats and easy to use.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unified Context Services: Unite resources files of users and systems (JAR, ZIP, Properties). With unified management of arguments/variables for users, systems and engines, it is achieved that modification in random place will reflect in all the other places automatically.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Material Library: System and user-level material management, capable of sharing, transferring materials and automatic lifecycle management.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Metadata Services: Real-time display of dataset table structure and partitions.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Compared with similar systems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/en_US/images/introduction/introduction01.png"&gt;&lt;img src="docs/en_US/images/introduction/introduction01.png" alt="introduction01" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-documentations" class="anchor" aria-hidden="true" href="#documentations"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentations：&lt;/h1&gt;
&lt;p&gt;&lt;a href="docs/en_US/ch3/Linkis_Introduction.md"&gt;Linkis, make big data easier&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="docs/en_US/ch1/deploy.md"&gt;Linkis Quick Deploy&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="docs/en_US/ch3/Linkis_Java_SDK_doc.md"&gt;Linkis Quick Start &amp;amp; Java SDK documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="docs/en_US/ch3/Linkis_HTTP_API_Doc.md"&gt;HTTP APIs for frontend applications&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="docs/en_US/ch3/Linkis_WebSocket_API_Doc.md"&gt;WebSocket APIs for frontend applications&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="docs/en_US/ch3/How_to_adapt_Linkis_with_a_new_computation_or_storage_engine.md"&gt;How to adapt Linkis with a new computation or storage engine&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-architecture" class="anchor" aria-hidden="true" href="#architecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Architecture：&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./docs/en_US/images/introduction/introduction02.png"&gt;&lt;img src="./docs/en_US/images/introduction/introduction02.png" alt="introduction02" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-communication" class="anchor" aria-hidden="true" href="#communication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Communication&lt;/h2&gt;
&lt;p&gt;If you desire immediate response, please kindly raise issues to us or scan the below QR code by WeChat and QQ to join our group:
&lt;br&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="docs/en_US/images/introduction/introduction05.png"&gt;&lt;img src="docs/en_US/images/introduction/introduction05.png" alt="introduction05" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Linkis is under the Apache 2.0 license. See the &lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;LICENSE &lt;/a&gt;file for details.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>WeBankFinTech</author><guid isPermaLink="false">https://github.com/WeBankFinTech/Linkis</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>chipsalliance/rocket-chip #15 in Scala, Today</title><link>https://github.com/chipsalliance/rocket-chip</link><description>&lt;p&gt;&lt;i&gt;Rocket Chip Generator&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-rocket-chip-generator-rocket-" class="anchor" aria-hidden="true" href="#rocket-chip-generator-rocket-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Rocket Chip Generator &lt;g-emoji class="g-emoji" alias="rocket" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png"&gt;🚀&lt;/g-emoji&gt; &lt;a href="https://travis-ci.org/chipsalliance/rocket-chip" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/563aaf3fa30dd9b369f41906d20cb451d0508762/68747470733a2f2f7472617669732d63692e6f72672f6368697073616c6c69616e63652f726f636b65742d636869702e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/chipsalliance/rocket-chip.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;This repository contains the Rocket chip generator necessary to instantiate
the RISC-V Rocket Core. For more information on Rocket Chip, please consult our &lt;a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html" rel="nofollow"&gt;technical report&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#quick"&gt;Quick instructions&lt;/a&gt; for those who want to dive directly into the details without knowing exactly what's in the repository.&lt;/li&gt;
&lt;li&gt;&lt;a href="#what"&gt;What's in the Rocket chip generator repository?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how"&gt;How should I use the Rocket chip generator?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#emulator"&gt;Using the cycle-accurate Verilator simulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fpga"&gt;Mapping a Rocket core down to an FPGA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#vlsi"&gt;Pushing a Rocket core through the VLSI tools&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#param"&gt;How can I parameterize my Rocket chip?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#debug"&gt;Debugging with GDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content--quick-instructions" class="anchor" aria-hidden="true" href="#-quick-instructions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-quick"&gt;&lt;/a&gt; Quick Instructions&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-checkout-the-code" class="anchor" aria-hidden="true" href="#checkout-the-code"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Checkout The Code&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ucb-bar/rocket-chip.git
$ cd rocket-chip
$ git submodule update --init
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-setting-up-the-riscv-environment-variable" class="anchor" aria-hidden="true" href="#setting-up-the-riscv-environment-variable"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setting up the RISCV environment variable&lt;/h3&gt;
&lt;p&gt;To build the rocket-chip repository, you must point the RISCV
environment variable to your rocket-tools installation directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ export RISCV=/path/to/riscv/toolchain/installation
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The rocket-tools repository known to work with rocket-chip is noted
in the file riscv-tools.hash. However, any recent rocket-tools should work.
You can build rocket-tools as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/freechipsproject/rocket-tools
$ cd rocket-tools
$ git submodule update --init --recursive
$ export RISCV=/path/to/install/riscv/toolchain
$ export MAKEFLAGS="$MAKEFLAGS -jN" # Assuming you have N cores on your host system
$ ./build.sh
$ ./build-rv32ima.sh (if you are using RV32).
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-install-necessary-dependencies" class="anchor" aria-hidden="true" href="#install-necessary-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Install Necessary Dependencies&lt;/h3&gt;
&lt;p&gt;You may need to install some additional packages to use this repository.
Rather than list all dependencies here, please see the appropriate section of the READMEs for each of the subprojects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/freechipsproject/rocket-tools/blob/master/README.md"&gt;rocket-tools "Ubuntu Packages Needed"&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ucb-bar/chisel3#installation"&gt;chisel3 "Installation"&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-building-the-project" class="anchor" aria-hidden="true" href="#building-the-project"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building The Project&lt;/h3&gt;
&lt;p&gt;First, to build the C simulator:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd emulator
$ make
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or to build the VCS simulator:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd vsim
$ make
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In either case, you can run a set of assembly tests or simple benchmarks
(Assuming you have N cores on your host system):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests
$ make -jN run-bmark-tests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To build a C simulator that is capable of VCD waveform generation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd emulator
$ make debug
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to run the assembly tests on the C simulator and generate waveforms:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests-debug
$ make -jN run-bmark-tests-debug
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate FPGA- or VLSI-synthesizable Verilog (output will be in &lt;code&gt;vsim/generated-src&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd vsim
$ make verilog
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-keeping-your-repo-up-to-date" class="anchor" aria-hidden="true" href="#keeping-your-repo-up-to-date"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Keeping Your Repo Up-to-Date&lt;/h3&gt;
&lt;p&gt;If you are trying to keep your repo up to date with this GitHub repo,
you also need to keep the submodules and tools up to date.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ # Get the newest versions of the files in this repo
$ git pull origin master
$ # Make sure the submodules have the correct versions
$ git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If rocket-tools version changes, you should recompile and install rocket-tools according to the directions in the &lt;a href="https://github.com/freechipsproject/rocket-tools/blob/master/README.md"&gt;rocket-tools/README&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd rocket-tools
$ ./build.sh
$ ./build-rv32ima.sh (if you are using RV32)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content--whats-in-the-rocket-chip-generator-repository" class="anchor" aria-hidden="true" href="#-whats-in-the-rocket-chip-generator-repository"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-what"&gt;&lt;/a&gt; What's in the Rocket chip generator repository?&lt;/h2&gt;
&lt;p&gt;The rocket-chip repository is a meta-repository that points to several
sub-repositories using &lt;a href="http://git-scm.com/book/en/Git-Tools-Submodules" rel="nofollow"&gt;Git submodules&lt;/a&gt;.
Those repositories contain tools needed to generate and test SoC designs.
This respository also contains code that is used to generate RTL.
Hardware generation is done using &lt;a href="http://chisel.eecs.berkeley.edu" rel="nofollow"&gt;Chisel&lt;/a&gt;,
a hardware construction language embedded in Scala.
The rocket-chip generator is a Scala program that invokes the Chisel compiler
in order to emit RTL describing a complete SoC.
The following sections describe the components of this repository.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-git-submodules" class="anchor" aria-hidden="true" href="#git-submodules"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-what_submodules"&gt;&lt;/a&gt;Git Submodules&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules" rel="nofollow"&gt;Git submodules&lt;/a&gt; allow you to keep a Git repository as a subdirectory of another Git repository.
For projects being co-developed with the Rocket Chip Generator, we have often found it expedient to track them as submodules,
allowing for rapid exploitation of new features while keeping commit histories separate.
As submoduled projects adopt stable public APIs, we transition them to external dependencies.
Here are the submodules that are currently being tracked in the rocket-chip repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;chisel3&lt;/strong&gt;
(&lt;a href="https://github.com/ucb-bar/chisel3"&gt;https://github.com/ucb-bar/chisel3&lt;/a&gt;):
The Rocket Chip Generator uses &lt;a href="http://chisel.eecs.berkeley.edu" rel="nofollow"&gt;Chisel&lt;/a&gt; to generate RTL.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;firrtl&lt;/strong&gt;
(&lt;a href="https://github.com/ucb-bar/firrtl"&gt;https://github.com/ucb-bar/firrtl&lt;/a&gt;):
&lt;a href="http://bar.eecs.berkeley.edu/projects/2015-firrtl.html" rel="nofollow"&gt;Firrtl (Flexible Internal Representation for RTL)&lt;/a&gt;
is the intermediate representation of RTL constructions used by Chisel3.
The Chisel3 compiler generates a Firrtl representation,
from which the final product (Verilog code, C code, etc) is generated.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hardfloat&lt;/strong&gt;
(&lt;a href="https://github.com/ucb-bar/berkeley-hardfloat"&gt;https://github.com/ucb-bar/berkeley-hardfloat&lt;/a&gt;):
Hardfloat holds Chisel code that generates parameterized IEEE 754-2008 compliant
floating-point units used for fused multiply-add operations, conversions
between integer and floating-point numbers, and conversions between
floating-point conversions with different precision.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rocket-tools&lt;/strong&gt;
(&lt;a href="https://github.com/freechipsproject/rocket-tools"&gt;https://github.com/freechipsproject/rocket-tools&lt;/a&gt;):
We tag a version of RISC-V software tools that work with the RTL committed in this repository.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;torture&lt;/strong&gt;
(&lt;a href="https://github.com/ucb-bar/riscv-torture"&gt;https://github.com/ucb-bar/riscv-torture&lt;/a&gt;):
This module is used to generate and execute constrained random instruction streams that can
be used to stress-test both the core and uncore portions of the design.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-scala-packages" class="anchor" aria-hidden="true" href="#scala-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-what_packages"&gt;&lt;/a&gt;Scala Packages&lt;/h3&gt;
&lt;p&gt;In addition to submodules that track independent Git repositories,
the rocket-chip code base is itself factored into a number of Scala packages.
These packages are all found within the src/main/scala directory.
Some of these packages provide Scala utilities for generator configuration,
while other contain the actual Chisel RTL generators themselves.
Here is a brief description of what can be found in each package:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;amba&lt;/strong&gt;
This RTL package uses diplomacy to generate bus implementations of AMBA protocols, including AXI4, AHB-lite, and APB.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;config&lt;/strong&gt;
This utility package provides Scala interfaces for configuring a generator via a dynamically-scoped
parameterization library.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coreplex&lt;/strong&gt;
This RTL package generates a complete coreplex by gluing together a variety of components from other packages,
including: tiled Rocket cores, a system bus network, coherence agents, debug devices, interrupt handlers, externally-facing peripherals,
clock-crossers and converters from TileLink to external bus protocols (e.g. AXI or AHB).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;devices&lt;/strong&gt;
This RTL package contains implementations for peripheral devices, including the Debug module and various TL slaves.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;diplomacy&lt;/strong&gt;
This utility package extends Chisel by allowing for two-phase hardware elaboration, in which certain parameters
are dynamically negotiated between modules. For more information about diplomacy, see &lt;a href="https://carrv.github.io/papers/cook-diplomacy-carrv2017.pdf" rel="nofollow"&gt;this paper&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;groundtest&lt;/strong&gt;
This RTL package generates synthesizable hardware testers that emit randomized
memory access streams in order to stress-tests the uncore memory hierarchy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jtag&lt;/strong&gt;
This RTL package provides definitions for generating JTAG bus interfaces.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;regmapper&lt;/strong&gt;
This utility package generates slave devices with a standardized interface for accessing their memory-mapped registers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rocket&lt;/strong&gt;
This RTL package generates the Rocket in-order pipelined core,
as well as the L1 instruction and data caches.
This library is intended to be used by a chip generator that instantiates the
core within a memory system and connects it to the outside world.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tile&lt;/strong&gt;
This RTL package contains components that can be combined with cores to construct tiles, such as FPUs and accelerators.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tilelink&lt;/strong&gt;
This RTL package uses diplomacy to generate bus implementations of the TileLink protocol. It also contains a variety
of adapters and protocol converters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;system&lt;/strong&gt;
This top-level utility package invokes Chisel to elaborate a particular configuration of a coreplex,
along with the appropriate testing collateral.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;unittest&lt;/strong&gt;
This utility package contains a framework for generateing synthesizable hardware testers of individual modules.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;util&lt;/strong&gt;
This utility package provides a variety of common Scala and Chisel constructs that are re-used across
multiple other packages,&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-other-resources" class="anchor" aria-hidden="true" href="#other-resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-what_else"&gt;&lt;/a&gt;Other Resources&lt;/h3&gt;
&lt;p&gt;Outside of Scala, we also provide a variety of resources to create a complete SoC implementation and
test the generated designs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bootrom&lt;/strong&gt;
Sources for the first-stage bootloader included in the BootROM.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;csrc&lt;/strong&gt;
C sources for use with Verilator simulation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;emulator&lt;/strong&gt;
Directory in which Verilator simulations are compiled and run.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;project&lt;/strong&gt;
Directory used by SBT for Scala compilation and build.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;regression&lt;/strong&gt;
Defines continuous integration and nightly regression suites.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;scripts&lt;/strong&gt;
Utilities for parsing the output of simulations or manipulating the contents of source files.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vsim&lt;/strong&gt;
Directory in which Synopsys VCS simulations are compiled and run.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vsrc&lt;/strong&gt;
Verilog sources containing interfaces, harnesses and VPI.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-extending-the-top-level-design" class="anchor" aria-hidden="true" href="#extending-the-top-level-design"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-what_toplevel"&gt;&lt;/a&gt;Extending the Top-Level Design&lt;/h3&gt;
&lt;p&gt;See &lt;a href="https://github.com/ucb-bar/project-template"&gt;this description&lt;/a&gt; of how to create
you own top-level design with custom devices.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--how-should-i-use-the-rocket-chip-generator" class="anchor" aria-hidden="true" href="#-how-should-i-use-the-rocket-chip-generator"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-how"&gt;&lt;/a&gt; How should I use the Rocket chip generator?&lt;/h2&gt;
&lt;p&gt;Chisel can generate code for three targets: a high-performance
cycle-accurate Verilator, Verilog optimized for FPGAs, and Verilog
for VLSI. The rocket-chip generator can target all three backends.  You
will need a Java runtime installed on your machine, since Chisel is
overlaid on top of &lt;a href="http://www.scala-lang.org/" rel="nofollow"&gt;Scala&lt;/a&gt;. Chisel RTL (i.e.
rocket-chip source code) is a Scala program executing on top of your
Java runtime. To begin, ensure that the ROCKETCHIP environment variable
points to the rocket-chip repository.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ucb-bar/rocket-chip.git
$ cd rocket-chip
$ export ROCKETCHIP=`pwd`
$ git submodule update --init
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before going any further, you must point the RISCV environment variable
to your rocket-tools installation directory. If you do not yet have
rocket-tools installed, follow the directions in the
&lt;a href="https://github.com/freechipsproject/rocket-tools/blob/master/README.md"&gt;rocket-tools/README&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export RISCV=/path/to/install/riscv/toolchain
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Otherwise, you will see the following error message while executing any
command in the rocket-chip generator:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;*** Please set environment variable RISCV. Please take a look at README.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content--1-using-the-high-performance-cycle-accurate-verilator" class="anchor" aria-hidden="true" href="#-1-using-the-high-performance-cycle-accurate-verilator"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-emulator"&gt;&lt;/a&gt; 1) Using the high-performance cycle-accurate Verilator&lt;/h3&gt;
&lt;p&gt;Your next step is to get the Verilator working. Assuming you have N
cores on your host system, do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/emulator
$ make -jN run
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By doing so, the build system will generate C++ code for the
cycle-accurate emulator, compile the emulator, compile all RISC-V
assembly tests and benchmarks, and run both tests and benchmarks on the
emulator. If Make finished without any errors, it means that the
generated Rocket chip has passed all assembly tests and benchmarks!&lt;/p&gt;
&lt;p&gt;You can also run assembly tests and benchmarks separately:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make -jN run-asm-tests
$ make -jN run-bmark-tests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate vcd waveforms, you can run one of the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make -jN run-debug
$ make -jN run-asm-tests-debug
$ make -jN run-bmark-tests-debug
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or call out individual assembly tests or benchmarks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make output/rv64ui-p-add.out
$ make output/rv64ui-p-add.vcd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now take a look in the emulator/generated-src directory. You will find
Chisel generated Verilog code and its associated C++ code generated by
Verilator.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls $ROCKETCHIP/emulator/generated-src
DefaultConfig.dts
DefaultConfig.graphml
DefaultConfig.json
DefaultConfig.memmap.json
freechips.rocketchip.system.DefaultConfig
freechips.rocketchip.system.DefaultConfig.d
freechips.rocketchip.system.DefaultConfig.fir
freechips.rocketchip.system.DefaultConfig.v
$ ls $ROCKETCHIP/emulator/generated-src/freechips.rocketchip.system.DefaultConfig
VTestHarness__1.cpp
VTestHarness__2.cpp
VTestHarness__3.cpp
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, output of the executed assembly tests and benchmarks can be found
at emulator/output/*.out. Each file has a cycle-by-cycle dump of
write-back stage of the pipeline. Here's an excerpt of
emulator/output/rv64ui-p-add.out:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C0: 483 [1] pc=[00000002138] W[r 3=000000007fff7fff][1] R[r 1=000000007fffffff] R[r 2=ffffffffffff8000] inst=[002081b3] add s1, ra, s0
C0: 484 [1] pc=[0000000213c] W[r29=000000007fff8000][1] R[r31=ffffffff80007ffe] R[r31=0000000000000005] inst=[7fff8eb7] lui t3, 0x7fff8
C0: 485 [0] pc=[00000002140] W[r 0=0000000000000000][0] R[r 0=0000000000000000] R[r 0=0000000000000000] inst=[00000000] unknown
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first [1] at cycle 483, core 0, shows that there's a
valid instruction at PC 0x2138 in the writeback stage, which is
0x002081b3 (add s1, ra, s0). The second [1] tells us that the register
file is writing r3 with the corresponding value 0x7fff7fff. When the add
instruction was in the decode stage, the pipeline had read r1 and r2
with the corresponding values next to it. Similarly at cycle 484,
there's a valid instruction (lui instruction) at PC 0x213c in the
writeback stage. At cycle 485, there isn't a valid instruction in the
writeback stage, perhaps, because of a instruction cache miss at PC
0x2140.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content--2-mapping-a-rocket-core-to-an-fpga" class="anchor" aria-hidden="true" href="#-2-mapping-a-rocket-core-to-an-fpga"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-fpga"&gt;&lt;/a&gt; 2) Mapping a Rocket core to an FPGA&lt;/h3&gt;
&lt;p&gt;You can generate synthesizable Verilog with the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim
$ make verilog CONFIG=DefaultFPGAConfig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Verilog used for the FPGA tools will be generated in
vsim/generated-src. Please proceed further with the directions shown in
the &lt;a href="https://github.com/sifive/freedom/blob/master/README.md"&gt;README&lt;/a&gt;
of the freedom repository. You can also run Rocket Chip on Amazon EC2 F1
with &lt;a href="https://github.com/firesim/firesim"&gt;FireSim&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have access to VCS, you will be able to run assembly
tests and benchmarks in simulation with the following commands
(again assuming you have N cores on your host machine):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim
$ make -jN run CONFIG=DefaultFPGAConfig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The generated output looks similar to those generated from the emulator.
Look into vsim/output/*.out for the output of the executed assembly
tests and benchmarks.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content--3-pushing-a-rocket-core-through-the-vlsi-tools" class="anchor" aria-hidden="true" href="#-3-pushing-a-rocket-core-through-the-vlsi-tools"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-vlsi"&gt;&lt;/a&gt; 3) Pushing a Rocket core through the VLSI tools&lt;/h3&gt;
&lt;p&gt;You can generate Verilog for your VLSI flow with the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim
$ make verilog
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now take a look at vsim/generated-src, and the contents of the
Top.DefaultConfig.conf file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim/generated-src
DefaultConfig.dts
DefaultConfig.graphml
DefaultConfig.json
DefaultConfig.memmap.json
freechips.rocketchip.system.DefaultConfig.behav_srams.v
freechips.rocketchip.system.DefaultConfig.conf
freechips.rocketchip.system.DefaultConfig.d
freechips.rocketchip.system.DefaultConfig.fir
freechips.rocketchip.system.DefaultConfig.v
$ cat $ROCKETCHIP/vsim/generated-src/*.conf
name data_arrays_0_ext depth 512 width 256 ports mrw mask_gran 8
name tag_array_ext depth 64 width 88 ports mrw mask_gran 22
name tag_array_0_ext depth 64 width 84 ports mrw mask_gran 21
name data_arrays_0_1_ext depth 512 width 128 ports mrw mask_gran 32
name mem_ext depth 33554432 width 64 ports mwrite,read mask_gran 8
name mem_2_ext depth 512 width 64 ports mwrite,read mask_gran 8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The conf file contains information for all SRAMs instantiated in the
flow. If you take a close look at the $ROCKETCHIP/Makefrag, you will see
that during Verilog generation, the build system calls a $(mem_gen)
script with the generated configuration file as an argument, which will
fill in the Verilog for the SRAMs. Currently, the $(mem_gen) script
points to vsim/vlsi_mem_gen, which simply instantiates behavioral
SRAMs.  You will see those SRAMs being appended at the end of
vsim/generated-src/Top.DefaultConfig.v. To target vendor-specific
SRAMs, you will need to make necessary changes to vsim/vlsi_mem_gen.&lt;/p&gt;
&lt;p&gt;Similarly, if you have access to VCS, you can run assembly tests and
benchmarks with the following commands (again assuming you have N cores
on your host machine):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim
$ make -jN run
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The generated output looks similar to those generated from the emulator.
Look into vsim/output/*.out for the output of the executed assembly
tests and benchmarks.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--how-can-i-parameterize-my-rocket-chip" class="anchor" aria-hidden="true" href="#-how-can-i-parameterize-my-rocket-chip"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-param"&gt;&lt;/a&gt; How can I parameterize my Rocket chip?&lt;/h2&gt;
&lt;p&gt;By now, you probably figured out that all generated files have a configuration
name attached, e.g. DefaultConfig. Take a look at
src/main/scala/system/Configs.scala. Search for NSets and NWays defined in
BaseConfig. You can change those numbers to get a Rocket core with different
cache parameters. For example, by changing L1I, NWays to 4, you will get
a 32KB 4-way set-associative L1 instruction cache rather than a 16KB 2-way
set-associative L1 instruction cache.
Towards the end, you can also find that DefaultSmallConfig inherits all
parameters from BaseConfig but overrides the same parameters of
WithNSmallCores.&lt;/p&gt;
&lt;p&gt;Now take a look at vsim/Makefile. Search for the CONFIG variable.
By default, it is set to DefaultConfig.  You can also change the
CONFIG variable on the make command line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd $ROCKETCHIP/vsim
$ make -jN CONFIG=DefaultSmallConfig run-asm-tests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, even by defining CONFIG as an environment variable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ export CONFIG=DefaultSmallConfig
$ make -jN run-asm-tests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This parameterization is one of the many strengths of processor
generators written in Chisel, and will be more detailed in a future blog
post, so please stay tuned.&lt;/p&gt;
&lt;p&gt;To override specific configuration items, such as the number of external interrupts,
you can create your own Configuration(s) and compose them with Config's ++ operator&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class WithNExtInterrupts(nExt: Int) extends Config {
    (site, here, up) =&amp;gt; {
        case NExtInterrupts =&amp;gt; nExt
    }
}
class MyConfig extends Config (new WithNExtInterrupts(16) ++ new DefaultSmallConfig)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then you can build as usual with CONFIG=MyConfig.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--debugging-with-gdb" class="anchor" aria-hidden="true" href="#-debugging-with-gdb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-debug"&gt;&lt;/a&gt; Debugging with GDB&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-1-generating-the-remote-bit-bang-rbb-emulator" class="anchor" aria-hidden="true" href="#1-generating-the-remote-bit-bang-rbb-emulator"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1) Generating the Remote Bit-Bang (RBB) Emulator&lt;/h3&gt;
&lt;p&gt;The objective of this section is to use GNU debugger to debug RISC-V programs running on the emulator in the same fashion as in &lt;a href="https://github.com/riscv/riscv-isa-sim#debugging-with-gdb"&gt;Spike&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For that we need to add a Remote Bit-Bang client to the emulator. We can do so by extending our Config with JtagDTMSystem, which will add a DebugTransportModuleJTAG to the DUT and connect a SimJTAG module in the Test Harness. This will allow OpenOCD to interface with the emulator, and GDB can interface with OpenOCD. In the following example we added this Config extension to the DefaultConfig:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class DefaultConfigRBB extends Config(
new WithJtagDTMSystem ++ new WithNBigCores(1) ++ new BaseConfig)

class QuadCoreConfigRBB extends Config(
new WithJtagDTMSystem ++ new WithNBigCores(4) ++ new BaseConfig)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To build the emulator with &lt;code&gt;DefaultConfigRBB&lt;/code&gt; configuration we use the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rocket-chip$ cd emulator
emulator$ CONFIG=DefaultConfigRBB make
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also build a debug version capable of generating VCD waveforms using the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;emulator$ CONFIG=DefaultConfigRBB make debug
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default the emulator is generated under the name &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB&lt;/code&gt; in the first case and &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB-debug&lt;/code&gt; in the second.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-2-compiling-and-executing-a-custom-program-using-the-emulator" class="anchor" aria-hidden="true" href="#2-compiling-and-executing-a-custom-program-using-the-emulator"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2) Compiling and executing a custom program using the emulator&lt;/h3&gt;
&lt;p&gt;We suppose that &lt;code&gt;helloworld&lt;/code&gt; is our program, you can use &lt;code&gt;crt.S&lt;/code&gt;, &lt;code&gt;syscalls.c&lt;/code&gt; and the linker script &lt;code&gt;test.ld&lt;/code&gt; to construct your own program, check examples stated in &lt;a href="https://github.com/riscv/riscv-tests"&gt;riscv-tests&lt;/a&gt;. Note that &lt;code&gt;test.ld&lt;/code&gt; loads the program at 0x80000000 so you will need to use &lt;code&gt;-mcmodel=medany&lt;/code&gt; otherwise you will get relocation errors. See &lt;a href="https://www.sifive.com/blog/2017/09/11/all-aboard-part-4-risc-v-code-models/" rel="nofollow"&gt;All Aboard, Part 4: The RISC-V Code Models&lt;/a&gt; for more details.&lt;/p&gt;
&lt;p&gt;In our case we will use the following example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;char text[] = "Vafgehpgvba frgf jnag gb or serr!";

// Don't use the stack, because sp isn't set up.
volatile int wait = 1;

int main()
{
    while (wait)
        ;

    // Doesn't actually go on the stack, because there are lots of GPRs.
    int i = 0;
    while (text[i]) {
        char lower = text[i] | 32;
        if (lower &amp;gt;= 'a' &amp;amp;&amp;amp; lower &amp;lt;= 'm')
            text[i] += 13;
        else if (lower &amp;gt; 'm' &amp;amp;&amp;amp; lower &amp;lt;= 'z')
            text[i] -= 13;
        i++;
    }

    while (!wait)
        ;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First we can test if your program executes well in the simple version of emulator before moving to debugging in step 3 :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig helloworld 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additional verbose information (clock cycle, pc, instruction being executed) can be printed using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig +verbose helloworld 2&amp;gt;&amp;amp;1 | spike-dasm 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;VCD output files can be obtained using the &lt;code&gt;-debug&lt;/code&gt; version of the emulator and are specified using &lt;code&gt;-v&lt;/code&gt; or &lt;code&gt;--vcd=FILE&lt;/code&gt; arguments. A detailed log file of all executed instructions can also be obtained from the emulator, this is an example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig-debug +verbose -v output.vcd  helloworld 2&amp;gt;&amp;amp;1 | spike-dasm &amp;gt; output.log
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please note that generated VCD waveforms and execution log files can be very voluminous depending on the size of the .elf file (i.e. code size + debugging symbols).&lt;/p&gt;
&lt;p&gt;Please note also that the time it takes the emulator to load your program depends on executable size. Stripping the .elf executable will unsurprisingly make it run faster. For this you can use &lt;code&gt;$RISCV/bin/riscv64-unknown-elf-strip&lt;/code&gt; tool to reduce the size. This is good for accelerating your simulation but not for debugging. Keep in mind that the HTIF communication interface between our system and the emulator relies on &lt;code&gt;tohost&lt;/code&gt; and &lt;code&gt;fromhost&lt;/code&gt; symbols to communicate. This is why you may get the following error when you try to run a totally stripped executable on the emulator:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./emulator-freechips.rocketchip.system-DefaultConfig totally-stripped-helloworld 
This emulator compiled with JTAG Remote Bitbang client. To enable, use +jtag_rbb_enable=1.
Listening on port 46529
warning: tohost and fromhost symbols not in ELF; can't communicate with target
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To resolve this, we need to strip all the .elf executable but keep &lt;code&gt;tohost&lt;/code&gt; and &lt;code&gt;fromhost&lt;/code&gt; symbols using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$riscv64-unknown-elf-strip -s -Kfromhost -Ktohost helloworld
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More details on the GNU strip tool can be found &lt;a href="https://www.thegeekstuff.com/2012/09/strip-command-examples/" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The interest of this step is to make sure your program executes well. To perform debugging you need the original unstripped version, as explained in step 3.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-3-launch-the-emulator" class="anchor" aria-hidden="true" href="#3-launch-the-emulator"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3) Launch the emulator&lt;/h3&gt;
&lt;p&gt;First, do not forget to compile your program with &lt;code&gt;-g -Og&lt;/code&gt; flags to provide debugging support as explained &lt;a href="https://github.com/riscv/riscv-isa-sim#debugging-with-gdb"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can then launch the Remote Bit-Bang enabled emulator with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./emulator-freechips.rocketchip.system-DefaultConfigRBB +jtag_rbb_enable=1 --rbb-port=9823 helloworld
This emulator compiled with JTAG Remote Bitbang client. To enable, use +jtag_rbb_enable=1.
Listening on port 9823
Attempting to accept client socket
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use the &lt;code&gt;emulator-freechips.rocketchip.system-DefaultConfigRBB-debug&lt;/code&gt; version instead if you would like to generate VCD waveforms.&lt;/p&gt;
&lt;p&gt;Please note that if the argument &lt;code&gt;--rbb-port&lt;/code&gt; is not passed, a default free TCP port on your computer will be chosen randomly.&lt;/p&gt;
&lt;p&gt;Please note also that when debugging with GDB, the .elf file is not actually loaded by the FESVR. In contrast with Spike, it must  be loaded from GDB as explained in step 5. So the &lt;code&gt;helloworld&lt;/code&gt; argument may be replaced by any dummy name.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-4-launch-openocd" class="anchor" aria-hidden="true" href="#4-launch-openocd"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4) Launch OpenOCD&lt;/h3&gt;
&lt;p&gt;You will need a RISC-V Enabled OpenOCD binary. This is installed with rocket-tools in &lt;code&gt;$(RISCV)/bin/openocd&lt;/code&gt;, or can be compiled manually from riscv-openocd. OpenOCD requires a configuration file, in which we define the RBB port we will use, which is in our case &lt;code&gt;9823&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat cemulator.cfg 
interface remote_bitbang
remote_bitbang_host localhost
remote_bitbang_port 9823

set _CHIPNAME riscv
jtag newtap $_CHIPNAME cpu -irlen 5

set _TARGETNAME $_CHIPNAME.cpu
target create $_TARGETNAME riscv -chain-position $_TARGETNAME

gdb_report_data_abort enable

init
halt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we launch OpenOCD in another terminal using the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$(RISCV)/bin/openocd -f ./cemulator.cfg
Open On-Chip Debugger 0.10.0+dev-00112-g3c1c6e0 (2018-04-12-10:40)
Licensed under GNU GPL v2
For bug reports, read
http://openocd.org/doc/doxygen/bugs.html
Warn : Adapter driver 'remote_bitbang' did not declare which transports it allows; assuming legacy JTAG-only
Info : only one transport option; autoselect 'jtag'
Info : Initializing remote_bitbang driver
Info : Connecting to localhost:9823
Info : remote_bitbang driver initialized
Info : This adapter doesn't support configurable speed
Info : JTAG tap: riscv.cpu tap/device found: 0x00000001 (mfg: 0x000 (&amp;lt;invalid&amp;gt;), part: 0x0000, ver: 0x0)
Info : datacount=2 progbufsize=16
Info : Disabling abstract command reads from CSRs.
Info : Disabling abstract command writes to CSRs.
Info : [0] Found 1 triggers
Info : Examined RISC-V core; found 1 harts
Info :  hart 0: XLEN=64, 1 triggers
Info : Listening on port 3333 for gdb connections
Info : Listening on port 6666 for tcl connections
Info : Listening on port 4444 for telnet connections
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A &lt;code&gt;-d&lt;/code&gt; flag can be added to the command to show further debug information.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-5-launch-gdb" class="anchor" aria-hidden="true" href="#5-launch-gdb"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5) Launch GDB&lt;/h3&gt;
&lt;p&gt;In another terminal launch GDB and point to the elf file you would like to load then run it with the debugger (in this example, &lt;code&gt;helloworld&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ riscv64-unknown-elf-gdb helloworld
GNU gdb (GDB) 8.0.50.20170724-git
Copyright (C) 2017 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "--host=x86_64-pc-linux-gnu --target=riscv64-unknown-elf".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
&amp;lt;http://www.gnu.org/software/gdb/bugs/&amp;gt;.
Find the GDB manual and other documentation resources online at:
&amp;lt;http://www.gnu.org/software/gdb/documentation/&amp;gt;.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from ./proj1.out...done.
(gdb)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compared to Spike, the C Emulator is very slow, so several problems may be encountered due to timeouts between issuing commands and response from the emulator. To solve this problem, we increase the timeout with the GDB &lt;code&gt;set remotetimeout&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;After that we load our program by performing a &lt;code&gt;load&lt;/code&gt; command. This automatically sets the &lt;code&gt;$PC&lt;/code&gt; to the &lt;code&gt;_start&lt;/code&gt; symbol in our .elf file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(gdb) set remotetimeout 2000
(gdb) target remote localhost:3333
Remote debugging using localhost:3333
0x0000000000010050 in ?? ()
(gdb) load
Loading section .text.init, size 0x2cc lma 0x80000000
Loading section .tohost, size 0x48 lma 0x80001000
Loading section .text, size 0x98c lma 0x80001048
Loading section .rodata, size 0x158 lma 0x800019d4
Loading section .rodata.str1.8, size 0x20 lma 0x80001b30
Loading section .data, size 0x22 lma 0x80001b50
Loading section .sdata, size 0x4 lma 0x80001b74
Start address 0x80000000, load size 3646
Transfer rate: 40 bytes/sec, 520 bytes/write.
(gdb) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can proceed as with Spike, debugging works in a similar way:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(gdb) print wait
$1 = 1
(gdb) print wait=0
$2 = 0
(gdb) print text
$3 = "Vafgehpgvba frgf jnag gb or serr!"
(gdb) c
Continuing.

^C
Program received signal SIGINT, Interrupt.
main (argc=0, argv=&amp;lt;optimized out&amp;gt;) at src/main.c:33
33	    while (!wait)
(gdb) print wait
$4 = 0
(gdb) print text
$5 = "Instruction sets want to be free!"
(gdb)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Further information about GDB debugging is available &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/" rel="nofollow"&gt;here&lt;/a&gt; and &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Remote-Debugging.html#Remote-Debugging" rel="nofollow"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--contributors" class="anchor" aria-hidden="true" href="#-contributors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-contributors"&gt;&lt;/a&gt; Contributors&lt;/h2&gt;
&lt;p&gt;Can be found &lt;a href="https://github.com/ucb-bar/rocket-chip/graphs/contributors"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content--attribution" class="anchor" aria-hidden="true" href="#-attribution"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a name="user-content-attribution"&gt;&lt;/a&gt; Attribution&lt;/h2&gt;
&lt;p&gt;If used for research, please cite Rocket Chip by the technical report:&lt;/p&gt;
&lt;p&gt;Krste Asanović, Rimas Avižienis, Jonathan Bachrach, Scott Beamer, David Biancolin, Christopher Celio, Henry Cook, Palmer Dabbelt, John Hauser, Adam Izraelevitz, Sagar Karandikar, Benjamin Keller, Donggyu Kim, John Koenig, Yunsup Lee, Eric Love, Martin Maas, Albert Magyar, Howard Mao, Miquel Moreto, Albert Ou, David Patterson, Brian Richards, Colin Schmidt, Stephen Twigg, Huy Vo, and Andrew Waterman, &lt;em&gt;&lt;a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html" rel="nofollow"&gt;The Rocket Chip Generator&lt;/a&gt;&lt;/em&gt;, Technical Report UCB/EECS-2016-17, EECS Department, University of California, Berkeley, April 2016&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>chipsalliance</author><guid isPermaLink="false">https://github.com/chipsalliance/rocket-chip</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>gatling/gatling #16 in Scala, Today</title><link>https://github.com/gatling/gatling</link><description>&lt;p&gt;&lt;i&gt;Async Scala-Akka-Netty based Load Test Tool&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-gatling--" class="anchor" aria-hidden="true" href="#gatling--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gatling &lt;a href="https://travis-ci.org/gatling/gatling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e87d40ad3c3901b02cc99091df3484450b0c9f2d/68747470733a2f2f7472617669732d63692e6f72672f6761746c696e672f6761746c696e672e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/gatling/gatling.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://maven-badges.herokuapp.com/maven-central/io.gatling/gatling-core/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c8415d087772ac68ab22a404ed7ac2dcea6169c4/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f696f2e6761746c696e672f6761746c696e672d636f72652f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/io.gatling/gatling-core/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-gatling-" class="anchor" aria-hidden="true" href="#what-is-gatling-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is Gatling ?&lt;/h2&gt;
&lt;p&gt;Gatling is a stress tool.
Development is currently focusing on HTTP support.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Finding fancy GUIs not that convenient for describing stress tests, what you want is a friendly expressive DSL?&lt;/li&gt;
&lt;li&gt;Wanting something more convenient than huge XML dumps to store in your source version control system?&lt;/li&gt;
&lt;li&gt;Fed up with having to host a farm of injecting servers because your tool uses blocking IO and one-thread-per-user architecture?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gatling is for you!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-underlying-technologies" class="anchor" aria-hidden="true" href="#underlying-technologies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Underlying technologies&lt;/h2&gt;
&lt;p&gt;Gatling is developed in Scala and built upon :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://netty.io" rel="nofollow"&gt;Netty&lt;/a&gt; for non blocking HTTP&lt;/li&gt;
&lt;li&gt;&lt;a href="https://akka.io" rel="nofollow"&gt;Akka&lt;/a&gt; for actions (requests, pauses, assertions, etc...) modeling and orchestration
...&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-snapshots" class="anchor" aria-hidden="true" href="#snapshots"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Snapshots&lt;/h2&gt;
&lt;p&gt;For people wanting to use the latest evolutions, the SNAPSHOT versions are available from the Sonatype OSS &lt;a href="https://oss.sonatype.org/content/repositories/snapshots/io/gatling/highcharts/gatling-charts-highcharts/" rel="nofollow"&gt;repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-questions-help" class="anchor" aria-hidden="true" href="#questions-help"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Questions, help?&lt;/h2&gt;
&lt;p&gt;Read the &lt;a href="https://gatling.io/docs/current/" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Join the &lt;a href="https://groups.google.com/group/gatling" rel="nofollow"&gt;Gatling User Group&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Found a real bug? Raise an &lt;a href="https://github.com/gatling/gatling/issues?sort=created&amp;amp;direction=desc&amp;amp;state=open"&gt;issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-partners" class="anchor" aria-hidden="true" href="#partners"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Partners&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/logo-takima-1-nom-bas.png"&gt;&lt;img alt="Takima" src="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/logo-takima-1-nom-bas.png" width="80" style="max-width:100%;"&gt;&lt;/a&gt;    
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/highsoft_logo.png"&gt;&lt;img src="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/highsoft_logo.png" alt="Highsoft AS" style="max-width:100%;"&gt;&lt;/a&gt;    &lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>gatling</author><guid isPermaLink="false">https://github.com/gatling/gatling</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>apache/openwhisk #17 in Scala, Today</title><link>https://github.com/apache/openwhisk</link><description>&lt;p&gt;&lt;i&gt;Apache OpenWhisk is an open source serverless cloud platform&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;h1&gt;&lt;a id="user-content-openwhisk" class="anchor" aria-hidden="true" href="#openwhisk"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;OpenWhisk&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/apache/openwhisk" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d6c5a4d09a67f3ef8a873eba0a11d4bafc033ff1/68747470733a2f2f7472617669732d63692e6f72672f6170616368652f6f70656e776869736b2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/apache/openwhisk.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3a4d3bc039085cffdfecbe3077ffe49c5fe23286/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4170616368652d2d322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/license-Apache--2.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://slack.openwhisk.org/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/27e0d1aacb710bf42dfd32b2edbef4162c7723ec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6a6f696e2d736c61636b2d3942363941302e737667" alt="Join Slack" data-canonical-src="https://img.shields.io/badge/join-slack-9B69A0.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://codecov.io/gh/apache/openwhisk" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6b91d016d5e66f4dd722ab921e64a694f224eed5/68747470733a2f2f636f6465636f762e696f2f67682f6170616368652f6f70656e776869736b2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/apache/openwhisk/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/intent/follow?screen_name=openwhisk" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/54993a7b6d48bd5174688432028894296657d82b/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6f70656e776869736b2e7376673f7374796c653d736f6369616c266c6f676f3d74776974746572" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/openwhisk.svg?style=social&amp;amp;logo=twitter" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OpenWhisk is a cloud-first distributed event-based programming service. It provides a programming model to upload event handlers to a cloud service, and register the handlers to respond to various events. Learn more at &lt;a href="http://openwhisk.apache.org" rel="nofollow"&gt;http://openwhisk.apache.org&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#quick-start"&gt;Quick Start&lt;/a&gt; (Docker-Compose)&lt;/li&gt;
&lt;li&gt;&lt;a href="#native-development"&gt;Native development&lt;/a&gt; (Mac and Ubuntu)&lt;/li&gt;
&lt;li&gt;&lt;a href="#kubernetes-setup"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#vagrant-setup"&gt;Vagrant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#learn-concepts-and-commands"&gt;Learn concepts and commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#issues"&gt;Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#slack"&gt;Slack&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h3&gt;
&lt;p&gt;The easiest way to start using OpenWhisk is to get Docker installed on Mac, Windows or Linux. The &lt;a href="https://docs.docker.com/install/" rel="nofollow"&gt;Docker website&lt;/a&gt; has detailed instructions on getting the tools installed. This does not give you a production deployment but gives you enough of the pieces to start writing functions and seeing them run.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/apache/openwhisk-devtools.git
cd openwhisk-devtools/docker-compose
make quick-start
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more detailed instructions or if you encounter problems see the &lt;a href="https://github.com/apache/openwhisk-devtools/blob/master/docker-compose/README.md"&gt;OpenWhisk-dev tools&lt;/a&gt; project.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-kubernetes-setup" class="anchor" aria-hidden="true" href="#kubernetes-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Kubernetes Setup&lt;/h3&gt;
&lt;p&gt;Another path to quickly starting to use OpenWhisk is to install it on a Kubernetes cluster.  On a Mac, you can use the Kubernetes support built into Docker 18.06 (or higher). You can also deploy OpenWhisk on Minikube, on a managed Kubernetes cluster provisioned from a public cloud provider, or on a Kubernetes cluster you manage yourself. To get started,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/apache/openwhisk-deploy-kube.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then follow the instructions in the &lt;a href="https://github.com/apache/openwhisk-deploy-kube/blob/master/README.md"&gt;OpenWhisk on Kubernetes README.md&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-vagrant-setup" class="anchor" aria-hidden="true" href="#vagrant-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Vagrant Setup&lt;/h3&gt;
&lt;p&gt;A &lt;a href="http://vagrantup.com" rel="nofollow"&gt;Vagrant&lt;/a&gt; machine is also available to run OpenWhisk on Mac, Windows PC or GNU/Linux but isn't used by as much of the dev team so sometimes lags behind.
Download and install &lt;a href="https://www.virtualbox.org/wiki/Downloads" rel="nofollow"&gt;VirtualBox&lt;/a&gt; and &lt;a href="https://www.vagrantup.com/downloads.html" rel="nofollow"&gt;Vagrant&lt;/a&gt; for your operating system and architecture.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For Windows, you may need to install an ssh client in order to use the command &lt;code&gt;vagrant ssh&lt;/code&gt;. Cygwin works well for this, and Git Bash comes with an ssh client you can point to. If you run the command and no ssh is installed, Vagrant will give you some options to try.&lt;/p&gt;
&lt;p&gt;Follow these step to run your first OpenWhisk Action:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Clone openwhisk
git clone --depth=1 https://github.com/apache/openwhisk.git openwhisk

# Change directory to tools/vagrant
cd openwhisk/tools/vagrant

# Run script to create vm and run hello action
./hello
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wait for hello action output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wsk action invoke /whisk.system/utils/echo -p message hello --result
{
    "message": "hello"
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These steps were tested on Mac OS X El Capitan, Ubuntu 14.04.3 LTS and Windows using Vagrant.
For more information about using OpenWhisk on Vagrant see the &lt;a href="tools/vagrant/README.md"&gt;tools/vagrant/README.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;During the Vagrant setup, the Oracle JDK 8 is used as the default Java environment. If you would like to use OpenJDK 8, please change the line "su vagrant -c 'source all.sh oracle'" into "su vagrant -c 'source all.sh'" in tools/vagrant/Vagrantfile.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-native-development" class="anchor" aria-hidden="true" href="#native-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Native development&lt;/h3&gt;
&lt;p&gt;Docker must be natively installed in order to build and deploy OpenWhisk.
If you plan to make contributions to OpenWhisk, we recommend either a Mac or Ubuntu environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="tools/macos/README.md"&gt;Setup Mac for OpenWhisk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="tools/ubuntu-setup/README.md"&gt;Setup Ubuntu for OpenWhisk&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-learn-concepts-and-commands" class="anchor" aria-hidden="true" href="#learn-concepts-and-commands"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn concepts and commands&lt;/h3&gt;
&lt;p&gt;Browse the &lt;a href="docs/"&gt;documentation&lt;/a&gt; to learn more. Here are some topics you may be
interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="docs/about.md"&gt;System overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/README.md"&gt;Getting Started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/actions.md"&gt;Create and invoke actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/triggers_rules.md"&gt;Create triggers and rules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/packages.md"&gt;Use and create packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/catalog.md"&gt;Browse and use the catalog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/mobile_sdk.md"&gt;Using the OpenWhisk mobile SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/reference.md"&gt;OpenWhisk system details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/feeds.md"&gt;Implementing feeds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="docs/actions-actionloop.md"&gt;Developing a runtime for a new language&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-repository-structure" class="anchor" aria-hidden="true" href="#repository-structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Repository Structure&lt;/h3&gt;
&lt;p&gt;The OpenWhisk system is built from a &lt;a href="docs/dev/modules.md"&gt;number of components&lt;/a&gt;.  The picture below groups the components by their GitHub repos. Please open issues for a component against the appropriate repo (if in doubt just open against the main openwhisk repo).&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="docs/images/components_to_repos.png"&gt;&lt;img src="docs/images/components_to_repos.png" alt="component/repo mapping" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-issues" class="anchor" aria-hidden="true" href="#issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Issues&lt;/h3&gt;
&lt;p&gt;Report bugs, ask questions and request features &lt;a href="../../issues"&gt;here on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-slack" class="anchor" aria-hidden="true" href="#slack"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Slack&lt;/h3&gt;
&lt;p&gt;You can also join the OpenWhisk Team on Slack &lt;a href="https://openwhisk-team.slack.com" rel="nofollow"&gt;https://openwhisk-team.slack.com&lt;/a&gt; and chat with developers. To get access to our public slack team, request an invite &lt;a href="https://openwhisk.apache.org/slack.html" rel="nofollow"&gt;https://openwhisk.apache.org/slack.html&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/openwhisk</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>alphaneet/dice-slayer #18 in Scala, Today</title><link>https://github.com/alphaneet/dice-slayer</link><description>&lt;p&gt;&lt;i&gt;[No description found.]&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-run" class="anchor" aria-hidden="true" href="#run"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;run&lt;/h1&gt;
&lt;p&gt;sbt run&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-ぷるりくえすともとむくれくれ厨" class="anchor" aria-hidden="true" href="#ぷるりくえすともとむくれくれ厨"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ぷるりくえすともとむ！！（くれくれ厨）&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;var を消したバージョン&lt;/li&gt;
&lt;li&gt;scalaz のバージョン&lt;/li&gt;
&lt;li&gt;proguard 化のデプロイ作業の sbt の自動化&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-please-pull-request-requests" class="anchor" aria-hidden="true" href="#please-pull-request-requests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Please Pull Request Requests&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;from var to val&lt;/li&gt;
&lt;li&gt;from scala to scalaz&lt;/li&gt;
&lt;li&gt;proguard auto delpoy by sbt&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>alphaneet</author><guid isPermaLink="false">https://github.com/alphaneet/dice-slayer</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>akka/akka-http #19 in Scala, Today</title><link>https://github.com/akka/akka-http</link><description>&lt;p&gt;&lt;i&gt;The Streaming-first HTTP server/module of Akka&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-akka-http" class="anchor" aria-hidden="true" href="#akka-http"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Akka HTTP&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://index.scala-lang.org/akka/akka-http" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7b1522b66746b631fe6da21c99d7745a61d9d07b/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f616b6b612f616b6b612d687474702f616b6b612d687474702d636f72652f6c61746573742e737667" alt="Latest version" data-canonical-src="https://index.scala-lang.org/akka/akka-http/akka-http-core/latest.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Akka HTTP modules implement a full server- and client-side HTTP stack on top
of akka-actor and akka-stream. It's not a web-framework but rather a more
general toolkit for providing and consuming HTTP-based services. While
interaction with a browser is of course also in scope it is not the primary
focus of Akka HTTP.&lt;/p&gt;
&lt;p&gt;Akka HTTP follows a rather open design and many times offers several different
API levels for "doing the same thing". You get to pick the API level of
abstraction that is most suitable for your application. This means that, if you
have trouble achieving something using a high-level API, there's a good chance
that you can get it done with a low-level API, which offers more flexibility but
might require you to write more application code.&lt;/p&gt;
&lt;p&gt;Learn more at &lt;a href="https://akka.io/" rel="nofollow"&gt;akka.io&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;The documentation is available at
&lt;a href="https://doc.akka.io/docs/akka-http/current/" rel="nofollow"&gt;doc.akka.io&lt;/a&gt;, for
&lt;a href="https://doc.akka.io/docs/akka-http/current/scala/http/" rel="nofollow"&gt;Scala&lt;/a&gt; and
&lt;a href="https://doc.akka.io/docs/akka-http/current/java/http/" rel="nofollow"&gt;Java&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;You can join these groups and chats to discuss and ask Akka related questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forums: &lt;a href="https://discuss.akka.io" rel="nofollow"&gt;discuss.akka.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Chat room about &lt;em&gt;using&lt;/em&gt; Akka HTTP: &lt;a href="https://gitter.im/akka/akka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f9e40f1fe5bdc832a177e1a241915b4521db7272/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769747465722533412d616b6b61253246616b6b612d626c75652e7376673f7374796c653d666c61742d737175617265" alt="gitter: akka/akka" data-canonical-src="https://img.shields.io/badge/gitter%3A-akka%2Fakka-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Q&amp;amp;A: &lt;a href="https://stackoverflow.com/questions/tagged/akka-http" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b7fc3be07076f573e0d8916ba1ebdf3233d35a6e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737461636b6f766572666c6f772533412d616b6b612d2d687474702d626c75652e7376673f7374796c653d666c61742d737175617265" alt="stackoverflow: #akka-http" data-canonical-src="https://img.shields.io/badge/stackoverflow%3A-akka--http-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Issue tracker: &lt;a href="https://github.com/akka/akka-http/issues"&gt;&lt;img src="https://camo.githubusercontent.com/b278eef1d47203c00101c53e739670458e8252b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769746875622533412d6973737565732d626c75652e7376673f7374796c653d666c61742d737175617265" alt="github: akka/akka-http" data-canonical-src="https://img.shields.io/badge/github%3A-issues-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt; (Please use the issue
tracker for bugs and reasonable feature requests. Please ask usage questions on the other channels.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of our forums, chat rooms, and issue trackers are governed by our &lt;a href="https://www.lightbend.com/conduct" rel="nofollow"&gt;Code Of Conduct&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In addition to that, you may enjoy following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href="https://akka.io/blog/news-archive.html" rel="nofollow"&gt;news&lt;/a&gt; section of the page, which is updated whenever a new version is released&lt;/li&gt;
&lt;li&gt;The &lt;a href="https://akka.io/blog" rel="nofollow"&gt;Akka Team Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/akkateam" rel="nofollow"&gt;@akkateam&lt;/a&gt; on Twitter&lt;/li&gt;
&lt;li&gt;Projects built with Akka HTTP: &lt;a href="https://index.scala-lang.org/search?q=dependencies:akka/akka-http*" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/4ecfd7f2cbcd4cd9eb91164b704f16ede8a34ba3/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f636f756e742e7376673f713d646570656e64656e636965733a616b6b612f616b6b612d687474702a267375626a6563743d7363616c616465783a26636f6c6f723d626c7565267374796c653d666c61742d737175617265" alt="Built with Akka HTTP" data-canonical-src="https://index.scala-lang.org/count.svg?q=dependencies:akka/akka-http*&amp;amp;subject=scaladex:&amp;amp;color=blue&amp;amp;style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Contributions are &lt;em&gt;very&lt;/em&gt; welcome!&lt;/p&gt;
&lt;p&gt;If you see an issue that you'd like to see fixed, the best way to make it happen is to help out by submitting a pull request.
For ideas of where to contribute, &lt;a href="https://github.com/akka/akka-http/labels/help%20wanted"&gt;tickets marked as "help wanted"&lt;/a&gt; are a good starting point.&lt;/p&gt;
&lt;p&gt;Refer to the &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file for more details about the workflow,
and general hints on how to prepare your pull request. You can also ask for clarifications or guidance in GitHub issues directly,
or in the &lt;a href="https://gitter.im/akka/dev" rel="nofollow"&gt;akka/dev&lt;/a&gt; chat if a more real-time communication would be of benefit.&lt;/p&gt;
&lt;p&gt;A chat room is available for all questions related to &lt;em&gt;developing and contributing&lt;/em&gt; to Akka:
&lt;a href="https://gitter.im/akka/dev" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0a6c1891578680ac0418fb1b4e8beb0bbb1e00a8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769747465722533412d616b6b612532466465762d626c75652e7376673f7374796c653d666c61742d737175617265" alt="gitter: akka/dev" data-canonical-src="https://img.shields.io/badge/gitter%3A-akka%2Fdev-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-maintenance" class="anchor" aria-hidden="true" href="#maintenance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Maintenance&lt;/h2&gt;
&lt;p&gt;This project is maintained by Lightbend's core Akka Team as well as the extended Akka HTTP Team, consisting of excellent and experienced developers who have shown their dedication and knowledge about HTTP and the codebase. This team may grow dynamically, and it is possible to propose new members to it.&lt;/p&gt;
&lt;p&gt;Joining the extended team in such form gives you, in addition to street-cred, of course committer rights to this repository as well as higher impact onto the roadmap of the project. Come and join us!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Akka HTTP is Open Source and available under the Apache 2 License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>akka</author><guid isPermaLink="false">https://github.com/akka/akka-http</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>lensesio/stream-reactor #20 in Scala, Today</title><link>https://github.com/lensesio/stream-reactor</link><description>&lt;p&gt;&lt;i&gt;Streaming reference architecture for ETL with Kafka and Kafka-Connect.                                                                         You can find more on http://lenses.io on how we provide a unified solution to manage your connectors,  most advanced SQL engine for Kafka and Kafka Streams, cluster monitoring and alerting, and more.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://circleci.com/gh/Landoop/stream-reactor/tree/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ac9d7e06e870f01c41c783d1e0426dc442f820f3/68747470733a2f2f636972636c6563692e636f6d2f67682f4c616e646f6f702f73747265616d2d72656163746f722f747265652f6d61737465722e7376673f7374796c653d73766726636972636c652d746f6b656e3d34656536346239623434393961376164306362333261373439396161346566383766333535393234" alt="CircleCI" data-canonical-src="https://circleci.com/gh/Landoop/stream-reactor/tree/master.svg?style=svg&amp;amp;circle-token=4ee64b9b4499a7ad0cb32a7499aa4ef87f355924" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://docs.lenses.io/connectors/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0b233e4a210326868c5be7197bd9ccb416aacff0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d2d6f72616e67652e7376673f" data-canonical-src="https://img.shields.io/badge/docs--orange.svg?" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.datamountaineer%22" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9cdf5aef7376f738a7e1ff40a3d326f6923a5168/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c617465737425323072656c656173652d312e322e312d626c75652e7376673f6c6162656c3d6c617465737425323072656c65617365" data-canonical-src="https://img.shields.io/badge/latest%20release-1.2.1-blue.svg?label=latest%20release" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Join us on slack &lt;a href="https://launchpass.com/lensesio" rel="nofollow"&gt;&lt;img src="images/slack.jpeg" alt="Alt text" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-lenses-for-apache-kafka" class="anchor" aria-hidden="true" href="#lenses-for-apache-kafka"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Lenses for Apache Kafka&lt;/h1&gt;
&lt;p&gt;Lenses offers SQL (for data browsing and Kafka Streams), Kafka Connect connector management, cluster monitoring and more.&lt;/p&gt;
&lt;p&gt;You can find more on &lt;a href="http://www.lenses.io" rel="nofollow"&gt;lenses.io&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-stream-reactor" class="anchor" aria-hidden="true" href="#stream-reactor"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Stream Reactor&lt;/h1&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="images/streamreactor-logo.png"&gt;&lt;img src="images/streamreactor-logo.png" alt="Alt text" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A collection of components to build a real time ingestion pipeline.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-connectors" class="anchor" aria-hidden="true" href="#connectors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Connectors&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Please take a moment and read the documentation and make sure the software prerequisites are met!!&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Connector&lt;/th&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Docs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AzureDocumentDb&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Azure DocumentDb sink to subscribe to write to the cloud Azure Document Db.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/azuredocdb.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BlockChain&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect Blockchain source to subscribe to Blockchain streams and write to Kafka.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/blockchain.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bloomberg&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect source to subscribe to Bloomberg streams and write to Kafka.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/bloomberg.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cassandra&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect Cassandra source to read Cassandra and write to Kafka.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/cassandra.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*Cassandra&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Certified DSE Kafka connect Cassandra sink task to write Kafka topic payloads to Cassandra.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/cassandra.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Coap&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect Coap source to read from IoT Coap endpoints using Californium.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/coap.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Coap&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Coap sink to write kafka topic payload to IoT Coap endpoints using Californium.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/coap.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Druid&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Druid sink to write Kafka topic payloads to Druid.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Elastic&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Elastic Search sink to write Kafka topic payloads to Elastic Search 2.x&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/elastic.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Elastic 5&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Elastic Search sink to write payloads to Elastic Search 5.x w. tcp or http&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/elastic5.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Elastic 6&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Elastic Search sink to write payloads to Elastic Search 6.x w. tcp or http&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/elastic6.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FTP/HTTP&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect FTP and HTTP source to write file data into Kafka topics.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/ftp.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hazelcast&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Hazelcast sink to write Kafka topic payloads to Hazelcast.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/hazelcast.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HBase&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect HBase sink to write Kafka topic payloads to HBase.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/hbase.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hive&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect Hive source to read data from Hive/HDFS into Kafka.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/hive.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hive&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Hive sink to read data Kafka and load into Hive/HDFS&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/hive.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;InfluxDb&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect InfluxDb sink to write Kafka topic payloads to InfluxDb.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kudu&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Kudu sink to write Kafka topic payloads to Kudu.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/kudu.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;JMS&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect JMS source to write from JMS to Kafka topics.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/jms.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;JMS&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect JMS sink to write Kafka topic payloads to JMS.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/jms.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MongoDB&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect MongoDB sink to write Kafka topic payloads to MongoDB.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/mongo.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MQTT&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect MQTT source to write data from MQTT to Kafka.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/mqtt.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MQTT&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect MQTT sink to write data from Kafka to MQTT.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/mqtt.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pulsar&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect Pulsar source to write data from Pulsar to Kafka.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/pulsar.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pulsar&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Pulsar sink to write data from Kafka to Pulsar.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/pulsar.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Redis&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Redis sink to write Kafka topic payloads to Redis.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/redis.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReThinkDB&lt;/td&gt;
&lt;td&gt;Source&lt;/td&gt;
&lt;td&gt;Kafka connect RethinkDb source subscribe to ReThinkDB changefeeds and write to Kafka.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/source/rethink.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReThinkDB&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect RethinkDb sink to write Kafka topic payloads to RethinkDb.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/rethink.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VoltDB&lt;/td&gt;
&lt;td&gt;Sink&lt;/td&gt;
&lt;td&gt;Kafka connect Voltdb sink to write Kafka topic payloads to Voltdb.&lt;/td&gt;
&lt;td&gt;&lt;a href="https://docs.lenses.io/connectors/sink/voltdb.html" rel="nofollow"&gt;Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-release-notes" class="anchor" aria-hidden="true" href="#release-notes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Release Notes&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1.2.1&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fixed Set support on the Cassandra source connector&lt;/li&gt;
&lt;li&gt;Support Array type in InfluxDB connector&lt;/li&gt;
&lt;li&gt;Fixed records out of order when insert on the Kudu sink connector&lt;/li&gt;
&lt;li&gt;Upgrade to kafka 2.1.0&lt;/li&gt;
&lt;li&gt;Added support for custom delimiter in composite primary keys on the Redis sink connector&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.2.0&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Upgrade to Kafka 2.0&lt;/li&gt;
&lt;li&gt;New Hive source and sink connector supporting Avro, Parquet and ORC&lt;/li&gt;
&lt;li&gt;Fix on NPE for Redis multiple sorted sets&lt;/li&gt;
&lt;li&gt;Fixed setting Mongo primary _id field in upsert mode&lt;/li&gt;
&lt;li&gt;Fix on handling multiple topics in Redis sort set&lt;/li&gt;
&lt;li&gt;Fixed mongodb sink exception when PK is compound key&lt;/li&gt;
&lt;li&gt;Fixed JMS sink with password is not working, wrong context&lt;/li&gt;
&lt;li&gt;Fixed handling multiple primary keys for sorted sets&lt;/li&gt;
&lt;li&gt;Fixed Kudu sink autocreate adding unnecessary partition&lt;/li&gt;
&lt;li&gt;Fixed Avro field with default value does not create table in Kudu&lt;/li&gt;
&lt;li&gt;Fixed Kudu Connector Can Not AutoCreate Table from Sink Record&lt;/li&gt;
&lt;li&gt;Fixed JMS sink session rollback exception if session is closed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.1.0&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Upgrade to Kafka 1.1.0&lt;/li&gt;
&lt;li&gt;Added SSL, subscription, partitioning, batching and key selection to Pulsar source and sink&lt;/li&gt;
&lt;li&gt;Elastic6 connector @caiooliveiraeti !&lt;/li&gt;
&lt;li&gt;HTTP Basic Auth for Elasticsearch http client thanks @justinsoong !&lt;/li&gt;
&lt;li&gt;Add polling timeout on the JMS source connector to avoid high CPU in the source connector poll thanks #373 @matthedude&lt;/li&gt;
&lt;li&gt;Fixes on the elastic primary key separator thanks @caiooliveiraeti!&lt;/li&gt;
&lt;li&gt;Fix on the MQTT class loader&lt;/li&gt;
&lt;li&gt;Fix on the JMS class loader&lt;/li&gt;
&lt;li&gt;Fix on JMS to close down connections cleanly #363 thanks @matthedude!&lt;/li&gt;
&lt;li&gt;Fix on MQTT to correctly handle authentication&lt;/li&gt;
&lt;li&gt;Moved MongoDB batch size to KCQL. &lt;code&gt;connect.mongodb.batch.size&lt;/code&gt; is deprecated&lt;/li&gt;
&lt;li&gt;Added &lt;code&gt;connect.mapping.collection.to.json&lt;/code&gt; to treat maps, list, sets as json when inserting into Cassandra&lt;/li&gt;
&lt;li&gt;Added support for Elastic Pipelines thanks @caiooliveiraeti!&lt;/li&gt;
&lt;li&gt;Moved ReThinkDB batch size to KCQL &lt;code&gt;connect.rethink.batch.size&lt;/code&gt; is deprecated&lt;/li&gt;
&lt;li&gt;MQTT source allows full control of matching the topic &lt;code&gt;INSERT INTO targetTopic SELECT * FROM mqttTopic ... WITHREGEX=`$THE_REGEX` &lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upgrade Kudu Client to 0.7&lt;/li&gt;
&lt;li&gt;Upgrade Azure documentDB client to 1.16.0&lt;/li&gt;
&lt;li&gt;Upgrade Elastic5 to elastic4s 5.6.5&lt;/li&gt;
&lt;li&gt;Upgrade Elastic6 to elastic4s 6.2.5&lt;/li&gt;
&lt;li&gt;Upgrade Hazelcast client to 3.10&lt;/li&gt;
&lt;li&gt;Upgrade InfluxDB client to 2.9&lt;/li&gt;
&lt;li&gt;Upgrade MongoDB client to 3.6.3&lt;/li&gt;
&lt;li&gt;Upgrade Redis client to 2.9&lt;/li&gt;
&lt;li&gt;Kudu connector now accepts a comma separated list of master addresses&lt;/li&gt;
&lt;li&gt;Added missing &lt;code&gt;connect.elastic.retry.interval&lt;/code&gt; to elastic5 and elastic6&lt;/li&gt;
&lt;li&gt;Added a default value set property to Cassandra to allow &lt;code&gt;DEFAULT UNSET&lt;/code&gt; to be added on insert. Omitted columns from maps default to null.
Alternatively, if set &lt;code&gt;UNSET&lt;/code&gt;, pre-existing value  will be preserved&lt;/li&gt;
&lt;li&gt;Cassandra source batch size now in KCQL. &lt;code&gt;connect.cassandra.batch.size&lt;/code&gt; is deprecated .&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.0.0&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 1.0.0 Support&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;0.4.0&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add FTPS support to FTP connector, new configuration option &lt;code&gt;ftp.protocol&lt;/code&gt; introduced, either ftp (default) or ftps.&lt;/li&gt;
&lt;li&gt;Fix for MQTT source High CPU Thanks @masahirom!&lt;/li&gt;
&lt;li&gt;Improve logging on Kudu&lt;/li&gt;
&lt;li&gt;DELETE functionality add to the Cassandra sink, deletion now possible for null payloads, thanks @sandonjacobs !&lt;/li&gt;
&lt;li&gt;Fix in kafka-connect-common to handle primary keys with doc strings thanks, @medvekoma !&lt;/li&gt;
&lt;li&gt;Fix writing multiple topics to the same table in Cassandra #284&lt;/li&gt;
&lt;li&gt;Upgrade to Cassandra driver 3.3.0 and refactor Cassandra tests&lt;/li&gt;
&lt;li&gt;Fix on JMS source transacted queues #285 thanks @matthedude !&lt;/li&gt;
&lt;li&gt;Fix on Cassandra source, configurable timespan queries. You can now control the timespan the Connector will query for&lt;/li&gt;
&lt;li&gt;Allow setting initial query timestamp on Cassandra source&lt;/li&gt;
&lt;li&gt;Allow multiple primary keys on the redis sink&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;0.3.0&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Upgrade CoAP to 2.0.0-M4&lt;/li&gt;
&lt;li&gt;Upgrade to Confluent 3.3 and Kafka 0.11.0.0.&lt;/li&gt;
&lt;li&gt;Added MQTT Sink.&lt;/li&gt;
&lt;li&gt;Add MQTT wildcard support.&lt;/li&gt;
&lt;li&gt;Upgrade CoAP to 2.0.0-M4.&lt;/li&gt;
&lt;li&gt;Added WITHCONVERTERS and WITHTYPE to JMS and MQTT connectors in KCQL to simplify configuration.&lt;/li&gt;
&lt;li&gt;Added FLUSH MODE to Kudu. Thanks! @patsak&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;0.2.6&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Added MQTT Sink&lt;/li&gt;
&lt;li&gt;Upgrade to Confluent 3.2.2&lt;/li&gt;
&lt;li&gt;Upgrade to KCQL 2x&lt;/li&gt;
&lt;li&gt;Add CQL generator to Cassandra source&lt;/li&gt;
&lt;li&gt;Add KCQL INCREMENTALMODE support to the Cassandra source, bulk mode and the timestamp column type is now take from KCQL&lt;/li&gt;
&lt;li&gt;Support for setting key and truststore type on Cassandra connectors&lt;/li&gt;
&lt;li&gt;Added token based paging support for Cassandra source&lt;/li&gt;
&lt;li&gt;Added default bytes converter to JMS Source&lt;/li&gt;
&lt;li&gt;Added default connection factory to JMS Source&lt;/li&gt;
&lt;li&gt;Added support for SharedDurableConsumers to JMS Connectors&lt;/li&gt;
&lt;li&gt;Upgraded JMS Connector to JMS 2.0&lt;/li&gt;
&lt;li&gt;Moved to Elastic4s 2.4&lt;/li&gt;
&lt;li&gt;Added Elastic5s with TCP, TCP+XPACK and HTTP client support&lt;/li&gt;
&lt;li&gt;Upgrade Azure Documentdb to 1.11.0&lt;/li&gt;
&lt;li&gt;Added optional progress counter to all connectors, it can be enabled with &lt;code&gt;connect.progress.enabled&lt;/code&gt; which will periodically report log messages processed&lt;/li&gt;
&lt;li&gt;Added authentication and TLS to ReThink Connectors&lt;/li&gt;
&lt;li&gt;Added TLS support for ReThinkDB, add batch size option to source for draining the internal queues.&lt;/li&gt;
&lt;li&gt;Upgrade Kudu Client to 1.4.0&lt;/li&gt;
&lt;li&gt;Support for dates in Elastic Indexes and custom document types&lt;/li&gt;
&lt;li&gt;Upgrade Connect CLI to 1.0.2 (Renamed to connect-cli)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-bug-fixes" class="anchor" aria-hidden="true" href="#bug-fixes"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bug Fixes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fixes for high CPU on CoAP source&lt;/li&gt;
&lt;li&gt;Fixes for high CPU on Cassandra source&lt;/li&gt;
&lt;li&gt;Fixed Avro double fields mapping to Kudu columns&lt;/li&gt;
&lt;li&gt;Fixes on JMS properties converter, Invalid schema when extracting properties&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-misc" class="anchor" aria-hidden="true" href="#misc"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Misc&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Refactored Cassandra Tests to use only one embedded instance&lt;/li&gt;
&lt;li&gt;Removed unused batch size and bucket size options from Kudu, they are taken from KCQL&lt;/li&gt;
&lt;li&gt;Removed unused batch size option from DocumentDb&lt;/li&gt;
&lt;li&gt;Rename Azure DocumentDb &lt;code&gt;connect.documentdb.db&lt;/code&gt; to &lt;code&gt;connect.documentdb.db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Azure DocumentDb &lt;code&gt;connect.documentdb.database.create&lt;/code&gt; to &lt;code&gt;connect.documentdb.db.create&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Source &lt;code&gt;connect.cassandra.source.kcql&lt;/code&gt; to &lt;code&gt;connect.cassandra.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Source &lt;code&gt;connect.cassandra.source.timestamp.type&lt;/code&gt; to &lt;code&gt;connect.cassandra.timestamp.type&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Source &lt;code&gt;connect.cassandra.source.import.poll.interval&lt;/code&gt; to &lt;code&gt;connect.cassandra.import.poll.interval&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Source &lt;code&gt;connect.cassandra.source.error.policy&lt;/code&gt; to &lt;code&gt;connect.cassandra.error.policy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Source &lt;code&gt;connect.cassandra.source.max.retries&lt;/code&gt; to &lt;code&gt;connect.cassandra.max.retries&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Sink &lt;code&gt;connect.cassandra.source.retry.interval&lt;/code&gt; to &lt;code&gt;connect.cassandra.retry.interval&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Sink &lt;code&gt;connect.cassandra.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.cassandra.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Sink &lt;code&gt;connect.cassandra.sink.error.policy&lt;/code&gt; to &lt;code&gt;connect.cassandra.error.policy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Sink &lt;code&gt;connect.cassandra.sink.max.retries&lt;/code&gt; to &lt;code&gt;connect.cassandra.max.retries&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Cassandra Sink Sink &lt;code&gt;connect.cassandra.sink.retry.interval&lt;/code&gt; to &lt;code&gt;connect.cassandra.retry.interval&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Coap Source &lt;code&gt;connect.coap.bind.port&lt;/code&gt; to &lt;code&gt;connect.coap.port&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Coap Sink &lt;code&gt;connect.coap.bind.port&lt;/code&gt; to &lt;code&gt;connect.coap.port&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Coap Source &lt;code&gt;connect.coap.bind.host&lt;/code&gt; to &lt;code&gt;connect.coap.host&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Coap Sink &lt;code&gt;connect.coap.bind.host&lt;/code&gt; to &lt;code&gt;connect.coap.host&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename MongoDb &lt;code&gt;connect.mongo.database&lt;/code&gt; to &lt;code&gt;connect.mongo.db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename MongoDb &lt;code&gt;connect.mongo.sink.batch.size&lt;/code&gt; to &lt;code&gt;connect.mongo.batch.size&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Druid &lt;code&gt;connect.druid.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.druid.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Druid &lt;code&gt;connect.druid.sink.conf.file&lt;/code&gt; to &lt;code&gt;connect.druid.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Druid &lt;code&gt;connect.druid.sink.write.timeout&lt;/code&gt; to &lt;code&gt;connect.druid.write.timeout&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Elastic &lt;code&gt;connect.elastic.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.elastic.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename HBase &lt;code&gt;connect.hbase.sink.column.family&lt;/code&gt; to &lt;code&gt;connect.hbase.column.family&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename HBase &lt;code&gt;connect.hbase.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.hbase.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename HBase &lt;code&gt;connect.hbase.sink.error.policy&lt;/code&gt; to &lt;code&gt;connect.hbase.error.policy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename HBase &lt;code&gt;connect.hbase.sink.max.retries&lt;/code&gt; to &lt;code&gt;connect.hbase.max.retries&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename HBase &lt;code&gt;connect.hbase.sink.retry.interval&lt;/code&gt; to &lt;code&gt;connect.hbase.retry.interval&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Influx &lt;code&gt;connect.influx.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.influx.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Influx &lt;code&gt;connect.influx.connection.user&lt;/code&gt; to &lt;code&gt;connect.influx.username&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Influx &lt;code&gt;connect.influx.connection.password&lt;/code&gt; to &lt;code&gt;connect.influx.password&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Influx &lt;code&gt;connect.influx.connection.database&lt;/code&gt; to &lt;code&gt;connect.influx.db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Influx &lt;code&gt;connect.influx.connection.url&lt;/code&gt; to &lt;code&gt;connect.influx.url&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Kudu &lt;code&gt;connect.kudu.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.kudu.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Kudu &lt;code&gt;connect.kudu.sink.error.policy&lt;/code&gt; to &lt;code&gt;connect.kudu.error.policy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Kudu &lt;code&gt;connect.kudu.sink.retry.interval&lt;/code&gt; to &lt;code&gt;connect.kudu.retry.interval&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Kudu &lt;code&gt;connect.kudu.sink.max.retries&lt;/code&gt; to &lt;code&gt;connect.kudu.max.reties&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Kudu &lt;code&gt;connect.kudu.sink.schema.registry.url&lt;/code&gt; to &lt;code&gt;connect.kudu.schema.registry.url&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Redis &lt;code&gt;connect.redis.connection.password&lt;/code&gt; to &lt;code&gt;connect.redis.password&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Redis &lt;code&gt;connect.redis.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.redis.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Redis &lt;code&gt;connect.redis.connection.host&lt;/code&gt; to &lt;code&gt;connect.redis.host&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Redis &lt;code&gt;connect.redis.connection.port&lt;/code&gt; to &lt;code&gt;connect.redis.port&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink &lt;code&gt;connect.rethink.source.host&lt;/code&gt; to &lt;code&gt;connect.rethink.host&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink &lt;code&gt;connect.rethink.source.port&lt;/code&gt; to &lt;code&gt;connect.rethink.port&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink &lt;code&gt;connect.rethink.source.db&lt;/code&gt; to &lt;code&gt;connect.rethink.db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink &lt;code&gt;connect.rethink.source.kcql&lt;/code&gt; to &lt;code&gt;connect.rethink.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink Sink &lt;code&gt;connect.rethink.sink.host&lt;/code&gt; to &lt;code&gt;connect.rethink.host&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink Sink &lt;code&gt;connect.rethink.sink.port&lt;/code&gt; to &lt;code&gt;connect.rethink.port&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink Sink &lt;code&gt;connect.rethink.sink.db&lt;/code&gt; to &lt;code&gt;connect.rethink.db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename ReThink Sink &lt;code&gt;connect.rethink.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.rethink.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename JMS &lt;code&gt;connect.jms.user&lt;/code&gt; to &lt;code&gt;connect.jms.username&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename JMS &lt;code&gt;connect.jms.source.converters&lt;/code&gt; to &lt;code&gt;connect.jms.converters&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Remove JMS &lt;code&gt;connect.jms.converters&lt;/code&gt; and replace my kcql &lt;code&gt;withConverters&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Remove JMS &lt;code&gt;connect.jms.queues&lt;/code&gt; and replace my kcql &lt;code&gt;withType QUEUE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Remove JMS &lt;code&gt;connect.jms.topics&lt;/code&gt; and replace my kcql &lt;code&gt;withType TOPIC&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Mqtt &lt;code&gt;connect.mqtt.source.kcql&lt;/code&gt; to &lt;code&gt;connect.mqtt.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Mqtt &lt;code&gt;connect.mqtt.user&lt;/code&gt; to &lt;code&gt;connect.mqtt.username&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Mqtt &lt;code&gt;connect.mqtt.hosts&lt;/code&gt; to &lt;code&gt;connect.mqtt.connection.hosts&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Remove Mqtt &lt;code&gt;connect.mqtt.converters&lt;/code&gt; and replace my kcql &lt;code&gt;withConverters&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Remove Mqtt &lt;code&gt;connect.mqtt.queues&lt;/code&gt; and replace my kcql &lt;code&gt;withType=QUEUE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Remove Mqtt &lt;code&gt;connect.mqtt.topics&lt;/code&gt; and replace my kcql &lt;code&gt;withType=TOPIC&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.hazelcast.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.group.name&lt;/code&gt; to &lt;code&gt;connect.hazelcast.group.name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.group.password&lt;/code&gt; to &lt;code&gt;connect.hazelcast.group.password&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.cluster.members&lt;/code&gt; tp &lt;code&gt;connect.hazelcast.cluster.members&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.batch.size&lt;/code&gt; to &lt;code&gt;connect.hazelcast.batch.size&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.error.policy&lt;/code&gt; to &lt;code&gt;connect.hazelcast.error.policy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.max.retries&lt;/code&gt; to &lt;code&gt;connect.hazelcast.max.retries&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename Hazelcast &lt;code&gt;connect.hazelcast.sink.retry.interval&lt;/code&gt; to &lt;code&gt;connect.hazelcast.retry.interval&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename VoltDB &lt;code&gt;connect.volt.sink.kcql&lt;/code&gt; to &lt;code&gt;connect.volt.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename VoltDB &lt;code&gt;connect.volt.sink.connection.servers&lt;/code&gt; to &lt;code&gt;connect.volt.servers&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename VoltDB &lt;code&gt;connect.volt.sink.connection.user&lt;/code&gt; to &lt;code&gt;connect.volt.username&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename VoltDB &lt;code&gt;connect.volt.sink.connection.password&lt;/code&gt; to &lt;code&gt;connect.volt.password&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename VoltDB &lt;code&gt;connect.volt.sink.error.policy&lt;/code&gt; to &lt;code&gt;connect.volt.error.policy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename VoltDB &lt;code&gt;connect.volt.sink.max.retries&lt;/code&gt; to &lt;code&gt;connect.volt.max.retries&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Rename VoltDB &lt;code&gt;connect.volt.sink.retry.interval&lt;/code&gt; to &lt;code&gt;connect.volt.retry.interval&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;0.2.5 (8 Apr 2017)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Added Azure DocumentDB Sink Connector&lt;/li&gt;
&lt;li&gt;Added JMS Source Connector.&lt;/li&gt;
&lt;li&gt;Added UPSERT to Elastic Search&lt;/li&gt;
&lt;li&gt;Support Confluent 3.2 and Kafka 0.10.2.&lt;/li&gt;
&lt;li&gt;Cassandra improvements &lt;code&gt;withunwrap&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upgrade to Kudu 1.0 and CLI 1.0&lt;/li&gt;
&lt;li&gt;Add ingest_time to CoAP Source&lt;/li&gt;
&lt;li&gt;InfluxDB bug fixes for tags and field selection.&lt;/li&gt;
&lt;li&gt;Added Schemaless Json and Json with schema support to JMS Sink.&lt;/li&gt;
&lt;li&gt;Support for Cassandra data type of &lt;code&gt;timestamp&lt;/code&gt; in the Cassandra Source for timestamp tracking.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;0.2.4&lt;/strong&gt; (26 Jan 2017)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Added FTP and HTTP Source.&lt;/li&gt;
&lt;li&gt;Added InfluxDB tag support. KCQL: INSERT INTO targetdimension &lt;code&gt;SELECT * FROM influx-topic WITHTIMESTAMP sys_time() WITHTAG(field1, CONSTANT_KEY1=CONSTANT_VALUE1, field2,CONSTANT_KEY2=CONSTANT_VALUE1)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Added InfluxDb consistency level. Default is &lt;code&gt;ALL&lt;/code&gt;. Use &lt;code&gt;connect.influx.consistency.level&lt;/code&gt; to set it to ONE/QUORUM/ALL/ANY&lt;/li&gt;
&lt;li&gt;InfluxDb &lt;code&gt;connect.influx.sink.route.query&lt;/code&gt; was renamed to &lt;code&gt;connect.influx.sink.kcql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Added support for multiple contact points in Cassandra&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;0.2.3&lt;/strong&gt; (5 Jan 2017)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Added CoAP Source and Sink.&lt;/li&gt;
&lt;li&gt;Added MongoDB Sink.&lt;/li&gt;
&lt;li&gt;Added MQTT Source.&lt;/li&gt;
&lt;li&gt;Hazelcast support for ring buffers.&lt;/li&gt;
&lt;li&gt;Redis support for Sorted Sets.&lt;/li&gt;
&lt;li&gt;Added start scripts.&lt;/li&gt;
&lt;li&gt;Added Kafka Connect and Schema Registry CLI.&lt;/li&gt;
&lt;li&gt;Kafka Connect CLI now supports pause/restart/resume; checking connectors on the classpath and validating configuration of connectors.&lt;/li&gt;
&lt;li&gt;Support for &lt;code&gt;Struct&lt;/code&gt;, &lt;code&gt;Schema.STRING&lt;/code&gt; and &lt;code&gt;Json&lt;/code&gt; with schema in the Cassandra, ReThinkDB, InfluxDB and MongoDB sinks.&lt;/li&gt;
&lt;li&gt;Rename &lt;code&gt;export.query.route&lt;/code&gt; to &lt;code&gt;sink.kcql&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Rename &lt;code&gt;import.query.route&lt;/code&gt; to &lt;code&gt;source.kcql&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Upgrade to KCQL 0.9.5 - Add support for &lt;code&gt;STOREAS&lt;/code&gt; so specify target sink types, e.g. Redis Sorted Sets, Hazelcast map, queues, ringbuffers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-building" class="anchor" aria-hidden="true" href="#building"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Requires gradle 3.0 to build.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To build&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;gradle compile&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To test&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;gradle &lt;span class="pl-c1"&gt;test&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To create a fat jar&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;gradle shadowJar&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can also use the gradle wrapper&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./gradlew shadowJar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To view dependency trees&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gradle dependencies # or
gradle :kafka-connect-cassandra:dependencies
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To build a particular project&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gradle :kafka-connect-elastic5:build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a jar of a particular project:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gradle :kafka-connect-elastic5:shadowJar
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;We'd love to accept your contributions! Please use GitHub pull requests: fork the repo, develop and test your code,
&lt;a href="http://karma-runner.github.io/1.0/dev/git-commit-msg.html" rel="nofollow"&gt;semantically commit&lt;/a&gt; and submit a pull request. Thanks!&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>lensesio</author><guid isPermaLink="false">https://github.com/lensesio/stream-reactor</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item><item><title>playframework/playframework #21 in Scala, Today</title><link>https://github.com/playframework/playframework</link><description>&lt;p&gt;&lt;i&gt;Play Framework&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="instapaper_body md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-play-framework---the-high-velocity-web-framework" class="anchor" aria-hidden="true" href="#play-framework---the-high-velocity-web-framework"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Play Framework - The High Velocity Web Framework&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://gitter.im/playframework/playframework?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e9c60a0e4c534f0f6e4b18c0d71e337e683104c3/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f67697474657248512f6769747465722e737667" alt="Gitter" data-canonical-src="https://img.shields.io/gitter/room/gitterHQ/gitter.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://travis-ci.org/playframework/playframework" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2494b1b0c8a9027b30f41fe465e0333d3b2db61f/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f706c61796672616d65776f726b2f706c61796672616d65776f726b2e737667" data-canonical-src="https://img.shields.io/travis/playframework/playframework.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="http://mvnrepository.com/artifact/com.typesafe.play/play_2.13" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ab77956dd4d9def7cc89402b168f2d8ca2e49883/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f636f6d2e74797065736166652e706c61792f706c61795f322e31332e737667" alt="Maven" data-canonical-src="https://img.shields.io/maven-central/v/com.typesafe.play/play_2.13.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Play Framework combines productivity and performance making it easy to build scalable web applications with Java and Scala.  Play is developer friendly with a "just hit refresh" workflow and built-in testing support.  With Play, applications scale predictably due to a stateless and non-blocking architecture.  By being RESTful by default, including assets compilers, JSON &amp;amp; WebSocket support, Play is a perfect fit for modern web &amp;amp; mobile applications.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-learn-more" class="anchor" aria-hidden="true" href="#learn-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com" rel="nofollow"&gt;www.playframework.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/download" rel="nofollow"&gt;Download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/Installing" rel="nofollow"&gt;Install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/NewApplication" rel="nofollow"&gt;Create a new application&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/ScalaHome" rel="nofollow"&gt;Play for Scala developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/JavaHome" rel="nofollow"&gt;Play for Java developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/BuildingFromSource" rel="nofollow"&gt;Build from source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/playframework/playframework/issues"&gt;Search or create issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/tagged/playframework" rel="nofollow"&gt;Get help&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.playframework.com/contributing" rel="nofollow"&gt;Contribute&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright (C) 2009-2019 Lightbend Inc. (&lt;a href="https://www.lightbend.com" rel="nofollow"&gt;https://www.lightbend.com&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this project except in compliance with the License. You may obtain a copy of the License at &lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>playframework</author><guid isPermaLink="false">https://github.com/playframework/playframework</guid><pubDate>Fri, 01 Nov 2019 00:00:00 GMT</pubDate></item></channel></rss>