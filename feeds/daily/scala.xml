<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>GitHub Trending: Scala, Today</title><link>https://github.com/trending/scala?since=daily</link><description>The top repositories on GitHub for scala, measured daily</description><pubDate>Tue, 21 Jan 2020 01:04:21 GMT</pubDate><lastBuildDate>Tue, 21 Jan 2020 01:04:21 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><ttl>720</ttl><item><title>apache/predictionio #1 in Scala, Today</title><link>https://github.com/apache/predictionio</link><description>&lt;p&gt;&lt;i&gt;PredictionIO, a machine learning server for developers and ML engineers.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;
&lt;h1&gt;&lt;a id="user-content-apache-predictionio" class="anchor" aria-hidden="true" href="#apache-predictionio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="http://predictionio.apache.org" rel="nofollow"&gt;Apache PredictionIO&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/apache/predictionio" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/35da66076f807165ee2a8d81917e9cb8c910753d/68747470733a2f2f6170692e7472617669732d63692e6f72672f6170616368652f70726564696374696f6e696f2e7376673f6272616e63683d646576656c6f70" alt="Build Status" data-canonical-src="https://api.travis-ci.org/apache/predictionio.svg?branch=develop" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Apache PredictionIO is an open source machine learning framework
for developers, data scientists, and end users. It supports event collection,
deployment of algorithms, evaluation, querying predictive results via REST APIs.
It is based on scalable open source services like Hadoop, HBase (and other DBs),
Elasticsearch, Spark and implements what is called a Lambda Architecture.&lt;/p&gt;
&lt;p&gt;To get started, check out &lt;a href="http://predictionio.apache.org" rel="nofollow"&gt;http://predictionio.apache.org&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Table of contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bugs-and-feature-requests"&gt;Bugs and Feature Requests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#community"&gt;Community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;A few installation options available.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://predictionio.apache.org/install/install-sourcecode/" rel="nofollow"&gt;Installing Apache PredictionIO from
Binary/Source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://predictionio.apache.org/install/install-docker/" rel="nofollow"&gt;Installing Apache PredictionIO with
Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://predictionio.apache.org/templates/recommendation/quickstart/" rel="nofollow"&gt;Recommendation Engine Template Quick
Start&lt;/a&gt;
Guide&lt;/li&gt;
&lt;li&gt;&lt;a href="http://predictionio.apache.org/templates/similarproduct/quickstart/" rel="nofollow"&gt;Similiar Product Engine Template Quick
Start&lt;/a&gt;
Guide&lt;/li&gt;
&lt;li&gt;&lt;a href="http://predictionio.apache.org/templates/classification/quickstart/" rel="nofollow"&gt;Classification Engine Template Quick
Start&lt;/a&gt;
Guide&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-bugs-and-feature-requests" class="anchor" aria-hidden="true" href="#bugs-and-feature-requests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bugs and Feature Requests&lt;/h2&gt;
&lt;p&gt;Use &lt;a href="https://issues.apache.org/jira/browse/PIO" rel="nofollow"&gt;Apache JIRA&lt;/a&gt; to report bugs or request new features.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;Documentation, included in this repo in the &lt;code&gt;docs/manual&lt;/code&gt; directory, is built
with &lt;a href="http://middlemanapp.com/" rel="nofollow"&gt;Middleman&lt;/a&gt; and publicly hosted at
&lt;a href="http://predictionio.apache.org/" rel="nofollow"&gt;predictionio.apache.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Interested in helping with our documentation? Read &lt;a href="http://predictionio.apache.org/community/contribute-documentation/" rel="nofollow"&gt;Contributing
Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;Keep track of development and community news.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Subscribe to the user mailing list &lt;a href="mailto:user-subscribe@predictionio.apache.org"&gt;mailto:user-subscribe@predictionio.apache.org&lt;/a&gt;
and the dev mailing list &lt;a href="mailto:dev-subscribe@predictionio.apache.org"&gt;mailto:dev-subscribe@predictionio.apache.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Follow &lt;a href="https://twitter.com/predictionio" rel="nofollow"&gt;@predictionio&lt;/a&gt; on Twitter.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Read the &lt;a href="http://predictionio.apache.org/community/contribute-code/" rel="nofollow"&gt;Contribute Code&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;You can also list your projects on the &lt;a href="http://predictionio.apache.org//community/projects/" rel="nofollow"&gt;Community Project
page&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Apache PredictionIO is under &lt;a href="http://www.apache.org/licenses/LICENSE-2.0.html" rel="nofollow"&gt;Apache 2
license&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/predictionio</guid><pubDate>Tue, 21 Jan 2020 00:01:00 GMT</pubDate></item><item><title>apache/spark #2 in Scala, Today</title><link>https://github.com/apache/spark</link><description>&lt;p&gt;&lt;i&gt;Apache Spark&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-apache-spark" class="anchor" aria-hidden="true" href="#apache-spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Apache Spark&lt;/h1&gt;
&lt;p&gt;Spark is a unified analytics engine for large-scale data processing. It provides
high-level APIs in Scala, Java, Python, and R, and an optimized engine that
supports general computation graphs for data analysis. It also supports a
rich set of higher-level tools including Spark SQL for SQL and DataFrames,
MLlib for machine learning, GraphX for graph processing,
and Structured Streaming for stream processing.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://spark.apache.org/" rel="nofollow"&gt;https://spark.apache.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cd70373593f382473fbf1fb17a08856e918039d4/68747470733a2f2f616d706c61622e63732e6265726b656c65792e6564752f6a656e6b696e732f6a6f622f737061726b2d6d61737465722d746573742d7362742d6861646f6f702d322e372f62616467652f69636f6e" alt="Jenkins Build" data-canonical-src="https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7/badge/icon" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d3336700f9c89f8132189f928e567a2c104503af/68747470733a2f2f696d672e736869656c64732e696f2f6170707665796f722f63692f417061636865536f667477617265466f756e646174696f6e2f737061726b2f6d61737465722e7376673f7374796c653d706c6173746963266c6f676f3d6170707665796f72" alt="AppVeyor Build" data-canonical-src="https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&amp;amp;logo=appveyor" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://spark-test.github.io/pyspark-coverage-site" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2aa88140c358afddfa651b98a462bd69c4af7eb8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f786d6c2e7376673f6c6162656c3d7079737061726b253230636f7665726167652675726c3d6874747073253341253246253246737061726b2d746573742e6769746875622e696f2532467079737061726b2d636f7665726167652d736974652671756572793d25324668746d6c253246626f64792532466469762535423125354425324664697625324668312532467370616e26636f6c6f72423d627269676874677265656e267374796c653d706c6173746963" alt="PySpark Coverage" data-canonical-src="https://img.shields.io/badge/dynamic/xml.svg?label=pyspark%20coverage&amp;amp;url=https%3A%2F%2Fspark-test.github.io%2Fpyspark-coverage-site&amp;amp;query=%2Fhtml%2Fbody%2Fdiv%5B1%5D%2Fdiv%2Fh1%2Fspan&amp;amp;colorB=brightgreen&amp;amp;style=plastic" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-online-documentation" class="anchor" aria-hidden="true" href="#online-documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online Documentation&lt;/h2&gt;
&lt;p&gt;You can find the latest Spark documentation, including a programming
guide, on the &lt;a href="https://spark.apache.org/documentation.html" rel="nofollow"&gt;project web page&lt;/a&gt;.
This README file only contains basic setup instructions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-building-spark" class="anchor" aria-hidden="true" href="#building-spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building Spark&lt;/h2&gt;
&lt;p&gt;Spark is built using &lt;a href="https://maven.apache.org/" rel="nofollow"&gt;Apache Maven&lt;/a&gt;.
To build Spark and its example programs, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./build/mvn -DskipTests clean package
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(You do not need to do this if you downloaded a pre-built package.)&lt;/p&gt;
&lt;p&gt;More detailed documentation is available from the project site, at
&lt;a href="https://spark.apache.org/docs/latest/building-spark.html" rel="nofollow"&gt;"Building Spark"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For general development tips, including info on developing Spark using an IDE, see &lt;a href="https://spark.apache.org/developer-tools.html" rel="nofollow"&gt;"Useful Developer Tools"&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-scala-shell" class="anchor" aria-hidden="true" href="#interactive-scala-shell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Scala Shell&lt;/h2&gt;
&lt;p&gt;The easiest way to start using Spark is through the Scala shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/spark-shell
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try the following command, which should return 1,000,000,000:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scala&amp;gt; spark.range(1000 * 1000 * 1000).count()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-interactive-python-shell" class="anchor" aria-hidden="true" href="#interactive-python-shell"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Interactive Python Shell&lt;/h2&gt;
&lt;p&gt;Alternatively, if you prefer Python, you can use the Python shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/pyspark
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And run the following command, which should also return 1,000,000,000:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; spark.range(1000 * 1000 * 1000).count()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-example-programs" class="anchor" aria-hidden="true" href="#example-programs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example Programs&lt;/h2&gt;
&lt;p&gt;Spark also comes with several sample programs in the &lt;code&gt;examples&lt;/code&gt; directory.
To run one of them, use &lt;code&gt;./bin/run-example &amp;lt;class&amp;gt; [params]&lt;/code&gt;. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/run-example SparkPi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will run the Pi example locally.&lt;/p&gt;
&lt;p&gt;You can set the MASTER environment variable when running examples to submit
examples to a cluster. This can be a mesos:// or spark:// URL,
"yarn" to run on YARN, and "local" to run
locally with one thread, or "local[N]" to run locally with N threads. You
can also use an abbreviated class name if the class is in the &lt;code&gt;examples&lt;/code&gt;
package. For instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MASTER=spark://host:7077 ./bin/run-example SparkPi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many of the example programs print usage help if no params are given.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-running-tests" class="anchor" aria-hidden="true" href="#running-tests"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Running Tests&lt;/h2&gt;
&lt;p&gt;Testing first requires &lt;a href="#building-spark"&gt;building Spark&lt;/a&gt;. Once Spark is built, tests
can be run using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./dev/run-tests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please see the guidance on how to
&lt;a href="https://spark.apache.org/developer-tools.html#individual-tests" rel="nofollow"&gt;run tests for a module, or individual tests&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-a-note-about-hadoop-versions" class="anchor" aria-hidden="true" href="#a-note-about-hadoop-versions"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A Note About Hadoop Versions&lt;/h2&gt;
&lt;p&gt;Spark uses the Hadoop core library to talk to HDFS and other Hadoop-supported
storage systems. Because the protocols have changed in different versions of
Hadoop, you must build Spark against the same version that your cluster runs.&lt;/p&gt;
&lt;p&gt;Please refer to the build documentation at
&lt;a href="https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn" rel="nofollow"&gt;"Specifying the Hadoop Version and Enabling YARN"&lt;/a&gt;
for detailed guidance on building for a particular distribution of Hadoop, including
building for particular Hive and Hive Thriftserver distributions.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-configuration" class="anchor" aria-hidden="true" href="#configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Please refer to the &lt;a href="https://spark.apache.org/docs/latest/configuration.html" rel="nofollow"&gt;Configuration Guide&lt;/a&gt;
in the online documentation for an overview on how to configure Spark.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;Please review the &lt;a href="https://spark.apache.org/contributing.html" rel="nofollow"&gt;Contribution to Spark guide&lt;/a&gt;
for information on how to get started contributing to the project.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>apache</author><guid isPermaLink="false">https://github.com/apache/spark</guid><pubDate>Tue, 21 Jan 2020 00:02:00 GMT</pubDate></item><item><title>zio/zio #3 in Scala, Today</title><link>https://github.com/zio/zio</link><description>&lt;p&gt;&lt;i&gt;ZIO — A type-safe, composable library for asynchronous and concurrent programming in Scala&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="./ZIO.png"&gt;&lt;img src="./ZIO.png" alt="ZIO Logo" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CI&lt;/th&gt;
&lt;th&gt;Release&lt;/th&gt;
&lt;th&gt;Issues&lt;/th&gt;
&lt;th&gt;Scaladex&lt;/th&gt;
&lt;th&gt;Discord&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://circleci.com/gh/zio/zio" title="circleci" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b1f4a66f890c9d1895b24b5241ab093b9b50691b/68747470733a2f2f636972636c6563692e636f6d2f67682f7a696f2f7a696f2e7376673f7374796c653d737667" alt="Build Status" title="circleci" data-canonical-src="https://circleci.com/gh/zio/zio.svg?style=svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://oss.sonatype.org/content/repositories/releases/dev/zio/zio_2.12/" title="Sonatype Releases" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b382d867705c5ff62e587294ad310c1c460f6c75/68747470733a2f2f696d672e736869656c64732e696f2f6e657875732f722f68747470732f6f73732e736f6e61747970652e6f72672f6465762e7a696f2f7a696f5f322e31322e737667" alt="Release Artifacts" title="Sonatype Releases" data-canonical-src="https://img.shields.io/nexus/r/https/oss.sonatype.org/dev.zio/zio_2.12.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="http://isitmaintained.com/project/zio/zio" title="Average time to resolve an issue" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/dd188de6364b90695c3fbedc0d1f2ed5b875ae2d/687474703a2f2f697369746d61696e7461696e65642e636f6d2f62616467652f7265736f6c7574696f6e2f7a696f2f7a696f2e737667" alt="Average time to resolve an issue" title="Average time to resolve an issue" data-canonical-src="http://isitmaintained.com/badge/resolution/zio/zio.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://index.scala-lang.org/zio/zio/zio" title="Scaladex" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/68f9a94760c1bef87c7a4820404bdb089003c5c4/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f7a696f2f7a696f2f7a696f2f6c61746573742e737667" alt="Badge-Scaladex-page" title="Scaladex" data-canonical-src="https://index.scala-lang.org/zio/zio/zio/latest.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://discord.gg/2ccFBr4" title="Discord" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/961c29d1189d8f042d8c93614057a6accea86731/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3632393439313539373037303832373533303f6c6f676f3d646973636f7264" alt="Badge-Discord" title="chat on discord" data-canonical-src="https://img.shields.io/discord/629491597070827530?logo=discord" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;&lt;a id="user-content-welcome-to-zio" class="anchor" aria-hidden="true" href="#welcome-to-zio"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome to ZIO&lt;/h1&gt;
&lt;p&gt;ZIO is a zero-dependency Scala library for asynchronous and concurrent programming.&lt;/p&gt;
&lt;p&gt;Powered by highly-scalable, non-blocking fibers that never waste or leak resources, ZIO lets you build scalable, resilient, and reactive applications that meet the needs of your business.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;High-performance&lt;/strong&gt;. Build scalable applications with 100x the performance of Scala's &lt;code&gt;Future&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type-safe&lt;/strong&gt;. Use the full power of the Scala compiler to catch bugs at compile time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Concurrent&lt;/strong&gt;. Easily build concurrent apps without deadlocks, race conditions, or complexity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Asynchronous&lt;/strong&gt;. Write sequential code that looks the same whether it's asynchronous or synchronous.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resource-safe&lt;/strong&gt;. Build apps that never leak resources (including threads!), even when they fail.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Testable&lt;/strong&gt;. Inject test services into your app for fast, deterministic, and type-safe testing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resilient&lt;/strong&gt;. Build apps that never lose errors, and which respond to failure locally and flexibly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Functional&lt;/strong&gt;. Rapidly compose solutions to complex problems from simple building blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To learn more about ZIO, see the following references:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zio.dev/" rel="nofollow"&gt;Homepage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="./docs/about/contributing.md"&gt;Contributor's Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="LICENSE"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zio/zio/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zio/zio/pulls"&gt;Pull Requests&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-sponsors" class="anchor" aria-hidden="true" href="#sponsors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sponsors&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://7mind.io" title="Septimal Mind" rel="nofollow"&gt;&lt;img src="./website/static/img/septimal_mind.svg" alt="Septimal Mind" title="Septimal Mind" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://7mind.io" title="Septimal Mind" rel="nofollow"&gt;Septimal Mind&lt;/a&gt; sponsors work on ZIO Tracing and continuous maintenance.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://softwaremill.com" title="SoftwareMill" rel="nofollow"&gt;&lt;img src="./website/static/img/softwaremill.svg" alt="SoftwareMill" title="SoftwareMill" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://softwaremill.com" title="SoftwareMill" rel="nofollow"&gt;SoftwareMill&lt;/a&gt; generously provides ZIO with paid-for CircleCI build infrastructure.&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;&lt;a id="user-content-learn-more-on-the-zio-homepage" class="anchor" aria-hidden="true" href="#learn-more-on-the-zio-homepage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://zio.dev/" rel="nofollow"&gt;Learn More on the ZIO Homepage&lt;/a&gt;&lt;/h1&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-code-of-conduct" class="anchor" aria-hidden="true" href="#code-of-conduct"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Code of Conduct&lt;/h2&gt;
&lt;p&gt;See the &lt;a href="./docs/about/code_of_conduct.md"&gt;Code of Conduct&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;p&gt;Come chat with us on &lt;a href="https://discord.gg/2ccFBr4" title="Discord" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/961c29d1189d8f042d8c93614057a6accea86731/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3632393439313539373037303832373533303f6c6f676f3d646973636f7264" alt="Badge-Discord" title="chat on discord" data-canonical-src="https://img.shields.io/discord/629491597070827530?logo=discord" style="max-width:100%;"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;&lt;a id="user-content-legal" class="anchor" aria-hidden="true" href="#legal"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Legal&lt;/h3&gt;
&lt;p&gt;Copyright 2017 - 2020 John A. De Goes and the ZIO Contributors. All rights reserved.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>zio</author><guid isPermaLink="false">https://github.com/zio/zio</guid><pubDate>Tue, 21 Jan 2020 00:03:00 GMT</pubDate></item><item><title>gatling/gatling #4 in Scala, Today</title><link>https://github.com/gatling/gatling</link><description>&lt;p&gt;&lt;i&gt;Async Scala-Akka-Netty based Load Test Tool&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-gatling--" class="anchor" aria-hidden="true" href="#gatling--"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gatling &lt;a href="https://travis-ci.org/gatling/gatling" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e87d40ad3c3901b02cc99091df3484450b0c9f2d/68747470733a2f2f7472617669732d63692e6f72672f6761746c696e672f6761746c696e672e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/gatling/gatling.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://maven-badges.herokuapp.com/maven-central/io.gatling/gatling-core/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c8415d087772ac68ab22a404ed7ac2dcea6169c4/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f696f2e6761746c696e672f6761746c696e672d636f72652f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/io.gatling/gatling-core/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-what-is-gatling-" class="anchor" aria-hidden="true" href="#what-is-gatling-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What is Gatling ?&lt;/h2&gt;
&lt;p&gt;Gatling is a load test tool.
It officially supports HTTP, WebSocket, Server-Sent-Events and JMS.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-motivation" class="anchor" aria-hidden="true" href="#motivation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Finding fancy GUIs not that convenient for describing load tests, what you want is a friendly expressive DSL?&lt;/li&gt;
&lt;li&gt;Wanting something more convenient than huge XML dumps to store in your source version control system?&lt;/li&gt;
&lt;li&gt;Fed up with having to host a farm of injecting servers because your tool uses blocking IO and one-thread-per-user architecture?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gatling is for you!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-underlying-technologies" class="anchor" aria-hidden="true" href="#underlying-technologies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Underlying technologies&lt;/h2&gt;
&lt;p&gt;Gatling is developed in Scala and built upon :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://netty.io" rel="nofollow"&gt;Netty&lt;/a&gt; for non blocking HTTP&lt;/li&gt;
&lt;li&gt;&lt;a href="https://akka.io" rel="nofollow"&gt;Akka&lt;/a&gt; for virtual users orchestration
...&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-questions-help" class="anchor" aria-hidden="true" href="#questions-help"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Questions, help?&lt;/h2&gt;
&lt;p&gt;Read the &lt;a href="https://gatling.io/docs/current/" rel="nofollow"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Join the &lt;a href="https://groups.google.com/forum/#!forum/gatling" rel="nofollow"&gt;Gatling User Group&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Found a real bug? Raise an &lt;a href="https://github.com/gatling/gatling/issues"&gt;issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-partners" class="anchor" aria-hidden="true" href="#partners"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Partners&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/logo-takima-1-nom-bas.png"&gt;&lt;img alt="Takima" src="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/logo-takima-1-nom-bas.png" width="80" style="max-width:100%;"&gt;&lt;/a&gt;    
&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/highsoft_logo.png"&gt;&lt;img src="https://raw.githubusercontent.com/gatling/gatling/master/src/sphinx/project/img/highsoft_logo.png" alt="Highsoft AS" style="max-width:100%;"&gt;&lt;/a&gt;    &lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>gatling</author><guid isPermaLink="false">https://github.com/gatling/gatling</guid><pubDate>Tue, 21 Jan 2020 00:04:00 GMT</pubDate></item><item><title>polynote/polynote #5 in Scala, Today</title><link>https://github.com/polynote/polynote</link><description>&lt;p&gt;&lt;i&gt;A better notebook for Scala (and more)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-polynote" class="anchor" aria-hidden="true" href="#polynote"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;polynote&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://gitter.im/polynote/polynote" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b049cfe0cf659697dd0671f5c9cec9156f040c26/68747470733a2f2f6261646765732e6769747465722e696d2f706f6c796e6f74652f706f6c796e6f74652e737667" alt="Gitter chat" data-canonical-src="https://badges.gitter.im/polynote/polynote.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/polynote/polynote/actions?query=workflow%3ABuild"&gt;&lt;img src="https://github.com/polynote/polynote/workflows/Build/badge.svg" alt="Build status" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Polynote is an experimental polyglot notebook environment. Currently, it supports Scala and Python (with or without Spark),
SQL, and Vega.&lt;/p&gt;
&lt;p&gt;For more information, see &lt;a href="https://polynote.org" rel="nofollow"&gt;Polynote's website&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-why" class="anchor" aria-hidden="true" href="#why"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why?&lt;/h2&gt;
&lt;p&gt;Current notebook solutions, like Jupyter and Zeppelin, are lacking in some fundamental features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Code editing&lt;/em&gt; – the code editing capabilities in most notebook tools leave plenty to be desired. Why can't a notebook
tool have modern editing capabilities like those you'd find in an IDE? Polynote provides useful autocomplete,
parameter hints, and more – we're planning to add even more features, like jump-to-definition.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Text editing&lt;/em&gt; – you can use the WYSIWYG editor for composing text cells, so you'll know what the text will look like as
you're writing. TeX equations are also supported.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Multi-language support&lt;/em&gt; – Polynote allows you to mix multiple languages in one notebook, while sharing definitions
seamlessly between them.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Runtime insight&lt;/em&gt; – Polynote tries to keep you informed of what's going on at runtime:
&lt;ul&gt;
&lt;li&gt;The tasks area shows you what the kernel is doing at any given time.&lt;/li&gt;
&lt;li&gt;The symbol table shows you what variables and functions you've defined, so you don't have to scroll around to remind yourself.&lt;/li&gt;
&lt;li&gt;Compile failures and runtime exceptions are highlighted in the editor (for supported languages), so you can see exactly what's going wrong.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>polynote</author><guid isPermaLink="false">https://github.com/polynote/polynote</guid><pubDate>Tue, 21 Jan 2020 00:05:00 GMT</pubDate></item><item><title>MethodJiao/PkpmSpark #6 in Scala, Today</title><link>https://github.com/MethodJiao/PkpmSpark</link><description>&lt;p&gt;&lt;i&gt;awesome 三维数据挖掘 数据分析 &amp; 推荐&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-pkpmspark" class="anchor" aria-hidden="true" href="#pkpmspark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PkpmSpark&lt;/h1&gt;
&lt;p&gt;大数据分析 三维数据挖掘运算分析程序&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-机理" class="anchor" aria-hidden="true" href="#机理"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;机理&lt;/h2&gt;
&lt;p&gt;获取mongodb中存储的三维数据进行分析,归并,聚合,加权运算，最后计算完成后的结果存入redis&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-环境配置" class="anchor" aria-hidden="true" href="#环境配置"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;环境配置&lt;/h2&gt;
&lt;p&gt;1.mongodb中需含有名称为mydb数据库与名为netflows的collection&lt;/p&gt;
&lt;p&gt;2.需要配置kafka 并新建topic名称为order(若不需要由kafka做触发源则不用配置)&lt;/p&gt;
&lt;p&gt;3.需配置redis，无用户名密码登录&lt;/p&gt;
&lt;p&gt;4.需spark运行环境 2.4.4测试通过&lt;/p&gt;
&lt;p&gt;5.需scala sdk 2.11.12测试通过&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-程序配置" class="anchor" aria-hidden="true" href="#程序配置"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;程序配置&lt;/h2&gt;
&lt;p&gt;1.kafka消费实例配置在OrderTopicKafka类中，请跟据需要修改，可由工厂模式附加新构造上去&lt;/p&gt;
&lt;p&gt;2.redis链接实例配置在RedisConnector类中，请跟据需要修改&lt;/p&gt;
&lt;p&gt;3.mongodb链接实例配置在SparkMainTask的main函数中，请跟据需要修改&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-编译" class="anchor" aria-hidden="true" href="#编译"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;编译&lt;/h2&gt;
&lt;p&gt;本项目配置了maven编译，在idea命令行执行&lt;code&gt;mvn assembly:assembly&lt;/code&gt;即可编译生成&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-数据源" class="anchor" aria-hidden="true" href="#数据源"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;数据源&lt;/h2&gt;
&lt;p&gt;本项目数据源来自mongodb，数据采集可以传入kafka借由如下链接项目完成kafka向mongodb的同步，采集端只需保证json格式：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/MethodJiao/Kafka2Mongodb"&gt;https://github.com/MethodJiao/Kafka2Mongodb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;也可直接在mongodb中仿造执行如下insert语句制造数据，数据格式如下：&lt;/p&gt;
&lt;p&gt;1.ChildNode中数组可嵌入多个立方体以此描述三维空间&lt;/p&gt;
&lt;p&gt;2.HighPt，LowPt分别为立方体体的对角线端点两点&lt;/p&gt;
&lt;p&gt;3.Name可以存储当前立方体表述对象名&lt;/p&gt;
&lt;p&gt;4.Origin为当前立方体的原点定位&lt;/p&gt;
&lt;p&gt;5.YPRangle为立方体姿态角&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;db.getCollection("netflows").insert( {
    _id: ObjectId("5dededecb3e6784f020c4e90"),
    RootNode: {
        ChildNode: [
            {
                HighPt: {
                    x: 83956,
                    y: 76703,
                    z: 2900
                },
                IsSet: {
                    set: false
                },
                LowPt: {
                    x: 80155,
                    y: 76502,
                    z: 2500
                },
                Name: {
                    name: "PBStructBeam"
                },
                Origin: {
                    x: 83955.9781857537,
                    y: 76602.633138063,
                    z: 2900
                },
                YPRangle: {
                    pitch: 0,
                    roll: 90,
                    yaw: -90
                }
            },
            {
                HighPt: {
                    x: 83557,
                    y: 74903,
                    z: 2900
                },
                IsSet: {
                    set: false
                },
                LowPt: {
                    x: 80756,
                    y: 74702,
                    z: 2420
                },
                Name: {
                    name: "PBStructBeam"
                },
                Origin: {
                    x: 83556.179,
                    y: 74802.2127855456,
                    z: 2900
                },
                YPRangle: {
                    pitch: 0,
                    roll: 90,
                    yaw: -90
                }
            }
        ],
        KeyValue: NumberInt("-6567")
    }
} );
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-运行" class="anchor" aria-hidden="true" href="#运行"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;运行&lt;/h2&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bin/spark-submit --class spark.bim.SparkMainTask --master spark://10.100.140.35:7077 /Users/method.jiao/code/pkpmspark/target/pkpmspark-1.0-SNAPSHOT-jar-with-dependencies.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;参数修改：&lt;/p&gt;
&lt;p&gt;1.配置ip 10.100.140.35:7077&lt;/p&gt;
&lt;p&gt;2.jar包编译路径 /Users/method.jiao/code/pkpmspark/target/pkpmspark-1.0-SNAPSHOT-jar-with-dependencies.jar&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-ps" class="anchor" aria-hidden="true" href="#ps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PS&lt;/h1&gt;
&lt;p&gt;1.如果想在idea直接本地启动不上传task到spark集群的话需要在sparksession加个.master("local")如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;val sparkSession = SparkSession.builder()
  .appName("PKPMBimAnalyse")
  .config("spark.mongodb.input.uri", "mongodb://10.100.140.35/mydb.netflows")
  .master("local")
  .getOrCreate()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2.如果上传task到集群务必去掉master属性&lt;/p&gt;
&lt;p&gt;3.如果想在idea远程提交并调试 如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;val sparkSession = SparkSession.builder()
  .appName("PKPMBimAnalyse")
  .config("spark.mongodb.input.uri", "mongodb://10.100.140.35/mydb.netflows")
  .master("spark://10.100.140.35:7077")
  .getOrCreate()
&lt;/code&gt;&lt;/pre&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>MethodJiao</author><guid isPermaLink="false">https://github.com/MethodJiao/PkpmSpark</guid><pubDate>Tue, 21 Jan 2020 00:06:00 GMT</pubDate></item><item><title>spark-jobserver/spark-jobserver #7 in Scala, Today</title><link>https://github.com/spark-jobserver/spark-jobserver</link><description>&lt;p&gt;&lt;i&gt;REST job server for Apache Spark&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://travis-ci.org/spark-jobserver/spark-jobserver" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c2f25b2f01af437fafa169b6a3fd7a59fe963ef0/68747470733a2f2f7472617669732d63692e6f72672f737061726b2d6a6f627365727665722f737061726b2d6a6f627365727665722e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/spark-jobserver/spark-jobserver.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/spark-jobserver/spark-jobserver/branch/master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5465af4128b7d50cf4dd4a7e92996d4a7e741706/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f737061726b2d6a6f627365727665722f737061726b2d6a6f627365727665722f6d61737465722e737667" alt="Coverage" data-canonical-src="https://img.shields.io/codecov/c/github/spark-jobserver/spark-jobserver/master.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gitter.im/spark-jobserver/spark-jobserver?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/spark-jobserver/spark-jobserver" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;spark-jobserver provides a RESTful interface for submitting and managing &lt;a href="http://spark-project.org" rel="nofollow"&gt;Apache Spark&lt;/a&gt; jobs, jars, and job contexts.
This repo contains the complete Spark job server project, including unit tests and deploy scripts.
It was originally started at &lt;a href="http://www.ooyala.com" rel="nofollow"&gt;Ooyala&lt;/a&gt;, but this is now the main development repo.&lt;/p&gt;
&lt;p&gt;Other useful links: &lt;a href="doc/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt;, &lt;a href="doc/cluster.md"&gt;cluster&lt;/a&gt;, &lt;a href="doc/yarn.md"&gt;YARN client&lt;/a&gt;, &lt;a href="doc/EMR.md"&gt;YARN on EMR&lt;/a&gt;, &lt;a href="doc/mesos.md"&gt;Mesos&lt;/a&gt;, &lt;a href="doc/jmx.md"&gt;JMX tips&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also see &lt;a href="doc/chinese/job-server.md"&gt;Chinese docs / 中文&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;  &lt;em&gt;generated with &lt;a href="https://github.com/thlorenz/doctoc"&gt;DocToc&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#users"&gt;Users&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#features"&gt;Features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#version-information"&gt;Version Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-started-with-spark-job-server"&gt;Getting Started with Spark Job Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#development-mode"&gt;Development mode&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#wordcountexample-walk-through"&gt;WordCountExample walk-through&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#package-jar---send-to-server"&gt;Package Jar - Send to Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ad-hoc-mode---single-unrelated-jobs-transient-context"&gt;Ad-hoc Mode - Single, Unrelated Jobs (Transient Context)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#persistent-context-mode---faster--required-for-related-jobs"&gt;Persistent Context Mode - Faster &amp;amp; Required for Related Jobs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#debug-mode"&gt;Debug mode&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-a-job-server-project"&gt;Create a Job Server Project&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#creating-a-project-from-scratch-using-giter8-template"&gt;Creating a project from scratch using giter8 template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#creating-a-project-manually-assuming-that-you-already-have-sbt-project-structure"&gt;Creating a project manually assuming that you already have sbt project structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#new-sparkjob-api"&gt;NEW SparkJob API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#new-sparkjob-api-with-spark-v21"&gt;NEW SparkJob API with Spark v2.1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dependency-jars"&gt;Dependency jars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#named-objects"&gt;Named Objects&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#using-named-rdds"&gt;Using Named RDDs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-named-objects"&gt;Using Named Objects&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#https--ssl-configuration"&gt;HTTPS / SSL Configuration&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#server-authentication"&gt;Server authentication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#client-authentication"&gt;Client authentication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#basic-authentication"&gt;Basic authentication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#deployment"&gt;Deployment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#manual-steps"&gt;Manual steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#context-per-jvm"&gt;Context per JVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuring-spark-jobserver-backend"&gt;Configuring Spark Jobserver backend&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#configuring-spark-jobserver-h2-database-backend"&gt;Configuring Spark Jobserver H2 Database backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuring-spark-jobserver-postgresql-database-backend"&gt;Configuring Spark Jobserver PostgreSQL Database backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuring-spark-jobserver-mysql-database-backend"&gt;Configuring Spark Jobserver MySQL Database backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuring-spark-jobserver-zookeeper--hdfs-database-backend"&gt;Configuring Spark Jobserver Zookeeper + HDFS Database backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuring-spark-jobserver-cassandra-backend"&gt;Configuring Spark Jobserver Cassandra backend&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#ha-deployment-beta"&gt;HA Deployment (beta)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#chef"&gt;Chef&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#api"&gt;API&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#binaries"&gt;Binaries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contexts"&gt;Contexts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#jobs"&gt;Jobs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#data"&gt;Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#data-api-example"&gt;Data API Example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#context-configuration"&gt;Context configuration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-configuration-settings"&gt;Other configuration settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#job-result-serialization"&gt;Job Result Serialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#http-override"&gt;HTTP Override&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#clients"&gt;Clients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contribution-and-development"&gt;Contribution and Development&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#publishing-packages"&gt;Publishing packages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#todo"&gt;TODO&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;&lt;a id="user-content-users" class="anchor" aria-hidden="true" href="#users"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Users&lt;/h2&gt;
&lt;p&gt;(Please add yourself to this list!)&lt;/p&gt;
&lt;p&gt;Spark Job Server is included in Datastax Enterprise!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.ooyala.com" rel="nofollow"&gt;Ooyala&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.netflix.com" rel="nofollow"&gt;Netflix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.avenida.com" rel="nofollow"&gt;Avenida.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GumGum&lt;/li&gt;
&lt;li&gt;Fuse Elements&lt;/li&gt;
&lt;li&gt;Frontline Solvers&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.arubanetworks.com/" rel="nofollow"&gt;Aruba Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.zed.com" rel="nofollow"&gt;Zed Worldwide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.knime.org/" rel="nofollow"&gt;KNIME&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://azavea.com" rel="nofollow"&gt;Azavea&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://maana.io/" rel="nofollow"&gt;Maana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.newsweaver.com" rel="nofollow"&gt;Newsweaver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.instaclustr.com" rel="nofollow"&gt;Instaclustr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.snappydata.io" rel="nofollow"&gt;SnappyData&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.linkfluence.com" rel="nofollow"&gt;Linkfluence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.smartsct.com" rel="nofollow"&gt;Smartsct&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.datadoghq.com/" rel="nofollow"&gt;Datadog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.planalytics.com" rel="nofollow"&gt;Planalytics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.target.com/" rel="nofollow"&gt;Target&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://branch.io" rel="nofollow"&gt;Branch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;"Spark as a Service"&lt;/em&gt;: Simple REST interface (including HTTPS) for all aspects of job, context management&lt;/li&gt;
&lt;li&gt;Support for Spark SQL, Hive, Streaming Contexts/jobs and custom job contexts!  See &lt;a href="doc/contexts.md"&gt;Contexts&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/python.md"&gt;Python&lt;/a&gt;, Scala, and &lt;a href="doc/javaapi.md"&gt;Java&lt;/a&gt; (see &lt;a href="https://github.com/spark-jobserver/spark-jobserver/blob/master/job-server-api/src/main/java/spark/jobserver/api/TestJob.java"&gt;TestJob.java&lt;/a&gt;) support&lt;/li&gt;
&lt;li&gt;LDAP Auth support via Apache Shiro integration&lt;/li&gt;
&lt;li&gt;Separate JVM per SparkContext for isolation (EXPERIMENTAL)&lt;/li&gt;
&lt;li&gt;Supports sub-second low-latency jobs via long-running job contexts&lt;/li&gt;
&lt;li&gt;Start and stop job contexts for RDD sharing and low-latency jobs; change resources on restart&lt;/li&gt;
&lt;li&gt;Kill running jobs via stop context and delete job&lt;/li&gt;
&lt;li&gt;Separate jar uploading step for faster job startup&lt;/li&gt;
&lt;li&gt;Asynchronous and synchronous job API.  Synchronous API is great for low latency jobs!&lt;/li&gt;
&lt;li&gt;Works with Standalone Spark as well on &lt;a href="doc/cluster.md"&gt;cluster&lt;/a&gt;, &lt;a href="doc/mesos.md"&gt;Mesos&lt;/a&gt;, YARN &lt;a href="doc/yarn.md"&gt;client&lt;/a&gt; and &lt;a href="doc/EMR.md"&gt;on EMR&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Job and jar info is persisted via a pluggable DAO interface&lt;/li&gt;
&lt;li&gt;Named Objects (such as RDDs or DataFrames) to cache and retrieve RDDs or DataFrames by name, improving object sharing and reuse among jobs.&lt;/li&gt;
&lt;li&gt;Supports Scala 2.10 and 2.11&lt;/li&gt;
&lt;li&gt;Support for supervise mode of Spark (EXPERIMENTAL)&lt;/li&gt;
&lt;li&gt;Possible to be deployed in an &lt;a href="#ha-deployment-beta"&gt;HA setup&lt;/a&gt; of multiple jobservers (beta)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-version-information" class="anchor" aria-hidden="true" href="#version-information"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Version Information&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;th&gt;Spark Version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.3.1&lt;/td&gt;
&lt;td&gt;0.9.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.4.0&lt;/td&gt;
&lt;td&gt;1.0.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.4.1&lt;/td&gt;
&lt;td&gt;1.1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.5.0&lt;/td&gt;
&lt;td&gt;1.2.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.5.1&lt;/td&gt;
&lt;td&gt;1.3.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.5.2&lt;/td&gt;
&lt;td&gt;1.3.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.6.0&lt;/td&gt;
&lt;td&gt;1.4.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.6.1&lt;/td&gt;
&lt;td&gt;1.5.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.6.2&lt;/td&gt;
&lt;td&gt;1.6.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.7.0&lt;/td&gt;
&lt;td&gt;1.6.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.8.0&lt;/td&gt;
&lt;td&gt;2.2.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.9.0-SNAPSHOT&lt;/td&gt;
&lt;td&gt;2.3.2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For release notes, look in the &lt;code&gt;notes/&lt;/code&gt; directory.&lt;/p&gt;
&lt;p&gt;If you need non-released jars, please visit &lt;a href="https://jitpack.io" rel="nofollow"&gt;Jitpack&lt;/a&gt; - they provide non-release jar builds for any Git repo.  :)&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started-with-spark-job-server" class="anchor" aria-hidden="true" href="#getting-started-with-spark-job-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Started with Spark Job Server&lt;/h2&gt;
&lt;p&gt;The easiest way to get started is to try the &lt;a href="doc/docker.md"&gt;Docker container&lt;/a&gt; which prepackages a Spark distribution with the job server and lets you start and deploy it.&lt;/p&gt;
&lt;p&gt;Alternatives:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Build and run Job Server in local &lt;a href="#development-mode"&gt;development mode&lt;/a&gt; within SBT.  NOTE:  This does NOT work for YARN, and in fact is only recommended with &lt;code&gt;spark.master&lt;/code&gt; set to &lt;code&gt;local[*]&lt;/code&gt;.  Please deploy if you want to try with YARN or other real cluster.&lt;/li&gt;
&lt;li&gt;Deploy job server to a cluster.  There are two alternatives (see the &lt;a href="#deployment"&gt;deployment section&lt;/a&gt;):
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;server_deploy.sh&lt;/code&gt;  deploys job server to a directory on a remote host.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;server_package.sh&lt;/code&gt; deploys job server to a local directory, from which you can deploy the directory, or create a .tar.gz for Mesos or YARN deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;EC2 Deploy scripts - follow the instructions in &lt;a href="doc/EC2.md"&gt;EC2&lt;/a&gt; to spin up a Spark cluster with job server and an example application.&lt;/li&gt;
&lt;li&gt;EMR Deploy instruction - follow the instruction in &lt;a href="doc/EMR.md"&gt;EMR&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NOTE: Spark Job Server can optionally run &lt;code&gt;SparkContext&lt;/code&gt;s in their own, forked JVM process when the config option &lt;code&gt;spark.jobserver.context-per-jvm&lt;/code&gt; is set to &lt;code&gt;true&lt;/code&gt;.  This option does not currently work for SBT/local dev mode. See &lt;a href="#deployment"&gt;Deployment&lt;/a&gt; section for more info.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-development-mode" class="anchor" aria-hidden="true" href="#development-mode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Development mode&lt;/h2&gt;
&lt;p&gt;The example walk-through below shows you how to use the job server with an included example job, by running the job server in local development mode in SBT.  This is not an example of usage in production.&lt;/p&gt;
&lt;p&gt;You need to have &lt;a href="http://www.scala-sbt.org/release/docs/Getting-Started/Setup.html" rel="nofollow"&gt;SBT&lt;/a&gt; installed.&lt;/p&gt;
&lt;p&gt;To set the current version, do something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export VER=`sbt version | tail -1 | cut -f2`
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From SBT shell, simply type "reStart".  This uses a default configuration file.  An optional argument is a
path to an alternative config file.  You can also specify JVM parameters after "---".  Including all the
options looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;job-server-extras/reStart /path/to/my.conf --- -Xmx8g
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that reStart (SBT Revolver) forks the job server in a separate process.  If you make a code change, simply
type reStart again at the SBT shell prompt, it will compile your changes and restart the jobserver.  It enables
very fast turnaround cycles.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE2&lt;/strong&gt;: You cannot do &lt;code&gt;sbt reStart&lt;/code&gt; from the OS shell.  SBT will start job server and immediately kill it.&lt;/p&gt;
&lt;p&gt;For example jobs see the job-server-tests/ project / folder.&lt;/p&gt;
&lt;p&gt;When you use &lt;code&gt;reStart&lt;/code&gt;, the log file goes to &lt;code&gt;job-server/job-server-local.log&lt;/code&gt;.  There is also an environment variable
EXTRA_JAR for adding a jar to the classpath.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-wordcountexample-walk-through" class="anchor" aria-hidden="true" href="#wordcountexample-walk-through"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;WordCountExample walk-through&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-package-jar---send-to-server" class="anchor" aria-hidden="true" href="#package-jar---send-to-server"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Package Jar - Send to Server&lt;/h4&gt;
&lt;p&gt;First, to package the test jar containing the WordCountExample: &lt;code&gt;sbt job-server-tests/package&lt;/code&gt;.
Then go ahead and start the job server using the instructions above.&lt;/p&gt;
&lt;p&gt;Let's upload the jar:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST localhost:8090/binaries/test -H "Content-Type: application/java-archive" --data-binary @job-server-tests/target/scala-2.10/job-server-tests-$VER.jar
OK⏎
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-ad-hoc-mode---single-unrelated-jobs-transient-context" class="anchor" aria-hidden="true" href="#ad-hoc-mode---single-unrelated-jobs-transient-context"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Ad-hoc Mode - Single, Unrelated Jobs (Transient Context)&lt;/h4&gt;
&lt;p&gt;The above jar is uploaded as app &lt;code&gt;test&lt;/code&gt;.  Next, let's start an ad-hoc word count job, meaning that the job
server will create its own SparkContext, and return a job ID for subsequent querying:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -d "input.string = a b c a b see" "localhost:8090/jobs?appName=test&amp;amp;classPath=spark.jobserver.WordCountExample"
{
  "duration": "Job not done yet",
  "classPath": "spark.jobserver.WordCountExample",
  "startTime": "2016-06-19T16:27:12.196+05:30",
  "context": "b7ea0eb5-spark.jobserver.WordCountExample",
  "status": "STARTED",
  "jobId": "5453779a-f004-45fc-a11d-a39dae0f9bf4"
}⏎
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: If you want to feed in a text file config and POST using curl, you want the &lt;code&gt;--data-binary&lt;/code&gt; option, otherwise
curl will munge your line separator chars.  Like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl --data-binary @my-job-config.json "localhost:8090/jobs?appNam=..."
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE2: If you want to send in UTF-8 chars, make sure you pass in a proper header to CURL for the encoding, otherwise it may assume an encoding which is not what you expect.&lt;/p&gt;
&lt;p&gt;From this point, you could asynchronously query the status and results:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl localhost:8090/jobs/5453779a-f004-45fc-a11d-a39dae0f9bf4
{
  "duration": "6.341 secs",
  "classPath": "spark.jobserver.WordCountExample",
  "startTime": "2015-10-16T03:17:03.127Z",
  "context": "b7ea0eb5-spark.jobserver.WordCountExample",
  "result": {
    "a": 2,
    "b": 2,
    "c": 1,
    "see": 1
  },
  "status": "FINISHED",
  "jobId": "5453779a-f004-45fc-a11d-a39dae0f9bf4"
}⏎
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that you could append &lt;code&gt;&amp;amp;sync=true&lt;/code&gt; when you POST to /jobs to get the results back in one request, but for
real clusters and most jobs this may be too slow.&lt;/p&gt;
&lt;p&gt;You can also append &lt;code&gt;&amp;amp;timeout=XX&lt;/code&gt; to extend the request timeout for &lt;code&gt;sync=true&lt;/code&gt; requests.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-persistent-context-mode---faster--required-for-related-jobs" class="anchor" aria-hidden="true" href="#persistent-context-mode---faster--required-for-related-jobs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Persistent Context Mode - Faster &amp;amp; Required for Related Jobs&lt;/h4&gt;
&lt;p&gt;Another way of running this job is in a pre-created context.  Start a new context:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -d "" "localhost:8090/contexts/test-context?num-cpu-cores=4&amp;amp;memory-per-node=512m"
OK⏎
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can verify that the context has been created:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl localhost:8090/contexts
["test-context"]⏎
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let's run the job in the context and get the results back right away:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -d "input.string = a b c a b see" "localhost:8090/jobs?appName=test&amp;amp;classPath=spark.jobserver.WordCountExample&amp;amp;context=test-context&amp;amp;sync=true"
{
  "result": {
    "a": 2,
    "b": 2,
    "c": 1,
    "see": 1
  }
}⏎
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the addition of &lt;code&gt;context=&lt;/code&gt; and &lt;code&gt;sync=true&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-debug-mode" class="anchor" aria-hidden="true" href="#debug-mode"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Debug mode&lt;/h3&gt;
&lt;p&gt;Spark job server is started using SBT Revolver (which forks a new JVM), so debugging directly in an IDE is not feasible.
To enable debugging, the Spark job server should be started from the SBT shell with the following Java options :&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;job-server-extras/reStart /absolute/path/to/your/dev.conf --- -Xdebug -Xrunjdwp:transport=dt_socket,address=15000,server=y,suspend=y&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above command starts a remote debugging server on port 15000. The Spark job server is not started until a debugging client
(Intellij, Eclipse, telnet, ...) connects to the exposed port.&lt;/p&gt;
&lt;p&gt;In your IDE you just have to start a Remote debugging debug job and use the above defined port. Once the client connects to the debugging server the Spark job server is started and you can start adding breakpoints and debugging requests.&lt;/p&gt;
&lt;p&gt;Note that you might need to adjust some server parameters to avoid short Spary/Akka/Spark timeouts, in your &lt;code&gt;dev.conf&lt;/code&gt; add the following values :&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;spark {
  jobserver {
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Dev debug timeouts&lt;/span&gt;
    context-creation-timeout = 1000000 s
    yarn-context-creation-timeout = 1000000 s
    default-sync-timeout = 1000000 s
  }

  context-settings {
    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Dev debug timeout&lt;/span&gt;
    context-init-timeout = 1000000 s
  }
}
spray.can.server {
      &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Debug timeouts&lt;/span&gt;
      idle-timeout = infinite
      request-timeout = infinite
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Additionally, you might have to increase the Akka Timeouts by adding the following query parameter &lt;code&gt;timeout=1000000&lt;/code&gt; in your HTTP requests :&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;curl -d &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;input.string = a b c a b see&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;localhost:8090/jobs?appName=test&amp;amp;classPath=spark.jobserver.WordCountExample&amp;amp;sync=true&amp;amp;timeout=100000&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-create-a-job-server-project" class="anchor" aria-hidden="true" href="#create-a-job-server-project"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Create a Job Server Project&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-creating-a-project-from-scratch-using-giter8-template" class="anchor" aria-hidden="true" href="#creating-a-project-from-scratch-using-giter8-template"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creating a project from scratch using giter8 template&lt;/h3&gt;
&lt;p&gt;There is a giter8 template available at &lt;a href="https://github.com/spark-jobserver/spark-jobserver.g8"&gt;https://github.com/spark-jobserver/spark-jobserver.g8&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sbt new spark-jobserver/spark-jobserver.g8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Answer the questions to generate a project structure for you. This contains Word Count example spark job using both old API and new one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd /path/to/project/directory
$ sbt package
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you could remove example application and start adding your one.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-creating-a-project-manually-assuming-that-you-already-have-sbt-project-structure" class="anchor" aria-hidden="true" href="#creating-a-project-manually-assuming-that-you-already-have-sbt-project-structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Creating a project manually assuming that you already have sbt project structure&lt;/h3&gt;
&lt;p&gt;In your &lt;code&gt;build.sbt&lt;/code&gt;, add this to use the job server jar:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    resolvers += "Job Server Bintray" at "https://dl.bintray.com/spark-jobserver/maven"

    libraryDependencies += "spark.jobserver" %% "job-server-api" % "0.8.0" % "provided"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If a SQL or Hive job/context is desired, you also want to pull in &lt;code&gt;job-server-extras&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;libraryDependencies += "spark.jobserver" %% "job-server-extras" % "0.8.0" % "provided"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For most use cases it's better to have the dependencies be "provided" because you don't want SBT assembly to include the whole job server jar.&lt;/p&gt;
&lt;p&gt;To create a job that can be submitted through the job server, the job must implement the &lt;code&gt;SparkJob&lt;/code&gt; trait.
Your job will look like:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;object&lt;/span&gt; &lt;span class="pl-en"&gt;SampleJob&lt;/span&gt; &lt;span class="pl-k"&gt;extends&lt;/span&gt; &lt;span class="pl-e"&gt;SparkJob&lt;/span&gt; {
    &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;runJob&lt;/span&gt;(&lt;span class="pl-v"&gt;sc&lt;/span&gt;: &lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;jobConfig&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Any&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;???&lt;/span&gt;
    &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;validate&lt;/span&gt;(&lt;span class="pl-v"&gt;sc&lt;/span&gt;: &lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;config&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;SparkJobValidation&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;???&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;runJob&lt;/code&gt; contains the implementation of the Job. The SparkContext is managed by the JobServer and will be provided to the job through this method.
This relieves the developer from the boiler-plate configuration management that comes with the creation of a Spark job and allows the Job Server to
manage and re-use contexts.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;validate&lt;/code&gt; allows for an initial validation of the context and any provided configuration. If the context and configuration are OK to run the job, returning &lt;code&gt;spark.jobserver.SparkJobValid&lt;/code&gt; will let the job execute, otherwise returning &lt;code&gt;spark.jobserver.SparkJobInvalid(reason)&lt;/code&gt; prevents the job from running and provides means to convey the reason of failure. In this case, the call immediately returns an &lt;code&gt;HTTP/1.1 400 Bad Request&lt;/code&gt; status code.
&lt;code&gt;validate&lt;/code&gt; helps you preventing running jobs that will eventually fail due to missing or wrong configuration and save both time and resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-new-sparkjob-api" class="anchor" aria-hidden="true" href="#new-sparkjob-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NEW SparkJob API&lt;/h3&gt;
&lt;p&gt;Note: As of version 0.7.0, a new SparkJob API that is significantly better than the old SparkJob API will take over.  Existing jobs should continue to compile against the old &lt;code&gt;spark.jobserver.SparkJob&lt;/code&gt; API, but this will be deprecated in the future.  Note that jobs before 0.7.0 will need to be recompiled, older jobs may not work with the current SJS example.  The new API looks like this:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;object&lt;/span&gt; &lt;span class="pl-en"&gt;WordCountExampleNewApi&lt;/span&gt; &lt;span class="pl-k"&gt;extends&lt;/span&gt; &lt;span class="pl-e"&gt;NewSparkJob&lt;/span&gt; {
  &lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-en"&gt;JobData&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Seq&lt;/span&gt;[&lt;span class="pl-en"&gt;String&lt;/span&gt;]
  &lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-en"&gt;JobOutput&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; collection.&lt;span class="pl-en"&gt;Map&lt;/span&gt;[&lt;span class="pl-en"&gt;String&lt;/span&gt;, &lt;span class="pl-en"&gt;Long&lt;/span&gt;]

  &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;runJob&lt;/span&gt;(&lt;span class="pl-v"&gt;sc&lt;/span&gt;: &lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;runtime&lt;/span&gt;: &lt;span class="pl-en"&gt;JobEnvironment&lt;/span&gt;, &lt;span class="pl-v"&gt;data&lt;/span&gt;: &lt;span class="pl-en"&gt;JobData&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;JobOutput&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt;
    sc.parallelize(data).countByValue

  &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;validate&lt;/span&gt;(&lt;span class="pl-v"&gt;sc&lt;/span&gt;: &lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;runtime&lt;/span&gt;: &lt;span class="pl-en"&gt;JobEnvironment&lt;/span&gt;, &lt;span class="pl-v"&gt;config&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt;
    &lt;span class="pl-en"&gt;JobData&lt;/span&gt; &lt;span class="pl-en"&gt;Or&lt;/span&gt; &lt;span class="pl-en"&gt;Every&lt;/span&gt;[&lt;span class="pl-en"&gt;ValidationProblem&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; {
    &lt;span class="pl-en"&gt;Try&lt;/span&gt;(config.getString(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;input.string&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).split(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt; &lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).toSeq)
      .map(words &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Good&lt;/span&gt;(words))
      .getOrElse(&lt;span class="pl-en"&gt;Bad&lt;/span&gt;(&lt;span class="pl-en"&gt;One&lt;/span&gt;(&lt;span class="pl-en"&gt;SingleProblem&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;No input.string param&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))))
  }
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It is much more type safe, separates context configuration, job ID, named objects, and other environment variables into a separate JobEnvironment input, and allows the validation method to return specific data for the runJob method.  See the &lt;a href="job-server-tests/src/main/scala/spark/jobserver/WordCountExample.scala"&gt;WordCountExample&lt;/a&gt; and &lt;a href="job-server-tests/src/main/scala/spark/jobserver/LongPiJob.scala"&gt;LongPiJob&lt;/a&gt; for examples.&lt;/p&gt;
&lt;p&gt;Let's try running our sample job with an invalid configuration:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -i -d "bad.input=abc" "localhost:8090/jobs?appName=test&amp;amp;classPath=spark.jobserver.WordCountExample"
HTTP/1.1 400 Bad Request
Server: spray-can/1.3.4
Date: Thu, 14 Sep 2017 12:01:37 GMT
Access-Control-Allow-Origin: *
Content-Type: application/json; charset=UTF-8
Content-Length: 738

{
  "status": "VALIDATION FAILED",
  "result": {
    "message": "One(SparkJobInvalid(No input.string config param))",
    "errorClass": "java.lang.Throwable",
    "stack": "java.lang.Throwable: One(SparkJobInvalid(No input.string config param))\n\tat spark.jobserver.JobManagerActor$$anonfun$getJobFuture$4.apply(JobManagerActor.scala:327)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-new-sparkjob-api-with-spark-v21" class="anchor" aria-hidden="true" href="#new-sparkjob-api-with-spark-v21"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;NEW SparkJob API with Spark v2.1&lt;/h3&gt;
&lt;p&gt;Deploying Spark JobServer with Spark v2.x cluster, you can create a SparkSession context which enables Spark-SQL and Hive support&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;curl &lt;span class="pl-k"&gt;-&lt;/span&gt;i &lt;span class="pl-k"&gt;-&lt;/span&gt;d &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;'http&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt;localhost:8090/contexts/sql-context-1?num-cpu-cores=2&amp;amp;memory-per-node=512M&amp;amp;context-factory=spark.jobserver.context.SessionContextFactory'&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Spark JobServer application shall extend from the SparkSessionJob to use the spark.jobserver.context.SessionContextFactory, here is an example&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;com&lt;/span&gt;.&lt;span class="pl-en"&gt;typesafe&lt;/span&gt;.&lt;span class="pl-en"&gt;config&lt;/span&gt;.&lt;span class="pl-en"&gt;Config&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;org&lt;/span&gt;.&lt;span class="pl-en"&gt;apache&lt;/span&gt;.&lt;span class="pl-en"&gt;spark&lt;/span&gt;.&lt;span class="pl-en"&gt;sql&lt;/span&gt;.&lt;span class="pl-en"&gt;SparkSession&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;org&lt;/span&gt;.&lt;span class="pl-en"&gt;scalactic&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;spark&lt;/span&gt;.&lt;span class="pl-en"&gt;jobserver&lt;/span&gt;.&lt;span class="pl-en"&gt;SparkSessionJob&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;spark&lt;/span&gt;.&lt;span class="pl-en"&gt;jobserver&lt;/span&gt;.&lt;span class="pl-en"&gt;api&lt;/span&gt;.{&lt;span class="pl-en"&gt;JobEnvironment&lt;/span&gt;, &lt;span class="pl-en"&gt;SingleProblem&lt;/span&gt;, &lt;span class="pl-en"&gt;ValidationProblem&lt;/span&gt;}

&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scala&lt;/span&gt;.&lt;span class="pl-en"&gt;util&lt;/span&gt;.&lt;span class="pl-en"&gt;Try&lt;/span&gt;

&lt;span class="pl-k"&gt;object&lt;/span&gt; &lt;span class="pl-en"&gt;WordCountExampleSparkSession&lt;/span&gt; &lt;span class="pl-k"&gt;extends&lt;/span&gt; &lt;span class="pl-e"&gt;SparkSessionJob&lt;/span&gt; {
  &lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-en"&gt;JobData&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Seq&lt;/span&gt;[&lt;span class="pl-en"&gt;String&lt;/span&gt;]
  &lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-en"&gt;JobOutput&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; collection.&lt;span class="pl-en"&gt;Map&lt;/span&gt;[&lt;span class="pl-en"&gt;String&lt;/span&gt;, &lt;span class="pl-en"&gt;Long&lt;/span&gt;]

  &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;runJob&lt;/span&gt;(&lt;span class="pl-v"&gt;sparkSession&lt;/span&gt;: &lt;span class="pl-en"&gt;SparkSession&lt;/span&gt;, &lt;span class="pl-v"&gt;runtime&lt;/span&gt;: &lt;span class="pl-en"&gt;JobEnvironment&lt;/span&gt;, &lt;span class="pl-v"&gt;data&lt;/span&gt;: &lt;span class="pl-en"&gt;JobData&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;JobOutput&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt;
    sparkSession.sparkContext.parallelize(data).countByValue

  &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;validate&lt;/span&gt;(&lt;span class="pl-v"&gt;sparkSession&lt;/span&gt;: &lt;span class="pl-en"&gt;SparkSession&lt;/span&gt;, &lt;span class="pl-v"&gt;runtime&lt;/span&gt;: &lt;span class="pl-en"&gt;JobEnvironment&lt;/span&gt;, &lt;span class="pl-v"&gt;config&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt;
  &lt;span class="pl-en"&gt;JobData&lt;/span&gt; &lt;span class="pl-en"&gt;Or&lt;/span&gt; &lt;span class="pl-en"&gt;Every&lt;/span&gt;[&lt;span class="pl-en"&gt;ValidationProblem&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; {
    &lt;span class="pl-en"&gt;Try&lt;/span&gt;(config.getString(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;input.string&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).split(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt; &lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).toSeq)
      .map(words &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Good&lt;/span&gt;(words))
      .getOrElse(&lt;span class="pl-en"&gt;Bad&lt;/span&gt;(&lt;span class="pl-en"&gt;One&lt;/span&gt;(&lt;span class="pl-en"&gt;SingleProblem&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;No input.string param&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;))))
  }
}&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-dependency-jars" class="anchor" aria-hidden="true" href="#dependency-jars"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Dependency jars&lt;/h3&gt;
&lt;p&gt;For Java/Scala applications you have a couple options to package and upload dependency jars.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The easiest is to use something like &lt;a href="https://github.com/sbt/sbt-assembly"&gt;sbt-assembly&lt;/a&gt; to produce a fat jar.  Be sure to mark the Spark and job-server dependencies as "provided" so it won't blow up the jar size.  This works well if the number of dependencies is not large.&lt;/li&gt;
&lt;li&gt;When the dependencies are sizeable and/or you don't want to load them with every different job, you can package the dependencies separately and use one of several options:
&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;dependent-jar-uris&lt;/code&gt; context configuration param. Then the jar gets loaded for every job.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;dependent-jar-uris&lt;/code&gt; can also be used in job configuration param when submitting a job. On an ad-hoc context this has the same effect as &lt;code&gt;dependent-jar-uris&lt;/code&gt; context configuration param. On a persistent context the jars will be loaded for the current job and then for every job that will be executed on the persistent context.
&lt;pre&gt;&lt;code&gt;curl -d "" "localhost:8090/contexts/test-context?num-cpu-cores=4&amp;amp;memory-per-node=512m"
OK⏎
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;curl "localhost:8090/jobs?appName=test&amp;amp;classPath=spark.jobserver.WordCountExample&amp;amp;context=test-context&amp;amp;sync=true" -d '{
    dependent-jar-uris = ["file:///myjars/deps01.jar", "file:///myjars/deps02.jar"],
    input.string = "a b c a b see"
}'
&lt;/code&gt;&lt;/pre&gt;
The jars /myjars/deps01.jar &amp;amp; /myjars/deps02.jar (present only on the SJS node) will be loaded and made available for the Spark driver &amp;amp; executors.
Please note that only only &lt;code&gt;file&lt;/code&gt;, &lt;code&gt;local&lt;/code&gt;, &lt;code&gt;ftp&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt; protocols will work (URIs will be added to standard java class loader).
Recent changes also allow to use names of the binaries, which were uploaded to Jobserver.&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;--package&lt;/code&gt; option with Maven coordinates with &lt;code&gt;server_start.sh&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Recent changes also allow you to use new parameters for the &lt;code&gt;POST /jobs&lt;/code&gt; request:
&lt;pre&gt;&lt;code&gt;POST /jobs?cp=someURI,binName1,binName2&amp;amp;mainClass=some.main.Class
&lt;/code&gt;&lt;/pre&gt;
&lt;code&gt;cp&lt;/code&gt; accepts list of binary names (under which you uploaded binary to Jobserver) and URIs,
&lt;code&gt;mainClass&lt;/code&gt; is the main class of your application.
Main advantage of this approach in comparison to using &lt;code&gt;dependent-jar-uris&lt;/code&gt; is that you don't need to
specify which jar is the main one and can just send all of needed jars in one list.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-named-objects" class="anchor" aria-hidden="true" href="#named-objects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Named Objects&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-using-named-rdds" class="anchor" aria-hidden="true" href="#using-named-rdds"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Named RDDs&lt;/h4&gt;
&lt;p&gt;Initially, the job server only supported Named RDDs. For backwards compatibility and convenience, the following is still supported even though it is now possible to use the more generic Named Object support described in the next section.&lt;/p&gt;
&lt;p&gt;Named RDDs are a way to easily share RDDs among jobs. Using this facility, computed RDDs can be cached with a given name and later on retrieved.
To use this feature, the SparkJob needs to mixin &lt;code&gt;NamedRddSupport&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;object&lt;/span&gt; &lt;span class="pl-en"&gt;SampleNamedRDDJob&lt;/span&gt;  &lt;span class="pl-k"&gt;extends&lt;/span&gt; &lt;span class="pl-e"&gt;SparkJob&lt;/span&gt; &lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-e"&gt;NamedRddSupport&lt;/span&gt; {
    &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;runJob&lt;/span&gt;(sc&lt;span class="pl-k"&gt;:&lt;/span&gt;&lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;jobConfig&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Any&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;???&lt;/span&gt;
    &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;validate&lt;/span&gt;(sc&lt;span class="pl-k"&gt;:&lt;/span&gt;&lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;config&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;SparkJobValidation&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;???&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then in the implementation of the job, RDDs can be stored with a given name:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;this&lt;/span&gt;.namedRdds.update(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;french_dictionary&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, frenchDictionaryRDD)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Other job running in the same context can retrieve and use this RDD later on:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;rdd&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;this&lt;/span&gt;.namedRdds.get[(&lt;span class="pl-en"&gt;String&lt;/span&gt;, &lt;span class="pl-en"&gt;String&lt;/span&gt;)](&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;french_dictionary&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).get&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(note the explicit type provided to get. This will allow to cast the retrieved RDD that otherwise is of type RDD[_])&lt;/p&gt;
&lt;p&gt;For jobs that depends on a named RDDs it's a good practice to check for the existence of the NamedRDD in the &lt;code&gt;validate&lt;/code&gt; method as explained earlier:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;validate&lt;/span&gt;(sc&lt;span class="pl-k"&gt;:&lt;/span&gt;&lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;config&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;SparkJobValidation&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
  ...
  &lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;rdd&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;this&lt;/span&gt;.namedRdds.get[(&lt;span class="pl-en"&gt;Long&lt;/span&gt;, scala.&lt;span class="pl-en"&gt;Seq&lt;/span&gt;[&lt;span class="pl-en"&gt;String&lt;/span&gt;])](&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dictionary&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
  &lt;span class="pl-k"&gt;if&lt;/span&gt; (rdd.isDefined) &lt;span class="pl-en"&gt;SparkJobValid&lt;/span&gt; &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-en"&gt;SparkJobInvalid&lt;/span&gt;(&lt;span class="pl-k"&gt;s&lt;/span&gt;&lt;span class="pl-s"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;Missing named RDD [dictionary]&lt;/span&gt;&lt;span class="pl-s"&gt;"&lt;/span&gt;)
}&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-using-named-objects" class="anchor" aria-hidden="true" href="#using-named-objects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using Named Objects&lt;/h4&gt;
&lt;p&gt;Named Objects are a way to easily share RDDs, DataFrames or other objects among jobs. Using this facility, computed objects can be cached with a given name and later on retrieved.
To use this feature, the SparkJob needs to mixin &lt;code&gt;NamedObjectSupport&lt;/code&gt;. It is also necessary to define implicit persisters for each desired type of named objects. For convencience, we have provided implementations for RDD persistence and for DataFrame persistence (defined in &lt;code&gt;job-server-extras&lt;/code&gt;):&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;object&lt;/span&gt; &lt;span class="pl-en"&gt;SampleNamedObjectJob&lt;/span&gt;  &lt;span class="pl-k"&gt;extends&lt;/span&gt; &lt;span class="pl-e"&gt;SparkJob&lt;/span&gt; &lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-e"&gt;NamedObjectSupport&lt;/span&gt; {

  &lt;span class="pl-k"&gt;implicit&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;rddPersister&lt;/span&gt;[&lt;span class="pl-en"&gt;T&lt;/span&gt;] &lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;NamedObjectPersister&lt;/span&gt;[&lt;span class="pl-en"&gt;NamedRDD&lt;/span&gt;[&lt;span class="pl-en"&gt;T&lt;/span&gt;]] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;new&lt;/span&gt; &lt;span class="pl-en"&gt;RDDPersister&lt;/span&gt;[&lt;span class="pl-en"&gt;T&lt;/span&gt;]
  &lt;span class="pl-k"&gt;implicit&lt;/span&gt; &lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;dataFramePersister&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;new&lt;/span&gt; &lt;span class="pl-en"&gt;DataFramePersister&lt;/span&gt;

    &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;runJob&lt;/span&gt;(sc&lt;span class="pl-k"&gt;:&lt;/span&gt;&lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;jobConfig&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Any&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;???&lt;/span&gt;
    &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;validate&lt;/span&gt;(sc&lt;span class="pl-k"&gt;:&lt;/span&gt;&lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;config&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;SparkJobValidation&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;???&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then in the implementation of the job, RDDs can be stored with a given name:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;this&lt;/span&gt;.namedObjects.update(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;rdd:french_dictionary&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-en"&gt;NamedRDD&lt;/span&gt;(frenchDictionaryRDD, forceComputation &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;false&lt;/span&gt;, storageLevel &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;StorageLevel&lt;/span&gt;.&lt;span class="pl-en"&gt;NONE&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;DataFrames can be stored like so:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;this&lt;/span&gt;.namedObjects.update(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;df:some df&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-en"&gt;NamedDataFrame&lt;/span&gt;(frenchDictionaryDF, forceComputation &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;false&lt;/span&gt;, storageLevel &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;StorageLevel&lt;/span&gt;.&lt;span class="pl-en"&gt;NONE&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It is advisable to use different name prefixes for different types of objects to avoid confusion.&lt;/p&gt;
&lt;p&gt;Another job running in the same context can retrieve and use these objects later on:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-c1"&gt;NamedRDD&lt;/span&gt;(frenchDictionaryRDD, _ ,_) &lt;span class="pl-k"&gt;=&lt;/span&gt; namedObjects.get[&lt;span class="pl-en"&gt;NamedRDD&lt;/span&gt;[(&lt;span class="pl-en"&gt;String&lt;/span&gt;, &lt;span class="pl-en"&gt;String&lt;/span&gt;)]](&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;rdd:french_dictionary&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).get

&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-c1"&gt;NamedDataFrame&lt;/span&gt;(frenchDictionaryDF, _, _) &lt;span class="pl-k"&gt;=&lt;/span&gt; namedObjects.get[&lt;span class="pl-en"&gt;NamedDataFrame&lt;/span&gt;](&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;df:some df&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).get
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(Note the explicit type provided to get. This will allow to cast the retrieved RDD/DataFrame object to the proper result type.)&lt;/p&gt;
&lt;p&gt;For jobs that depends on a named objects it's a good practice to check for the existence of the NamedObject in the &lt;code&gt;validate&lt;/code&gt; method as explained earlier:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;validate&lt;/span&gt;(sc&lt;span class="pl-k"&gt;:&lt;/span&gt;&lt;span class="pl-en"&gt;SparkContext&lt;/span&gt;, &lt;span class="pl-v"&gt;config&lt;/span&gt;: &lt;span class="pl-en"&gt;Config&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;SparkJobValidation&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; {
  ...
  &lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;obj&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;this&lt;/span&gt;.namedObjects.get(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;dictionary&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
  &lt;span class="pl-k"&gt;if&lt;/span&gt; (obj.isDefined) &lt;span class="pl-en"&gt;SparkJobValid&lt;/span&gt; &lt;span class="pl-k"&gt;else&lt;/span&gt; &lt;span class="pl-en"&gt;SparkJobInvalid&lt;/span&gt;(&lt;span class="pl-k"&gt;s&lt;/span&gt;&lt;span class="pl-s"&gt;"&lt;/span&gt;&lt;span class="pl-s"&gt;Missing named object [dictionary]&lt;/span&gt;&lt;span class="pl-s"&gt;"&lt;/span&gt;)
}&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-https--ssl-configuration" class="anchor" aria-hidden="true" href="#https--ssl-configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTTPS / SSL Configuration&lt;/h3&gt;
&lt;h4&gt;&lt;a id="user-content-server-authentication" class="anchor" aria-hidden="true" href="#server-authentication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Server authentication&lt;/h4&gt;
&lt;p&gt;To activate server authentication and ssl communication, set these flags in your application.conf file (Section 'spray.can.server'):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  ssl-encryption = on
  # absolute path to keystore file
  keystore = "/some/path/sjs.jks"
  keystorePW = "changeit"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will need a keystore that contains the server certificate. The bare minimum is achieved with this command which creates a self-signed certificate:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; keytool -genkey -keyalg RSA -alias jobserver -keystore ~/sjs.jks -storepass changeit -validity 360 -keysize 2048
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may place the keystore anywhere.
Here is an example of a simple curl command that utilizes ssl:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -k https://localhost:8090/contexts
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;-k&lt;/code&gt; flag tells curl to "Allow connections to SSL sites without certs". Export your server certificate and import it into the client's truststore to fully utilize ssl security.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-client-authentication" class="anchor" aria-hidden="true" href="#client-authentication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Client authentication&lt;/h4&gt;
&lt;p&gt;Client authentication can be enabled by simply pointing Job Server to a valid Trust Store.
As for server authentication, this is done by setting appropriate values in the application.conf.
The minimum set of parameters to enable client authentication consists of:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  # truststore = "/some/path/server-truststore.jks"
  # truststorePW = "changeit"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note, client authentication implies server authentication, therefore client authentication will only be enabled once server authentication is activated.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-basic-authentication" class="anchor" aria-hidden="true" href="#basic-authentication"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic authentication&lt;/h3&gt;
&lt;p&gt;Basic authentication (username and password) in Job Server relies on the &lt;a href="http://shiro.apache.org/index.html" rel="nofollow"&gt;Apache Shiro&lt;/a&gt; framework.
Basic authentication is activated by setting this flag (Section 'shiro'):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;authentication = on
# absolute path to shiro config file, including file name
config.path = "/some/path/shiro.ini"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Shiro-specific configuration options should be placed into a file named 'shiro.ini' in the directory as specified by the config option 'config.path'.
Here is an example that configures LDAP with user group verification:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# use this for basic ldap authorization, without group checking
# activeDirectoryRealm = org.apache.shiro.realm.ldap.JndiLdapRealm
# use this for checking group membership of users based on the 'member' attribute of the groups:
activeDirectoryRealm = spark.jobserver.auth.LdapGroupRealm
# search base for ldap groups (only relevant for LdapGroupRealm):
activeDirectoryRealm.contextFactory.environment[ldap.searchBase] = dc=xxx,dc=org
# allowed groups (only relevant for LdapGroupRealm):
activeDirectoryRealm.contextFactory.environment[ldap.allowedGroups] = "cn=group1,ou=groups", "cn=group2,ou=groups"
activeDirectoryRealm.contextFactory.environment[java.naming.security.credentials] = password
activeDirectoryRealm.contextFactory.url = ldap://localhost:389
activeDirectoryRealm.userDnTemplate = cn={0},ou=people,dc=xxx,dc=org

cacheManager = org.apache.shiro.cache.MemoryConstrainedCacheManager

securityManager.cacheManager = $cacheManager
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make sure to edit the url, credentials, userDnTemplate, ldap.allowedGroups and ldap.searchBase settings in accordance with your local setup.&lt;/p&gt;
&lt;p&gt;Here is an example of a simple curl command that authenticates a user and uses ssl (you may want to use -H to hide the
credentials, this is just a simple example to get you started):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -k --basic --user 'user:pw' https://localhost:8090/contexts
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-deployment" class="anchor" aria-hidden="true" href="#deployment"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Deployment&lt;/h2&gt;
&lt;p&gt;See also running on &lt;a href="doc/cluster.md"&gt;cluster&lt;/a&gt;, &lt;a href="doc/yarn.md"&gt;YARN client&lt;/a&gt;, on &lt;a href="doc/EMR.md"&gt;EMR&lt;/a&gt; and running on &lt;a href="doc/mesos.md"&gt;Mesos&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-manual-steps" class="anchor" aria-hidden="true" href="#manual-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Manual steps&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Copy &lt;code&gt;config/local.sh.template&lt;/code&gt; to &lt;code&gt;&amp;lt;environment&amp;gt;.sh&lt;/code&gt; and edit as appropriate.  NOTE: be sure to set SPARK_VERSION if you need to compile against a different version.&lt;/li&gt;
&lt;li&gt;Copy &lt;code&gt;config/shiro.ini.template&lt;/code&gt; to &lt;code&gt;shiro.ini&lt;/code&gt; and edit as appropriate. NOTE: only required when &lt;code&gt;authentication = on&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Copy &lt;code&gt;config/local.conf.template&lt;/code&gt; to &lt;code&gt;&amp;lt;environment&amp;gt;.conf&lt;/code&gt; and edit as appropriate.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bin/server_deploy.sh &amp;lt;environment&amp;gt;&lt;/code&gt; -- this packages the job server along with config files and pushes
it to the remotes you have configured in &lt;code&gt;&amp;lt;environment&amp;gt;.sh&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;On the remote server, start it in the deployed directory with &lt;code&gt;server_start.sh&lt;/code&gt; and stop it with &lt;code&gt;server_stop.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;code&gt;server_start.sh&lt;/code&gt; script uses &lt;code&gt;spark-submit&lt;/code&gt; under the hood and may be passed any of the standard extra arguments from &lt;code&gt;spark-submit&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;NOTE: Under the hood, the deploy scripts generate an assembly jar from the &lt;code&gt;job-server-extras&lt;/code&gt; project.  Generating assemblies from other projects may not include all the necessary components for job execution.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-context-per-jvm" class="anchor" aria-hidden="true" href="#context-per-jvm"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Context per JVM&lt;/h3&gt;
&lt;p&gt;Each context can be a separate process launched using SparkLauncher, if &lt;code&gt;context-per-jvm&lt;/code&gt; is set to true.
This can be especially desirable when you want to run many contexts at once, or for certain types of contexts such as StreamingContexts which really need their own processes.&lt;/p&gt;
&lt;p&gt;Also, the extra processes talk to the master HTTP process via random ports using the Akka Cluster gossip protocol.  If for some reason the separate processes causes issues, set &lt;code&gt;spark.jobserver.context-per-jvm&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;, which will cause the job server to use a single JVM for all contexts.&lt;/p&gt;
&lt;p&gt;Among the known issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Launched contexts do not shut down by themselves.  You need to manually kill each separate process, or do &lt;code&gt;-X DELETE /contexts/&amp;lt;context-name&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Log files are separated out for each context (assuming &lt;code&gt;context-per-jvm&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt;) in their own subdirs under the &lt;code&gt;LOG_DIR&lt;/code&gt; configured in &lt;code&gt;settings.sh&lt;/code&gt; in the deployed directory.&lt;/p&gt;
&lt;p&gt;Note: to test out the deploy to a local staging dir, or package the job server for Mesos,
use &lt;code&gt;bin/server_package.sh &amp;lt;environment&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-configuring-spark-jobserver-backend" class="anchor" aria-hidden="true" href="#configuring-spark-jobserver-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuring Spark Jobserver backend&lt;/h3&gt;
&lt;p&gt;Spark Jobserver offers a variety of options for backend storage such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;H2/PostreSQL or other SQL Databases&lt;/li&gt;
&lt;li&gt;Cassandra&lt;/li&gt;
&lt;li&gt;Combination of SQL DB or Zookeeper with HDFS&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-configuring-spark-jobserver-h2-database-backend" class="anchor" aria-hidden="true" href="#configuring-spark-jobserver-h2-database-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuring Spark Jobserver H2 Database backend&lt;/h4&gt;
&lt;p&gt;By default, H2 database is used for storing Spark Jobserver related meta data.
This can be overridden if you prefer to use PostgreSQL or MySQL.
It is also important that any dependent jars are to be added to Job Server class path.&lt;/p&gt;
&lt;p&gt;To use the embedded H2 db as a backend, add the following configuration to local.conf.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark {
  jobserver {
    ...
    sqldao {
      # Slick database driver, full classpath
      slick-driver = slick.driver.H2Driver

      # JDBC driver, full classpath
      jdbc-driver = org.h2.Driver

      # Directory where binaries are cached and default H2 driver stores its data
      rootdir = "/var/spark-jobserver/sqldao/data"

      jdbc {
        url = "jdbc:h2:file:/var/spark-jobserver/sqldao/data/h2-db"
        user = "secret"
        password = "secret"
      }

      dbcp {
        maxactive = 20
        maxidle = 10
        initialsize = 10
      }
    }
  }
}
# also add the following line at the root level.
flyway.locations="db/h2/migration"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you are using &lt;code&gt;context-per-jvm = true&lt;/code&gt;, be sure to add &lt;a href="http://h2database.com/html/features.html#auto_mixed_mode" rel="nofollow"&gt;AUTO_MIXED_MODE&lt;/a&gt; to your
H2 JDBC URL; this allows multiple processes to share the same H2 database using a lock file.&lt;/p&gt;
&lt;p&gt;In yarn-client mode, use H2 in server mode as described below instead of embedded mode.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the full H2 jar from &lt;a href="http://www.h2database.com/html/download.html" rel="nofollow"&gt;http://www.h2database.com/html/download.html&lt;/a&gt; and follow docs.&lt;/li&gt;
&lt;li&gt;Note that the version of H2 should match the H2 client version bundled with spark-jobserver, currently 1.3.176.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A sample JDBC configuration is below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jdbc {
        url = "jdbc:h2:tcp://localhost//ROOT/PARENT/DIRECTORIES/spark_jobserver"
        user = "secret"
        password = "secret"
      }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: /ROOT/PARENT/DIRECTORIES/spark_jobserver is the absolute path to a directory to which H2 has write access.&lt;/p&gt;
&lt;p&gt;Example command line to launch H2 Server:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java -cp h2-1.3.176.jar org.h2.tools.Server -tcp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use -? on command line to see other options.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-configuring-spark-jobserver-postgresql-database-backend" class="anchor" aria-hidden="true" href="#configuring-spark-jobserver-postgresql-database-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuring Spark Jobserver PostgreSQL Database backend&lt;/h4&gt;
&lt;p&gt;Ensure that you have spark_jobserver database created with necessary rights
granted to user.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# create database user jobserver and database spark_jobserver:
$ createuser --username=&amp;lt;superuser&amp;gt; -RDIElPS jobserver
$ createdb -Ojobserver -Eutf8 spark_jobserver
CTRL-D -&amp;gt; logout from psql

# logon as superuser and enable the large object extension:
$ psql -U &amp;lt;superuser&amp;gt; spark_jobserver
spark_jobserver=# CREATE EXTENSION lo;
CTRL-D -&amp;gt; logout from psql

# you can connect to the database using the psql command line client:
$ psql -U jobserver spark_jobserver
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To use PostgreSQL as backend add the following configuration to local.conf.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark {
  jobserver {
    ...
    sqldao {
      # Slick database driver, full classpath
      slick-driver = slick.driver.PostgresDriver

      # JDBC driver, full classpath
      jdbc-driver = org.postgresql.Driver

      # Directory where default H2 driver stores its data. Only needed for H2.
      rootdir = "/var/spark-jobserver/sqldao/data"

      jdbc {
        url = "jdbc:postgresql://db_host/spark_jobserver"
        user = "jobserver"
        password = "secret"
      }

      dbcp {
        maxactive = 20
        maxidle = 10
        initialsize = 10
      }
    }
  }
}
# also add the following line at the root level.
flyway.locations="db/postgresql/migration"
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-configuring-spark-jobserver-mysql-database-backend" class="anchor" aria-hidden="true" href="#configuring-spark-jobserver-mysql-database-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuring Spark Jobserver MySQL Database backend&lt;/h4&gt;
&lt;p&gt;Ensure that you have spark_jobserver database created with necessary rights
granted to user.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# secure your mysql installation and define password for mysql root user
$ mysql_secure_installation

# logon as database root
$ mysql -u root -p

# create a database user and a database for spark jobserver:
mysql&amp;gt; CREATE USER 'jobserver'@'localhost' IDENTIFIED BY 'secret';
mysql&amp;gt; CREATE DATABASE spark_jobserver;
mysql&amp;gt; GRANT ALL ON spark_jobserver.* TO 'jobserver'@'localhost';
mysql&amp;gt; FLUSH PRIVILEGES;
CTRL-D -&amp;gt; logout from mysql

# you can connect to the database using the mysql command line client:
$ mysql -u jobserver -p
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To use MySQL as backend add the following configuration to local.conf.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark {
  jobserver {
    ...
    sqldao {
      # Slick database driver, full classpath
      slick-driver = slick.driver.MySQLDriver

      # JDBC driver, full classpath
      jdbc-driver = com.mysql.jdbc.Driver

      jdbc {
        url = "jdbc:mysql://db_host/spark_jobserver"
        user = "jobserver"
        password = "secret"
      }

      dbcp {
        maxactive = 20
        maxidle = 10
        initialsize = 10
      }
    }
  }
}
# also add the following line at the root level.
flyway.locations="db/mysql/migration"
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-configuring-spark-jobserver-zookeeper--hdfs-database-backend" class="anchor" aria-hidden="true" href="#configuring-spark-jobserver-zookeeper--hdfs-database-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuring Spark Jobserver Zookeeper + HDFS Database backend&lt;/h4&gt;
&lt;p&gt;To use Zookeeper (for metadata) and HDFS (for binaries) as backend add the following
configuration to local.conf.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    combineddao {
      rootdir = "/tmp/combineddao"
      binarydao {
        class = spark.jobserver.io.HdfsBinaryDAO
        dir = "hdfs:///spark-jobserver/binaries"
      }
      metadatadao {
        class = spark.jobserver.io.zookeeper.MetaDataZookeeperDAO
      }
    }

    zookeeperdao {
      dir = "jobserver/db"
      connection-string = "localhost:2181"
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More information on setting up different backends for binaries and jobserver meta data: &lt;a href="doc/dao-setup.md"&gt;setting up dao&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-configuring-spark-jobserver-cassandra-backend" class="anchor" aria-hidden="true" href="#configuring-spark-jobserver-cassandra-backend"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Configuring Spark Jobserver Cassandra backend&lt;/h4&gt;
&lt;p&gt;To use Cassandra db as a backend, setup Cassandra and add the following configuration to local.conf:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    cassandra {
      consistency = "ONE"
      hosts = ["localhost:9042"]
      user = ""
      password = ""
      chunk-size-in-kb = 1024
    }

    cassandradao {
      # Directory where Jobserver will cache files before starting the job
      rootdir = /tmp/spark-jobserver/cassandradao/data
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;a id="user-content-ha-deployment-beta" class="anchor" aria-hidden="true" href="#ha-deployment-beta"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HA Deployment (beta)&lt;/h3&gt;
&lt;p&gt;It is possible to run multiple Spark Jobservers in a highly available setup. For a documentation of a Jobserver HA setup, refer to the &lt;a href="doc/HA.md"&gt;Jobserver HA documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-chef" class="anchor" aria-hidden="true" href="#chef"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Chef&lt;/h3&gt;
&lt;p&gt;There is also a &lt;a href="https://github.com/spark-jobserver/chef-spark-jobserver"&gt;Chef cookbook&lt;/a&gt; which can be used to deploy Spark Jobserver.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-architecture" class="anchor" aria-hidden="true" href="#architecture"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Architecture&lt;/h2&gt;
&lt;p&gt;The job server is intended to be run as one or more independent processes, separate from the Spark cluster
(though it very well may be collocated with say the Master).&lt;/p&gt;
&lt;p&gt;At first glance, it seems many of these functions (eg job management) could be integrated into the Spark standalone master.  While this is true, we believe there are many significant reasons to keep it separate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We want the job server to work for Mesos and YARN as well&lt;/li&gt;
&lt;li&gt;Spark and Mesos masters are organized around "applications" or contexts, but the job server supports running many discrete "jobs" inside a single context&lt;/li&gt;
&lt;li&gt;We want it to support Shark functionality in the future&lt;/li&gt;
&lt;li&gt;Loose coupling allows for flexible HA arrangements (multiple job servers targeting same standalone master, or possibly multiple Spark clusters per job server)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Flow diagrams are checked in in the doc/ subdirectory.  .diagram files are for websequencediagrams.com... check them out, they really will help you understand the flow of messages between actors.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-api" class="anchor" aria-hidden="true" href="#api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;API&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-binaries" class="anchor" aria-hidden="true" href="#binaries"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Binaries&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;GET /binaries               - lists all current binaries
GET /binaries /&amp;lt;appName&amp;gt;    - gets info about the last binary uploaded under this name (app-name, binary-type, upload-time)
POST /binaries/&amp;lt;appName&amp;gt;    - upload a new binary file
DELETE /binaries/&amp;lt;appName&amp;gt;  - delete defined binary
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When POSTing new binaries, the content-type header must be set to one of the types supported by the subclasses of the &lt;code&gt;BinaryType&lt;/code&gt; trait. e.g. "application/java-archive" or application/python-archive". If you are using curl command, then you must pass "-H 'Content-Type: application/python-archive'" or "-H 'Content-Type: application/java-archive'".&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-contexts" class="anchor" aria-hidden="true" href="#contexts"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contexts&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;GET /contexts               - lists all current contexts
GET /contexts/&amp;lt;name&amp;gt;        - gets info about a context, such as the spark UI url
POST /contexts/&amp;lt;name&amp;gt;       - creates a new context
DELETE /contexts/&amp;lt;name&amp;gt;     - stops a context and all jobs running in it. Additionally, you can pass ?force=true to stop a context forcefully. This is equivalent to killing the application from SparkUI (works for spark standalone only).
PUT /contexts?reset=reboot  - shuts down all contexts and re-loads only the contexts from config. Use ?sync=false to execute asynchronously.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spark context configuration params can follow &lt;code&gt;POST /contexts/&amp;lt;name&amp;gt;&lt;/code&gt; as query params. See section below for more details.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-jobs" class="anchor" aria-hidden="true" href="#jobs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Jobs&lt;/h3&gt;
&lt;p&gt;Jobs submitted to the job server must implement a &lt;code&gt;SparkJob&lt;/code&gt; trait.  It has a main &lt;code&gt;runJob&lt;/code&gt; method which is
passed a SparkContext and a typesafe Config object.  Results returned by the method are made available through
the REST API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /jobs                - Lists the last N jobs
POST /jobs               - Starts a new job, use ?sync=true to wait for results
GET /jobs/&amp;lt;jobId&amp;gt;        - Gets the result or status of a specific job
DELETE /jobs/&amp;lt;jobId&amp;gt;     - Kills the specified job
GET /jobs/&amp;lt;jobId&amp;gt;/config - Gets the job configuration
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For additional information on &lt;code&gt;POST /jobs&lt;/code&gt; check out &lt;a href="doc/submitting-jobs.md"&gt;submitting jobs documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For details on the Typesafe config format used for input (JSON also works), see the &lt;a href="https://github.com/typesafehub/config"&gt;Typesafe Config docs&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-data" class="anchor" aria-hidden="true" href="#data"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data&lt;/h3&gt;
&lt;p&gt;It is sometime necessary to programmatically upload files to the server. Use these paths to manage such files:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GET /data                - Lists previously uploaded files that were not yet deleted
POST /data/&amp;lt;prefix&amp;gt;      - Uploads a new file, the full path of the file on the server is returned, the
                           prefix is the prefix of the actual filename used on the server (a timestamp is
                           added to ensure uniqueness)
DELETE /data/&amp;lt;filename&amp;gt;  - Deletes the specified file (only if under control of the JobServer)
PUT /data?reset=reboot   - Deletes all uploaded files. Use ?sync=false to execute asynchronously.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These files are uploaded to the server and are stored in a local temporary
directory where the JobServer runs. The POST command returns the full
pathname and filename of the uploaded file so that later jobs can work with this
just the same as with any other server-local file. A job could therefore add this file to HDFS or distribute
it to worker nodes via the SparkContext.addFile command.
For files that are larger than a few hundred MB, it is recommended to manually upload these files to the server or
to directly add them to your HDFS.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-data-api-example" class="anchor" aria-hidden="true" href="#data-api-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Data API Example&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;$ curl -d "Test data file api" http://localhost:8090/data/test_data_file_upload.txt
{
  "result": {
    "filename": "/tmp/spark-jobserver/upload/test_data_file_upload.txt-2016-07-04T09_09_57.928+05_30.dat"
  }
}

$ curl http://localhost:8090/data
["/tmp/spark-jobserver/upload/test_data_file_upload.txt-2016-07-04T09_09_57.928+05_30.dat"]

$ curl -X DELETE http://localhost:8090/data/%2Ftmp%2Fspark-jobserver%2Fupload%2Ftest_data_file_upload.txt-2016-07-04T09_09_57.928%2B05_30.dat
OK

$ curl http://localhost:8090/data
[]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: Both POST and DELETE requests takes URI encoded file names.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-context-configuration" class="anchor" aria-hidden="true" href="#context-configuration"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Context configuration&lt;/h3&gt;
&lt;p&gt;A number of context-specific settings can be controlled when creating a context (POST /contexts) or running an
ad-hoc job (which creates a context on the spot).  For example, add urls of dependent jars for a context.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;POST '/contexts/my-new-context?dependent-jar-uris=file:///some/path/of/my-foo-lib.jar'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: Only the latest &lt;code&gt;dependent-jar-uris&lt;/code&gt; (btw it’s jar-uris, not jars-uri) takes effect.  You can specify multiple URIs by comma-separating them.  So like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;amp;dependent-jar-uris=file:///path/a.jar,file:///path/b.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When creating a context via POST /contexts, the query params are used to override the default configuration in
spark.context-settings.  For example,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;POST /contexts/my-new-context?num-cpu-cores=10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;would override the default spark.context-settings.num-cpu-cores setting.&lt;/p&gt;
&lt;p&gt;When starting a job, and the &lt;code&gt;context=&lt;/code&gt; query param is not specified, then an ad-hoc context is created.  Any
settings specified in spark.context-settings will override the defaults in the job server config when it is
started up.&lt;/p&gt;
&lt;p&gt;Any spark configuration param can be overridden either in POST /contexts query params, or through &lt;code&gt;spark .context-settings&lt;/code&gt; job configuration.  In addition, &lt;code&gt;num-cpu-cores&lt;/code&gt; maps to &lt;code&gt;spark.cores.max&lt;/code&gt;, and &lt;code&gt;mem-per- node&lt;/code&gt; maps to &lt;code&gt;spark.executor.memory&lt;/code&gt;.  Therefore the following are all equivalent:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;POST /contexts/my-new-context?num-cpu-cores=10

POST /contexts/my-new-context?spark.cores.max=10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or in the job config when using POST /jobs,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark.context-settings {
    spark.cores.max = 10
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;User impersonation for an already Kerberos authenticated user is supported via &lt;code&gt;spark.proxy.user&lt;/code&gt; query param:&lt;/p&gt;
&lt;p&gt;POST /contexts/my-new-context?spark.proxy.user=&lt;/p&gt;
&lt;p&gt;However, whenever the flag &lt;code&gt;shiro.use-as-proxy-user&lt;/code&gt; is set to &lt;code&gt;on&lt;/code&gt; (and authentication is &lt;code&gt;on&lt;/code&gt;) then this parameter
is ignored and the name of the authenticated user is &lt;em&gt;always&lt;/em&gt; used as the value of the &lt;code&gt;spark.proxy.user&lt;/code&gt;
parameter when creating contexts.&lt;/p&gt;
&lt;p&gt;To pass settings directly to the sparkConf that do not use the "spark." prefix "as-is", use the "passthrough" section.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark.context-settings {
    spark.cores.max = 10
    passthrough {
      some.custom.hadoop.config = "192.168.1.1"
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To add to the underlying Hadoop configuration in a Spark context, add the hadoop section to the context settings&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark.context-settings {
    hadoop {
        mapreduce.framework.name = "Foo"
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;stop-context-on-job-error=true&lt;/code&gt; can be passed to context if you want the context to stop immediately after first error is reported by a job. The default value is false.&lt;/p&gt;
&lt;p&gt;For the exact context configuration parameters, see JobManagerActor docs as well as application.conf.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-other-configuration-settings" class="anchor" aria-hidden="true" href="#other-configuration-settings"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other configuration settings&lt;/h3&gt;
&lt;p&gt;For all of the Spark Job Server configuration settings, see &lt;code&gt;job-server/src/main/resources/application.conf&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-job-result-serialization" class="anchor" aria-hidden="true" href="#job-result-serialization"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Job Result Serialization&lt;/h3&gt;
&lt;p&gt;The result returned by the &lt;code&gt;SparkJob&lt;/code&gt; &lt;code&gt;runJob&lt;/code&gt; method is serialized by the job server into JSON for routes
that return the result (GET /jobs with sync=true, GET /jobs/).  Currently the following types can be
serialized properly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String, Int, Long, Double, Float, Boolean&lt;/li&gt;
&lt;li&gt;Scala Map's with string key values (non-string keys may be converted to strings)&lt;/li&gt;
&lt;li&gt;Scala Seq's&lt;/li&gt;
&lt;li&gt;Array's&lt;/li&gt;
&lt;li&gt;Anything that implements Product (Option, case classes) -- they will be serialized as lists&lt;/li&gt;
&lt;li&gt;Subclasses of java.util.List&lt;/li&gt;
&lt;li&gt;Subclasses of java.util.Map with string key values (non-string keys may be converted to strings)&lt;/li&gt;
&lt;li&gt;Maps, Seqs, Java Maps and Java Lists may contain nested values of any of the above&lt;/li&gt;
&lt;li&gt;If a job result is of scala's Stream[Byte] type it will be serialised directly as a chunk encoded stream.
This is useful if your job result payload is large and may cause a timeout serialising as objects. Beware, this
will not currently work as desired with context-per-jvm=true configuration, since it would require serialising
Stream[_] blob between processes. For now use Stream[_] job results in context-per-jvm=false configuration, pending
potential future enhancements to support this in context-per-jvm=true mode.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we encounter a data type that is not supported, then the entire result will be serialized to a string.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-http-override" class="anchor" aria-hidden="true" href="#http-override"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTTP Override&lt;/h3&gt;
&lt;p&gt;Spark Job Server offers HTTP override functionality.
Often reverse proxies and firewall implement access limitations to, for example, DELETE and PUT requests.
HTTP override allows overcoming these limitations by wrapping, for example, a DELETE request into a POST request.&lt;/p&gt;
&lt;p&gt;Requesting the destruction of a context can be accomplished through HTTP override using the following syntax:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl -X POST "localhost:8090/contexts/test_context?_method=DELETE"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, a DELETE request is passed to Spark Job Server "through" a POST request.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-clients" class="anchor" aria-hidden="true" href="#clients"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Clients&lt;/h2&gt;
&lt;p&gt;Spark Jobserver project has a
&lt;a href="https://github.com/spark-jobserver/python-sjsclient"&gt;python binding&lt;/a&gt; package.
This can be used to quickly develop python applications that can interact with
Spark Jobserver programmatically.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contribution-and-development" class="anchor" aria-hidden="true" href="#contribution-and-development"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contribution and Development&lt;/h2&gt;
&lt;p&gt;Contributions via Github Pull Request are welcome. Please start by taking a look at the &lt;a href="doc/contribution-guidelines.md"&gt;contribution guidelines&lt;/a&gt; and check the TODO for some contribution ideas.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you need to build with a specific scala version use ++x.xx.x followed by the regular command,
for instance: &lt;code&gt;sbt ++2.11.6 job-server/compile&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;From the "master" project, please run "test" to ensure nothing is broken.
&lt;ul&gt;
&lt;li&gt;You may need to set &lt;code&gt;SPARK_LOCAL_IP&lt;/code&gt; to &lt;code&gt;localhost&lt;/code&gt; to ensure Akka port can bind successfully&lt;/li&gt;
&lt;li&gt;Note for Windows users: very few tests fail on Windows. Thus, run &lt;code&gt;testOnly -- -l WindowsIgnore&lt;/code&gt; from SBT shell to ignore them.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Logging for tests goes to "job-server-test.log". To see test logging in console also, add the following to your log4j.properties (&lt;code&gt;job-server/src/test/resources/log4j.properties&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre lang="$xslt"&gt;&lt;code&gt;log4j.rootLogger=INFO, LOGFILE, console

log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=[%d] %-5p %.26c [%X{testName}] [%X{akkaSource}] - %m%n
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Run &lt;code&gt;sbt clean coverage test&lt;/code&gt; to check the code coverage and improve it. You can generate reports by running
&lt;code&gt;sbt coverageReport&lt;/code&gt; or &lt;code&gt;sbt coverageAggregate&lt;/code&gt; for the full overview.
&lt;ul&gt;
&lt;li&gt;Windows users: run &lt;code&gt;; coverage ; testOnly -- -l WindowsIgnore ; coverageReport&lt;/code&gt; from SBT shell.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Please run scalastyle to ensure your code changes don't break the style guide.&lt;/li&gt;
&lt;li&gt;Do "reStart" from SBT for quick restarts of the job server process&lt;/li&gt;
&lt;li&gt;Please update the g8 template if you change the SparkJob API&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Profiling software generously provided by &lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/97fa03cac759a772255b93c64ab1c9f76a103681/68747470733a2f2f7777772e796f75726b69742e636f6d2f696d616765732f796b6c6f676f2e706e67"&gt;&lt;img src="https://camo.githubusercontent.com/97fa03cac759a772255b93c64ab1c9f76a103681/68747470733a2f2f7777772e796f75726b69742e636f6d2f696d616765732f796b6c6f676f2e706e67" alt="" data-canonical-src="https://www.yourkit.com/images/yklogo.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;YourKit supports open source projects with its full-featured &lt;a href="https://www.yourkit.com/java/profiler/index.jsp" rel="nofollow"&gt;Java Profiler&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-publishing-packages" class="anchor" aria-hidden="true" href="#publishing-packages"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Publishing packages&lt;/h3&gt;
&lt;p&gt;In the root project, do &lt;code&gt;release cross&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To announce the release on &lt;a href="http://ls.implicit.ly/" rel="nofollow"&gt;ls.implicit.ly&lt;/a&gt;, use
&lt;a href="https://github.com/n8han/herald#install"&gt;Herald&lt;/a&gt; after adding release notes in
the &lt;code&gt;notes/&lt;/code&gt; dir.  Also regenerate the catalog with &lt;code&gt;lsWriteVersion&lt;/code&gt; SBT task
and &lt;code&gt;lsync&lt;/code&gt;, in project job-server.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contact" class="anchor" aria-hidden="true" href="#contact"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contact&lt;/h2&gt;
&lt;p&gt;For user/dev questions, we are using google group for discussions:
&lt;a href="https://groups.google.com/forum/#!forum/spark-jobserver" rel="nofollow"&gt;https://groups.google.com/forum/#!forum/spark-jobserver&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Please report bugs/problems to:
&lt;a href="https://github.com/spark-jobserver/spark-jobserver/issues"&gt;https://github.com/spark-jobserver/spark-jobserver/issues&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Apache 2.0, see LICENSE.md&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-todo" class="anchor" aria-hidden="true" href="#todo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TODO&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;More debugging for classpath issues&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add Swagger support.  See the spray-swagger project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implement an interactive SQL window.  See: &lt;a href="https://github.com/adatao/spark-admin"&gt;spark-admin&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stream the current job progress via a Listener&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add routes to return stage info for a job.  Persist it via DAO so that we can always retrieve stage / performance info
even for historical jobs.  This would be pretty kickass.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>spark-jobserver</author><guid isPermaLink="false">https://github.com/spark-jobserver/spark-jobserver</guid><pubDate>Tue, 21 Jan 2020 00:07:00 GMT</pubDate></item><item><title>fpinscala/fpinscala #8 in Scala, Today</title><link>https://github.com/fpinscala/fpinscala</link><description>&lt;p&gt;&lt;i&gt;Code, exercises, answers, and hints to go along with the book "Functional Programming in Scala"&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://travis-ci.org/fpinscala/fpinscala" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/eda1ba73f57af016a5c2cdcd746f67cef92c0b41/68747470733a2f2f7472617669732d63692e6f72672f6670696e7363616c612f6670696e7363616c612e7376673f6272616e63683d6d6173746572" alt="Build status" data-canonical-src="https://travis-ci.org/fpinscala/fpinscala.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/fpinscala/fpinscala?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/fpinscala/fpinscala" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This repository contains exercises, hints, and answers for the book
&lt;a href="http://manning.com/bjarnason/" rel="nofollow"&gt;Functional Programming in Scala&lt;/a&gt;. Along
with the book itself, it's the closest you'll get to having your own
private functional programming tutor without actually having one.&lt;/p&gt;
&lt;p&gt;Here's how to use this repository:&lt;/p&gt;
&lt;p&gt;Each chapter in the book develops a fully working library of functions
and data types, built up through a series of exercises and example code
given in the book text. The shell of this working library and exercise
stubs live in
&lt;code&gt;exercises/src/main/scala/fpinscala/&amp;lt;chapter-description&amp;gt;&lt;/code&gt;, where
&lt;code&gt;&amp;lt;chapter-description&amp;gt;&lt;/code&gt; is a package name that corresponds to the
chapter title (see below). When you begin working on a chapter, we
recommend you open the exercise file(s) for that chapter, and when you
encounter exercises, implement them in the exercises file and make sure
they work.&lt;/p&gt;
&lt;p&gt;If you get stuck on an exercise, let's say exercise 4 in the chapter,
you can find hints in &lt;code&gt;answerkey/&amp;lt;chapter-description&amp;gt;/04.hint.txt&lt;/code&gt; (if
no hints are available for a problem, the file will just have a single
'-' as its contents) and the answer along with an explanation of the
answer and any variations in
&lt;code&gt;answerkey/&amp;lt;chapter-description&amp;gt;/04.answer.scala&lt;/code&gt; or
&lt;code&gt;04.answer.markdown&lt;/code&gt;. The finished Scala modules, with all answers for
each chapter live in
&lt;code&gt;answers/src/main/scala/fpinscala/&amp;lt;chapter-description&amp;gt;&lt;/code&gt;. Please feel
free to submit pull requests for alternate answers, improved hints, and
so on, so we can make this repo the very best resource for people
working through the book.&lt;/p&gt;
&lt;p&gt;Chapter descriptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chapter 2: gettingstarted&lt;/li&gt;
&lt;li&gt;Chapter 3: datastructures&lt;/li&gt;
&lt;li&gt;Chapter 4: errorhandling&lt;/li&gt;
&lt;li&gt;Chapter 5: laziness&lt;/li&gt;
&lt;li&gt;Chapter 6: state&lt;/li&gt;
&lt;li&gt;Chapter 7: parallelism&lt;/li&gt;
&lt;li&gt;Chapter 8: testing&lt;/li&gt;
&lt;li&gt;Chapter 9: parsing&lt;/li&gt;
&lt;li&gt;Chapter 10: monoids&lt;/li&gt;
&lt;li&gt;Chapter 11: monads&lt;/li&gt;
&lt;li&gt;Chapter 12: applicative&lt;/li&gt;
&lt;li&gt;Chapter 13: iomonad&lt;/li&gt;
&lt;li&gt;Chapter 14: localeffects&lt;/li&gt;
&lt;li&gt;Chapter 15: streamingio&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To build the code for the first time, if on windows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ .\sbt.cmd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If on mac/linux, first make sure you have not checked out the code onto
an encrypted file system, otherwise you will get compile errors
regarding too long file names (one solution is to put the fpinscala repo
on a unencrypted usb key, and symlink it into your preferred code
location).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ chmod a+x ./sbt
$ ./sbt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will download and launch &lt;a href="http://scala-sbt.org" rel="nofollow"&gt;sbt&lt;/a&gt;, a build tool
for Scala. Once it is finished downloading, you'll get a prompt from
which you can issue commands to build and interact with your code. Try
the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; project exercises
&amp;gt; compile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This switches to the exercises project, where your code lives, and
compiles the code. You can also do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; console
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to get a Scala REPL with access to your exercises, and&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; run
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get a menu of possible main methods to execute.&lt;/p&gt;
&lt;p&gt;To create project files for the eclipse IDE you can install the
&lt;a href="https://github.com/typesafehub/sbteclipse"&gt;sbteclipse&lt;/a&gt;
&lt;a href="http://scala-sbt.org" rel="nofollow"&gt;sbt&lt;/a&gt; plugin. This makes a new command available
in &lt;a href="http://scala-sbt.org" rel="nofollow"&gt;sbt&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; eclipse
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All code in this repository is
&lt;a href="http://opensource.org/licenses/mit-license.php" rel="nofollow"&gt;MIT-licensed&lt;/a&gt;. See the
LICENSE file for details.&lt;/p&gt;
&lt;p&gt;Have fun, and good luck! Also be sure to check out &lt;a href="https://github.com/fpinscala/fpinscala/wiki"&gt;the community
wiki&lt;/a&gt; for the &lt;strong&gt;chapter
notes&lt;/strong&gt;, links to more reading, and more.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Paul and Rúnar&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>fpinscala</author><guid isPermaLink="false">https://github.com/fpinscala/fpinscala</guid><pubDate>Tue, 21 Jan 2020 00:08:00 GMT</pubDate></item><item><title>scalalandio/chimney #9 in Scala, Today</title><link>https://github.com/scalalandio/chimney</link><description>&lt;p&gt;&lt;i&gt;Scala library for boilerplate-free, type-safe data transformations&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-chimney-" class="anchor" aria-hidden="true" href="#chimney-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Chimney &lt;a target="_blank" rel="noopener noreferrer" href="chimney.png"&gt;&lt;img src="chimney.png" alt="Chimney logo" width="64" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/scalalandio/chimney" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/56e57cc0860ba87ade4617fc406b0792d97919b6/68747470733a2f2f7472617669732d63692e6f72672f7363616c616c616e64696f2f6368696d6e65792e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/scalalandio/chimney.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://search.maven.org/#search%7Cga%7C1%7Cchimney" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/325aec62630b5c31aea5e692e3048a257c9c4221/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f696f2e7363616c616c616e642f6368696d6e65795f322e31322e737667" alt="Maven Central" data-canonical-src="https://img.shields.io/maven-central/v/io.scalaland/chimney_2.12.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.javadoc.io/doc/io.scalaland/chimney_2.11" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/8c9e0f79a3ca30961dc1869d3795bfb9d3219620/68747470733a2f2f7777772e6a617661646f632e696f2f62616467652f696f2e7363616c616c616e642f6368696d6e65795f322e31312e7376673f636f6c6f723d726564266c6162656c3d7363616c61646f63" alt="Javadocs" data-canonical-src="https://www.javadoc.io/badge/io.scalaland/chimney_2.11.svg?color=red&amp;amp;label=scaladoc" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://codecov.io/github/scalalandio/chimney?branch=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/6f2b584b16f5db34570520500822b7af1fcf07cf/687474703a2f2f636f6465636f762e696f2f6769746875622f7363616c616c616e64696f2f6368696d6e65792f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/scalalandio/chimney/coverage.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="http://www.apache.org/licenses/LICENSE-2.0.txt" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/03f8227fc6cd80406cbdec3a0f89095eab3a90e6/687474703a2f2f696d672e736869656c64732e696f2f3a6c6963656e73652d417061636865253230322d677265656e2e737667" alt="License" data-canonical-src="http://img.shields.io/:license-Apache%202-green.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/scalalandio/chimney?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cea06d75cbe9ee0dd02f629347797e791fd09cfb/68747470733a2f2f6261646765732e6769747465722e696d2f7363616c616c616e64696f2f6368696d6e65792e737667" alt="Join the chat at https://gitter.im/scalalandio/chimney" data-canonical-src="https://badges.gitter.im/scalalandio/chimney.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://www.scala-js.org" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/76faf4fa895d338b340a4fe01b157d54629ada38/68747470733a2f2f7777772e7363616c612d6a732e6f72672f6173736574732f6261646765732f7363616c616a732d302e362e31372e737667" alt="Scala.js" data-canonical-src="https://www.scala-js.org/assets/badges/scalajs-0.6.17.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scala library for boilerplate-free data transformations.&lt;/p&gt;
&lt;p&gt;In the daily life of a strongly-typed language's programmer sometimes it
happens we need to transform an object of one type to another object which
contains a number of the same or similar fields in their definitions.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;case&lt;/span&gt; &lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;MakeCoffee&lt;/span&gt;(&lt;span class="pl-v"&gt;id&lt;/span&gt;: &lt;span class="pl-en"&gt;Int&lt;/span&gt;, &lt;span class="pl-v"&gt;kind&lt;/span&gt;: &lt;span class="pl-en"&gt;String&lt;/span&gt;, &lt;span class="pl-v"&gt;addict&lt;/span&gt;: &lt;span class="pl-en"&gt;String&lt;/span&gt;)
&lt;span class="pl-k"&gt;case&lt;/span&gt; &lt;span class="pl-k"&gt;class&lt;/span&gt; &lt;span class="pl-en"&gt;CoffeeMade&lt;/span&gt;(&lt;span class="pl-v"&gt;id&lt;/span&gt;: &lt;span class="pl-en"&gt;Int&lt;/span&gt;, &lt;span class="pl-v"&gt;kind&lt;/span&gt;: &lt;span class="pl-en"&gt;String&lt;/span&gt;, &lt;span class="pl-v"&gt;forAddict&lt;/span&gt;: &lt;span class="pl-en"&gt;String&lt;/span&gt;, &lt;span class="pl-v"&gt;at&lt;/span&gt;: &lt;span class="pl-en"&gt;ZonedDateTime&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Usual approach is to just rewrite fields one by one&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;command&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;MakeCoffee&lt;/span&gt;(id &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Random&lt;/span&gt;.nextInt,
                         kind &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Espresso&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;,
                         addict &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Piotr&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;)
&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;event&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;CoffeeMade&lt;/span&gt;(id &lt;span class="pl-k"&gt;=&lt;/span&gt; command.id,
                       kind &lt;span class="pl-k"&gt;=&lt;/span&gt; command.kind,
                       forAddict &lt;span class="pl-k"&gt;=&lt;/span&gt; command.addict,
                       at &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;ZonedDateTime&lt;/span&gt;.now)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While the example stays lean, in real-life code we usually end up with tons
of such boilerplate, especially when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we maintain typed schema and want to migrate between multiple schema versions&lt;/li&gt;
&lt;li&gt;we apply practices like DDD (Domain-Driven-Design) where suggested
approach is to separate model schemas of different bounded contexts&lt;/li&gt;
&lt;li&gt;we use code-generation tools like Protocol Buffers that generate primitive
types like &lt;code&gt;Int&lt;/code&gt; or &lt;code&gt;String&lt;/code&gt;, while you'd prefer to
use value objects in you domain-level code to improve type-safety
and readability&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Chimney provides a compact DSL with which you can define transformation
rules and transform your objects with as little boilerplate as possible.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;io&lt;/span&gt;.&lt;span class="pl-en"&gt;scalaland&lt;/span&gt;.&lt;span class="pl-en"&gt;chimney&lt;/span&gt;.&lt;span class="pl-en"&gt;dsl&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;

&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;event&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; command.into[&lt;span class="pl-en"&gt;CoffeeMade&lt;/span&gt;]
  .withFieldComputed(_.at, _ &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;ZonedDateTime&lt;/span&gt;.now)
  .withFieldRenamed(_.addict, _.forAddict)
  .transform&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Underneath it uses Scala macros to give you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;type-safety at compile-time&lt;/li&gt;
&lt;li&gt;fast generated code, almost equivalent to hand-written version&lt;/li&gt;
&lt;li&gt;excellent error messages&lt;/li&gt;
&lt;li&gt;minimal overhead on compilation time&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-getting-started" class="anchor" aria-hidden="true" href="#getting-started"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting started&lt;/h2&gt;
&lt;p&gt;To include Chimney to your SBT project, add the following line to your &lt;code&gt;build.sbt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;libraryDependencies &lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;io.scalaland&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;chimney&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;0.3.5&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Library is released for Scala 2.11.x, 2.12.x and 2.13.x.&lt;/p&gt;
&lt;p&gt;If you want to use it with Scala.js (or Scala Native), you need to replace &lt;code&gt;%%&lt;/code&gt; with &lt;code&gt;%%%&lt;/code&gt;.
Due to some &lt;a href="https://issues.scala-lang.org/browse/SI-7046" rel="nofollow"&gt;compiler bugs&lt;/a&gt;,
it's recommended to use at least Scala 2.11.9 or 2.12.1.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-trying-with-ammonite-repl" class="anchor" aria-hidden="true" href="#trying-with-ammonite-repl"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Trying with Ammonite REPL&lt;/h3&gt;
&lt;p&gt;The quickest way to try out Chimney is to use a script that downloads
&lt;a href="https://github.com/alexarchambault/coursier"&gt;coursier&lt;/a&gt; and uses it to fetch
&lt;a href="https://github.com/lihaoyi/Ammonite"&gt;Ammonite&lt;/a&gt; REPL with the latest version
of Chimney. It drops you immediately into a REPL session.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s https://raw.githubusercontent.com/scalalandio/chimney/master/try-chimney.sh | bash
Loading...
Welcome to the Ammonite Repl 1.1.0
(Scala 2.12.4 Java 1.8.0_152)
If you like Ammonite, please support our development at www.patreon.com/lihaoyi
@ case class Foo(x: String, y: Int) 
defined class Foo

@ case class Bar(x: String, y: Int, z: Boolean = true) 
defined class Bar

@ Foo("abc", 10).transformInto[Bar] 
res2: Bar = Bar("abc", 10, true)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;Chimney documentation is available at &lt;a href="https://scalalandio.github.io/chimney" rel="nofollow"&gt;https://scalalandio.github.io/chimney&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-thanks" class="anchor" aria-hidden="true" href="#thanks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thanks&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;a href="https://www.ej-technologies.com/products/jprofiler/overview.html" rel="nofollow"&gt;JProfiler (Java profiler)&lt;/a&gt; for helping us develop the library and allowing us to use it during development.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>scalalandio</author><guid isPermaLink="false">https://github.com/scalalandio/chimney</guid><pubDate>Tue, 21 Jan 2020 00:09:00 GMT</pubDate></item><item><title>gitbucket/gitbucket #10 in Scala, Today</title><link>https://github.com/gitbucket/gitbucket</link><description>&lt;p&gt;&lt;i&gt;A Git platform powered by Scala with easy installation, high extensibility &amp; GitHub API compatibility&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-gitbucket----" class="anchor" aria-hidden="true" href="#gitbucket----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GitBucket &lt;a href="https://gitter.im/gitbucket/gitbucket" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/80991daab83c7504f938fe81ce11f8c241db9e53/68747470733a2f2f6261646765732e6769747465722e696d2f6769746275636b65742f6769746275636b65742e737667" alt="Gitter chat" data-canonical-src="https://badges.gitter.im/gitbucket/gitbucket.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://travis-ci.org/gitbucket/gitbucket" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c42fc7615b51af1d0b59be6233fb5c76d255d291/68747470733a2f2f7472617669732d63692e6f72672f6769746275636b65742f6769746275636b65742e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/gitbucket/gitbucket.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://maven-badges.herokuapp.com/maven-central/io.github.gitbucket/gitbucket_2.13" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/463aa101cad2714a9c400ff16a91fcc9948cb648/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f696f2e6769746875622e6769746275636b65742f6769746275636b65745f322e31332f62616467652e737667" alt="Maven Central" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/io.github.gitbucket/gitbucket_2.13/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://github.com/gitbucket/gitbucket/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/8051e9938a1ab39cf002818dfceb6b6092f34d68/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;GitBucket is a Git web platform powered by Scala offering:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easy installation&lt;/li&gt;
&lt;li&gt;Intuitive UI&lt;/li&gt;
&lt;li&gt;High extensibility by plugins&lt;/li&gt;
&lt;li&gt;API compatibility with GitHub&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can try an &lt;a href="https://gitbucket.herokuapp.com/" rel="nofollow"&gt;online demo&lt;/a&gt; &lt;em&gt;(ID: root / Pass: root)&lt;/em&gt; of GitBucket, and also get the latest information at &lt;a href="https://gitbucket.github.io/gitbucket-news/" rel="nofollow"&gt;GitBucket News&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;p&gt;The current version of GitBucket provides many features such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Public / Private Git repositories (with http/https and ssh access)&lt;/li&gt;
&lt;li&gt;GitLFS support&lt;/li&gt;
&lt;li&gt;Repository viewer including an online file editor&lt;/li&gt;
&lt;li&gt;Issues, Pull Requests and Wiki for repositories&lt;/li&gt;
&lt;li&gt;Activity timeline and email notifications&lt;/li&gt;
&lt;li&gt;Account and group management with LDAP integration&lt;/li&gt;
&lt;li&gt;a Plug-in system&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you want to try the development version of GitBucket, see the &lt;a href="https://github.com/gitbucket/gitbucket/blob/master/doc/readme.md"&gt;Developer's Guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;GitBucket requires &lt;strong&gt;Java8&lt;/strong&gt;. You have to install it, if it is not already installed.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download the latest &lt;strong&gt;gitbucket.war&lt;/strong&gt; from &lt;a href="https://github.com/gitbucket/gitbucket/releases"&gt;the releases page&lt;/a&gt; and run it by &lt;code&gt;java -jar gitbucket.war&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go to &lt;code&gt;http://[hostname]:8080/&lt;/code&gt; and log in with ID: &lt;strong&gt;root&lt;/strong&gt; / Pass: &lt;strong&gt;root&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can also deploy &lt;code&gt;gitbucket.war&lt;/code&gt; to a servlet container which supports Servlet 3.0 (like Jetty, Tomcat, JBoss, etc)&lt;/p&gt;
&lt;p&gt;For more information about installation on Mac or Windows Server (with IIS), or configuration of Apache or Nginx and also integration with other tools or services such as Jenkins or Slack, see &lt;a href="https://github.com/gitbucket/gitbucket/wiki"&gt;Wiki&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To upgrade GitBucket, replace &lt;code&gt;gitbucket.war&lt;/code&gt; with the new version, after stopping GitBucket. All GitBucket data is stored in &lt;code&gt;HOME/.gitbucket&lt;/code&gt; by default. So if you want to back up GitBucket's data, copy this directory to the backup location.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-plugins" class="anchor" aria-hidden="true" href="#plugins"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Plugins&lt;/h2&gt;
&lt;p&gt;GitBucket has a plug-in system that allows extra functionality. Officially the following plug-ins are provided:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gitbucket/gitbucket-gist-plugin"&gt;gitbucket-gist-plugin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gitbucket/gitbucket-emoji-plugin"&gt;gitbucket-emoji-plugin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gitbucket/gitbucket-pages-plugin"&gt;gitbucket-pages-plugin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/gitbucket/gitbucket-notifications-plugin"&gt;gitbucket-notifications-plugin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find more plugins made by the community at &lt;a href="https://gitbucket-plugins.github.io/" rel="nofollow"&gt;GitBucket community plugins&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-support" class="anchor" aria-hidden="true" href="#support"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Support&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If you have any questions about GitBucket, see &lt;a href="https://github.com/gitbucket/gitbucket/wiki"&gt;Wiki&lt;/a&gt; and check issues whether there is a same question or request in the past.&lt;/li&gt;
&lt;li&gt;If you can't find same question and report, send it to &lt;a href="https://gitter.im/gitbucket/gitbucket" rel="nofollow"&gt;gitter room&lt;/a&gt; before raising an issue.&lt;/li&gt;
&lt;li&gt;The highest priority of GitBucket is the ease of installation and API compatibility with GitHub, so your feature request might be rejected if they go against those principles.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-whats-new-in-433x" class="anchor" aria-hidden="true" href="#whats-new-in-433x"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What's New in 4.33.x&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-4330---31-dec-2019" class="anchor" aria-hidden="true" href="#4330---31-dec-2019"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4.33.0 - 31 Dec 2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;All CLI options are configurable by environment variables&lt;/li&gt;
&lt;li&gt;Folding pull request files&lt;/li&gt;
&lt;li&gt;WebHook security options&lt;/li&gt;
&lt;li&gt;Add assignee and assignees properties to some Web APIs' response&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See the &lt;a href="CHANGELOG.md"&gt;change log&lt;/a&gt; for all of the updates.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>gitbucket</author><guid isPermaLink="false">https://github.com/gitbucket/gitbucket</guid><pubDate>Tue, 21 Jan 2020 00:10:00 GMT</pubDate></item><item><title>Azure/mmlspark #11 in Scala, Today</title><link>https://github.com/Azure/mmlspark</link><description>&lt;p&gt;&lt;i&gt;Microsoft Machine Learning for Apache Spark&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/0f31d64469b1c4f3dbe5e854f52bb3eb349e0ba8/68747470733a2f2f6d6d6c737061726b2e617a757265656467652e6e65742f69636f6e732f6d6d6c737061726b2e737667"&gt;&lt;img src="https://camo.githubusercontent.com/0f31d64469b1c4f3dbe5e854f52bb3eb349e0ba8/68747470733a2f2f6d6d6c737061726b2e617a757265656467652e6e65742f69636f6e732f6d6d6c737061726b2e737667" alt="MMLSpark" data-canonical-src="https://mmlspark.azureedge.net/icons/mmlspark.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-microsoft-machine-learning-for-apache-spark" class="anchor" aria-hidden="true" href="#microsoft-machine-learning-for-apache-spark"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Microsoft Machine Learning for Apache Spark&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://msazure.visualstudio.com/Cognitive%20Services/_build/latest?definitionId=83120&amp;amp;branchName=master" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c6013b9f6e8d726998981acea8cf0c6afa87dc8d/68747470733a2f2f6d73617a7572652e76697375616c73747564696f2e636f6d2f436f676e697469766525323053657276696365732f5f617069732f6275696c642f7374617475732f417a7572652e6d6d6c737061726b3f6272616e63684e616d653d6d6173746572" alt="Build Status" data-canonical-src="https://msazure.visualstudio.com/Cognitive%20Services/_apis/build/status/Azure.mmlspark?branchName=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/Azure/mmlspark" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3d33b1f413ba945dce11c42625c751b6e13acca3/68747470733a2f2f636f6465636f762e696f2f67682f417a7572652f6d6d6c737061726b2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/Azure/mmlspark/branch/master/graph/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/Microsoft/MMLSpark?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2177ea7fddaac7ecb8a0d5ebda9e0550ec2f79fa/68747470733a2f2f6261646765732e6769747465722e696d2f4d6963726f736f66742f4d4d4c537061726b2e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/Microsoft/MMLSpark.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Azure/mmlspark/releases"&gt;&lt;img src="https://camo.githubusercontent.com/2b95bde9e35735d085f2a64e334564fddb1e792b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d6e6f7465732d626c7565" alt="Release Notes" data-canonical-src="https://img.shields.io/badge/release-notes-blue" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/scala/index.html#package" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/9541c1e00ab17b5c0f31ab880f7da0d1dd06cff0/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d617069253230646f6373266d6573736167653d7363616c6126636f6c6f723d626c7565266c6f676f3d7363616c61" alt="Scala Docs" data-canonical-src="https://img.shields.io/static/v1?label=api%20docs&amp;amp;message=scala&amp;amp;color=blue&amp;amp;logo=scala" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/pyspark/index.html" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a5ac918a682fe9c6992a7f1ab12e204964a53997/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d617069253230646f6373266d6573736167653d707974686f6e26636f6c6f723d626c7565266c6f676f3d707974686f6e" alt="PySpark Docs" data-canonical-src="https://img.shields.io/static/v1?label=api%20docs&amp;amp;message=python&amp;amp;color=blue&amp;amp;logo=python" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/1810.08744" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/efa888257e8261153f5ff4f426ad4893fb84badc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61636164656d69632d70617065722d376664636637" alt="Academic Paper" data-canonical-src="https://img.shields.io/badge/academic-paper-7fdcf7" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Azure/mmlspark/releases"&gt;&lt;img src="https://camo.githubusercontent.com/14e16b347646015d0f380e887d184c59e4640b4e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d312e302e302d2d7263312d626c7565" alt="Version" data-canonical-src="https://img.shields.io/badge/version-1.0.0--rc1-blue" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="#sbt"&gt;&lt;img src="https://camo.githubusercontent.com/f2134790d60abaea58ea73bbeed0e0853de9e0f5/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f69636f6e732f6261646765732f6d61737465725f76657273696f6e332e737667" alt="Snapshot Version" data-canonical-src="https://mmlspark.blob.core.windows.net/icons/badges/master_version3.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MMLSpark is an ecosystem of tools aimed towards expanding the distributed computing framework
&lt;a href="https://github.com/apache/spark"&gt;Apache Spark&lt;/a&gt; in several new directions.
MMLSpark adds many deep learning and data science tools to the Spark ecosystem,
including seamless integration of Spark Machine Learning pipelines with &lt;a href="https://github.com/Microsoft/CNTK"&gt;Microsoft Cognitive Toolkit
(CNTK)&lt;/a&gt;, &lt;a href="https://github.com/Microsoft/LightGBM"&gt;LightGBM&lt;/a&gt; and
&lt;a href="http://www.opencv.org/" rel="nofollow"&gt;OpenCV&lt;/a&gt;. These tools enable powerful and highly-scalable predictive and analytical models
for a variety of datasources.&lt;/p&gt;
&lt;p&gt;MMLSpark also brings new networking capabilities to the Spark Ecosystem. With the HTTP on Spark project, users
can embed &lt;strong&gt;any&lt;/strong&gt; web service into their SparkML models. In this vein, MMLSpark provides easy to use
SparkML transformers for a wide variety of &lt;a href="https://azure.microsoft.com/en-us/services/cognitive-services/" rel="nofollow"&gt;Microsoft Cognitive Services&lt;/a&gt;. For production grade deployment, the Spark Serving project enables high throughput,
sub-millisecond latency web services, backed by your Spark cluster.&lt;/p&gt;
&lt;p&gt;MMLSpark requires Scala 2.11, Spark 2.4+, and Python 3.5+.
See the API documentation &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/scala/index.html#package" rel="nofollow"&gt;for
Scala&lt;/a&gt; and &lt;a href="https://mmlspark.blob.core.windows.net/docs/1.0.0-rc1/pyspark/index.html" rel="nofollow"&gt;for
PySpark&lt;/a&gt;.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;&lt;em&gt;Table of Contents&lt;/em&gt;&lt;/strong&gt;&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#notable-features"&gt;Notable features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#a-short-example"&gt;A short example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#setup-and-installation"&gt;Setup and installation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gpu-vm-setup"&gt;GPU VM Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#spark-package"&gt;Spark package&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-cloud"&gt;Databricks cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sbt"&gt;SBT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#building-from-source"&gt;Building from source&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#blogs-and-publications"&gt;Blogs and Publications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing--feedback"&gt;Contributing &amp;amp; feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-relevant-projects"&gt;Other relevant projects&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;h2&gt;&lt;a id="user-content-projects" class="anchor" aria-hidden="true" href="#projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Projects&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/93b3b7e4dfc1a58a5a6bdbbe67177307c9a47359/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f76772d626c75652d6461726b2d6f72616e67652e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/93b3b7e4dfc1a58a5a6bdbbe67177307c9a47359/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f76772d626c75652d6461726b2d6f72616e67652e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/vw-blue-dark-orange.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/bfbef7ae756b550d3bd2648aed3bff7a7ceb03eb/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f636f675f73657276696365735f6f6e5f737061726b5f322e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/bfbef7ae756b550d3bd2648aed3bff7a7ceb03eb/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f636f675f73657276696365735f6f6e5f737061726b5f322e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/cog_services_on_spark_2.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ae54b5e5042ab39028bdf52f6fe7b42c7a475f55/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6465636973696f6e5f747265655f7265636f6c6f722e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/ae54b5e5042ab39028bdf52f6fe7b42c7a475f55/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6465636973696f6e5f747265655f7265636f6c6f722e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/decision_tree_recolor.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/2a836683e4c037d1c65a09cebf680b991f3cd07e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6d6c737061726b5f73657276696e675f7265636f6c6f722e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/2a836683e4c037d1c65a09cebf680b991f3cd07e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6d6c737061726b5f73657276696e675f7265636f6c6f722e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/mmlspark_serving_recolor.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;Vowpal Wabbit on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;The Cognitive Services on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;LightGBM on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;Spark Serving&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;Fast, Sparse, and Effective Text Analytics&lt;/td&gt;
&lt;td align="center"&gt;Leverage the Microsoft Cognitive Services at Unprecedented Scales in your existing SparkML pipelines&lt;/td&gt;
&lt;td align="center"&gt;Train Gradient Boosted Machines with LightGBM&lt;/td&gt;
&lt;td align="center"&gt;Serve any Spark Computation as a Web Service with Sub-Millisecond Latency&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/9ea135c7b4beaee0365bf05e2f35977c4f1b148e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6963726f736572766963655f7265636f6c6f722e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/9ea135c7b4beaee0365bf05e2f35977c4f1b148e/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f6d6963726f736572766963655f7265636f6c6f722e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/microservice_recolor.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/e706b7bfec0b1030f979a12a938b99dad9c329ce/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f64697374726962757465645f646565705f7265636f6c6f722e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/e706b7bfec0b1030f979a12a938b99dad9c329ce/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f64697374726962757465645f646565705f7265636f6c6f722e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/distributed_deep_recolor.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a27a8de5e9aede55d8565c7109b2becd20bbd5ed/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f4c494d452e737667"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/a27a8de5e9aede55d8565c7109b2becd20bbd5ed/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f4c494d452e737667" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/LIME.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/1b81d8cc571ba4b0e21fb975542089374ce3a72c/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f62696e64696e67732e706e67"&gt;&lt;img width="800" src="https://camo.githubusercontent.com/1b81d8cc571ba4b0e21fb975542089374ce3a72c/68747470733a2f2f6d6d6c737061726b2e626c6f622e636f72652e77696e646f77732e6e65742f67726170686963732f526561646d652f62696e64696e67732e706e67" data-canonical-src="https://mmlspark.blob.core.windows.net/graphics/Readme/bindings.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;strong&gt;HTTP on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;CNTK on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;Lime on Spark&lt;/strong&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;strong&gt;Spark Binding Autogeneration&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;An Integration Between Spark and the HTTP Protocol, enabling Distributed Microservice Orchestration&lt;/td&gt;
&lt;td align="center"&gt;Distributed Deep Learning with the Microsoft Cognitive Toolkit&lt;/td&gt;
&lt;td align="center"&gt;Distributed, Model Agnostic, Interpretations for Classifiers&lt;/td&gt;
&lt;td align="center"&gt;Automatically Generate Spark bindings for PySpark and SparklyR&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-examples" class="anchor" aria-hidden="true" href="#examples"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Create a deep image classifier with transfer learning (&lt;a href="notebooks/samples/DeepLearning%20-%20Flower%20Image%20Classification.ipynb" title="Deep Flower Classification"&gt;example 9&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Fit a LightGBM classification or regression model on a biochemical dataset
(&lt;a href="notebooks/samples/LightGBM%20-%20Quantile%20Regression%20for%20Drug%20Discovery.ipynb" title="Quantile Regression with LightGBM"&gt;example 3&lt;/a&gt;), to learn more check out the &lt;a href="docs/lightgbm.md"&gt;LightGBM documentation
page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Deploy a deep network as a distributed web service with &lt;a href="docs/mmlspark-serving.md"&gt;MMLSpark
Serving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Use web services in Spark with &lt;a href="docs/http.md"&gt;HTTP on Apache Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Use Bi-directional LSTMs from Keras for medical entity extraction
(&lt;a href="notebooks/samples/DeepLearning%20-%20BiLSTM%20Medical%20Entity%20Extraction.ipynb" title="Medical Entity Extraction"&gt;example 8&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Create a text analytics system on Amazon book reviews (&lt;a href="notebooks/samples/TextAnalytics%20-%20Amazon%20Book%20Reviews.ipynb" title="Amazon Book Reviews - TextFeaturizer"&gt;example 4&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Perform distributed hyperparameter tuning to identify Breast Cancer
(&lt;a href="notebooks/samples/HyperParameterTuning%20-%20Fighting%20Breast%20Cancer.ipynb" title="Hyperparameter Tuning with MMLSpark"&gt;example 5&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Easily ingest images from HDFS into Spark &lt;code&gt;DataFrame&lt;/code&gt; (&lt;a href="notebooks/samples/DeepLearning%20-%20CIFAR10%20Convolutional%20Network.ipynb" title="CIFAR10 CNTK CNN Evaluation"&gt;example 6&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Use OpenCV on Spark to manipulate images (&lt;a href="notebooks/samples/OpenCV%20-%20Pipeline%20Image%20Transformations.ipynb" title="Pipeline Image Transformations"&gt;example 7&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Train classification and regression models easily via implicit featurization
of data (&lt;a href="notebooks/samples/Classification%20-%20Adult%20Census.ipynb" title="Adult Census Income Training"&gt;example 1&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Train and evaluate a flight delay prediction system (&lt;a href="notebooks/samples/Regression%20-%20Flight%20Delays.ipynb" title="Regression Example with Flight Delay Dataset"&gt;example 2&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See our &lt;a href="notebooks/samples/"&gt;notebooks&lt;/a&gt; for all examples.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-a-short-example" class="anchor" aria-hidden="true" href="#a-short-example"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A short example&lt;/h2&gt;
&lt;p&gt;Below is an excerpt from a simple example of using a pre-trained CNN to
classify images in the CIFAR-10 dataset.  View the whole source code in notebook &lt;a href="notebooks/samples/DeepLearning%20-%20Flower%20Image%20Classification.ipynb" title="Deep Flower Classification"&gt;example 9&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-c1"&gt;...&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; mmlspark
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Initialize CNTKModel and define input and output columns&lt;/span&gt;
cntkModel &lt;span class="pl-k"&gt;=&lt;/span&gt; mmlspark.cntk.CNTKModel() \
  .setInputCol(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;images&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;).setOutputCol(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;output&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) \
  .setModelLocation(modelFile)
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; Train on dataset with internal spark pipeline&lt;/span&gt;
scoredImages &lt;span class="pl-k"&gt;=&lt;/span&gt; cntkModel.transform(imagesWithLabels)
&lt;span class="pl-c1"&gt;...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See &lt;a href="notebooks/samples/"&gt;other sample notebooks&lt;/a&gt; as well as the MMLSpark
documentation for &lt;a href="http://mmlspark.azureedge.net/docs/scala/" rel="nofollow"&gt;Scala&lt;/a&gt; and
&lt;a href="http://mmlspark.azureedge.net/docs/pyspark/" rel="nofollow"&gt;PySpark&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-setup-and-installation" class="anchor" aria-hidden="true" href="#setup-and-installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Setup and installation&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-spark-package" class="anchor" aria-hidden="true" href="#spark-package"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spark package&lt;/h3&gt;
&lt;p&gt;MMLSpark can be conveniently installed on existing Spark clusters via the
&lt;code&gt;--packages&lt;/code&gt; option, examples:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;spark-shell --packages com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1
pyspark --packages com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1
spark-submit --packages com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1 MyApp.jar&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This can be used in other Spark contexts too. For example, you can use MMLSpark
in &lt;a href="https://github.com/Azure/aztk/"&gt;AZTK&lt;/a&gt; by &lt;a href="https://github.com/Azure/aztk/wiki/PySpark-on-Azure-with-AZTK#optional-set-up-mmlspark"&gt;adding it to the
&lt;code&gt;.aztk/spark-defaults.conf&lt;/code&gt;
file&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-databricks" class="anchor" aria-hidden="true" href="#databricks"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Databricks&lt;/h3&gt;
&lt;p&gt;To install MMLSpark on the &lt;a href="http://community.cloud.databricks.com" rel="nofollow"&gt;Databricks
cloud&lt;/a&gt;, create a new &lt;a href="https://docs.databricks.com/user-guide/libraries.html#libraries-from-maven-pypi-or-spark-packages" rel="nofollow"&gt;library from Maven
coordinates&lt;/a&gt;
in your workspace.&lt;/p&gt;
&lt;p&gt;For the coordinates use: &lt;code&gt;com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1&lt;/code&gt;
with the resolver: &lt;code&gt;https://mmlspark.azureedge.net/maven&lt;/code&gt;. Ensure this library is
attached to your target cluster(s).&lt;/p&gt;
&lt;p&gt;Finally, ensure that your Spark cluster has at least Spark 2.4 and Scala 2.11.&lt;/p&gt;
&lt;p&gt;You can use MMLSpark in both your Scala and PySpark notebooks. To get started with our example notebooks import the following databricks archive:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://mmlspark.blob.core.windows.net/dbcs/MMLSpark%20Examples%20v1.0.0-rc1.dbc&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-docker" class="anchor" aria-hidden="true" href="#docker"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h3&gt;
&lt;p&gt;The easiest way to evaluate MMLSpark is via our pre-built Docker container.  To
do so, run the following command:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;docker run -it -p 8888:8888 -e ACCEPT_EULA=yes mcr.microsoft.com/mmlspark/release&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Navigate to &lt;a href="http://localhost:8888/" rel="nofollow"&gt;http://localhost:8888/&lt;/a&gt; in your web browser to run the sample
notebooks.  See the &lt;a href="docs/docker.md"&gt;documentation&lt;/a&gt; for more on Docker use.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To read the EULA for using the docker image, run \
&lt;code&gt;docker run -it -p 8888:8888 mcr.microsoft.com/mmlspark/release eula&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;a id="user-content-gpu-vm-setup" class="anchor" aria-hidden="true" href="#gpu-vm-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GPU VM Setup&lt;/h3&gt;
&lt;p&gt;MMLSpark can be used to train deep learning models on GPU nodes from a Spark
application.  See the instructions for &lt;a href="docs/gpu-setup.md"&gt;setting up an Azure GPU
VM&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-python" class="anchor" aria-hidden="true" href="#python"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Python&lt;/h3&gt;
&lt;p&gt;To try out MMLSpark on a Python (or Conda) installation you can get Spark
installed via pip with &lt;code&gt;pip install pyspark&lt;/code&gt;.  You can then use &lt;code&gt;pyspark&lt;/code&gt; as in
the above example, or from python:&lt;/p&gt;
&lt;div class="highlight highlight-source-python"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; pyspark
spark &lt;span class="pl-k"&gt;=&lt;/span&gt; pyspark.sql.SparkSession.builder.appName(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MyApp&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) \
            .config(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;spark.jars.packages&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) \
            .config(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;spark.jars.repositories&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;, &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://mmlspark.azureedge.net/maven&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;) \
            .getOrCreate()
&lt;span class="pl-k"&gt;import&lt;/span&gt; mmlspark&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-sbt" class="anchor" aria-hidden="true" href="#sbt"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;SBT&lt;/h3&gt;
&lt;p&gt;If you are building a Spark application in Scala, add the following lines to
your &lt;code&gt;build.sbt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;resolvers &lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;MMLSpark&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; at &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;https://mmlspark.azureedge.net/maven&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
libraryDependencies &lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;com.microsoft.ml.spark&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;mmlspark&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1.0.0-rc1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-building-from-source" class="anchor" aria-hidden="true" href="#building-from-source"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building from source&lt;/h3&gt;
&lt;p&gt;MMLSpark has recently transitioned to a new build infrastructure.
For detailed developer docs please see the &lt;a href="docs/developer-readme.md"&gt;Developer Readme&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are an existing mmlspark developer, you will need to reconfigure your
development setup. We now support platform independent development and
better integrate with intellij and SBT.
If you encounter issues please reach out to our support email!&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-r-beta" class="anchor" aria-hidden="true" href="#r-beta"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;R (Beta)&lt;/h3&gt;
&lt;p&gt;To try out MMLSpark using the R autogenerated wrappers &lt;a href="docs/R-setup.md"&gt;see our
instructions&lt;/a&gt;.  Note: This feature is still under development
and some necessary custom wrappers may be missing.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-learn-more" class="anchor" aria-hidden="true" href="#learn-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Visit our &lt;a href="https://mmlspark.blob.core.windows.net/website/index.html" title="aka.ms/spark" rel="nofollow"&gt;new website&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Watch our keynote demos at &lt;a href="https://youtu.be/T_fs4C0aqD0?t=425" rel="nofollow"&gt;the Spark+AI Summit 2019&lt;/a&gt;, &lt;a href="https://youtu.be/N3ozCZXeOeU?t=472" rel="nofollow"&gt;the Spark+AI European Summit 2018&lt;/a&gt;, and &lt;a href="https://databricks.com/sparkaisummit/north-america/spark-summit-2018-keynotes#Intelligent-cloud" title="Developing for the Intelligent Cloud and Intelligent Edge" rel="nofollow"&gt;the Spark+AI Summit 2018&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Read &lt;a href="https://arxiv.org/abs/1804.04031" title="Flexible and Scalable Deep Learning with MMLSpark" rel="nofollow"&gt;our paper&lt;/a&gt; for a deep dive on MMLSpark.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;See how MMLSpark is used to &lt;a href="https://www.microsoft.com/en-us/ai/ai-lab-stories?activetab=pivot1:primaryr3" title="Identifying snow leopards with AI" rel="nofollow"&gt;help endangered species&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Explore generative adversarial artwork in &lt;a href="https://www.microsoft.com/en-us/ai/ai-lab-stories?activetab=pivot1:primaryr4" title="Generative art at the MET" rel="nofollow"&gt;our collaboration with The MET and MIT&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Explore &lt;a href="https://blogs.technet.microsoft.com/machinelearning/2018/03/05/image-data-support-in-apache-spark/" title="Image Data Support in Apache Spark" rel="nofollow"&gt;our collaboration with Apache Spark&lt;/a&gt; on image analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/how-to-use-mmlspark" title="How to Use Microsoft Machine Learning Library for Apache Spark" rel="nofollow"&gt;MMLSpark in Azure Machine Learning&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing--feedback" class="anchor" aria-hidden="true" href="#contributing--feedback"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing &amp;amp; feedback&lt;/h2&gt;
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;.  For more
information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow"&gt;Code of Conduct FAQ&lt;/a&gt; or contact
&lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional
questions or comments.&lt;/p&gt;
&lt;p&gt;See &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for contribution guidelines.&lt;/p&gt;
&lt;p&gt;To give feedback and/or report an issue, open a &lt;a href="https://help.github.com/articles/creating-an-issue/"&gt;GitHub
Issue&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-other-relevant-projects" class="anchor" aria-hidden="true" href="#other-relevant-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Other relevant projects&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/VowpalWabbit/vowpal_wabbit"&gt;Vowpal Wabbit&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/LightGBM"&gt;LightGBM&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/DMTK"&gt;DMTK: Microsoft Distributed Machine Learning Toolkit&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/Recommenders"&gt;Recommenders&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/alipay/jpmml-sparkml-lightgbm"&gt;JPMML-SparkML plugin for converting MMLSpark LightGBM models to
PMML&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/CNTK"&gt;Microsoft Cognitive Toolkit&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview" rel="nofollow"&gt;Azure Machine Learning
preview features&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Apache®, Apache Spark, and Spark® are either registered trademarks or
trademarks of the Apache Software Foundation in the United States and/or other
countries.&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>Azure</author><guid isPermaLink="false">https://github.com/Azure/mmlspark</guid><pubDate>Tue, 21 Jan 2020 00:11:00 GMT</pubDate></item><item><title>rtyley/bfg-repo-cleaner #12 in Scala, Today</title><link>https://github.com/rtyley/bfg-repo-cleaner</link><description>&lt;p&gt;&lt;i&gt;Removes large or troublesome blobs like git-filter-branch does, but faster. And written in Scala&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-bfg-repo-cleaner-" class="anchor" aria-hidden="true" href="#bfg-repo-cleaner-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;BFG Repo-Cleaner &lt;a href="https://travis-ci.org/rtyley/bfg-repo-cleaner" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/763e7a896452f78e6d46e90e89b48dfe1580cf83/68747470733a2f2f7472617669732d63692e6f72672f7274796c65792f6266672d7265706f2d636c65616e65722e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/rtyley/bfg-repo-cleaner.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Removes large or troublesome blobs like git-filter-branch does, but faster - and written in Scala&lt;/em&gt; - &lt;a href="https://j.mp/fund-bfg" rel="nofollow"&gt;Fund the BFG&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bfg --strip-blobs-bigger-than 1M --replace-text banned.txt repo.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The BFG is a simpler, faster (&lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AsR1d5Zpes8HdER3VGU1a3dOcmVHMmtzT2dsS2xNenc" rel="nofollow"&gt;10 - 720x&lt;/a&gt; faster)
alternative to &lt;code&gt;git-filter-branch&lt;/code&gt; for cleansing bad data out of your Git repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Removing &lt;strong&gt;Crazy Big Files&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Removing &lt;strong&gt;Passwords, Credentials&lt;/strong&gt; &amp;amp; other &lt;strong&gt;Private data&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Main documentation for The BFG is here : &lt;strong&gt;&lt;a href="https://rtyley.github.io/bfg-repo-cleaner/" rel="nofollow"&gt;https://rtyley.github.io/bfg-repo-cleaner/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>rtyley</author><guid isPermaLink="false">https://github.com/rtyley/bfg-repo-cleaner</guid><pubDate>Tue, 21 Jan 2020 00:12:00 GMT</pubDate></item><item><title>akka/alpakka #13 in Scala, Today</title><link>https://github.com/akka/alpakka</link><description>&lt;p&gt;&lt;i&gt;Alpakka is a Reactive Enterprise Integration library for Java and Scala, based on Reactive Streams and Akka.&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-alpakka----" class="anchor" aria-hidden="true" href="#alpakka----"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alpakka &lt;a href="https://index.scala-lang.org/akka/alpakka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/28237f4187eb1c3b632144dd3f66da3e7da9389c/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f616b6b612f616c70616b6b612f6c61746573742e737667" alt="scaladex-badge" data-canonical-src="https://index.scala-lang.org/akka/alpakka/latest.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/#search%7Cga%7C1%7Cakka-stream-alpakka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/b8d4db65643c8f4e706b5be4eb4f7047c66c926d/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f636f6d2e6c6967687462656e642e616b6b612f616b6b612d73747265616d2d616c70616b6b612d66696c655f322e31322f62616467652e737667" alt="maven-central-badge" data-canonical-src="https://maven-badges.herokuapp.com/maven-central/com.lightbend.akka/akka-stream-alpakka-file_2.12/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://travis-ci.com/akka/alpakka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/595f2909acedfaaf889aabb2745fdce0303f5a91/68747470733a2f2f7472617669732d63692e636f6d2f616b6b612f616c70616b6b612e7376673f6272616e63683d6d6173746572" alt="travis-badge" data-canonical-src="https://travis-ci.com/akka/alpakka.svg?branch=master" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/akka/akka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d2e53b4d01b1ebab9516f6079a5facedcf57340f/68747470733a2f2f6261646765732e6769747465722e696d2f616b6b612f616b6b612e737667" alt="gitter-badge" data-canonical-src="https://badges.gitter.im/akka/akka.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Systems don't come alone. In the modern world of microservices and cloud deployment, new components must interact with legacy systems, making integration an important key to success. Reactive Streams give us a technology-independent tool to let these heterogeneous systems communicate without overwhelming each other.&lt;/p&gt;
&lt;p&gt;The Alpakka project is an open source initiative to implement stream-aware, reactive, integration pipelines for Java and Scala. It is built on top of &lt;a href="https://doc.akka.io/docs/akka/current/stream/index.html" rel="nofollow"&gt;Akka Streams&lt;/a&gt;, and has been designed from the ground up to understand streaming natively and provide a DSL for reactive and stream-oriented programming, with built-in support for backpressure. Akka Streams is a &lt;a href="http://www.reactive-streams.org/" rel="nofollow"&gt;Reactive Streams&lt;/a&gt; and JDK 9+ &lt;a href="https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/Flow.html" rel="nofollow"&gt;java.util.concurrent.Flow&lt;/a&gt;-compliant implementation and therefore &lt;a href="https://doc.akka.io/docs/akka/current/general/stream/stream-design.html#interoperation-with-other-reactive-streams-implementations" rel="nofollow"&gt;fully interoperable&lt;/a&gt; with other implementations.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://doc.akka.io/docs/alpakka/current/" rel="nofollow"&gt;Alpakka reference&lt;/a&gt; documentation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://doc.akka.io/docs/akka-stream-kafka/current/" rel="nofollow"&gt;Alpakka Kafka connector reference&lt;/a&gt; documentation&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To keep up with the latest Alpakka releases check out &lt;a href="https://github.com/akka/alpakka/releases"&gt;Alpakka releases&lt;/a&gt; and &lt;a href="https://github.com/akka/alpakka-kafka/releases"&gt;Alpakka Kafka connector releases&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;You can join these forums and chats to discuss and ask Akka and Alpakka related questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forums: &lt;a href="https://discuss.lightbend.com/c/akka/streams-and-alpakka" rel="nofollow"&gt;discuss.lightbend.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Chat room about &lt;em&gt;using&lt;/em&gt; Akka and Alpakka: &lt;a href="https://gitter.im/akka/akka" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/f9e40f1fe5bdc832a177e1a241915b4521db7272/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769747465722533412d616b6b61253246616b6b612d626c75652e7376673f7374796c653d666c61742d737175617265" alt="gitter: akka/akka" data-canonical-src="https://img.shields.io/badge/gitter%3A-akka%2Fakka-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Issue tracker: &lt;a href="https://github.com/akka/alpakka/issues"&gt;&lt;img src="https://camo.githubusercontent.com/b278eef1d47203c00101c53e739670458e8252b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769746875622533412d6973737565732d626c75652e7376673f7374796c653d666c61742d737175617265" alt="github: akka/alpakka" data-canonical-src="https://img.shields.io/badge/github%3A-issues-blue.svg?style=flat-square" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to that, you may enjoy the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href="https://akka.io/blog/" rel="nofollow"&gt;Akka Team Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/akkateam" rel="nofollow"&gt;@akkateam&lt;/a&gt; on Twitter&lt;/li&gt;
&lt;li&gt;Questions tagged &lt;a href="http://stackoverflow.com/questions/tagged/alpakka" rel="nofollow"&gt;#alpakka on StackOverflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.lightbend.com/" rel="nofollow"&gt;Lightbend&lt;/a&gt; is committed to Alpakka and has an Alpakka team working on it.&lt;/p&gt;
&lt;p&gt;Contributions are &lt;em&gt;very&lt;/em&gt; welcome! The Alpakka team appreciates community contributions by both those new to Alpakka and those more experienced.
Alpakka depends on the community to keep up with the ever-growing number of technologies with which to integrate. Please step up and share the successful Akka Stream integrations you implement with the Alpakka community.&lt;/p&gt;
&lt;p&gt;If you find an issue that you'd like to see fixed, the quickest way to make that happen is to implement the fix and submit a pull request.&lt;/p&gt;
&lt;p&gt;Refer to the &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file for more details about the workflow, and general hints on how to prepare your pull request. If you're planning to implement a new module within Alpakka, look at our &lt;a href="contributor-advice.md"&gt;contributor advice&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can also ask for clarifications or guidance in GitHub issues directly, or in the &lt;a href="https://gitter.im/akka/dev" rel="nofollow"&gt;akka/dev&lt;/a&gt; chat if a more real time communication would be of benefit.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-caveat-emptor" class="anchor" aria-hidden="true" href="#caveat-emptor"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Caveat Emptor&lt;/h2&gt;
&lt;p&gt;Alpakka components are not always binary compatible between releases. API changes that are not backward compatible might be introduced as we refine and simplify based on your feedback. A module may be dropped in any release without prior deprecation. If not stated otherwise, the &lt;a href="https://www.lightbend.com/subscription" rel="nofollow"&gt;Lightbend subscription&lt;/a&gt; does &lt;em&gt;not&lt;/em&gt; cover support for Alpakka modules.&lt;/p&gt;
&lt;p&gt;Our goal is to improve the stability and test coverage for Alpakka APIs over time.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>akka</author><guid isPermaLink="false">https://github.com/akka/alpakka</guid><pubDate>Tue, 21 Jan 2020 00:13:00 GMT</pubDate></item><item><title>datastax/spark-cassandra-connector #14 in Scala, Today</title><link>https://github.com/datastax/spark-cassandra-connector</link><description>&lt;p&gt;&lt;i&gt;DataStax Spark Cassandra Connector&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-spark-cassandra-connector-" class="anchor" aria-hidden="true" href="#spark-cassandra-connector-"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spark Cassandra Connector &lt;a href="https://travis-ci.org/datastax/spark-cassandra-connector" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/39a8c1c61a5bc3e93dbb7782ea9ce2081bd6327c/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f737061726b2d63617373616e6472612d636f6e6e6563746f722e737667" alt="Build Status" data-canonical-src="https://travis-ci.org/datastax/spark-cassandra-connector.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-quick-links" class="anchor" aria-hidden="true" href="#quick-links"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Links&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;What&lt;/th&gt;
&lt;th&gt;Where&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Packages&lt;/td&gt;
&lt;td&gt;&lt;a href="https://spark-packages.org/package/datastax/spark-cassandra-connector" rel="nofollow"&gt;Spark Cassandra Connector Spark Packages Website&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Community&lt;/td&gt;
&lt;td&gt;Chat with us at &lt;a href="#slack"&gt;DataStax Academy's #spark-connector Slack channel&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Scala Docs&lt;/td&gt;
&lt;td&gt;Most Recent Release (2.4.2): &lt;a href="https://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;, &lt;a href="https://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-features" class="anchor" aria-hidden="true" href="#features"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Features&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Lightning-fast cluster computing with Apache Spark™ and Apache Cassandra®.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This library lets you expose Cassandra tables as Spark RDDs, write Spark RDDs to Cassandra tables, and
execute arbitrary CQL queries in your Spark applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compatible with Apache Cassandra version 2.0 or higher (see table below)&lt;/li&gt;
&lt;li&gt;Compatible with Apache Spark 1.0 through 2.0 (see table below)&lt;/li&gt;
&lt;li&gt;Compatible with Scala 2.11 and 2.12&lt;/li&gt;
&lt;li&gt;Exposes Cassandra tables as Spark RDDs&lt;/li&gt;
&lt;li&gt;Maps table rows to CassandraRow objects or tuples&lt;/li&gt;
&lt;li&gt;Offers customizable object mapper for mapping rows to objects of user-defined classes&lt;/li&gt;
&lt;li&gt;Saves RDDs back to Cassandra by implicit &lt;code&gt;saveToCassandra&lt;/code&gt; call&lt;/li&gt;
&lt;li&gt;Delete rows and columns from cassandra by implicit &lt;code&gt;deleteFromCassandra&lt;/code&gt; call&lt;/li&gt;
&lt;li&gt;Join with a subset of Cassandra data using &lt;code&gt;joinWithCassandraTable&lt;/code&gt; call&lt;/li&gt;
&lt;li&gt;Partition RDDs according to Cassandra replication using &lt;code&gt;repartitionByCassandraReplica&lt;/code&gt; call&lt;/li&gt;
&lt;li&gt;Converts data types between Cassandra and Scala&lt;/li&gt;
&lt;li&gt;Supports all Cassandra data types including collections&lt;/li&gt;
&lt;li&gt;Filters rows on the server side via the CQL &lt;code&gt;WHERE&lt;/code&gt; clause&lt;/li&gt;
&lt;li&gt;Allows for execution of arbitrary CQL statements&lt;/li&gt;
&lt;li&gt;Plays nice with Cassandra Virtual Nodes&lt;/li&gt;
&lt;li&gt;Works with PySpark DataFrames&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-version-compatibility" class="anchor" aria-hidden="true" href="#version-compatibility"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Version Compatibility&lt;/h2&gt;
&lt;p&gt;The connector project has several branches, each of which map into different
supported versions of  Spark and Cassandra. For previous releases the branch is
named "bX.Y" where X.Y is the major+minor version; for example the "b1.6" branch
corresponds to the 1.6 release. The "master" branch will normally contain
development for the next connector release in progress.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Connector&lt;/th&gt;
&lt;th&gt;Spark&lt;/th&gt;
&lt;th&gt;Cassandra&lt;/th&gt;
&lt;th&gt;Cassandra Java Driver&lt;/th&gt;
&lt;th&gt;Minimum Java Version&lt;/th&gt;
&lt;th&gt;Supported Scala Versions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2.4.2&lt;/td&gt;
&lt;td&gt;2.4&lt;/td&gt;
&lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2.11, 2.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.4&lt;/td&gt;
&lt;td&gt;2.4&lt;/td&gt;
&lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.3&lt;/td&gt;
&lt;td&gt;2.3&lt;/td&gt;
&lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;2.0, 2.1, 2.2&lt;/td&gt;
&lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.6&lt;/td&gt;
&lt;td&gt;1.6&lt;/td&gt;
&lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.5&lt;/td&gt;
&lt;td&gt;1.5, 1.6&lt;/td&gt;
&lt;td&gt;2.1.5*, 2.2, 3.0&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.4&lt;/td&gt;
&lt;td&gt;1.4&lt;/td&gt;
&lt;td&gt;2.1.5*&lt;/td&gt;
&lt;td&gt;2.1&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.3&lt;/td&gt;
&lt;td&gt;1.3&lt;/td&gt;
&lt;td&gt;2.1.5*&lt;/td&gt;
&lt;td&gt;2.1&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.2&lt;/td&gt;
&lt;td&gt;1.2&lt;/td&gt;
&lt;td&gt;2.1, 2.0&lt;/td&gt;
&lt;td&gt;2.1&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.1&lt;/td&gt;
&lt;td&gt;1.1, 1.0&lt;/td&gt;
&lt;td&gt;2.1, 2.0&lt;/td&gt;
&lt;td&gt;2.1&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;1.0, 0.9&lt;/td&gt;
&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.10, 2.11&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;*&lt;em&gt;Compatible with 2.1.X where X &amp;gt;= 5&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-hosted-api-docs" class="anchor" aria-hidden="true" href="#hosted-api-docs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hosted API Docs&lt;/h2&gt;
&lt;p&gt;API documentation for the Scala and Java interfaces are available online:&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-242" class="anchor" aria-hidden="true" href="#242"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.4.2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.4.2/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-232" class="anchor" aria-hidden="true" href="#232"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.3.2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.3.2/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.3.2/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-2010" class="anchor" aria-hidden="true" href="#2010"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2.0.10&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.0.10/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/2.0.10/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-1613" class="anchor" aria-hidden="true" href="#1613"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.6.13&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.6.13/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.6.13/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-152" class="anchor" aria-hidden="true" href="#152"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.5.2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.5.2/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.5.2/spark-cassandra-connector-java/" rel="nofollow"&gt;Spark-Cassandra-Connector-Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.5.0/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-145" class="anchor" aria-hidden="true" href="#145"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.4.5&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.4.5/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.4.5/spark-cassandra-connector-java/" rel="nofollow"&gt;Spark-Cassandra-Connector-Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.4.2/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-131" class="anchor" aria-hidden="true" href="#131"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.3.1&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.3.1/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.3.1/spark-cassandra-connector-java/" rel="nofollow"&gt;Spark-Cassandra-Connector-Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.3.1/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-120" class="anchor" aria-hidden="true" href="#120"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1.2.0&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.2.0/spark-cassandra-connector/" rel="nofollow"&gt;Spark-Cassandra-Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.2.0/spark-cassandra-connector-java/" rel="nofollow"&gt;Spark-Cassandra-Connector-Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datastax.github.io/spark-cassandra-connector/ApiDocs/1.2.0/spark-cassandra-connector-embedded/" rel="nofollow"&gt;Embedded-Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-download" class="anchor" aria-hidden="true" href="#download"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Download&lt;/h2&gt;
&lt;p&gt;This project is available on Spark Packages; this is the easiest way to start using the connector:
&lt;a href="https://spark-packages.org/package/datastax/spark-cassandra-connector" rel="nofollow"&gt;https://spark-packages.org/package/datastax/spark-cassandra-connector&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This project has also been published to the Maven Central Repository.
For SBT to download the connector binaries, sources and javadoc, put this in your project
SBT config:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;libraryDependencies += "com.datastax.spark" %% "spark-cassandra-connector" % "2.4.2"
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The default Scala version for Spark 2.0+ is 2.11 please choose the appropriate build. See the
&lt;a href="doc/FAQ.md"&gt;FAQ&lt;/a&gt; for more information&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-building" class="anchor" aria-hidden="true" href="#building"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Building&lt;/h2&gt;
&lt;p&gt;See &lt;a href="doc/12_building_and_artifacts.md"&gt;Building And Artifacts&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="doc/0_quick_start.md"&gt;Quick-start guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/1_connecting.md"&gt;Connecting to Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/2_loading.md"&gt;Loading datasets from Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/3_selection.md"&gt;Server-side data selection and filtering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/4_mapper.md"&gt;Working with user-defined case classes and tuples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/5_saving.md"&gt;Saving and deleting datasets to/from Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/6_advanced_mapper.md"&gt;Customizing the object mapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/7_java_api.md"&gt;Using Connector in Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/8_streaming.md"&gt;Spark Streaming with Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/10_embedded.md"&gt;The spark-cassandra-connector-embedded Artifact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/11_metrics.md"&gt;Performance monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/12_building_and_artifacts.md"&gt;Building And Artifacts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/13_spark_shell.md"&gt;The Spark Shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/14_data_frames.md"&gt;DataFrames&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/15_python.md"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/16_partitioning.md"&gt;Partitioner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/FAQ.md"&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/reference.md"&gt;Configuration Parameter Reference Table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="doc/developers.md"&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-online-training" class="anchor" aria-hidden="true" href="#online-training"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Online Training&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-datastax-academy" class="anchor" aria-hidden="true" href="#datastax-academy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;DataStax Academy&lt;/h3&gt;
&lt;p&gt;DataStax Academy provides free online training for Apache Cassandra and DataStax Enterprise. In &lt;a href="https://academy.datastax.com/courses/ds320-analytics-with-apache-spark" rel="nofollow"&gt;DS320: Analytics with Spark&lt;/a&gt;, you will learn how to effectively and efficiently solve analytical problems with Apache Spark, Apache Cassandra, and DataStax Enterprise. You will learn about Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-reporting-bugs" class="anchor" aria-hidden="true" href="#reporting-bugs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Reporting Bugs&lt;/h3&gt;
&lt;p&gt;New issues may be reported using &lt;a href="https://datastax-oss.atlassian.net/browse/SPARKC/" rel="nofollow"&gt;JIRA&lt;/a&gt;. Please include
all relevant details including versions of Spark, Spark Cassandra Connector, Cassandra and/or DSE. A minimal
reproducible case with sample code is ideal.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-mailing-list" class="anchor" aria-hidden="true" href="#mailing-list"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Mailing List&lt;/h3&gt;
&lt;p&gt;Questions and requests for help may be submitted to the &lt;a href="https://groups.google.com/a/lists.datastax.com/forum/#!forum/spark-connector-user" rel="nofollow"&gt;user mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-slack" class="anchor" aria-hidden="true" href="#slack"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Slack&lt;/h3&gt;
&lt;p&gt;The project uses Slack to facilitate conversation in our community. Find us in the &lt;code&gt;#spark-connector&lt;/code&gt; channel at &lt;a href="https://academy.datastax.com/slack" rel="nofollow"&gt;DataStax Academy Slack&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;To protect the community, all contributors are required to sign the &lt;a href="http://spark-cassandra-connector-cla.datastax.com/" rel="nofollow"&gt;DataStax Spark Cassandra Connector Contribution License Agreement&lt;/a&gt;. The process is completely electronic and should only take a few minutes.&lt;/p&gt;
&lt;p&gt;To develop this project, we recommend using IntelliJ IDEA. Make sure you have
installed and enabled the Scala Plugin. Open the project with IntelliJ IDEA and
it will automatically create the project structure from the provided SBT
configuration.&lt;/p&gt;
&lt;p&gt;&lt;a href="doc/developers.md"&gt;Tips for Developing the Spark Cassandra Connector&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Checklist for contributing changes to the project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a &lt;a href="https://datastax-oss.atlassian.net/projects/SPARKC/issues" rel="nofollow"&gt;SPARKC JIRA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Make sure that all unit tests and integration tests pass&lt;/li&gt;
&lt;li&gt;Add an appropriate entry at the top of CHANGES.txt&lt;/li&gt;
&lt;li&gt;If the change has any end-user impacts, also include changes to the ./doc files as needed&lt;/li&gt;
&lt;li&gt;Prefix the pull request description with the JIRA number, for example: "SPARKC-123: Fix the ..."&lt;/li&gt;
&lt;li&gt;Open a pull-request on GitHub and await review&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-testing" class="anchor" aria-hidden="true" href="#testing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Testing&lt;/h2&gt;
&lt;p&gt;To run unit and integration tests:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./sbt/sbt test
./sbt/sbt it:test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, integration tests start up a separate, single Cassandra instance and run Spark in local mode.
It is possible to run integration tests with your own Cassandra and/or Spark cluster.
First, prepare a jar with testing code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./sbt/sbt test:package
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then copy the generated test jar to your Spark nodes and run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export IT_TEST_CASSANDRA_HOST=&amp;lt;IP of one of the Cassandra nodes&amp;gt;
export IT_TEST_SPARK_MASTER=&amp;lt;Spark Master URL&amp;gt;
./sbt/sbt it:test
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-generating-documents" class="anchor" aria-hidden="true" href="#generating-documents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generating Documents&lt;/h2&gt;
&lt;p&gt;To generate the Reference Document use&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./sbt/sbt spark-cassandra-connector-unshaded/run (outputLocation)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;outputLocation defaults to doc/reference.md&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2014-2017, DataStax, Inc.&lt;/p&gt;
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>datastax</author><guid isPermaLink="false">https://github.com/datastax/spark-cassandra-connector</guid><pubDate>Tue, 21 Jan 2020 00:14:00 GMT</pubDate></item><item><title>scalameta/metals #15 in Scala, Today</title><link>https://github.com/scalameta/metals</link><description>&lt;p&gt;&lt;i&gt;Scala language server with rich IDE features 🚀 &lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-metals" class="anchor" aria-hidden="true" href="#metals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Metals&lt;/h1&gt;
&lt;a href="https://travis-ci.org/scalameta/metals" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/a2524f52634adb07fd59d018693f072f552a90d0/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f7363616c616d6574612f6d6574616c732f6d61737465722e7376673f7374796c653d666c61742d737175617265" data-canonical-src="https://img.shields.io/travis/scalameta/metals/master.svg?style=flat-square" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://gitter.im/scalameta/metals" rel="nofollow"&gt;
&lt;img alt="Join the chat on Gitter" src="https://camo.githubusercontent.com/f7f01ae811427cbf536fb8047f67b2578a4cbe67/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f7363616c616d6574612f6d6574616c732e7376673f6c6f676f3d676974746572267374796c653d666c61742d73717561726526636f6c6f723d463731323633" data-canonical-src="https://img.shields.io/gitter/room/scalameta/metals.svg?logo=gitter&amp;amp;style=flat-square&amp;amp;color=F71263" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://twitter.com/scalameta" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/1079a3a4332d6c0fc38218766326dd730d3b2db4/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7363616c616d6574612e7376673f6c6f676f3d74776974746572267374796c653d666c61742d73717561726526636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/twitter/follow/scalameta.svg?logo=twitter&amp;amp;style=flat-square&amp;amp;color=blue" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;a href="https://index.scala-lang.org/scalameta/metals/metals" rel="nofollow"&gt;
&lt;img src="https://camo.githubusercontent.com/809e4a056728ca7f7ab406a3308a2e35e708a4fb/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f7363616c616d6574612f6d6574616c732f6d6574616c732f6c61746573742e737667" data-canonical-src="https://index.scala-lang.org/scalameta/metals/metals/latest.svg" style="max-width:100%;"&gt;
&lt;/a&gt;
&lt;h2&gt;&lt;a id="user-content-documentation" class="anchor" aria-hidden="true" href="#documentation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Documentation&lt;/h2&gt;
&lt;p&gt;See the website: &lt;a href="https://scalameta.org/metals/" rel="nofollow"&gt;https://scalameta.org/metals/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;See the contributing guide:
&lt;a href="https://scalameta.org/metals/docs/contributors/getting-started.html" rel="nofollow"&gt;https://scalameta.org/metals/docs/contributors/getting-started.html&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-team" class="anchor" aria-hidden="true" href="#team"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Team&lt;/h3&gt;
&lt;p&gt;The current maintainers (people who can merge pull requests) are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alexey Alekhin - &lt;a href="https://github.com/laughedelic"&gt;&lt;code&gt;@laughedelic&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Chris Kipp - &lt;a href="https://github.com/ckipp01"&gt;&lt;code&gt;@ckipp01&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gabriele Petronella - &lt;a href="https://github.com/gabro"&gt;&lt;code&gt;@gabro&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Johan Mudsam - &lt;a href="https://github.com/mudsam"&gt;&lt;code&gt;@mudsam&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jorge Vicente Cantero - &lt;a href="https://github.com/jvican"&gt;&lt;code&gt;@jvican&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Marek Żarnowski - &lt;a href="https://github.com/marek1840"&gt;&lt;code&gt;@marek1840&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ólafur Páll Geirsson - &lt;a href="https://github.com/olafurpg"&gt;&lt;code&gt;@olafurpg&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Shane Delmore - &lt;a href="https://github.com/ShaneDelmore"&gt;&lt;code&gt;@ShaneDelmore&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tomasz Godzik - &lt;a href="https://github.com/tgodzik"&gt;&lt;code&gt;@tgodzik&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-acknowledgement" class="anchor" aria-hidden="true" href="#acknowledgement"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;Huge thanks to &lt;a href="https://github.com/dragos"&gt;&lt;code&gt;@dragos&lt;/code&gt;&lt;/a&gt; for his work on a Scala
implementation of the LSP (see: &lt;a href="https://github.com/dragos/dragos-vscode-scala"&gt;https://github.com/dragos/dragos-vscode-scala&lt;/a&gt;).
This project helped us get quickly started with LSP. Since then, we have
refactored the project's original sources to the point where only a few simple
case classes remain.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-alternatives" class="anchor" aria-hidden="true" href="#alternatives"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Alternatives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.jetbrains.com/help/idea/discover-intellij-idea-for-scala.html" rel="nofollow"&gt;IntelliJ IDEA&lt;/a&gt;:
the most widely used IDE for Scala using a re-implementation of the Scala
typechecker.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scala-ide.org/" rel="nofollow"&gt;Scala IDE&lt;/a&gt;: Eclipse-based IDE using the Scala
Presentation Compiler.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-why-metals" class="anchor" aria-hidden="true" href="#why-metals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Metals?&lt;/h2&gt;
&lt;p&gt;Metals = Meta (from Scalameta) + LS (from Language Server)&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>scalameta</author><guid isPermaLink="false">https://github.com/scalameta/metals</guid><pubDate>Tue, 21 Jan 2020 00:15:00 GMT</pubDate></item><item><title>ornicar/lila #16 in Scala, Today</title><link>https://github.com/ornicar/lila</link><description>&lt;p&gt;&lt;i&gt;♞ lichess.org: the forever free, adless and open source chess server ♞&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-lichessorg" class="anchor" aria-hidden="true" href="#lichessorg"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href="https://lichess.org" rel="nofollow"&gt;lichess.org&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/ornicar/lila/actions?query=workflow%3A%22Build+server%22"&gt;&lt;img src="https://github.com/ornicar/lila/workflows/Build%20server/badge.svg" alt="Build server" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://github.com/ornicar/lila/actions?query=workflow%3A%22Build+assets%22"&gt;&lt;img src="https://github.com/ornicar/lila/workflows/Build%20assets/badge.svg" alt="Build assets" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://crowdin.com/project/lichess" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/23588c80b3a8c9a04dd2e12956326ac0f3d2ee5d/68747470733a2f2f64333232637174353834626f346f2e636c6f756466726f6e742e6e65742f6c6963686573732f6c6f63616c697a65642e737667" alt="Crowdin" data-canonical-src="https://d322cqt584bo4o.cloudfront.net/lichess/localized.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/lichess" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c9726f1341a098dd47e78700566287dc967e767c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f547769747465722d2534306c6963686573732d626c75652e737667" alt="Twitter" data-canonical-src="https://img.shields.io/badge/Twitter-%40lichess-blue.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://raw.githubusercontent.com/ornicar/lila/master/public/images/home-bicolor.png"&gt;&lt;img src="https://raw.githubusercontent.com/ornicar/lila/master/public/images/home-bicolor.png" alt="Lichess homepage" title="Lichess comes with light and dark theme, this screenshot shows both." style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lila (li[chess in sca]la) is a free online chess game server focused on &lt;a href="https://lichess.org/games" rel="nofollow"&gt;realtime&lt;/a&gt; gameplay and ease of use.&lt;/p&gt;
&lt;p&gt;It features a &lt;a href="https://lichess.org/games/search" rel="nofollow"&gt;search engine&lt;/a&gt;,
&lt;a href="https://lichess.org/ief49lif" rel="nofollow"&gt;computer analysis&lt;/a&gt; distributed with &lt;a href="https://github.com/niklasf/fishnet"&gt;fishnet&lt;/a&gt;,
&lt;a href="https://lichess.org/tournament" rel="nofollow"&gt;tournaments&lt;/a&gt;,
&lt;a href="https://lichess.org/simul" rel="nofollow"&gt;simuls&lt;/a&gt;,
&lt;a href="https://lichess.org/forum" rel="nofollow"&gt;forums&lt;/a&gt;,
&lt;a href="https://lichess.org/team" rel="nofollow"&gt;teams&lt;/a&gt;,
&lt;a href="https://lichess.org/training" rel="nofollow"&gt;tactic trainer&lt;/a&gt;,
a &lt;a href="https://lichess.org/mobile" rel="nofollow"&gt;mobile app&lt;/a&gt;,
and a &lt;a href="https://lichess.org/study" rel="nofollow"&gt;shared analysis board&lt;/a&gt;.
The UI is available in more than &lt;a href="https://crowdin.com/project/lichess" rel="nofollow"&gt;130 languages&lt;/a&gt; thanks to the community.&lt;/p&gt;
&lt;p&gt;Lichess is written in &lt;a href="https://www.scala-lang.org/" rel="nofollow"&gt;Scala 2.13&lt;/a&gt;,
and relies on the &lt;a href="https://www.playframework.com/" rel="nofollow"&gt;Play 2.8&lt;/a&gt; framework.
&lt;a href="http://www.lihaoyi.com/scalatags/" rel="nofollow"&gt;scalatags&lt;/a&gt; is used for templating.
Pure chess logic is contained in the &lt;a href="https://github.com/ornicar/scalachess"&gt;scalachess&lt;/a&gt; submodule.
The server is fully asynchronous, making heavy use of Scala Futures and &lt;a href="http://akka.io" rel="nofollow"&gt;Akka streams&lt;/a&gt;.
WebSocket connections are handled by a &lt;a href="https://github.com/ornicar/lila-ws"&gt;seperate server&lt;/a&gt; that communicates using &lt;a href="https://redis.io/" rel="nofollow"&gt;redis&lt;/a&gt;.
Lichess talks to &lt;a href="http://stockfishchess.org/" rel="nofollow"&gt;Stockfish&lt;/a&gt; deployed in an &lt;a href="https://github.com/niklasf/fishnet"&gt;AI cluster&lt;/a&gt; of donated servers.
It uses &lt;a href="https://mongodb.org" rel="nofollow"&gt;MongoDB&lt;/a&gt; to store more than 1.7 billion games, which are indexed by &lt;a href="http://elasticsearch.org" rel="nofollow"&gt;elasticsearch&lt;/a&gt;.
HTTP requests and WebSocket connections can be proxied by &lt;a href="http://nginx.org" rel="nofollow"&gt;nginx&lt;/a&gt;.
The web client is written in &lt;a href="https://typescriptlang.org" rel="nofollow"&gt;TypeScript&lt;/a&gt; and &lt;a href="https://github.com/snabbdom/snabbdom"&gt;snabbdom&lt;/a&gt;, using &lt;a href="https://sass-lang.com/" rel="nofollow"&gt;Sass&lt;/a&gt; to generate CSS.
The &lt;a href="https://lichess.org/blog" rel="nofollow"&gt;blog&lt;/a&gt; uses a free open content plan from &lt;a href="https://prismic.io" rel="nofollow"&gt;prismic.io&lt;/a&gt;.
All rated games are published in a &lt;a href="https://database.lichess.org" rel="nofollow"&gt;free PGN database&lt;/a&gt;.
Browser testing done with &lt;a href="https://www.browserstack.com" rel="nofollow"&gt;&lt;img src="https://raw.githubusercontent.com/ornicar/lila/master/public/images/browserstack.png" alt="Browserstack" style="max-width:100%;"&gt;&lt;/a&gt;.
Please help us &lt;a href="https://crowdin.com/project/lichess" rel="nofollow"&gt;translate lichess with Crowdin&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://lichess.org/source" rel="nofollow"&gt;lichess.org/source&lt;/a&gt; for a list of repositories.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://discord.gg/hy5jqSs" rel="nofollow"&gt;Join us on discord&lt;/a&gt; or in the &lt;code&gt;#lichess&lt;/code&gt; freenode IRC channel for more info.
Use &lt;a href="https://github.com/ornicar/lila/issues"&gt;GitHub issues&lt;/a&gt; for bug reports and feature requests.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;./lila # thin wrapper around sbt
run
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Wiki describes &lt;a href="https://github.com/ornicar/lila/wiki/Lichess-Development-Onboarding"&gt;how to setup a development environment&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-http-api" class="anchor" aria-hidden="true" href="#http-api"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;HTTP API&lt;/h2&gt;
&lt;p&gt;Feel free to use the &lt;a href="https://lichess.org/api" rel="nofollow"&gt;Lichess API&lt;/a&gt; in your applications and websites.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;See the &lt;a href="https://github.com/ornicar/lila/graphs/contributors"&gt;contributors&lt;/a&gt; on this repository and &lt;a href="https://lichess.org/thanks" rel="nofollow"&gt;lichess.org/thanks&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-supported-browsers" class="anchor" aria-hidden="true" href="#supported-browsers"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Supported browsers&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;th&gt;Notes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Chromium / Chrome&lt;/td&gt;
&lt;td&gt;last 10&lt;/td&gt;
&lt;td&gt;Full support, fastest local analysis&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Firefox&lt;/td&gt;
&lt;td&gt;55+&lt;/td&gt;
&lt;td&gt;Full support, second fastest local analysis&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Safari&lt;/td&gt;
&lt;td&gt;10.1+&lt;/td&gt;
&lt;td&gt;Reasonable support&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Opera&lt;/td&gt;
&lt;td&gt;55+&lt;/td&gt;
&lt;td&gt;Reasonable support&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Edge&lt;/td&gt;
&lt;td&gt;17+&lt;/td&gt;
&lt;td&gt;Reasonable support&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Older browsers (including any version of Internet Explorer) will not work.
For your own sake, please upgrade. Security and performance, think about
it!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Lila is licensed under the GNU Affero General Public License 3 or any later
version at your choice with an exception for Highcharts. See COPYING for
details.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>ornicar</author><guid isPermaLink="false">https://github.com/ornicar/lila</guid><pubDate>Tue, 21 Jan 2020 00:16:00 GMT</pubDate></item><item><title>nwtgck/gh-card #17 in Scala, Today</title><link>https://github.com/nwtgck/gh-card</link><description>&lt;p&gt;&lt;i&gt;:octocat: GitHub Repository Card for Every Web Site&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-gh-card" class="anchor" aria-hidden="true" href="#gh-card"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;gh-card&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/nwtgck/gh-card" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ef8cdbd0ab4381ce154e3e644f79ffc8ea0b8129/68747470733a2f2f636972636c6563692e636f6d2f67682f6e777467636b2f67682d636172642e7376673f7374796c653d736869656c64" alt="CircleCI" data-canonical-src="https://circleci.com/gh/nwtgck/gh-card.svg?style=shield" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub Repository Card for Every Web Site: &lt;a href="https://gh-card.dev" rel="nofollow"&gt;https://gh-card.dev&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-example-svg-card" class="anchor" aria-hidden="true" href="#example-svg-card"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Example SVG card&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc_assets/piping-server.svg"&gt;&lt;img src="doc_assets/piping-server.svg" alt="Piping Server static repo card" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-demo" class="anchor" aria-hidden="true" href="#demo"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener noreferrer" href="doc_assets/gh-card.gif"&gt;&lt;img src="doc_assets/gh-card.gif" alt="gh-card" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-how-it-works" class="anchor" aria-hidden="true" href="#how-it-works"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How it works?&lt;/h2&gt;
&lt;p&gt;The idea is similar to status badges from Travis CI, CircleCI and etc.&lt;/p&gt;
&lt;p&gt;An image URL is like "&lt;a href="https://gh-card.dev/repos/nwtgck/piping-server.svg" rel="nofollow"&gt;https://gh-card.dev/repos/nwtgck/piping-server.svg&lt;/a&gt;". The request triggers the backend server to call GitHub API request. The repository information are cached currently by Redis.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-related-projects" class="anchor" aria-hidden="true" href="#related-projects"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Related projects&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/po3rin/github_link_creator"&gt;GitHub Link Card Creator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lepture/github-cards"&gt;Unofficial GitHub Cards&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This might be similar to them. The purpose of this project is to provide an image which can be used in every site and the design should be like official GitHub repo card. I hope one day GitHub itself provides this feature officially.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>nwtgck</author><guid isPermaLink="false">https://github.com/nwtgck/gh-card</guid><pubDate>Tue, 21 Jan 2020 00:17:00 GMT</pubDate></item><item><title>playframework/playframework #18 in Scala, Today</title><link>https://github.com/playframework/playframework</link><description>&lt;p&gt;&lt;i&gt;Play Framework&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-play-framework---the-high-velocity-web-framework" class="anchor" aria-hidden="true" href="#play-framework---the-high-velocity-web-framework"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Play Framework - The High Velocity Web Framework&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://gitter.im/playframework/playframework?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e9c60a0e4c534f0f6e4b18c0d71e337e683104c3/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f67697474657248512f6769747465722e737667" alt="Gitter" data-canonical-src="https://img.shields.io/gitter/room/gitterHQ/gitter.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://travis-ci.org/playframework/playframework" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2494b1b0c8a9027b30f41fe465e0333d3b2db61f/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f706c61796672616d65776f726b2f706c61796672616d65776f726b2e737667" data-canonical-src="https://img.shields.io/travis/playframework/playframework.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="http://mvnrepository.com/artifact/com.typesafe.play/play_2.13" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/ab77956dd4d9def7cc89402b168f2d8ca2e49883/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f636f6d2e74797065736166652e706c61792f706c61795f322e31332e737667" alt="Maven" data-canonical-src="https://img.shields.io/maven-central/v/com.typesafe.play/play_2.13.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Play Framework combines productivity and performance making it easy to build scalable web applications with Java and Scala.  Play is developer friendly with a "just hit refresh" workflow and built-in testing support.  With Play, applications scale predictably due to a stateless and non-blocking architecture.  By being RESTful by default, including assets compilers, JSON &amp;amp; WebSocket support, Play is a perfect fit for modern web &amp;amp; mobile applications.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-learn-more" class="anchor" aria-hidden="true" href="#learn-more"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Learn More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com" rel="nofollow"&gt;www.playframework.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/download" rel="nofollow"&gt;Download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/Installing" rel="nofollow"&gt;Install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/NewApplication" rel="nofollow"&gt;Create a new application&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/ScalaHome" rel="nofollow"&gt;Play for Scala developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/JavaHome" rel="nofollow"&gt;Play for Java developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.playframework.com/documentation/latest/BuildingFromSource" rel="nofollow"&gt;Build from source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/playframework/playframework/issues"&gt;Search or create issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/tagged/playframework" rel="nofollow"&gt;Get help&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.playframework.com/contributing" rel="nofollow"&gt;Contribute&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-license" class="anchor" aria-hidden="true" href="#license"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright (C) Lightbend Inc. (&lt;a href="https://www.lightbend.com" rel="nofollow"&gt;https://www.lightbend.com&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this project except in compliance with the License. You may obtain a copy of the License at &lt;a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>playframework</author><guid isPermaLink="false">https://github.com/playframework/playframework</guid><pubDate>Tue, 21 Jan 2020 00:18:00 GMT</pubDate></item><item><title>prisma/prisma #19 in Scala, Today</title><link>https://github.com/prisma/prisma</link><description>&lt;p&gt;&lt;i&gt;💾 Database Tools incl. ORM, Migrations and Admin UI (Postgres, MySQL &amp; MongoDB)&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;p align="center"&gt;&lt;a href="https://www.prisma.io" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70ce08bb5adc4c15c49f51883552ec229124b978/68747470733a2f2f692e696d6775722e636f6d2f5167774469654f2e706e67" alt="Prisma" data-canonical-src="https://i.imgur.com/QgwDieO.png" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.prisma.io" rel="nofollow"&gt;Website&lt;/a&gt; • &lt;a href="https://www.prisma.io/docs/" rel="nofollow"&gt;Docs&lt;/a&gt; • &lt;a href="https://github.com/prisma/prisma-examples/"&gt;Examples&lt;/a&gt; • &lt;a href="https://www.prisma.io/blog" rel="nofollow"&gt;Blog&lt;/a&gt; • &lt;a href="https://slack.prisma.io/" rel="nofollow"&gt;Slack&lt;/a&gt; • &lt;a href="https://twitter.com/prisma" rel="nofollow"&gt;Twitter&lt;/a&gt; • &lt;a href="https://github.com/prisma/prisma2"&gt;Prisma Framework (Preview)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://circleci.com/gh/prisma/prisma" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/db2d4bf960796bc876c33ac155a52f342aa68ec3/68747470733a2f2f636972636c6563692e636f6d2f67682f707269736d612f707269736d612e7376673f7374796c653d736869656c64" alt="CircleCI" data-canonical-src="https://circleci.com/gh/prisma/prisma.svg?style=shield" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://slack.prisma.io" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0364c250658135b458cd7f0026373ab06ad99f3d/68747470733a2f2f736c61636b2e707269736d612e696f2f62616467652e737667" alt="Slack Status" data-canonical-src="https://slack.prisma.io/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt; &lt;a href="https://spectrum.chat/prisma" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/3cc3d27f23a2c3948de24fc02c58bc576655d621/68747470733a2f2f77697468737065637472756d2e6769746875622e696f2f62616467652f62616467652e737667" alt="Join the community on Spectrum" data-canonical-src="https://withspectrum.github.io/badge/badge.svg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Prisma replaces traditional ORMs and simplifies database workflows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Access&lt;/em&gt;: &lt;strong&gt;Type-safe database access with the auto-generated Prisma client&lt;/strong&gt; (in &lt;a href="https://www.prisma.io/client/client-javscript/" rel="nofollow"&gt;JavaScript&lt;/a&gt;, &lt;a href="https://www.prisma.io/client/client-typescript/" rel="nofollow"&gt;TypeScript&lt;/a&gt;, &lt;a href="https://www.prisma.io/client/client-go/" rel="nofollow"&gt;Go&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Migrate&lt;/em&gt;: &lt;strong&gt;Declarative data modelling and migrations&lt;/strong&gt; (optional)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Manage&lt;/em&gt;: &lt;strong&gt;Visual data management with Prisma Admin&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is used to build &lt;strong&gt;GraphQL, REST, gRPC APIs&lt;/strong&gt; and more. Prisma &lt;a href="#database-connectors"&gt;currently supports&lt;/a&gt; MySQL, PostgreSQL, MongoDB.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A new version of Prisma, the &lt;a href="https://github.com/prisma/prisma2"&gt;&lt;strong&gt;Prisma Framework&lt;/strong&gt;&lt;/a&gt; (initially called &lt;em&gt;Prisma 2&lt;/em&gt;), is currently in Preview. It doesn't require a database proxy server and features a more modular architecture based on three tools: &lt;a href="https://github.com/prisma/photonjs"&gt;Photon.js&lt;/a&gt;, &lt;a href="https://github.com/prisma/lift"&gt;Lift&lt;/a&gt; and &lt;a href="https://github.com/prisma/studio"&gt;Studio&lt;/a&gt;. Follow the development of the Prisma Framework on: &lt;a href="https://isprisma2ready.com" rel="nofollow"&gt;&lt;strong&gt;isprisma2ready.com&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Get started with the &lt;a href="https://github.com/prisma/prisma2/blob/master/docs/tutorial.md"&gt;tutorial&lt;/a&gt; or some ready-to-run &lt;a href="https://github.com/prisma/prisma-examples/tree/prisma2"&gt;examples&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a id="user-content-contents" class="anchor" aria-hidden="true" href="#contents"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database-connectors"&gt;Database Connectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#community"&gt;Community&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#prisma-framework-preview"&gt;Prisma Framework Preview&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-quickstart" class="anchor" aria-hidden="true" href="#quickstart"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quickstart&lt;/h2&gt;
&lt;p&gt;Get started with Prisma from scratch (or &lt;a href="https://www.prisma.io/docs/-t003/" rel="nofollow"&gt;use your existing database&lt;/a&gt;):&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-1-install-prisma-via-homebrew" class="anchor" aria-hidden="true" href="#1-install-prisma-via-homebrew"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;1. Install Prisma via Homebrew&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;brew tap prisma/prisma
brew install prisma
&lt;/code&gt;&lt;/pre&gt;
&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Alternative&lt;/b&gt;: Install with NPM or Yarn&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;npm install -g prisma
# or
yarn global add prisma
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;h4&gt;&lt;a id="user-content-2-connect-prisma-to-a-database" class="anchor" aria-hidden="true" href="#2-connect-prisma-to-a-database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;2. Connect Prisma to a database&lt;/h4&gt;
&lt;p&gt;To setup Prisma, you need to have &lt;a href="https://www.docker.com" rel="nofollow"&gt;Docker&lt;/a&gt; installed. Run the following command to get started with Prisma:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;prisma init hello-world
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;If you don't want to use Docker to host the Prisma server as a database proxy, be sure to check out the new &lt;a href="https://github.com/prisma/prisma2"&gt;Prisma Framework&lt;/a&gt; which removes the need for the Prisma server.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The interactive CLI wizard now helps you with the required setup:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Select &lt;strong&gt;Create new database&lt;/strong&gt; (you can also use an &lt;a href="https://www.prisma.io/docs/-t003/" rel="nofollow"&gt;existing database&lt;/a&gt; or a hosted &lt;a href="https://www.prisma.io/docs/-t001/" rel="nofollow"&gt;demo database&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Select the database type: &lt;strong&gt;MySQL&lt;/strong&gt; or &lt;strong&gt;PostgreSQL&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Select the language for the generated Prisma client: &lt;strong&gt;TypeScript&lt;/strong&gt;, &lt;strong&gt;Flow&lt;/strong&gt;, &lt;strong&gt;JavaScript&lt;/strong&gt; or &lt;strong&gt;Go&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once the wizard has terminated, run the following commands to setup Prisma:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd hello-world
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;&lt;a id="user-content-3-define-your-datamodel" class="anchor" aria-hidden="true" href="#3-define-your-datamodel"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;3. Define your datamodel&lt;/h4&gt;
&lt;p&gt;Edit &lt;code&gt;datamodel.prisma&lt;/code&gt; to define your datamodel using &lt;a href="https://www.prisma.io/blog/graphql-sdl-schema-definition-language-6755bcb9ce51/" rel="nofollow"&gt;SDL&lt;/a&gt; syntax. Each model is mapped to a table in your database schema:&lt;/p&gt;
&lt;div class="highlight highlight-source-graphql"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-c1"&gt;User&lt;/span&gt; {
  &lt;span class="pl-v"&gt;id&lt;/span&gt;: &lt;span class="pl-c1"&gt;ID&lt;/span&gt;&lt;span class="pl-k"&gt;!&lt;/span&gt; &lt;span class="pl-en"&gt;@id&lt;/span&gt;
  &lt;span class="pl-v"&gt;email&lt;/span&gt;: &lt;span class="pl-c1"&gt;String&lt;/span&gt; &lt;span class="pl-en"&gt;@unique&lt;/span&gt;
  &lt;span class="pl-v"&gt;name&lt;/span&gt;: &lt;span class="pl-c1"&gt;String&lt;/span&gt;&lt;span class="pl-k"&gt;!&lt;/span&gt;
  &lt;span class="pl-v"&gt;posts&lt;/span&gt;: [&lt;span class="pl-c1"&gt;Post&lt;/span&gt;&lt;span class="pl-k"&gt;!&lt;/span&gt;]&lt;span class="pl-k"&gt;!&lt;/span&gt;
}

&lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-c1"&gt;Post&lt;/span&gt; {
  &lt;span class="pl-v"&gt;id&lt;/span&gt;: &lt;span class="pl-c1"&gt;ID&lt;/span&gt;&lt;span class="pl-k"&gt;!&lt;/span&gt; &lt;span class="pl-en"&gt;@id&lt;/span&gt;
  &lt;span class="pl-v"&gt;title&lt;/span&gt;: &lt;span class="pl-c1"&gt;String&lt;/span&gt;&lt;span class="pl-k"&gt;!&lt;/span&gt;
  &lt;span class="pl-v"&gt;published&lt;/span&gt;: &lt;span class="pl-c1"&gt;Boolean&lt;/span&gt;&lt;span class="pl-k"&gt;!&lt;/span&gt; &lt;span class="pl-en"&gt;@default&lt;/span&gt;(&lt;span class="pl-v"&gt;value&lt;/span&gt;: &lt;span class="pl-c1"&gt;false&lt;/span&gt;)
  &lt;span class="pl-v"&gt;author&lt;/span&gt;: &lt;span class="pl-c1"&gt;User&lt;/span&gt;
}&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;a id="user-content-4-deploy-datamodel--migrate-database" class="anchor" aria-hidden="true" href="#4-deploy-datamodel--migrate-database"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;4. Deploy datamodel &amp;amp; migrate database&lt;/h4&gt;
&lt;p&gt;To deploy your Prisma API, run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;prisma deploy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Prisma API is deployed based on the datamodel and exposes CRUD &amp;amp; realtime operations for each model in that file.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-5-use-the-prisma-client-nodejs" class="anchor" aria-hidden="true" href="#5-use-the-prisma-client-nodejs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;5. Use the Prisma client (Node.js)&lt;/h4&gt;
&lt;p&gt;The Prisma client connects to the Prisma API and lets you perform read and write operations against your database. This section explains how to use the Prisma client from &lt;strong&gt;Node.js&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Inside the &lt;code&gt;hello-world&lt;/code&gt; directory, install the &lt;code&gt;prisma-client-lib&lt;/code&gt; dependency:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;npm install --save prisma-client-lib
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To generate the Prisma client, run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;prisma generate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create a new Node script inside the &lt;code&gt;hello-world&lt;/code&gt; directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;touch index.js
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add the following code to it:&lt;/p&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;const&lt;/span&gt; { &lt;span class="pl-c1"&gt;prisma&lt;/span&gt; } &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-c1"&gt;require&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;./generated/prisma-client&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; A `main` function so that we can use async/await&lt;/span&gt;
&lt;span class="pl-k"&gt;async&lt;/span&gt; &lt;span class="pl-k"&gt;function&lt;/span&gt; &lt;span class="pl-en"&gt;main&lt;/span&gt;() {
  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Create a new user with a new post&lt;/span&gt;
  &lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;newUser&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;await&lt;/span&gt; &lt;span class="pl-smi"&gt;prisma&lt;/span&gt;.&lt;span class="pl-en"&gt;createUser&lt;/span&gt;({
    name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Alice&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;,
    posts&lt;span class="pl-k"&gt;:&lt;/span&gt; {
      create&lt;span class="pl-k"&gt;:&lt;/span&gt; { title&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;The data layer for modern apps&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; }
    }
  })
  &lt;span class="pl-en"&gt;console&lt;/span&gt;.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;`&lt;/span&gt;Created new user: &lt;span class="pl-s1"&gt;&lt;span class="pl-pse"&gt;${&lt;/span&gt;&lt;span class="pl-smi"&gt;newUser&lt;/span&gt;.&lt;span class="pl-c1"&gt;name&lt;/span&gt;&lt;span class="pl-pse"&gt;}&lt;/span&gt;&lt;/span&gt; (ID: &lt;span class="pl-s1"&gt;&lt;span class="pl-pse"&gt;${&lt;/span&gt;&lt;span class="pl-smi"&gt;newUser&lt;/span&gt;.&lt;span class="pl-c1"&gt;id&lt;/span&gt;&lt;span class="pl-pse"&gt;}&lt;/span&gt;&lt;/span&gt;)&lt;span class="pl-pds"&gt;`&lt;/span&gt;&lt;/span&gt;)

  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Read all users from the database and print them to the console&lt;/span&gt;
  &lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;allUsers&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;await&lt;/span&gt; &lt;span class="pl-smi"&gt;prisma&lt;/span&gt;.&lt;span class="pl-en"&gt;users&lt;/span&gt;()
  &lt;span class="pl-en"&gt;console&lt;/span&gt;.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(allUsers)

  &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Read all posts from the database and print them to the console&lt;/span&gt;
  &lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;allPosts&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;await&lt;/span&gt; &lt;span class="pl-smi"&gt;prisma&lt;/span&gt;.&lt;span class="pl-en"&gt;posts&lt;/span&gt;()
  &lt;span class="pl-en"&gt;console&lt;/span&gt;.&lt;span class="pl-c1"&gt;log&lt;/span&gt;(allPosts)
}

&lt;span class="pl-en"&gt;main&lt;/span&gt;().&lt;span class="pl-c1"&gt;catch&lt;/span&gt;(&lt;span class="pl-smi"&gt;e&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;console&lt;/span&gt;.&lt;span class="pl-c1"&gt;error&lt;/span&gt;(e))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, run the code using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;node index.js
&lt;/code&gt;&lt;/pre&gt;
&lt;details&gt;&lt;summary&gt;&lt;b&gt;See more API operations&lt;/b&gt;&lt;/summary&gt;
&lt;p&gt;
&lt;/p&gt;&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;usersCalledAlice&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;await&lt;/span&gt; prisma
  .&lt;span class="pl-en"&gt;users&lt;/span&gt;({
    where&lt;span class="pl-k"&gt;:&lt;/span&gt; {
      name&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Alice&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
    }
  })&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; replace the __USER_ID__ placeholder with an actual user ID&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;updatedUser&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;await&lt;/span&gt; prisma
  .&lt;span class="pl-en"&gt;updateUser&lt;/span&gt;({
    where&lt;span class="pl-k"&gt;:&lt;/span&gt; { id&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;__USER_ID__&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; },
    data&lt;span class="pl-k"&gt;:&lt;/span&gt; { email&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;alice@prisma.io&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; }
  })&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; replace the __USER_ID__ placeholder with an actual user ID&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;deletedUser&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;await&lt;/span&gt; prisma
  .&lt;span class="pl-en"&gt;deleteUser&lt;/span&gt;({ id&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;__USER_ID__&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; })&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight highlight-source-js"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-c1"&gt;postsByAuthor&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;await&lt;/span&gt; prisma
  .&lt;span class="pl-en"&gt;user&lt;/span&gt;({ email&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;alice@prisma.io&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; })
  .&lt;span class="pl-en"&gt;posts&lt;/span&gt;()&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;h4&gt;&lt;a id="user-content-6-next-steps" class="anchor" aria-hidden="true" href="#6-next-steps"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;6. Next steps&lt;/h4&gt;
&lt;p&gt;Here is what you can do next:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.prisma.io/docs/-t201/" rel="nofollow"&gt;Build an app with Prisma client&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples"&gt;Check out some examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.prisma.io/docs/-j9ff/" rel="nofollow"&gt;Read more about how Prisma works&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-examples-prisma-1" class="anchor" aria-hidden="true" href="#examples-prisma-1"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples (Prisma 1)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;You can find the examples for the &lt;strong&gt;Prisma Framework&lt;/strong&gt; (originally called &lt;em&gt;Prisma 2&lt;/em&gt;) &lt;a href="https://github.com/prisma/prisma-examples/tree/prisma2"&gt;here&lt;/a&gt;. These example are based on the &lt;a href="https://www.prisma.io/blog/announcing-prisma-2-zq1s745db8i5/" rel="nofollow"&gt;new&lt;/a&gt; Prisma tools: &lt;a href="https://github.com/prisma/photonjs"&gt;Photon.js&lt;/a&gt; and &lt;a href="https://github.com/prisma/lift"&gt;Lift&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;&lt;a id="user-content-typescript" class="anchor" aria-hidden="true" href="#typescript"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TypeScript&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Demo&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/script"&gt;&lt;code&gt;script&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple usage of Prisma client in script&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/graphql"&gt;&lt;code&gt;graphql&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple GraphQL server based on &lt;a href="https://github.com/prisma/graphql-yoga"&gt;&lt;code&gt;graphql-yoga&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/graphql-apollo-server"&gt;&lt;code&gt;graphql-apollo-server&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple GraphQL server based on &lt;a href="https://www.apollographql.com/docs/apollo-server/" rel="nofollow"&gt;&lt;code&gt;apollo-server&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/graphql-crud"&gt;&lt;code&gt;graphql-crud&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;GraphQL server with full CRUD API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/graphql-auth"&gt;&lt;code&gt;graphql-auth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;GraphQL server with email-password authentication &amp;amp; permissions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/graphql-subscriptions"&gt;&lt;code&gt;graphql-subscriptions&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;GraphQL server with realtime subscriptions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/rest-express"&gt;&lt;code&gt;rest-express&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple REST API with Express.JS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/grpc"&gt;&lt;code&gt;grpc&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple gRPC API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/docker-mongodb"&gt;&lt;code&gt;docker-mongodb&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Set up Prisma locally with MongoDB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/docker-mysql"&gt;&lt;code&gt;docker-mysql&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Set up Prisma locally with MySQL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/docker-postgres"&gt;&lt;code&gt;docker-postgres&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Set up Prisma locally with PostgreSQL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/typescript/cli-app"&gt;&lt;code&gt;cli-app&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple CLI TODO list app&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-nodejs" class="anchor" aria-hidden="true" href="#nodejs"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Node.js&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Demo&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/script"&gt;&lt;code&gt;script&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple usage of Prisma client in script&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/graphql"&gt;&lt;code&gt;graphql&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple GraphQL server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/graphql-auth"&gt;&lt;code&gt;graphql-auth&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;GraphQL server with email-password authentication &amp;amp; permissions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/graphql-subscriptions"&gt;&lt;code&gt;graphql-subscriptions&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;GraphQL server with realtime subscriptions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/rest-express"&gt;&lt;code&gt;rest-express&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple REST API with Express.JS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/grpc"&gt;&lt;code&gt;grpc&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple gRPC API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/docker-mongodb"&gt;&lt;code&gt;docker-mongodb&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Set up Prisma locally with MongoDB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/docker-mysql"&gt;&lt;code&gt;docker-mysql&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Set up Prisma locally with MySQL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/docker-postgres"&gt;&lt;code&gt;docker-postgres&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Set up Prisma locally with PostgreSQL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/node/cli-app"&gt;&lt;code&gt;cli-app&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple CLI TODO list app&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-golang" class="anchor" aria-hidden="true" href="#golang"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Golang&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Demo&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/go/cli-app"&gt;&lt;code&gt;cli-app&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple CLI TODO list app&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/go/graphql"&gt;&lt;code&gt;graphql&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple GraphQL server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/go/http-mux"&gt;&lt;code&gt;http-mux&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple REST API with &lt;a href="https://github.com/gorilla/mux"&gt;gorilla/mux&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/go/rest-gin"&gt;&lt;code&gt;rest-gin&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple REST API with &lt;a href="https://github.com/gin-gonic/gin"&gt;Gin&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/go/script"&gt;&lt;code&gt;script&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple usage of Prisma client in script&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;&lt;a id="user-content-flow" class="anchor" aria-hidden="true" href="#flow"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Flow&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Demo&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/flow/graphql"&gt;&lt;code&gt;graphql&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple GraphQL server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;a href="https://github.com/prisma/prisma-examples/tree/master/flow/script"&gt;&lt;code&gt;script&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="left"&gt;Simple usage of Prisma client in script&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;&lt;a id="user-content-database-connectors" class="anchor" aria-hidden="true" href="#database-connectors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Database Connectors&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/prisma/prisma/issues/1751"&gt;Database connectors&lt;/a&gt; provide the link between Prisma and the underlying database.&lt;/p&gt;
&lt;p&gt;You can connect the following databases to Prisma already:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL&lt;/li&gt;
&lt;li&gt;PostgreSQL&lt;/li&gt;
&lt;li&gt;MongoDB&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-upcoming-connectors" class="anchor" aria-hidden="true" href="#upcoming-connectors"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Upcoming Connectors&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Prisma 1 is currently in maintenance mode in favor of the development of the &lt;a href="https://github.com/prisma/prisma2"&gt;Prisma Framework&lt;/a&gt;. The data source connectors listed below will be implemented in the scope of the Prisma Framework instead of Prisma 1.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you are interested to participate in the preview for one of the following connectors, please reach out in our &lt;a href="https://slack.prisma.io" rel="nofollow"&gt;Slack&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1665"&gt;Elastic Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1642"&gt;MS SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1644"&gt;Oracle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1645"&gt;ArangoDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1646"&gt;Neo4j&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1647"&gt;Druid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1648"&gt;Dgraph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1655"&gt;DynamoDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1660"&gt;Cloud Firestore&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1705"&gt;CockroachDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1750"&gt;Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1722"&gt;Redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1752"&gt;AWS Neptune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1663"&gt;CosmosDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prisma/prisma/issues/1857"&gt;Influx&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Join the discussion or contribute to influence which we'll work on next!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community" class="anchor" aria-hidden="true" href="#community"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community&lt;/h2&gt;
&lt;p&gt;Prisma has a &lt;a href="https://www.prisma.io/community" rel="nofollow"&gt;community&lt;/a&gt; of thousands of amazing developers and contributors. Welcome, please join us! &lt;g-emoji class="g-emoji" alias="wave" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44b.png"&gt;👋&lt;/g-emoji&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-channels" class="anchor" aria-hidden="true" href="#channels"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Channels&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://slack.prisma.io/" rel="nofollow"&gt;Slack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/prisma" rel="nofollow"&gt;Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.facebook.com/prisma.io" rel="nofollow"&gt;Facebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="mailto:hello@prisma.io"&gt;Email&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-events" class="anchor" aria-hidden="true" href="#events"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Events&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.prisma.io/day/" rel="nofollow"&gt;Prisma Day&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.graphqlconf.org/" rel="nofollow"&gt;GraphQL Conf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.meetup.com/TypeScript-Berlin/" rel="nofollow"&gt;TypeScript Berlin Meetup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.meetup.com/graphql-berlin" rel="nofollow"&gt;GraphQL Berlin Meetup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://prisma.1wire.com/" rel="nofollow"&gt;Chinese translation of the Prisma docs&lt;/a&gt; (Thanks to &lt;a href="https://github.com/Victorkangsh"&gt;Victor Kang&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/catalinmiron/awesome-prisma"&gt;Awesome Prisma&lt;/a&gt; (Thanks to &lt;a href="https://github.com/catalinmiron"&gt;Catalin Miron&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-prisma-framework-preview" class="anchor" aria-hidden="true" href="#prisma-framework-preview"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Prisma Framework Preview&lt;/h2&gt;
&lt;p&gt;Prisma 2 splits up Prisma's core functionality into 2 standalone tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://photonjs.prisma.io/" rel="nofollow"&gt;Photon&lt;/a&gt;: Type-safe database access&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lift.prisma.io/" rel="nofollow"&gt;Lift&lt;/a&gt;: Declarative data modeling and migrations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Photon and Lift are currently in Preview! Get started with the &lt;a href="https://github.com/prisma/prisma2/blob/master/docs/tutorial.md"&gt;tutorial&lt;/a&gt; or some ready-to-run &lt;a href="https://github.com/prisma/prisma-examples/tree/prisma2"&gt;examples&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can track the progress of Prisma 2 on &lt;a href="https://www.isprisma2ready.com" rel="nofollow"&gt;&lt;strong&gt;isprisma2ready.com&lt;/strong&gt;&lt;/a&gt; or follow the development of the &lt;a href="https://github.com/prisma/specs"&gt;technical specification&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>prisma</author><guid isPermaLink="false">https://github.com/prisma/prisma</guid><pubDate>Tue, 21 Jan 2020 00:19:00 GMT</pubDate></item><item><title>scala/scala #20 in Scala, Today</title><link>https://github.com/scala/scala</link><description>&lt;p&gt;&lt;i&gt;The Scala programming language&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-welcome" class="anchor" aria-hidden="true" href="#welcome"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Welcome!&lt;/h1&gt;
&lt;p&gt;This is the official repository for the &lt;a href="http://www.scala-lang.org" rel="nofollow"&gt;Scala Programming Language&lt;/a&gt;
standard library, compiler, and language spec.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-how-to-contribute" class="anchor" aria-hidden="true" href="#how-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How to contribute&lt;/h1&gt;
&lt;p&gt;To contribute in this repo, please open a &lt;a href="https://help.github.com/articles/using-pull-requests/#fork--pull"&gt;pull request&lt;/a&gt; from your fork of this repository.&lt;/p&gt;
&lt;p&gt;We do have to ask you to sign the &lt;a href="http://www.lightbend.com/contribute/cla/scala" rel="nofollow"&gt;Scala CLA&lt;/a&gt; before we can merge any of your work, to protect its open source nature.&lt;/p&gt;
&lt;p&gt;For more information on building and developing the core of Scala, make sure to read
the rest of this README!&lt;/p&gt;
&lt;p&gt;In order to get in touch with other Scala contributors, join
&lt;a href="https://gitter.im/scala/contributors" rel="nofollow"&gt;scala/contributors&lt;/a&gt; (Gitter) or post on
&lt;a href="http://contributors.scala-lang.org" rel="nofollow"&gt;contributors.scala-lang.org&lt;/a&gt; (Discourse).&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-bugs--issues" class="anchor" aria-hidden="true" href="#bugs--issues"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bugs / issues&lt;/h1&gt;
&lt;p&gt;Please report bugs at the &lt;a href="https://github.com/scala/bug/issues"&gt;scala/bug issue tracker&lt;/a&gt;. This tracker is also where new contributors may find good first issues to work on.&lt;/p&gt;
&lt;p&gt;We use the &lt;a href="https://github.com/scala/scala-dev/issues"&gt;scala/scala-dev tracker&lt;/a&gt; for coordinating bigger work items.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-get-in-touch" class="anchor" aria-hidden="true" href="#get-in-touch"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get in touch!&lt;/h1&gt;
&lt;p&gt;If you need some help with your PR at any time, please feel free to @-mention anyone from the list below, and we will do our best to help you out:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;username&lt;/th&gt;
&lt;th&gt;talk to me about...&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/adriaanm"&gt;&lt;img src="https://avatars.githubusercontent.com/adriaanm" height="50px" title="Adriaan Moors" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/adriaanm"&gt;&lt;code&gt;@adriaanm&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;type checker, pattern matcher, infrastructure, language spec&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/SethTisue"&gt;&lt;img src="https://avatars.githubusercontent.com/SethTisue" height="50px" title="Seth Tisue" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/SethTisue"&gt;&lt;code&gt;@SethTisue&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;getting started, build, developer docs, community build, Jenkins, library&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/retronym"&gt;&lt;img src="https://avatars.githubusercontent.com/retronym" height="50px" title="Jason Zaugg" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/retronym"&gt;&lt;code&gt;@retronym&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;compiler performance, weird compiler bugs, Java 8 lambdas, REPL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/szeiger"&gt;&lt;img src="https://avatars.githubusercontent.com/szeiger" height="50px" title="Stefan Zeiger" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/szeiger"&gt;&lt;code&gt;@szeiger&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;collections, build&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/lrytz"&gt;&lt;img src="https://avatars.githubusercontent.com/lrytz" height="50px" title="Lukas Rytz" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/lrytz"&gt;&lt;code&gt;@lrytz&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;back end, optimizer, named &amp;amp; default arguments, reporters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/Ichoran"&gt;&lt;img src="https://avatars.githubusercontent.com/Ichoran" height="50px" title="Rex Kerr" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/Ichoran"&gt;&lt;code&gt;@Ichoran&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;collections library, performance&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/viktorklang"&gt;&lt;img src="https://avatars.githubusercontent.com/viktorklang" height="50px" title="Viktor Klang" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/viktorklang"&gt;&lt;code&gt;@viktorklang&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;concurrency, futures&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/axel22"&gt;&lt;img src="https://avatars.githubusercontent.com/axel22" height="50px" title="Aleksandr Prokopec" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/axel22"&gt;&lt;code&gt;@axel22&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;concurrency, parallel collections, specialization&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/dragos"&gt;&lt;img src="https://avatars.githubusercontent.com/dragos" height="50px" title="Iulian Dragos" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/dragos"&gt;&lt;code&gt;@dragos&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;specialization, back end&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/janekdb"&gt;&lt;img src="https://avatars.githubusercontent.com/janekdb" height="50px" title="Janek Bogucki" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/janekdb"&gt;&lt;code&gt;@janekdb&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;documentation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a target="_blank" rel="noopener noreferrer" href="https://avatars.githubusercontent.com/sjrd"&gt;&lt;img src="https://avatars.githubusercontent.com/sjrd" height="50px" title="Sébastien Doeraene" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/sjrd"&gt;&lt;code&gt;@sjrd&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;interactions with Scala.js&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;P.S.: If you have some spare time to help out around here, we would be delighted to add your name to this list!&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-repository-structure" class="anchor" aria-hidden="true" href="#repository-structure"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Repository structure&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;scala/
+--build.sbt                 The main sbt build script
+--lib/                      Pre-compiled libraries for the build
+--src/                      All sources
   +---/library              Scala Standard Library
   +---/reflect              Scala Reflection
   +---/compiler             Scala Compiler
   +---/intellij             IntelliJ project templates
+--spec/                     The Scala language specification
+--scripts/                  Scripts for the CI jobs (including building releases)
+--test/                     The Scala test suite
   +---/files                Partest tests
   +---/junit                JUnit tests
   +---/scalacheck           ScalaCheck tests
+--build/                    [Generated] Build output directory
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;&lt;a id="user-content-get-ready-to-contribute" class="anchor" aria-hidden="true" href="#get-ready-to-contribute"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Get ready to contribute&lt;/h1&gt;
&lt;h2&gt;&lt;a id="user-content-requirements" class="anchor" aria-hidden="true" href="#requirements"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Requirements&lt;/h2&gt;
&lt;p&gt;You need the following tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Java SDK. The baseline version is 8 for both 2.12.x and 2.13.x. It may be possible to use a
later SDK for local development, but the CI will verify against the baseline
version.&lt;/li&gt;
&lt;li&gt;sbt (sbt 0.13 on the 2.12.x branch, sbt 1 on the 2.13.x branch)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MacOS and Linux work. Windows may work if you use Cygwin. Community help with keeping
the build working on Windows is appreciated.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-tools-we-use" class="anchor" aria-hidden="true" href="#tools-we-use"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tools we use&lt;/h2&gt;
&lt;p&gt;We are grateful for the following OSS licenses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.ej-technologies.com/products/jprofiler/overview.html" rel="nofollow"&gt;JProfiler Java profiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.yourkit.com/java/profiler/" rel="nofollow"&gt;YourKit Java Profiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jetbrains.com/idea/download/" rel="nofollow"&gt;IntelliJ IDEA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a id="user-content-build-setup" class="anchor" aria-hidden="true" href="#build-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Build setup&lt;/h2&gt;
&lt;h3&gt;&lt;a id="user-content-basics" class="anchor" aria-hidden="true" href="#basics"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basics&lt;/h3&gt;
&lt;p&gt;During ordinary development, a new Scala build is built by the
previously released version.  For short we call the previous release
"starr": the stable reference release.  Building with starr is
sufficient for most kinds of changes.&lt;/p&gt;
&lt;p&gt;However, a full build of Scala (a &lt;em&gt;bootstrap&lt;/em&gt;, as performed by our CI)
requires two layers. This guarantees that every Scala version can
build itself. If you change the code generation part of the Scala
compiler, your changes will only show up in the bytecode of the
library and compiler after a bootstrap. See below for how to do a
bootstrap build locally.&lt;/p&gt;
&lt;p&gt;For history on how the current scheme was arrived at, see
&lt;a href="https://groups.google.com/d/topic/scala-internals/gp5JsM1E0Fo/discussion" rel="nofollow"&gt;https://groups.google.com/d/topic/scala-internals/gp5JsM1E0Fo/discussion&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-using-the-sbt-build" class="anchor" aria-hidden="true" href="#using-the-sbt-build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Using the sbt build&lt;/h3&gt;
&lt;p&gt;Once you've started an &lt;code&gt;sbt&lt;/code&gt; session you can run one of the core commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;compile&lt;/code&gt; compiles all sub-projects (library, reflect, compiler, scaladoc, etc)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;scala&lt;/code&gt; / &lt;code&gt;scalac&lt;/code&gt; run the REPL / compiler directly from sbt (accept options /
arguments)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enableOptimizer&lt;/code&gt; reloads the build with the Scala optimizer enabled. Our releases are built this way. Enable this when working on compiler performance improvements. When the optimizer is enabled the build will be slower and incremental builds can be incorrect.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;setupPublishCore&lt;/code&gt; which runs &lt;code&gt;enableOptimizer&lt;/code&gt; and also configures a version number based on the current Git SHA. Often used as part of bootstrapping &lt;code&gt;sbt setupPublishCore publishLocal &amp;amp;&amp;amp; sbt -Dstarr.version=&amp;lt;VERSION&amp;gt; testAll&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dist/mkBin&lt;/code&gt; generates runner scripts (&lt;code&gt;scala&lt;/code&gt;, &lt;code&gt;scalac&lt;/code&gt;, etc) in &lt;code&gt;build/quick/bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dist/mkPack&lt;/code&gt; creates a build in the Scala distribution format in &lt;code&gt;build/pack&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test&lt;/code&gt; runs the JUnit test, &lt;code&gt;testOnly *immutable.ListTest&lt;/code&gt; runs a subset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;partest&lt;/code&gt; runs partest tests (accepts options, try &lt;code&gt;partest --help&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;scalacheck/test&lt;/code&gt; runs scalacheck tests, &lt;code&gt;scalacheck/testOnly *FloatFormatTest&lt;/code&gt; runs a subset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;publishLocal&lt;/code&gt; publishes a distribution locally (can be used as &lt;code&gt;scalaVersion&lt;/code&gt; in
other sbt projects)
&lt;ul&gt;
&lt;li&gt;Optionally &lt;code&gt;set baseVersionSuffix := "bin-abcd123-SNAPSHOT"&lt;/code&gt;
where &lt;code&gt;abcd123&lt;/code&gt; is the git hash of the revision being published. You can also
use something custom like &lt;code&gt;"bin-mypatch"&lt;/code&gt;. This changes the version number from
&lt;code&gt;2.12.2-SNAPSHOT&lt;/code&gt; to something more stable (&lt;code&gt;2.12.2-bin-abcd123-SNAPSHOT&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Note that the &lt;code&gt;-bin&lt;/code&gt; string marks the version binary compatible. Using it in
sbt will cause the &lt;code&gt;scalaBinaryVersion&lt;/code&gt; to be &lt;code&gt;2.12&lt;/code&gt;. If the version is not
binary compatible, we recommend using &lt;code&gt;-pre&lt;/code&gt;, e.g., &lt;code&gt;2.13.0-pre-abcd123-SNAPSHOT&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Optionally &lt;code&gt;set publishArtifact in (Compile, packageDoc) in ThisBuild := false&lt;/code&gt;
to skip generating / publishing API docs (speeds up the process).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If a command results in an error message like &lt;code&gt;a module is not authorized to depend on itself&lt;/code&gt;, it may be that a global sbt plugin is
resulting in a cyclical dependency. Try disabling global sbt plugins (perhaps by
temporarily commenting them out in &lt;code&gt;~/.sbt/1.0/plugins/plugins.sbt&lt;/code&gt;).&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-sandbox" class="anchor" aria-hidden="true" href="#sandbox"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Sandbox&lt;/h4&gt;
&lt;p&gt;We recommend to keep local test files in the &lt;code&gt;sandbox&lt;/code&gt; directory which is listed in
the &lt;code&gt;.gitignore&lt;/code&gt; of the Scala repo.&lt;/p&gt;
&lt;h4&gt;&lt;a id="user-content-incremental-compilation" class="anchor" aria-hidden="true" href="#incremental-compilation"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Incremental compilation&lt;/h4&gt;
&lt;p&gt;Note that sbt's incremental compilation is often too coarse for the Scala compiler
codebase and re-compiles too many files, resulting in long build times (check
&lt;a href="https://github.com/sbt/sbt/issues/1104"&gt;sbt#1104&lt;/a&gt; for progress on that front). In the
meantime you can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use IntelliJ IDEA for incremental compiles (see &lt;a href="#ide-setup"&gt;IDE Setup&lt;/a&gt; below) - its
incremental compiler is a bit less conservative, but usually correct.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;a id="user-content-bootstrapping-locally" class="anchor" aria-hidden="true" href="#bootstrapping-locally"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Bootstrapping locally&lt;/h4&gt;
&lt;p&gt;To perform a bootstrap using sbt&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;first a build is published either locally or on a temporary repository,&lt;/li&gt;
&lt;li&gt;then a separate invocation of sbt (using the previously built version as &lt;code&gt;starr&lt;/code&gt;)
is used to build / publish the actual build.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Assume the current &lt;code&gt;starr&lt;/code&gt; version is &lt;code&gt;2.12.0&lt;/code&gt; (defined in
&lt;a href="versions.properties"&gt;versions.properties&lt;/a&gt;) and the current version is &lt;code&gt;2.12.0-SNAPSHOT&lt;/code&gt;
(defined in &lt;a href="build.sbt"&gt;build.sbt&lt;/a&gt;). To perform a local bootstrap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run &lt;code&gt;publishLocal&lt;/code&gt; (you may want to specify a custom version suffix and skip
generating API docs, see above).&lt;/li&gt;
&lt;li&gt;Quit sbt and start a new sbt instance using &lt;code&gt;sbt -Dstarr.version=&amp;lt;version&amp;gt;&lt;/code&gt; where
&lt;code&gt;&amp;lt;version&amp;gt;&lt;/code&gt; is the version number you published locally.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-ide-setup" class="anchor" aria-hidden="true" href="#ide-setup"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;IDE setup&lt;/h3&gt;
&lt;p&gt;We suggest using IntelliJ IDEA (see
&lt;a href="src/intellij/README.md"&gt;src/intellij/README.md&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(&lt;a href="https://scalameta.org/metals/" rel="nofollow"&gt;Metals&lt;/a&gt; should also work, but we don't yet have instructions or sample
configuration for that. A pull request in this area would be
exceedingly welcome.)&lt;/p&gt;
&lt;p&gt;In order to use IntelliJ's incremental compiler:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run &lt;code&gt;dist/mkBin&lt;/code&gt; in sbt to get a build and the runner scripts in &lt;code&gt;build/quick/bin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;run "Build" - "Make Project" in IntelliJ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now you can edit and build in IntelliJ and use the scripts (compiler, REPL) to
directly test your changes. You can also run the &lt;code&gt;scala&lt;/code&gt;, &lt;code&gt;scalac&lt;/code&gt; and &lt;code&gt;partest&lt;/code&gt;
commands in sbt. Enable "Ant mode" (explained above) to prevent sbt's incremental
compiler from re-compiling (too many) files before each &lt;code&gt;partest&lt;/code&gt; invocation.&lt;/p&gt;
&lt;h1&gt;&lt;a id="user-content-coding-guidelines" class="anchor" aria-hidden="true" href="#coding-guidelines"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Coding guidelines&lt;/h1&gt;
&lt;p&gt;Our guidelines for contributing are explained in &lt;a href="CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.
It contains useful information on our coding standards, testing, documentation, how
we use git and GitHub and how to get your code reviewed.&lt;/p&gt;
&lt;p&gt;You may also want to check out the following resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href="http://scala-lang.org/contribute/hacker-guide.html" rel="nofollow"&gt;"Scala Hacker Guide"&lt;/a&gt;
covers some of the same ground as this README, but in greater detail and in a more
tutorial style, using a running example.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.scala-lang.org" rel="nofollow"&gt;Scala documentation site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a id="user-content-scala-ci" class="anchor" aria-hidden="true" href="#scala-ci"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scala CI&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/scala/scala" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/cc24c7c2bc2170823717876bfcb701d550e6754b/68747470733a2f2f7472617669732d63692e6f72672f7363616c612f7363616c612e7376673f6272616e63683d322e31332e78" alt="Build Status" data-canonical-src="https://travis-ci.org/scala/scala.svg?branch=2.13.x" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once you submit a PR your commits will be automatically tested by the Scala CI.&lt;/p&gt;
&lt;p&gt;If you see a spurious build failure, you can post &lt;code&gt;/rebuild&lt;/code&gt; as a PR comment.
The &lt;a href="https://github.com/scala/scabot"&gt;scabot README&lt;/a&gt; lists all available commands.&lt;/p&gt;
&lt;p&gt;If you'd like to test your patch before having everything polished for review,
feel free to submit a PR and add the &lt;code&gt;WIP&lt;/code&gt; label. In case your WIP branch contains
a large number of commits (that you didn't clean up / squash yet for review),
consider adding &lt;code&gt;[ci: last-only]&lt;/code&gt; to the PR title. That way only the last commit
will be tested, saving some energy and CI-resources. Note that inactive WIP PRs
will be closed eventually, which does not mean the change is being rejected.&lt;/p&gt;
&lt;p&gt;CI performs a full bootstrap. The first task, &lt;code&gt;validate-publish-core&lt;/code&gt;, publishes
a build of your commit to the temporary repository
&lt;a href="https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots" rel="nofollow"&gt;https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots&lt;/a&gt;.
Note that this build is not yet bootstrapped, its bytecode is built using the
current &lt;code&gt;starr&lt;/code&gt;. The version number is &lt;code&gt;2.12.2-bin-abcd123-SNAPSHOT&lt;/code&gt; where &lt;code&gt;abcd123&lt;/code&gt;
is the commit hash. For binary incompatible builds, the version number is
&lt;code&gt;2.13.0-pre-abcd123-SNAPSHOT&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can use Scala builds in the validation repository locally by adding a resolver
and specifying the corresponding &lt;code&gt;scalaVersion&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sbt
&amp;gt; set resolvers += "pr" at "https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots/"
&amp;gt; set scalaVersion := "2.12.2-bin-abcd123-SNAPSHOT"
&amp;gt; console
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a id="user-content-nightly-builds" class="anchor" aria-hidden="true" href="#nightly-builds"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Nightly builds&lt;/h2&gt;
&lt;p&gt;The Scala CI builds nightly download releases and publishes
them to the following locations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.scala-lang.org/files/archive/nightly/2.12.x/?C=M;O=D" rel="nofollow"&gt;2.12.x&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.scala-lang.org/files/archive/nightly/2.13.x/?C=M;O=D" rel="nofollow"&gt;2.13.x&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The CI also publishes nightly API docs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.scala-lang.org/files/archive/nightly/2.12.x/api/?C=M;O=D" rel="nofollow"&gt;2.12.x&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.scala-lang.org/files/archive/nightly/2.12.x/api/2.12.x/" rel="nofollow"&gt;symlink to the latest&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.scala-lang.org/files/archive/nightly/2.13.x/api/?C=M;O=D" rel="nofollow"&gt;2.13.x&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.scala-lang.org/files/archive/nightly/2.13.x/api/2.13.x/" rel="nofollow"&gt;symlink to the latest&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using a nightly build in sbt is explained in
&lt;a href="http://stackoverflow.com/questions/40622878" rel="nofollow"&gt;this Stack Overflow answer&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-scala-ci-internals" class="anchor" aria-hidden="true" href="#scala-ci-internals"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scala CI internals&lt;/h2&gt;
&lt;p&gt;The Scala CI runs as a Jenkins instance on &lt;a href="https://scala-ci.typesafe.com/" rel="nofollow"&gt;scala-ci.typesafe.com&lt;/a&gt;,
configured by a chef cookbook at &lt;a href="https://github.com/scala/scala-jenkins-infra"&gt;scala/scala-jenkins-infra&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The build bot that watches PRs, triggers testing builds and applies the "reviewed" label
after an LGTM comment is in the &lt;a href="https://github.com/scala/scabot"&gt;scala/scabot&lt;/a&gt; repo.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-community-build" class="anchor" aria-hidden="true" href="#community-build"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Community build&lt;/h2&gt;
&lt;p&gt;The Scala community build is an important method for testing Scala
releases. A community build can be launched for any Scala commit, even
before the commit's PR has been merged. That commit is then used to
build a large number of open-source projects from source and run their
test suites.&lt;/p&gt;
&lt;p&gt;To request a community build run on your PR, just ask in a comment on
the PR and a Scala team member (probably @SethTisue) will take care of
it. (&lt;a href="https://github.com/scala/community-builds/wiki#can-i-run-it-against-a-pull-request-in-scalascala"&gt;details&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Community builds run on the Scala Jenkins instance.  The jobs are
named &lt;code&gt;..-integrate-community-build&lt;/code&gt;. See the
&lt;a href="https://github.com/scala/community-builds"&gt;scala/community-builds&lt;/a&gt;
repo.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>scala</author><guid isPermaLink="false">https://github.com/scala/scala</guid><pubDate>Tue, 21 Jan 2020 00:20:00 GMT</pubDate></item><item><title>scalaz/scalaz #21 in Scala, Today</title><link>https://github.com/scalaz/scalaz</link><description>&lt;p&gt;&lt;i&gt;Principled Functional Programming in Scala&lt;/i&gt;&lt;/p&gt;&lt;div id="readme" class="md" data-path="README.md"&gt;&lt;article class="markdown-body entry-content p-5" itemprop="text"&gt;&lt;h1&gt;&lt;a id="user-content-scalaz" class="anchor" aria-hidden="true" href="#scalaz"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Scalaz&lt;/h1&gt;
&lt;p&gt;Scalaz is a Scala library for functional programming.&lt;/p&gt;
&lt;p&gt;It provides purely functional data structures to complement those from the Scala standard library.
It defines a set of foundational type classes (e.g. &lt;code&gt;Functor&lt;/code&gt;, &lt;code&gt;Monad&lt;/code&gt;) and corresponding instances for
a large number of data structures.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/scalaz/scalaz" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/e147337d171c28ae435c4ea8b626660442b8a934/68747470733a2f2f7365637572652e7472617669732d63692e6f72672f7363616c617a2f7363616c617a2e706e673f6272616e63683d7365726965732f372e332e78" alt="Build Status" data-canonical-src="https://secure.travis-ci.org/scalaz/scalaz.png?branch=series/7.3.x" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/11cbf2e80af31ece15f2f8f41264eec4173994ec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230667265656e6f64652d627269676874677265656e2e737667"&gt;&lt;img src="https://camo.githubusercontent.com/11cbf2e80af31ece15f2f8f41264eec4173994ec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230667265656e6f64652d627269676874677265656e2e737667" alt="IRC" data-canonical-src="https://img.shields.io/badge/chat-on%20freenode-brightgreen.svg" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://gitter.im/scalaz/scalaz" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/d95e6ae7648f673207a5287afbe8e0a7fcebed61/687474703a2f2f6261646765732e6769747465722e696d2f7363616c617a2f7363616c617a2e706e67" alt="Gitter" data-canonical-src="http://badges.gitter.im/scalaz/scalaz.png" style="max-width:100%;"&gt;&lt;/a&gt;
&lt;a href="https://discord.gg/cVHGnke" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/70fde840843ab7d25c331d7f3d50d576e51fbaec/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3435353136343434313835323634313238322e7376673f6c6162656c3d446973636f7264" alt="Discord" data-canonical-src="https://img.shields.io/discord/455164441852641282.svg?label=Discord" style="max-width:100%;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-getting-scalaz" class="anchor" aria-hidden="true" href="#getting-scalaz"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Getting Scalaz&lt;/h2&gt;
&lt;p&gt;The current stable version is 7.2.29, which is cross-built against Scala 2.10.x, 2.11.x, 2.12.x, 2.13.x and Scala.js.&lt;/p&gt;
&lt;p&gt;If you're using SBT, add the following line to your build file:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;libraryDependencies &lt;span class="pl-k"&gt;+&lt;/span&gt;&lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;org.scalaz&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;scalaz-core&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-k"&gt;%&lt;/span&gt; &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;7.2.29&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For Maven and other build tools, you can visit &lt;a href="https://search.maven.org/search?q=g:org.scalaz%20AND%20v:7.2.29" rel="nofollow"&gt;search.maven.org&lt;/a&gt;.
(This search will also list all available modules of scalaz.)&lt;/p&gt;
&lt;p&gt;To get sample configurations, click on the version of the module you are interested in.
You can also find direct download links at the bottom of that page. Choose the file ending in &lt;code&gt;7.2.29.jar&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-quick-start" class="anchor" aria-hidden="true" href="#quick-start"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;std&lt;/span&gt;.&lt;span class="pl-en"&gt;option&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;, &lt;span class="pl-en"&gt;std&lt;/span&gt;.&lt;span class="pl-en"&gt;list&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt; &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; functions and type class instances for Option and List&lt;/span&gt;

scala&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Apply&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;].apply2(some(&lt;span class="pl-c1"&gt;1&lt;/span&gt;), some(&lt;span class="pl-c1"&gt;2&lt;/span&gt;))((a, b) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; a &lt;span class="pl-k"&gt;+&lt;/span&gt; b)
res0&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-c1"&gt;3&lt;/span&gt;)

scala&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Traverse&lt;/span&gt;[&lt;span class="pl-en"&gt;List&lt;/span&gt;].traverse(&lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))(i &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; some(i))
res1&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;List&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;]] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Use of the &lt;code&gt;Ops&lt;/code&gt; classes, defined under &lt;code&gt;scalaz.syntax&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;std&lt;/span&gt;.&lt;span class="pl-en"&gt;list&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt; &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; type class instances for List&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;syntax&lt;/span&gt;.&lt;span class="pl-en"&gt;bind&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt; &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; syntax for the Bind type class (and its parents)&lt;/span&gt;

scala&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;)).join
res0&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;List&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;)

scala&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;true&lt;/span&gt;, &lt;span class="pl-c1"&gt;false&lt;/span&gt;).ifM(&lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;0&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;), &lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;))
res1&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;List&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-c1"&gt;0&lt;/span&gt;, &lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We've gone to great lengths to give you an &lt;em&gt;a-la-carte&lt;/em&gt; importing experience, but if you prefer an all-you-can-eat
buffet, you're in luck:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;Scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;

scala&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;NonEmptyList&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;).cojoin
res0&lt;span class="pl-k"&gt;:&lt;/span&gt; scalaz.&lt;span class="pl-en"&gt;NonEmptyList&lt;/span&gt;[scalaz.&lt;span class="pl-en"&gt;NonEmptyList&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;]] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;NonEmptyList&lt;/span&gt;(&lt;span class="pl-en"&gt;NonEmptyList&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;, &lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-en"&gt;NonEmptyList&lt;/span&gt;(&lt;span class="pl-c1"&gt;2&lt;/span&gt;, &lt;span class="pl-c1"&gt;3&lt;/span&gt;), &lt;span class="pl-en"&gt;NonEmptyList&lt;/span&gt;(&lt;span class="pl-c1"&gt;3&lt;/span&gt;))

scala&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-c1"&gt;1&lt;/span&gt;.node(&lt;span class="pl-c1"&gt;2&lt;/span&gt;.leaf, &lt;span class="pl-c1"&gt;3&lt;/span&gt;.node(&lt;span class="pl-c1"&gt;4&lt;/span&gt;.leaf))
res1&lt;span class="pl-k"&gt;:&lt;/span&gt; scalaz.&lt;span class="pl-en"&gt;Tree&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &amp;lt;&lt;span class="pl-ent"&gt;tree&lt;/span&gt;&amp;gt;

scala&lt;span class="pl-k"&gt;&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;List&lt;/span&gt;(some(&lt;span class="pl-c1"&gt;1&lt;/span&gt;), none).suml
res2&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-resources" class="anchor" aria-hidden="true" href="#resources"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Resources&lt;/h2&gt;
&lt;p&gt;Let the types speak for themselves via the &lt;a href="https://scalaz.github.io/scalaz/#scaladoc" rel="nofollow"&gt;Scalaz Scaladocs&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/scalaz/scalaz/tree/series/7.3.x/example/src/main/scala/scalaz/example"&gt;examples module&lt;/a&gt; contains some snippets of Scalaz usage.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/scalaz/scalaz/wiki"&gt;wiki&lt;/a&gt; contains release and migration information.&lt;/p&gt;
&lt;p&gt;Talk with us by joining &lt;a href="https://webchat.freenode.net/?channels=%23scalaz&amp;amp;uio=d4" rel="nofollow"&gt;IRC: irc.freenode.net channel #scalaz&lt;/a&gt;, or join &lt;a href="https://groups.google.com/group/scalaz" rel="nofollow"&gt;the Scalaz mailing list on Google Groups&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://typelevel.org/blog/" rel="nofollow"&gt;typelevel blog&lt;/a&gt; has some great posts such as &lt;a href="https://typelevel.org/blog/2013/10/13/towards-scalaz-1.html" rel="nofollow"&gt;Towards Scalaz&lt;/a&gt; by &lt;a href="https://twitter.com/adelbertchang" rel="nofollow"&gt;Adelbert Chang&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://eed3si9n.com/learning-scalaz/index.html" rel="nofollow"&gt;Learning Scalaz&lt;/a&gt; is a great series of blog posts by &lt;a href="https://twitter.com/eed3si9n" rel="nofollow"&gt;Eugene Yokota&lt;/a&gt;. Thanks, Eugene!&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-changes-in-version-7" class="anchor" aria-hidden="true" href="#changes-in-version-7"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Changes in Version 7&lt;/h2&gt;
&lt;p&gt;Scalaz 7 represents a major reorganization of the library. We have taken a fresh look
at the challenges of encoding type classes in Scala, in particular at when and how to
employ the implicit scope.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-at-a-glance" class="anchor" aria-hidden="true" href="#at-a-glance"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;At a glance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;scalaz.{effect, iteratee}&lt;/code&gt; split to separate sub-projects; &lt;code&gt;scalaz.{http, geo}&lt;/code&gt; dropped.&lt;/li&gt;
&lt;li&gt;Refined and expanded the type class hierarchy.&lt;/li&gt;
&lt;li&gt;Type class instances are no longer defined in the companion objects of the type class.
Instances for standard library types are defined under &lt;code&gt;scalaz.std&lt;/code&gt;, and instances for
Scalaz data types are defined in the companion object for those types. An instance definition
can provide multiple type classes in a single place, which was not always possible in Scalaz 6.&lt;/li&gt;
&lt;li&gt;Type class instances have been organized to avoid ambiguity, a problem that arises when
instances are dependent on other instances (for example, &lt;code&gt;Monoid[(A, B)]&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Use of implicit views to provide access to Scalaz functionality as extension methods
has been segregated to &lt;code&gt;scalaz.syntax&lt;/code&gt;, and can be imported selectively, and need not
be used at all.&lt;/li&gt;
&lt;li&gt;Related functions are defined in the type class trait, to support standalone
usage of the type class. In Scalaz 6, these were defined in &lt;code&gt;Identity&lt;/code&gt;, &lt;code&gt;MA&lt;/code&gt;, or &lt;code&gt;MAB&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;New data structures have been added, and existing ones generalized. A number of monad
transformers have been provided, in some cases generalizing old data structures.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-modularity" class="anchor" aria-hidden="true" href="#modularity"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Modularity&lt;/h3&gt;
&lt;p&gt;Scalaz has been modularised.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;scalaz-core&lt;/strong&gt;: Type class hierarchy, data structures, type class instances for the Scala and Java standard libraries,
implicit conversions / syntax to access these.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;scalaz-effect&lt;/strong&gt;: Data structures to represent and compose IO effects in the type system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;scalaz-iteratee&lt;/strong&gt;: Experimental new Iteratee implementation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-type-class-hierarchy" class="anchor" aria-hidden="true" href="#type-class-hierarchy"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Type Class Hierarchy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Type classes form an inheritance hierarchy, as in Scalaz 6. This is convenient both at the call site and at the
type class instance definition. At the call site, it ensures that you can call a method requiring a more general
type class with an instance of a more specific type class:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;bar&lt;/span&gt;[&lt;span class="pl-en"&gt;M&lt;/span&gt;[_]&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Functor&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; ()

&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;foo&lt;/span&gt;[&lt;span class="pl-en"&gt;M&lt;/span&gt;[_]&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Monad&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; bar[&lt;span class="pl-en"&gt;M&lt;/span&gt;] &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Monad[M] is a subtype of Functor[M]&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;The hierarchy itself is largely the same as in Scalaz 6. However, there have been a few
adjustments, some method signatures have been adjusted to support better standalone usage, so code depending on these will
need to be re-worked.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a id="user-content-type-class-instance-definition" class="anchor" aria-hidden="true" href="#type-class-instance-definition"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Type Class Instance Definition&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Constructive&lt;/em&gt; implicits, which create a type class instance automatically based on instances of
all parent type classes, are removed. These led to subtle errors with ambiguous implicits, such as
this problem with &lt;a href="https://stackoverflow.com/questions/7447591/how-do-i-use-name-as-an-applicative/7448111#7448111" rel="nofollow"&gt;FunctorBindApply&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Type class instances are no longer declared in fragments in the companion objects of the type class. Instead, they
are defined in the package &lt;code&gt;scalaz.std&lt;/code&gt;, and must be imported. These instances are defined in traits which will be
mixed together into an object for importing &lt;em&gt;en-masse&lt;/em&gt;, if desired.&lt;/li&gt;
&lt;li&gt;A single implicit can define a number of type class instances for a type.&lt;/li&gt;
&lt;li&gt;A type class definition can override methods (including derived methods) for efficiency.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an instance definition for &lt;code&gt;Option&lt;/code&gt;. Notice that the method &lt;code&gt;map&lt;/code&gt; has been overridden.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;  &lt;span class="pl-k"&gt;implicit&lt;/span&gt; &lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;option&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;new&lt;/span&gt; &lt;span class="pl-en"&gt;Traverse&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;] &lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-e"&gt;MonadPlus&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;] {
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;point&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;](&lt;span class="pl-v"&gt;a&lt;/span&gt;: &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;A&lt;/span&gt;) &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(a)
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;bind&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;, &lt;span class="pl-en"&gt;B&lt;/span&gt;](&lt;span class="pl-v"&gt;fa&lt;/span&gt;: &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;])(&lt;span class="pl-v"&gt;f&lt;/span&gt;: &lt;span class="pl-en"&gt;A&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;B&lt;/span&gt;])&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;B&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; fa flatMap f
    &lt;span class="pl-k"&gt;override&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;map&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;, &lt;span class="pl-en"&gt;B&lt;/span&gt;](&lt;span class="pl-v"&gt;fa&lt;/span&gt;: &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;])(&lt;span class="pl-v"&gt;f&lt;/span&gt;: &lt;span class="pl-en"&gt;A&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;B&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;B&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; fa map f
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;traverseImpl&lt;/span&gt;[&lt;span class="pl-en"&gt;F&lt;/span&gt;[_], &lt;span class="pl-en"&gt;A&lt;/span&gt;, &lt;span class="pl-en"&gt;B&lt;/span&gt;](&lt;span class="pl-v"&gt;fa&lt;/span&gt;: &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;])(&lt;span class="pl-v"&gt;f&lt;/span&gt;: &lt;span class="pl-en"&gt;A&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;F&lt;/span&gt;[&lt;span class="pl-en"&gt;B&lt;/span&gt;])(&lt;span class="pl-k"&gt;implicit&lt;/span&gt; &lt;span class="pl-en"&gt;F&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Applicative&lt;/span&gt;[&lt;span class="pl-en"&gt;F&lt;/span&gt;]) &lt;span class="pl-k"&gt;=&lt;/span&gt;
      fa map (a &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;F&lt;/span&gt;.map(f(a))(&lt;span class="pl-en"&gt;Some&lt;/span&gt;(_)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;B&lt;/span&gt;])) getOrElse &lt;span class="pl-en"&gt;F&lt;/span&gt;.point(&lt;span class="pl-en"&gt;None&lt;/span&gt;)
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;empty&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;]&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;None&lt;/span&gt;
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;plus&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;](&lt;span class="pl-v"&gt;a&lt;/span&gt;: &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;], &lt;span class="pl-v"&gt;b&lt;/span&gt;: &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;]) &lt;span class="pl-k"&gt;=&lt;/span&gt; a orElse b
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;foldR&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;, &lt;span class="pl-en"&gt;B&lt;/span&gt;](&lt;span class="pl-v"&gt;fa&lt;/span&gt;: &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;], &lt;span class="pl-v"&gt;z&lt;/span&gt;: &lt;span class="pl-en"&gt;B&lt;/span&gt;)(&lt;span class="pl-v"&gt;f&lt;/span&gt;: (&lt;span class="pl-en"&gt;A&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; (&lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;B&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;B&lt;/span&gt;)&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;B&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; fa &lt;span class="pl-k"&gt;match&lt;/span&gt; {
      &lt;span class="pl-k"&gt;case&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(a) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; f(a)(z)
      &lt;span class="pl-k"&gt;case&lt;/span&gt; &lt;span class="pl-en"&gt;None&lt;/span&gt; &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; z
    }
  }&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To use this, one would:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;std&lt;/span&gt;.&lt;span class="pl-en"&gt;option&lt;/span&gt;.&lt;span class="pl-en"&gt;optionInstance&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; or, importing all instances en-masse&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; import scalaz.Scalaz._&lt;/span&gt;

&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-c1"&gt;M&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Monad&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;]
&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;oi&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;M&lt;/span&gt;.point(&lt;span class="pl-c1"&gt;0&lt;/span&gt;)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-syntax" class="anchor" aria-hidden="true" href="#syntax"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Syntax&lt;/h3&gt;
&lt;p&gt;We co-opt the term &lt;em&gt;syntax&lt;/em&gt; to refer to the way we allow the functionality of Scalaz to be
called in the &lt;code&gt;object.method(args)&lt;/code&gt; form, which can be easier to read, and, given that type inference
in Scala flows from left-to-right, can require fewer type annotations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No more &lt;code&gt;Identity&lt;/code&gt;, &lt;code&gt;MA&lt;/code&gt;, or &lt;code&gt;MAB&lt;/code&gt; from Scalaz 6.&lt;/li&gt;
&lt;li&gt;Syntax is segregated from rest of the library, in a sub-package &lt;code&gt;scalaz.syntax&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;All Scalaz functionality is available &lt;em&gt;without&lt;/em&gt; using the provided syntax, by directly calling methods
on the type class or its companion object.&lt;/li&gt;
&lt;li&gt;Syntax is available &lt;em&gt;a-la-carte&lt;/em&gt;. You can import the syntax for working with particular
type classes where you need it. This avoids flooding the autocompletion in your IDE with
every possible extension method. This should also help compiler performance,
by reducing the implicit search space.&lt;/li&gt;
&lt;li&gt;Syntax is layered in the same way as type classes. Importing the syntax for, say, &lt;code&gt;Applicative&lt;/code&gt;
will also provide the syntax for &lt;code&gt;Apply&lt;/code&gt; and &lt;code&gt;Functor&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Syntax can be imported in two ways. Firstly, the syntax specialized for a particular instance
of a type class can be imported directly from the instance itself.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; import the type class instance&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;std&lt;/span&gt;.&lt;span class="pl-en"&gt;option&lt;/span&gt;.&lt;span class="pl-en"&gt;optionInstance&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; import the implicit conversions to `MonadOps[Option, A]`, `BindOps[Option, A]`, ...&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;optionInstance&lt;/span&gt;.&lt;span class="pl-en"&gt;monadSyntax&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;

&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;oi&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;]] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Expands to: `ToBindOps(io).join`&lt;/span&gt;
oi.join&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively, the syntax can be imported for a particular type class.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; import the type class instance&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;std&lt;/span&gt;.&lt;span class="pl-en"&gt;option&lt;/span&gt;.&lt;span class="pl-en"&gt;optionInstance&lt;/span&gt;

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; import the implicit conversions to `MonadOps[F, A]`, `BindOps[F, A]`, ...&lt;/span&gt;
&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-en"&gt;scalaz&lt;/span&gt;.&lt;span class="pl-en"&gt;syntax&lt;/span&gt;.&lt;span class="pl-en"&gt;monad&lt;/span&gt;.&lt;span class="pl-en"&gt;_&lt;/span&gt;

&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;oi&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;Int&lt;/span&gt;]] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;))

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Expands to: ToBindOps(io).join&lt;/span&gt;
oi.join&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For some degree of backwards compatibility with Scalaz 6, the über-import of &lt;code&gt;import scalaz.Scalaz._&lt;/code&gt;
will import &lt;em&gt;all&lt;/em&gt; implicit conversions that provide syntax (as well as type class instances and other
functions). However, we recommend to review usage of this and replace with more focussed imports.&lt;/p&gt;
&lt;h3&gt;&lt;a id="user-content-standalone-type-class-usage" class="anchor" aria-hidden="true" href="#standalone-type-class-usage"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Standalone Type Class Usage&lt;/h3&gt;
&lt;p&gt;Type classes should be directly usable, without first needing to trigger implicit conversions. This might be
desirable to reduce the runtime or cognitive overhead of the pimped types, or to define your own pimped
types with a syntax of your choosing.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The methods in type classes have been curried to maximize type inference.&lt;/li&gt;
&lt;li&gt;Derived methods, based on the abstract methods in a type class, are defined in the type class itself.&lt;/li&gt;
&lt;li&gt;Each type class companion object is fitted with a convenient &lt;code&gt;apply&lt;/code&gt; method to obtain an instance of the type class.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Equivalent to `implicitly[Monad[Option]]`&lt;/span&gt;
    &lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-c1"&gt;O&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;Monad&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;]

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; `bind` is defined with two parameter sections, so that the type of `x` is inferred as `Int`.&lt;/span&gt;
    &lt;span class="pl-en"&gt;O&lt;/span&gt;.bind(&lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;))(x &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(x &lt;span class="pl-k"&gt;*&lt;/span&gt; &lt;span class="pl-c1"&gt;2&lt;/span&gt;))

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;plus&lt;/span&gt;(&lt;span class="pl-v"&gt;a&lt;/span&gt;: &lt;span class="pl-en"&gt;Int&lt;/span&gt;, &lt;span class="pl-v"&gt;b&lt;/span&gt;: &lt;span class="pl-en"&gt;Int&lt;/span&gt;) &lt;span class="pl-k"&gt;=&lt;/span&gt; a &lt;span class="pl-k"&gt;+&lt;/span&gt; b

    &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; `Apply#lift2` is a function derived from `Apply#ap`.&lt;/span&gt;
    &lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;plusOpt&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;O&lt;/span&gt;.lift2(plus)&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-type-class-instance-dependencies" class="anchor" aria-hidden="true" href="#type-class-instance-dependencies"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Type Class Instance Dependencies&lt;/h3&gt;
&lt;p&gt;Type class instances may depend on other instances. In simple cases, this is as straightforward as adding an implicit
parameter (or, equivalently, a context bound), to the implicit method.&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;  &lt;span class="pl-k"&gt;implicit&lt;/span&gt; &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;optionMonoid&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Semigroup&lt;/span&gt;]&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Monoid&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;]] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-k"&gt;new&lt;/span&gt; &lt;span class="pl-en"&gt;Monoid&lt;/span&gt;[&lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;]] {
    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;append&lt;/span&gt;(&lt;span class="pl-v"&gt;f1&lt;/span&gt;: &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;], &lt;span class="pl-v"&gt;f2&lt;/span&gt;: &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;])&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; (f1, f2) &lt;span class="pl-k"&gt;match&lt;/span&gt; {
      &lt;span class="pl-k"&gt;case&lt;/span&gt; (&lt;span class="pl-en"&gt;Some&lt;/span&gt;(a1), &lt;span class="pl-en"&gt;Some&lt;/span&gt;(a2)) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-en"&gt;Semigroup&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;].append(a1, a2))
      &lt;span class="pl-k"&gt;case&lt;/span&gt; (&lt;span class="pl-en"&gt;Some&lt;/span&gt;(a1), &lt;span class="pl-en"&gt;None&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; f1
      &lt;span class="pl-k"&gt;case&lt;/span&gt; (&lt;span class="pl-en"&gt;None&lt;/span&gt;, &lt;span class="pl-en"&gt;Some&lt;/span&gt;(a2)) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; f2
      &lt;span class="pl-k"&gt;case&lt;/span&gt; (&lt;span class="pl-en"&gt;None&lt;/span&gt;, &lt;span class="pl-en"&gt;None&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="pl-en"&gt;None&lt;/span&gt;
    }

    &lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;zero&lt;/span&gt;&lt;span class="pl-k"&gt;:&lt;/span&gt; &lt;span class="pl-en"&gt;Option&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;None&lt;/span&gt;
  }&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Type class instances for 'transformers', such as &lt;code&gt;OptionT&lt;/code&gt;, present a more subtle challenge. &lt;code&gt;OptionT[F, A]&lt;/code&gt;
is a wrapper for a value of type &lt;code&gt;F[Option[A]]&lt;/code&gt;. It allows us to write:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;val&lt;/span&gt; &lt;span class="pl-smi"&gt;ot&lt;/span&gt; &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;OptionT&lt;/span&gt;(&lt;span class="pl-en"&gt;List&lt;/span&gt;(&lt;span class="pl-en"&gt;Some&lt;/span&gt;(&lt;span class="pl-c1"&gt;1&lt;/span&gt;), &lt;span class="pl-en"&gt;None&lt;/span&gt;))
ot.map((&lt;span class="pl-v"&gt;a&lt;/span&gt;: &lt;span class="pl-en"&gt;Int&lt;/span&gt;) &lt;span class="pl-k"&gt;=&amp;gt;&lt;/span&gt; a &lt;span class="pl-k"&gt;*&lt;/span&gt; &lt;span class="pl-c1"&gt;2&lt;/span&gt;) &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; OptionT(List(Some(2), None))&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The method &lt;code&gt;OptionT#map&lt;/code&gt; requires an implicit parameter of type &lt;code&gt;Functor[F]&lt;/code&gt;, whereas &lt;code&gt;OptionT#flatMap&lt;/code&gt;
requires one of type &lt;code&gt;Monad[F]&lt;/code&gt;. The capabilities of &lt;code&gt;OptionT&lt;/code&gt; increase with those of &lt;code&gt;F&lt;/code&gt;. We need to encode
this into the type class instances for &lt;code&gt;[a]OptionT[F[A]]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This is done with a hierarchy of &lt;a href="https://github.com/scalaz/scalaz/blob/v7.1.2/core/src/main/scala/scalaz/OptionT.scala#L122"&gt;type class implementation traits&lt;/a&gt;
and a corresponding set of &lt;a href="https://github.com/scalaz/scalaz/blob/v7.1.2/core/src/main/scala/scalaz/OptionT.scala#L24"&gt;prioritized implicit methods&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In case of ambiguous implicits, Scala will favour one defined in a sub-class of the other. This is to avoid ambiguity
when in cases like the following:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-en"&gt;OptionTList&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;OptionT&lt;/span&gt;[&lt;span class="pl-en"&gt;List&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;]]
implicitly[&lt;span class="pl-en"&gt;Functor&lt;/span&gt;[&lt;span class="pl-en"&gt;OptionTList&lt;/span&gt;]]

&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; Candidates:&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; 1. OptionT.OptionTFunctor[List](implicitly[Functor[List]])&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; 2. OptionT.OptionTMonad[List](implicitly[Functor[List]])&lt;/span&gt;
&lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;//&lt;/span&gt; #2 is defined in a subclass of the enclosing class of #1, so #2 is preferred.&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a id="user-content-transformers-and-identity" class="anchor" aria-hidden="true" href="#transformers-and-identity"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transformers and Identity&lt;/h3&gt;
&lt;p&gt;A stronger emphasis has been placed on transformer data structures (aka Monad Transformers). For example &lt;code&gt;State&lt;/code&gt; is now
a type alias for &lt;code&gt;StateT[Id, A, B]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Id&lt;/code&gt; is defined in the &lt;code&gt;scalaz&lt;/code&gt; package object as:&lt;/p&gt;
&lt;div class="highlight highlight-source-scala"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;type&lt;/span&gt; &lt;span class="pl-en"&gt;Id&lt;/span&gt;[&lt;span class="pl-en"&gt;A&lt;/span&gt;] &lt;span class="pl-k"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;A&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Contributing&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/scalaz/scalaz/blob/series/7.3.x/CONTRIBUTING.md"&gt;Documentation for contributors&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a id="user-content-credits" class="anchor" aria-hidden="true" href="#credits"&gt;&lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Credits&lt;/h2&gt;
&lt;p&gt;Support for Scalaz development is provided by &lt;a href="https://www.jetbrains.com/idea/" rel="nofollow"&gt;Jetbrains&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thanks to Mark Harrah and the sbt contributors for providing &lt;a href="https://www.scala-sbt.org" rel="nofollow"&gt;our build tool&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;</description><author>scalaz</author><guid isPermaLink="false">https://github.com/scalaz/scalaz</guid><pubDate>Tue, 21 Jan 2020 00:21:00 GMT</pubDate></item></channel></rss>